Query 1: 
{
  "search": "Azure"
}

Response 1:
{
  "@odata.context": "https://training-catalog-jms.search.windows.net/indexes('azuretable-index')/$metadata#docs(*)",
  "@search.nextPageParameters": {
    "search": "Azure",
    "skip": 50
  },
  "value": [
    {
      "@search.score": 3.9113765,
      "RowKey": "1769801f-ea93-456d-afe4-06dc019e8f71",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "solution-architect",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.9113765,
      "RowKey": "56bc8c78-fa2b-4b59-9daa-ba89721ce27c",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "administrator",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.9113765,
      "RowKey": "76dcb4e7-6c94-4ed5-93e8-8ec05ce9b86b",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.9113765,
      "RowKey": "89c14ed4-e008-400d-baac-0549e8299b57",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "devops-engineer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.8558946,
      "RowKey": "21933bf9-68d3-4649-b58a-79fbb476be02",
      "description": "Provision databases in Azure Pipelines",
      "duration": "62",
      "instructor": null,
      "rating_average": 0,
      "rating_count": 0,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Provision databases in Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.8558946,
      "RowKey": "360412d8-4f79-4219-acc3-6d5e2134d880",
      "description": "Provision databases in Azure Pipelines",
      "duration": "62",
      "instructor": null,
      "rating_average": 0,
      "rating_count": 0,
      "role": "devops-engineer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Provision databases in Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.8558946,
      "RowKey": "4c970879-187f-473c-83d5-986109db3183",
      "description": "Provision databases in Azure Pipelines",
      "duration": "62",
      "instructor": null,
      "rating_average": 0,
      "rating_count": 0,
      "role": "administrator",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Provision databases in Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.8558946,
      "RowKey": "c9f624d0-f2ec-49c8-bcb2-c89b79b051d2",
      "description": "Provision databases in Azure Pipelines",
      "duration": "62",
      "instructor": null,
      "rating_average": 0,
      "rating_count": 0,
      "role": "solution-architect",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Provision databases in Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.7414844,
      "RowKey": "3b2eceda-f984-4440-804d-c18cce4d3653",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "solution-architect",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "product": "azure-devops",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.7414844,
      "RowKey": "7682ab16-a067-41b8-9188-b8c4f433cec6",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "devops-engineer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "product": "azure-devops",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.7414844,
      "RowKey": "ae8e2557-daa0-4f90-bafd-d80ba94675c0",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "product": "azure-devops",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.7414844,
      "RowKey": "f05da97a-a2dd-4dcc-8018-c9826fb2b0dd",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "administrator",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "product": "azure-devops",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6869361,
      "RowKey": "db69aa91-d4da-48f9-a77c-5603bcae3596",
      "description": "Discover Azure portal and Azure DevOps tools that help you quickly and efficiently define and scale up load tests for apps.",
      "duration": "54",
      "instructor": null,
      "rating_average": 4.63,
      "rating_count": 147,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/load-test-web-app-azure-devops/?WT.mc_id=api_CatalogApi",
      "title": "Load test Azure web apps by using Azure DevOps",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6860027,
      "RowKey": "48efecbf-9b8c-47a5-aa46-deea3294ab25",
      "description": "Provision databases in Azure Pipelines",
      "duration": "62",
      "instructor": null,
      "rating_average": 0,
      "rating_count": 0,
      "role": "administrator",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Provision databases in Azure Pipelines",
      "product": "azure-devops",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6860027,
      "RowKey": "f394c98b-a99f-4225-aa77-152294025ebd",
      "description": "Provision databases in Azure Pipelines",
      "duration": "62",
      "instructor": null,
      "rating_average": 0,
      "rating_count": 0,
      "role": "solution-architect",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Provision databases in Azure Pipelines",
      "product": "azure-devops",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6860027,
      "RowKey": "f41794e0-2585-4036-9237-05f74b61d6b0",
      "description": "Provision databases in Azure Pipelines",
      "duration": "62",
      "instructor": null,
      "rating_average": 0,
      "rating_count": 0,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Provision databases in Azure Pipelines",
      "product": "azure-devops",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6860027,
      "RowKey": "f41e6014-6251-40f2-85c5-03baed68b755",
      "description": "Provision databases in Azure Pipelines",
      "duration": "62",
      "instructor": null,
      "rating_average": 0,
      "rating_count": 0,
      "role": "devops-engineer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Provision databases in Azure Pipelines",
      "product": "azure-devops",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6013048,
      "RowKey": "3f5306a1-2460-4628-9ada-8f0628b20bbd",
      "description": "Monitor models with Azure Machine Learning",
      "duration": "39",
      "instructor": null,
      "rating_average": 4.75,
      "rating_count": 504,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-models-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "title": "Monitor models with Azure Machine Learning",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6013048,
      "RowKey": "59c58efa-d830-4c65-8ac4-5432bb0ec73e",
      "description": "Introduction to the Azure Machine Learning SDK",
      "duration": "60",
      "instructor": null,
      "rating_average": 4.65,
      "rating_count": 2869,
      "role": "student",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/intro-to-azure-machine-learning-service/?WT.mc_id=api_CatalogApi",
      "title": "Introduction to the Azure Machine Learning SDK",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6013048,
      "RowKey": "5de4bb8a-9063-4a38-adb6-4d8f6f0c12b1",
      "description": "Work with Data in Azure Machine Learning",
      "duration": "45",
      "instructor": null,
      "rating_average": 4.66,
      "rating_count": 1119,
      "role": "student",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/work-with-data-in-aml/?WT.mc_id=api_CatalogApi",
      "title": "Work with Data in Azure Machine Learning",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6013048,
      "RowKey": "6456b6d8-0af1-4dfd-b895-37ecfb3df42b",
      "description": "Introduction to the Azure Machine Learning SDK",
      "duration": "60",
      "instructor": null,
      "rating_average": 4.65,
      "rating_count": 2869,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/intro-to-azure-machine-learning-service/?WT.mc_id=api_CatalogApi",
      "title": "Introduction to the Azure Machine Learning SDK",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6013048,
      "RowKey": "7dfc1bb4-abe2-4277-a732-162f1b38b412",
      "description": "Work with Compute in Azure Machine Learning",
      "duration": "45",
      "instructor": null,
      "rating_average": 4.68,
      "rating_count": 992,
      "role": "student",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/use-compute-contexts-in-aml/?WT.mc_id=api_CatalogApi",
      "title": "Work with Compute in Azure Machine Learning",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6013048,
      "RowKey": "81d1ec7d-958f-4e0f-9607-9ec1344b67ab",
      "description": "Work with Compute in Azure Machine Learning",
      "duration": "45",
      "instructor": null,
      "rating_average": 4.68,
      "rating_count": 992,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/use-compute-contexts-in-aml/?WT.mc_id=api_CatalogApi",
      "title": "Work with Compute in Azure Machine Learning",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6013048,
      "RowKey": "94a8abf2-6e37-40ed-8fed-6c23d50a7424",
      "description": "Monitor data drift with Azure Machine Learning",
      "duration": "42",
      "instructor": null,
      "rating_average": 4.8,
      "rating_count": 814,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-data-drift-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "title": "Monitor data drift with Azure Machine Learning",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6013048,
      "RowKey": "9e2bd51e-0f26-487b-b828-4bd6fd850743",
      "description": "Tune hyperparameters with Azure Machine Learning",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.76,
      "rating_count": 544,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/tune-hyperparameters-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "title": "Tune hyperparameters with Azure Machine Learning",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.6013048,
      "RowKey": "a274e897-5b2e-4ff3-aec9-2066e94d9a51",
      "description": "Work with Data in Azure Machine Learning",
      "duration": "45",
      "instructor": null,
      "rating_average": 4.66,
      "rating_count": 1119,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/work-with-data-in-aml/?WT.mc_id=api_CatalogApi",
      "title": "Work with Data in Azure Machine Learning",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.431413,
      "RowKey": "16681c04-f885-49d8-ab7e-e477936a6bdc",
      "description": "Tune hyperparameters with Azure Machine Learning",
      "duration": "46",
      "instructor": null,
      "rating_average": 4.76,
      "rating_count": 544,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/tune-hyperparameters-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "title": "Tune hyperparameters with Azure Machine Learning",
      "product": "azure-portal",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.431413,
      "RowKey": "181bbcf0-6713-4ee7-b858-3cf54674ed18",
      "description": "Monitor models with Azure Machine Learning",
      "duration": "39",
      "instructor": null,
      "rating_average": 4.75,
      "rating_count": 504,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-models-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "title": "Monitor models with Azure Machine Learning",
      "product": "azure-portal",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.431413,
      "RowKey": "a5ffe016-69df-4be9-be9a-76bdfc4092c2",
      "description": "Monitor data drift with Azure Machine Learning",
      "duration": "42",
      "instructor": null,
      "rating_average": 4.8,
      "rating_count": 814,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-data-drift-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "title": "Monitor data drift with Azure Machine Learning",
      "product": "azure-portal",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.431413,
      "RowKey": "d6417f73-e2e0-4eba-8996-bcda8666a60b",
      "description": "Implement CI/CD with Azure DevOps",
      "duration": "28",
      "instructor": null,
      "rating_average": 4.74,
      "rating_count": 141,
      "role": "data-engineer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/implement-ci-cd-azure-devops/?WT.mc_id=api_CatalogApi",
      "title": "Implement CI/CD with Azure DevOps",
      "product": "azure-databricks",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.374013,
      "RowKey": "1b484256-265d-4584-96f1-28819888c92f",
      "description": "Run configuration management tools in Azure Pipelines to help keep your infrastructure configured as you need.",
      "duration": "62",
      "instructor": null,
      "rating_average": 4.57,
      "rating_count": 464,
      "role": "solution-architect",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/configure-infrastructure-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Configure infrastructure in Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.374013,
      "RowKey": "3507b031-6c3c-4a37-87f1-791e775b70f6",
      "description": "Run configuration management tools in Azure Pipelines to help keep your infrastructure configured as you need.",
      "duration": "62",
      "instructor": null,
      "rating_average": 4.57,
      "rating_count": 464,
      "role": "devops-engineer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/configure-infrastructure-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Configure infrastructure in Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.374013,
      "RowKey": "8498078e-8004-4397-9753-9b1c8242ee2b",
      "description": "Run configuration management tools in Azure Pipelines to help keep your infrastructure configured as you need.",
      "duration": "62",
      "instructor": null,
      "rating_average": 4.57,
      "rating_count": 464,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/configure-infrastructure-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Configure infrastructure in Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.374013,
      "RowKey": "9fa7eae2-9879-4f9d-bfad-1a166d7b2bd1",
      "description": "Run configuration management tools in Azure Pipelines to help keep your infrastructure configured as you need.",
      "duration": "62",
      "instructor": null,
      "rating_average": 4.57,
      "rating_count": 464,
      "role": "administrator",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/configure-infrastructure-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "title": "Configure infrastructure in Azure Pipelines",
      "product": "azure",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "0479d887-32ce-477b-b184-9230e096562a",
      "description": "Get started with AI on Azure",
      "duration": "34",
      "instructor": null,
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "title": "Get started with AI on Azure",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "13f442b0-f1d1-4402-8c3e-13f0c8b6ce8d",
      "description": "Create an Azure Cognitive Search solution",
      "duration": "63",
      "instructor": null,
      "rating_average": 4.91,
      "rating_count": 45,
      "role": "ai-engineer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/create-azure-cognitive-search-solution/?WT.mc_id=api_CatalogApi",
      "title": "Create an Azure Cognitive Search solution",
      "product": "azure-cognitive-search",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "25b613a7-0afa-46dc-be9a-3b34c30a1d40",
      "description": "Get started with AI on Azure",
      "duration": "34",
      "instructor": null,
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "title": "Get started with AI on Azure",
      "product": "azure-bot-service",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "2b0ef195-b399-4e30-a61d-07b2bcf90857",
      "description": "Monitor data drift with Azure Machine Learning",
      "duration": "42",
      "instructor": null,
      "rating_average": 4.8,
      "rating_count": 814,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-data-drift-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "title": "Monitor data drift with Azure Machine Learning",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "2eb64953-5f7a-4985-8632-314014c8a8c2",
      "description": "Introduction to the Azure Machine Learning SDK",
      "duration": "60",
      "instructor": null,
      "rating_average": 4.65,
      "rating_count": 2869,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/intro-to-azure-machine-learning-service/?WT.mc_id=api_CatalogApi",
      "title": "Introduction to the Azure Machine Learning SDK",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "3e93d44c-8438-46e8-a157-15a2dfa6c6ca",
      "description": "Get started with AI on Azure",
      "duration": "34",
      "instructor": null,
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "student",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "title": "Get started with AI on Azure",
      "product": "azure-cognitive-services",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "4ffb7ba0-0771-4a01-9da7-915635fb6ba4",
      "description": "Monitor models with Azure Machine Learning",
      "duration": "39",
      "instructor": null,
      "rating_average": 4.75,
      "rating_count": 504,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-models-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "title": "Monitor models with Azure Machine Learning",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "64fe0253-71fd-4c27-b288-6e8cf819d02c",
      "description": "Get started with AI on Azure",
      "duration": "34",
      "instructor": null,
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "title": "Get started with AI on Azure",
      "product": "azure-cognitive-services",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "683814dd-934d-4e72-a5fd-81a3c8037999",
      "description": "Create an Azure Cognitive Search solution",
      "duration": "63",
      "instructor": null,
      "rating_average": 4.91,
      "rating_count": 45,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/create-azure-cognitive-search-solution/?WT.mc_id=api_CatalogApi",
      "title": "Create an Azure Cognitive Search solution",
      "product": "azure-cognitive-search",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "6b32e048-d4a8-426c-abf7-956369670549",
      "description": "Work with Compute in Azure Machine Learning",
      "duration": "45",
      "instructor": null,
      "rating_average": 4.68,
      "rating_count": 992,
      "role": "data-scientist",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/use-compute-contexts-in-aml/?WT.mc_id=api_CatalogApi",
      "title": "Work with Compute in Azure Machine Learning",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "7a84294d-d64c-4fa9-afb8-6f99822c848e",
      "description": "Get started with AI on Azure",
      "duration": "34",
      "instructor": null,
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "developer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "title": "Get started with AI on Azure",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "7be24452-07d1-4acc-99b3-89b901049505",
      "description": "Get started with AI on Azure",
      "duration": "34",
      "instructor": null,
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "ai-engineer",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "title": "Get started with AI on Azure",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "843d6d18-cb80-417e-932e-206e15c80b57",
      "description": "Get started with AI on Azure",
      "duration": "34",
      "instructor": null,
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "student",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "title": "Get started with AI on Azure",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "88c9641b-7fc9-4791-9798-fc047ba013a5",
      "description": "Get started with AI on Azure",
      "duration": "34",
      "instructor": null,
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "student",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "title": "Get started with AI on Azure",
      "product": "azure-bot-service",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "a5b5e7fc-04c9-44a6-8f6d-2ffe764516c9",
      "description": "Work with Data in Azure Machine Learning",
      "duration": "45",
      "instructor": null,
      "rating_average": 4.66,
      "rating_count": 1119,
      "role": "student",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/work-with-data-in-aml/?WT.mc_id=api_CatalogApi",
      "title": "Work with Data in Azure Machine Learning",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    },
    {
      "@search.score": 3.3480043,
      "RowKey": "a7182168-4625-4f3f-8348-bd0ddc542f63",
      "description": "Introduction to the Azure Machine Learning SDK",
      "duration": "60",
      "instructor": null,
      "rating_average": 4.65,
      "rating_count": 2869,
      "role": "student",
      "source": "MS Learn",
      "url": "https://docs.microsoft.com/en-us/learn/modules/intro-to-azure-machine-learning-service/?WT.mc_id=api_CatalogApi",
      "title": "Introduction to the Azure Machine Learning SDK",
      "product": "azure-machine-learning",
      "level": "System.Byte[]",
      "keyphrases": [
        "ms",
        "learn"
      ]
    }
  ],
  "@odata.nextLink": "https://training-catalog-jms.search.windows.net/indexes/azuretable-index/docs/search?api-version=2024-05-01-preview"
}


Query 2: Library 
{
  "search": "routinized workplace decisions"
}

Response 2: 
{
  "@odata.context": "https://training-catalog-jms.search.windows.net/indexes('azureblob-index')/$metadata#docs(*)",
  "value": [
    {
      "@search.score": 29.167116,
      "content": "\nORIGINAL RESEARCH\n\nDiscriminated by an algorithm: a systematic review\nof discrimination and fairness by algorithmic decision-\nmaking in the context of HR recruitment and HR\ndevelopment\n\nAlina Köchling1\n• Marius Claus Wehner1\n\nReceived: 15 October 2019 / Accepted: 1 November 2020 / Published online: 20 November 2020\n\n� The Author(s) 2020\n\nAbstract Algorithmic decision-making is becoming increasingly common as a new\n\nsource of advice in HR recruitment and HR development. While firms implement\n\nalgorithmic decision-making to save costs as well as increase efficiency and\n\nobjectivity, algorithmic decision-making might also lead to the unfair treatment of\n\ncertain groups of people, implicit discrimination, and perceived unfairness. Current\n\nknowledge about the threats of unfairness and (implicit) discrimination by algo-\n\nrithmic decision-making is mostly unexplored in the human resource management\n\ncontext. Our goal is to clarify the current state of research related to HR recruitment\n\nand HR development, identify research gaps, and provide crucial future research\n\ndirections. Based on a systematic review of 36 journal articles from 2014 to 2020,\n\nwe present some applications of algorithmic decision-making and evaluate the\n\npossible pitfalls in these two essential HR functions. In doing this, we inform\n\nresearchers and practitioners, offer important theoretical and practical implications,\n\nand suggest fruitful avenues for future research.\n\nKeywords Fairness � Discrimination � Perceived fairness � Ethics �\nAlgorithmic decision-making in HRM � Literature review\n\n1 Introduction\n\nAlgorithmic decision-making in human resource management (HRM) is becoming\n\nincreasingly common as a new source of information and advice, and it will gain\n\nmore importance due to the rapid growth of digitalization in organizations.\n\n& Alina Köchling\n\nalina.koechling@hhu.de\n\n1 Faculty of Business Administration and Economics, Heinrich-Heine-University Düsseldorf,\n\nUniversitätsstrasse 1, 40225 Dusseldorf, Germany\n\n123\n\nBusiness Research (2020) 13:795–848\n\nhttps://doi.org/10.1007/s40685-020-00134-w\n\nhttp://orcid.org/0000-0001-7039-9852\nhttp://orcid.org/0000-0002-1932-3155\nhttp://crossmark.crossref.org/dialog/?doi=10.1007/s40685-020-00134-w&amp;domain=pdf\nhttps://doi.org/10.1007/s40685-020-00134-w\n\n\nAlgorithmic decision-making is defined as automated decision-making and remote\n\ncontrol, as well as standardization of routinized workplace decisions (Möhlmann\n\nand Zalmanson 2017). Algorithms, instead of humans, make decisions, and this has\n\nimportant individual and societal implications in organizational optimization\n\n(Chalfin et al. 2016; Lee 2018; Lindebaum et al. 2019). These changes in favor\n\nof algorithmic decision-making make it easier to discover hidden talented\n\nemployees in organizations and review a large number of applications automatically\n\n(Silverman and Waller 2015; Carey and Smith 2016; Savage and Bales 2017). In a\n\nsurvey of 200 artificial intelligence (AI) specialists from German companies, 79%\n\nstated that AI is irreplaceable for competitive advantages (Deloitte 2020). Several\n\ncommercial providers, such as Google, IBM, SAP, and Microsoft, already offer\n\nalgorithmic platforms and systems that facilitate current human resource (HR)\n\npractices, such as hiring and performance measurements (Walker 2012). In turn,\n\nwell-known and large companies, such as Vodafone, Intel, Unilever, and Ikea, apply\n\nalgorithmic decision-making in HR recruitment and HR development (Daugherty\n\nand Wilson 2018; Precire 2020).\n\nThe major driving forces for algorithmic decision-making are savings in both\n\ncosts and time, minimizing risks, enhancing productivity, and increasing certainty in\n\ndecision-making (Suen et al. 2019; McDonald et al. 2017; McColl and Michelotti\n\n2019; Woods et al. 2020). Besides these economic reasons, firms seek to diminish\n\nthe human biases (e.g., prejudices and personal beliefs) by applying algorithmic\n\ndecision-making, thereby increasing the objectivity, consistency, and fairness of the\n\nHR recruitment as well as HR development processes (Langer et al. 2019;\n\nFlorentine 2016; Raghavan et al. 2020). For example, Deloitte argues that the\n\nalgorithmic decision-making system always manages each application with the\n\nsame attention according to the same requirements and criteria (Deloitte 2018). At\n\nfirst glance, algorithmic decision-making seems to be more objective and fairer than\n\nhuman decision-making (Lepri et al. 2018).\n\nHowever, there is a possible threat of discrimination and unfairness by relying\n\nsolely on algorithmic decision-making (e.g., (Lee 2018; Lindebaum et al. 2019;\n\nSimbeck 2019)). In general, discrimination is defined as the unequal treatment of\n\ndifferent groups based on gender, age, or ethnicity instead of on qualitative\n\ndifferences, such as individual performance (Arrow 1973). Algorithms produce\n\ndiscrimination or biased outcomes if they are trained on inaccurate (Kim 2016),\n\nbiased (Barocas and Selbst 2016), or unrepresentative input data (Suresh and Guttag\n\n2019). Consequently, algorithms are vulnerable to produce or replicate biased\n\ndecisions if their input (or training) data are biased (Chander 2016).\n\nComplicating this issue, biases and discrimination are often only recognized after\n\nalgorithms have made a decision. As a prominent example stemming from the\n\ncurrent debate around transparency, bias, and fairness in algorithmic decision-\n\nmaking (Dwork et al. 2012; Lepri et al. 2018; Diakopoulos 2015), the hiring\n\nalgorithms applied by the American e-commerce specialist Amazon yielded an\n\nextreme disadvantage of female applicants, which finally led Amazon to shut down\n\nthe complete algorithmic decision-making for their hiring decision (Dastin 2018;\n\nMiller 2015). Thus, the lack of transparency and accountability of the input data, the\n\nalgorithm itself, and the factors influencing algorithmic outcomes are potential\n\n796 Business Research (2020) 13:795–848\n\n123\n\n\n\nissues associated with algorithmic decision-making (Citron and Pasquale 2014;\n\nPasquale 2015). Another question remains whether applicants and/or employees\n\nperceive the algorithmic decision-making to be fair. Previous studies showed that\n\napplicants’ and employees’ acceptance of algorithmic decision-making is lower in\n\nHR recruitment and HR development compared to common procedures conducted\n\nby humans (Kaibel et al. 2019; Langer et al. 2019; Lee 2018).\n\nConsequently, there is a discrepancy between the enthusiasm about algorithmic\n\ndecision-making as a panacea for inefficiencies and labor shortages on one hand and\n\nthe threat of discrimination and unfairness of algorithmic decision-making on the\n\nother side. While the literature in the field of computer science has already\n\naddressed the issues of biases, knowledge about the potential downsides of\n\nalgorithmic decision-making is still in its infancy in the field of HRM despite its\n\nimportance due to increased digitization and automation in HRM. This heteroge-\n\nneous state of research on discrimination and fairness raises distinct challenges for\n\nfuture research. From a practical point of view, it is problematic if large and well-\n\nknown companies implement algorithms without being aware of the possible pitfalls\n\nand negative consequences. Thus, to move the field forward, it is paramount to\n\nsystematically review and synthesize existing knowledge about biases and\n\ndiscrimination in algorithmic decision-making and to offer new research avenues.\n\nThe aim of this study is threefold. First, this review creates an awareness of\n\npotential biases and discrimination resulting from algorithmic decision-making in\n\nthe context of HR recruitment and HR development. Second, this study contributes\n\nto the current literature by informing both researchers and practitioners about the\n\npotential dangers of algorithmic decision-making in the HRM context. Finally, we\n\nguide future research directions with an understanding of existing knowledge and\n\ngaps in the literature. To this end, the present paper conducts a systematic review of\n\nthe current literature with a focus on HR recruitment and HR development. These\n\ntwo HR functions deal with the potential of future and current employees and the\n\n(automatic) prediction of person-organization fit, career development, and future\n\nperformance (Huselid 1995; Walker 2012). Decisions made by algorithms and AI in\n\nthese two important HR areas have serious consequences for individuals, the\n\ncompany, and society concerning ethics and both procedural and distributive\n\nfairness (Ötting and Maier 2018; Lee 2018; Tambe et al. 2019; Cappelli et al. 2020).\n\nOur study contributes to the existing body of research in several ways. First, the\n\nsystematic literature review contributes to the literature by highlighting the current\n\ndebate on ethical issues associated with algorithmic decision-making, including bias\n\nand discrimination (Barocas and Selbst 2016). Second, our research provides\n\nillustrative examples of various algorithmic decision-making tools used in HR\n\nrecruitment, HR development, and their potential for discrimination and perceived\n\nfairness. Moreover, our systematic review underlines the fact that it is a timely topic\n\ngaining enormous importance. Companies will face legal and reputational risk if\n\ntheir HR recruitment and HR development methods turn out to be discriminatory,\n\nand applicants and employees may consider the algorithmic selection or develop-\n\nment process to be unfair.\n\nFor this reason, companies need to know that the use of algorithmic decision-\n\nmaking can yield to discrimination, unfairness, and dissatisfaction in the context of\n\nBusiness Research (2020) 13:795–848 797\n\n123\n\n\n\nHRM. We offer an understanding of how discrimination might arise when\n\nimplementing algorithmic decision-making. We try to give guidance on how\n\ndiscrimination and perceived unfairness could be avoided and provide detailed\n\ndirections for future research in the existing literature, especially in the HRM field.\n\nMoreover, we identify several research gaps, mainly a lacking focus on perceived\n\nfairness.\n\nThe paper is organized as follows: first, we give an understanding of key terms\n\nand definitions. Afterward, we present the methodology of our systematic literature\n\nreview accompanied by a descriptive analysis of the reviewed literature. This is\n\nfollowed by an illustration of the current state of knowledge on algorithmic\n\ndecision-making and subsequent discussion. Finally, we offer practical as well as\n\ntheoretical implications and outline future research avenues.\n\n2 Conceptual background and definitions\n\n2.1 Definition of algorithms\n\nThe Oxford Living Dictionary defines algorithms as ‘‘processes or sets of rules to be\n\nfollowed in calculations or other problem-solving operations, especially by a\n\ncomputer.’’ Möhlmann and Zalmanson (2017) refer to algorithmic decision-making\n\nas automated decision-making and remote control, and standardization of routinized\n\nworkplace decision. Thus, in this paper, we use the term algorithmic decision-\n\nmaking to describe a computational mechanism that autonomously makes decisions\n\nbased on rules and statistical models without explicit human interference (Lee\n\n2018). Algorithms are the basis for several AI decision tools.\n\nAI is an umbrella term for a wide array of models, methods, and prescriptions\n\nused to simulate human intelligence, often when it comes to collecting, processing,\n\nand acting on data. AI applications can apply rules, learn over time through the\n\nacquisition of new data and information, and adapt to changes in the environment\n\n(Russell and Norvig 2016). AI includes several different research areas, such as\n\nmachine learning (ML), speech and image recognition, and natural language\n\nprocessing (NLP) (Kaplan and Haenlein 2019; Paschen et al. 2020).\n\nAs mentioned, the basis for many AI decision-making tools used in HR are ML\n\nalgorithms, which can be categorized into three major types: supervised, unsuper-\n\nvised, and reinforcement learning (Lee and Shin 2020). Supervised ML algorithms\n\naim to make predictions (often divided into classification- or regression-type\n\nproblems), given the input data and desired outputs considered as the ground truth.\n\nHuman experts often provide these labels and thus provide the algorithm with the\n\nground truth. To replicate human decisions or to make predictions, the algorithm\n\nlearns patterns from the labeled data and develops rules, which can be applied for\n\nfuture instances for the same problem (Canhoto and Clear 2020). In contrast, in\n\nunsupervised ML, only input data are given, and the model learns patterns from the\n\ndata without a priori labeling (Murphy 2012). Unsupervised ML algorithms capture\n\nthe structural behaviors of variables in the input data for theme analysis or grouping\n\n798 Business Research (2020) 13:795–848\n\n123\n\n\n\ndata (Canhoto and Clear 2020). Finally, reinforcement learning, as a separate group\n\nof methods, is not based on fixed input/output data. Instead, the ML algorithm learns\n\nbehavior through trial-and-error interactions with a dynamic environment (Kael-\n\nbling et al. 1996).\n\nFurthermore, instead of grouping ML models as supervised, unsupervised, or\n\nreinforcement type learning, the methodologies of algorithms may also be used to\n\ncategorize ML models. Examples are probabilistic models, which may be used in\n\nsupervised or unsupervised settings (Murphy 2012), or deep learning models (Lee\n\nand Shin 2020), which rely on artificial neural networks and perform complex\n\nlearning tasks. In supervised settings, neural network models often determine the\n\nrelationship between input and output using network structures containing the so-\n\ncalled hidden layers, meaning phases of transformation of the input data. Single\n\nnodes of these layers (neurons) were first modeled after neurons in the human brain,\n\nand they resemble human thinking (Bengio et al. 2017). In other settings, deep\n\nlearning may be used, for instance, to (1) process information through multiple\n\nstages of nonlinear transformation; or (2) determine features, representations of the\n\ndata providing an advantage for, e.g., prediction tasks (Deng and Yu 2014).\n\n2.2 Reason for biases\n\nFor any estimation bY of a random variable Y , bias refers to the difference between\n\nthe expected values of bY and Y and is also referred to as systematic error\n\n(Kauermann and Kuechenhoff 2010; Goodfellow et al. 2016). Cognitive biases,\n\nspecifically, are systematic errors in human judgment when dealing with uncertainty\n\n(Kahneman et al. 1982). These cognitive biases are thought to be transferred to\n\nalgorithmic evaluations or predictions, where bias may refer to ‘‘computer systems\n\nthat systematically and unfairly discriminate against certain individuals or groups in\n\nfavor of others’’ (Friedman and Nissenbaum 1996, p. 332).\n\nAlgorithms are often characterized as ‘‘black box’’. In the context of HRM,\n\nCheng and Hackett (2019) characterize algorithms as ‘‘glass boxes’’, since some,\n\nbut not all, components of the theory are reflective. In this context, the consideration\n\nand distinction of the three core elements are necessary, namely, transparency,\n\ninterpretability, and explainability (Roscher et al. 2020). Transparency is concerned\n\nwith the ML approach, while interpretability is concerned with the ML model in\n\ncombination with the data, which means the making sense of the obtained ML\n\nmodel (Roscher et al. 2020). Finally, explainability comprises the model, the data,\n\nand human involvement (Roscher et al. 2020). Concerning the former, transparency\n\ncan be distinguished at three different levels: ‘‘[…] at the level of the entire model\n\n(simulatability), at the level of individual components, such as parameters\n\n(decomposability), and at the level of the training (algorithmic transparency)’’\n\n(Roscher et al. 2020, p. 4). Interpretability concerns the characteristics of an ML\n\nmodel that need to be understood by a human (Roscher et al. 2020). Finally, the\n\nelement of explainability is paramount in HRM. Contextual information of human\n\nand their knowledge from the domain of HRM are necessary to explain the different\n\nsets of interpretations and derive conclusions about the results of the algorithms\n\nBusiness Research (2020) 13:795–848 799\n\n123\n\n\n\n(Roscher et al. 2020). Especially in HRM, in which ML algorithms are increasingly\n\nused for prediction of variables of interest to the HR department (e.g., personality\n\ncharacteristics, employee satisfaction, and turnover intentions), it is essential to\n\nunderstand how the ML algorithm operates (e.g., how the ML algorithm uses data\n\nand weighs specific criteria) and the underlying reasons for the produced decision.\n\nIn the following, we will outline the main reasons for biases in algorithmic\n\ndecision-making and briefly summarize different biases, namely historical, repre-\n\nsentation, technical, and emergent bias. One of the main reasons for bias in\n\nalgorithmic decision-making is the quality of input data, because algorithms learn\n\nfrom historical data as an example; thus, the learning process depends on the\n\nexposed examples (Friedman and Nissenbaum 1996; Barocas and Selbst 2016;\n\nDanks and London 2017). The input data are usually historical. Consequently, if the\n\ninput data set is biased in one way or another, the subsequent analysis is biased, as\n\nwell (keyword: ‘‘garbage in, garbage out’’). For example, if the input data of an\n\nalgorithm include implicit or explicit human judgments, stereotypes, or biases, an\n\naccurate algorithmic output will inevitably entail these human judgments, stereo-\n\ntypes, and prejudices (Diakopoulos 2015; Suresh and Guttag 2019; Barfield and\n\nPagallo 2018). This bias usually exists before the creation of the system and may not\n\nbe apparent at first glance. In turn, the algorithm replicates these preexisting biases,\n\nbecause it treats all information, in which a certain kind of discrimination or bias is\n\nembedded, as a valid example (Barocas and Selbst 2016; Lindebaum et al. 2019). In\n\nthe worst case, the algorithm can yield racist or discriminatory outputs (Veale and\n\nBinns 2017). Algorithms exhibit these tendencies, even if it is not the intention of\n\nthe manual programming since they compound the historical biases of the past.\n\nThus, any predictive algorithmic decision-making tool built on historical data may\n\ninherit historical biases (Datta et al. 2015).\n\nAs an example from the recruitment process, if an algorithm is trained on\n\nhistorical employment data, integrating an implicit bias that favors white men over\n\nHispanics, then, without even being fed data on gender or ethnicity, an algorithm\n\nmay recognize patterns in the data, which expose an applicant as a member of a\n\ncertain protected group, which, historically, is less likely to be chosen for a job\n\ninterview. This, in turn, may lead to a systematic disadvantage of certain groups,\n\neven if the designer has no intention of marginalizing people based on these\n\ncategories and if the algorithm is not directly given this information (Barocas and\n\nSelbst 2016).\n\nAnother reason for biases in algorithms related to the input data is that certain\n\ngroups or characteristics are mostly underrepresented or sometimes overrepre-\n\nsented, which is also called representation bias (Barocas and Selbst 2016; Suresh\n\nand Guttag 2019; Barfield and Pagallo 2018). Any decision based on this kind of\n\nbiased data might lead to disadvantages of groups of individuals who are\n\nunderrepresented or overrepresented (Barocas and Selbst 2016). Another reason\n\nfor representation bias can be the absence of specific information (Barfield and\n\nPagallo 2018). Thus, not only the selection of measurements but also the\n\npreprocessing of the measurement data might yield to bias. ML models often\n\nevolve in several steps of feature engineering or model testing, since there is no\n\nuniversally best model (as shown in the ‘‘no free lunch’’ theorems, [see Wolpert and\n\n800 Business Research (2020) 13:795–848\n\n123\n\n\n\nMacready (1997)]. Here, the choice of the benchmark or rather the value indicating\n\nthe performance of the model is optimized through rotations of different\n\nrepresentations of the data and methods for prediction. For example, representative\n\nbias might occur if females in comparison to males are underrepresented in the\n\ntraining data of an algorithm. Hence, the outcome could be in favor of the\n\noverrepresented group (i.e., males) and, hence, lead to discriminatory outcomes.\n\nTechnical bias may arise from technical constraints or technical consideration for\n\nseveral reasons. For example, technical bias can originate from limited ‘‘[…]\n\ncomputer technology, including hardware, software, and peripherals’’ (Friedman\n\nand Nissenbaum 1996, p. 334). Another reason could be a decontextualized\n\nalgorithm that does not manage to treat all groups fairly under all important\n\nconditions (Friedman and Nissenbaum 1996; Bozdag 2013). The formalization of\n\nhuman constructs to computers can be another problem leading to technical bias.\n\nHuman constructs, such as judgments or intuitions, are often hard to quantify, which\n\nmakes it difficult or even impossible to translate them to the computer (Friedman\n\nand Nissenbaum 1996). As an example, the human interpretation of law can be\n\nambiguous and highly dependent on the specific context, making it difficult for an\n\nalgorithmic system to correctly advise in litigation (c.f., Friedman and Nissenbaum\n\n1996).\n\nIn the context of real users, emergent bias may arise. Typically, this bias occurs\n\nafter the construction as a result of changed societal knowledge, population, or\n\ncultural values (Friedman and Nissenbaum 1996). Consequently, a shift in the\n\ncontext of use might yield to problems and an emergent bias due to two reasons,\n\nnamely ‘‘new societal knowledge’’ and ‘‘mismatch between users and system\n\ndesign’’ (see Table 1 in Friedman and Nissenbaum 1996, p. 335). If it is not possible\n\nto incorporate new knowledge in society into the system design, emergent bias due\n\nto new societal knowledge occurs. The mismatch between users and system design\n\ncan occur due to changes in state-of-the-art-research or due to different values. Also,\n\nemergent bias can occur if a population uses the system with different values than\n\nthose assumed in the design process (Friedman and Nissenbaum 1996). Problems\n\noccur, for example, when users originate from a cultural context that avoids\n\ncompetition and promotes cooperative efforts, while the algorithm is trained to\n\nreward individualistic and competitive behavior (Friedman and Nissenbaum 1996).\n\n2.3 Fairness and discrimination in information systems\n\nLeventhal (1980) describes fairness as equal treatment based on people’s\n\nperformance and needs. Table 1 offers an overview of the different fairness\n\ndefinitions. Individual fairness means that, independent of group membership, two\n\nindividuals who are perceived to be similar by the measures at hand should also be\n\ntreated similarly (Dwork et al. 2012). Rising from the micro-level onto the meso-\n\nlevel, Dwork et al. (2012) also proposed another measure of fairness, that is, group\n\nfairness, in which entire (protected) groups of people are required to be treated\n\nsimilarly (statistical parity). Hardt et al. (2016) extended these notions by including\n\ntrue outcomes of predicted variables to achieve fair treatment. In their sense, false-\n\nBusiness Research (2020) 13:795–848 801\n\n123\n\n\n\npositives/negatives are sources of disadvantage and should be equal among groups\n\nmeans equal opportunity for false-positives/negatives (Hardt et al. 2016).\n\nUnfair treatment of certain groups of people or individual subjects yields to\n\ndiscrimination. Discrimination is defined as the unequal treatment of different\n\ngroups (Arrow 1973). Discrimination is very similar to unfairness. Discriminatory\n\ncategories can be strongly correlated with non-discriminatory categories, such as\n\nage (i.e., discriminatory) and years of working experience (non-discriminatory)\n\n(Persson 2016). Also, there is a difference between implicit and explicit\n\ndiscrimination. Implicit discrimination is based on implicit attitudes or stereotypes\n\nand often unintentional (Bertrand et al. 2005). In contrast, explicit discrimination is\n\na conscious process due to an aversion to certain groups of people. In HR\n\nrecruitment and HR development, discrimination means the not-hiring or support of\n\na person due to characteristics not related to that person’s productivity in the current\n\nposition (Frijters 1998).\n\nThe HR literature, especially the literature on personnel selection, is concerned\n\nwith fairness in hiring decisions, because every selection measure of individual\n\ndifferences is inevitably discriminatory (Cascio and Aguinis 2013). However, the\n\nquestion arises ‘‘whether the measure discriminates unfairly’’ (Cascio and Aguinis\n\n2013, p. 183). Hence, the actual fairness of prediction systems needs to be tested\n\nbased on probabilities and estimates, which we refer to as objective fairness. In the\n\nselection context, the literature distinguishes between differential validity (i.e.,\n\ndifferences in subgroup validity) and differential prediction (i.e., differences in\n\nslopes and intercepts of subgroups), and both might lead to biased results (Meade\n\nand Fetzer 2009; Roth et al. 2017; Bobko and Bartlett 1978).\n\nIn HR recruitment and HR development, both objective fairness and subjective\n\nfairness perceptions of applicants and employees about the usage of algorithmic\n\ndecision-making need to be considered. In this regard, perceived fairness or justice\n\nis more a subjective and descriptive personal evaluation rather than an objective\n\nreality (Cropanzano et al. 2007). Subjective fairness plays an essential role in the\n\nrelationship between humans and their employers. Previous studies showed that the\n\nTable 1 Definitions of fairness\n\nName Author Definition\n\nIndividual\n\nfairness\n\nDwork et al.\n\n(2012)\n\n‘‘Similar’’ subjects should have ‘‘similar’’ classifications\n\nGroup\n\nfairness\n\nSubjects in protected and unprotected groups have an equal probability\n\nof being assigned positive\n\nP bY ¼ 1\n� �\n\n�\n\n�G ¼ 1Þ ¼ Pð bY ¼ 1jG ¼ 0Þ\n\nEqual\n\nopportunity\n\nHardt et al.\n\n(2016)\n\nFalse-negative rates should be equal\n\nP bY ¼ 0\n� �\n\n�\n\n�Y ¼ 1;G ¼ 1Þ ¼ Pð bY ¼ 0jY ¼ 1;G ¼ 0Þ\n\nY 2 0; 1f g is a random variable describing, e.g., the recidivism of a subject, bY its estimator and G 2\nf0; 1g; describes whether a subject is a member of a certain protected group (G ¼ 1Þ or not ðG ¼ 0Þ\n\n802 Business Research (2020) 13:795–848\n\n123\n\n\n\nlikelihood of conscientious behavior and altruisms is higher for employees who feel\n\ntreated fairly (Cohen-Charash and Spector 2001). Conversely, unfairness can have\n\nconsiderable adverse consequences. For example, in the recruitment context,\n\nfairness perceptions of candidates during the selection process have important\n\nconsequences for decision to stay in the applicant pool or accept a job offer (Bauer\n\net al. 2001). Therefore, it is crucial to know how people feel about algorithmic\n\ndecision-making taking over managerial decisions formerly made by humans, since\n\nthe fairness perceptions during the recruitment process and/or training process have\n\nessential and meaningful effects on attitudes, performance, morale, intentions, and\n\nbehavior (e.g., the acceptance or rejection of a job offer or job turnover, job\n\ndissatisfaction, and reduction or elimination of conflicts) (Gilliland 1993; McCarthy\n\net al. 2017; Hausknecht et al. 2004; Cropanzano et al. 2007; Cohen-Charash and\n\nSpector 2001). Moreover, negative experiences might damage the employer�s\nimage. Several online platforms offer the possibility of rating companies and their\n\nrecruitment and development process (Van Hoye 2013; Woods et al. 2020).\n\nConsidering justice and fairness in the organizational context (Gilliland 1993),\n\nthere are three core dimensions of justice: distributive, procedural, and interactional.\n\nThe three dimensions tend to be correlated. Distributive justice deals with the\n\noutcome that some humans receive and some do not (Cropanzano et al. 2007). Rules\n\nthat can lead to distributive justice are ‘‘[…] equality (to each the same), equity (to\n\neach in accordance with contributions, and need (to each in accordance with the\n\nmost urgency)’’ (Cropanzano et al. 2007, p. 37). To some extent, especially\n\nconcerning equity, this can be connected with individual fairness and group fairness\n\nfrom Dwork et al. (2012) and equal opportunities from Hardt et al. (2016).\n\nProcedural justice means that the process is consistent with all humans, not\n\nincluding bias, accurate, and consistent with the ethical norms (Cropanzano et al.\n\n2007; Leventhal 1980). Consistency plays an essential role in procedural justice,\n\nmeaning that all employees and all candidates need to receive the same treatment.\n\nAdditionally, the lack of bias, accuracy, representation of all parties, correction, and\n\nethics play an important role in achieving a high procedural justice (Cropanzano\n\net al. 2007). In contrast, interactional justice is about the treatment of humans,\n\nmeaning the appropriateness of the treatment from another member of the company,\n\nthe treatment with dignity, courtesy, and respect, and informational justice (share of\n\nrelevant information) (Cropanzano et al. 2007).\n\nIn general, algorithmic decision-making increases the standardization of\n\nprocedures, so that decisions should be more objective and less biased, and errors\n\nshould occur less frequently (Kaibel et al. 2019), since information processing by\n\nhuman raters can be unsystematic, leading to contradictory and insufficient\n\nevidence-based decisions (Woods et al. 2020). Consequently, procedural justice and\n\ndistributive justice are higher using algorithmic decision-making, because the\n\nprocess is more standardized, which still not means that it is without bias.\n\nHowever, especially in the context of an application or an employee evaluation, it\n\nis not only about how fair the procedure itself is (according to fairness measures),\n\nbut it is also about how people involved in the decision process perceive the fairness\n\nof the whole process. Often the personal contact, which characterizes the\n\nBusiness Research (2020) 13:795–848 803\n\n123\n\n\n\ninteractional fairness, is missing when using algorithmic decision-making. It is\n\ndifficult to fulfill all three fairness dimensions.\n\n3 Methods\n\nThis systematic literature review aims at offering a coherent, transparent, and\n\nreliable picture of existing knowledge and providing insights into fruitful research\n\navenues about the discrimination potential and fairness when using algorithmic\n\ndecision-making in HR recruitment and HR development. This is in line with other\n\nsystematic literature reviews that organize, evaluate, and synthesize knowledge in a\n\nparticular field and provide an overall picture of knowledge and suggestions for\n\nfuture research (Petticrew and Roberts 2008; Crossan and Apaydin 2010; Siddaway\n\net al. 2019). To this end, we followed the systematic literature review approach\n\ndescribed by Siddaway et al. (2019) and Gough et al. (2017) to ensure a methodical,\n\ntransparent, and replicable approach.1\n\n3.1 Search terms and databases\n\nWe engaged in an extensive keyword searching, which we derived in an iterative\n\nprocess of search and discussion between the two authors of this study (see\n\n‘‘Appendix’’ for the employed keywords). According to our research question, we\n\nfirst defined individual concepts to create search terms. We considered different\n\nterminology, including synonyms, singular/plural forms, different spellings, broader\n\nvs. narrow terms, and classification terms of databases to categorize contents\n\n(Siddaway et al. 2019) (see Table 2 for a complete list of employed keywords and\n\nsearch strings). Our priority was to achieve the balance between sensitivity and\n\nspecificity to get broad coverage of the literature and to avoid the unintentional\n\nomission of relevant articles (Siddaway et al. 2019).\n\nAs the first source of data, we used the social science citation index (SSCI) to\n\nensure broad coverage of scholarly literature. This database covers English-\n\nlanguage peer-reviewed journals in business and management. As part of the Web\n\nof Knowledge, the database includes all journals with an impact factor, which is a\n\nreasonable proxy for the most important publications in the field. We completed our\n\nsearch with the EBSCO Business Source Premier database to add further breadth.\n\nSince electronic databases are not fully comprehensive, we additionally searched in\n\nthe reference section of the considered papers and manually searched for articles\n\n(Siddaway et ",
      "metadata_storage_size": 593265,
      "metadata_storage_path": "aHR0cHM6Ly9qdHJhaW5pbmdjYXRhbG9nc3RvcmFnZS5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL0slQzMlQjZjaGxpbmctV2VobmVyMjAyMF9BcnRpY2xlX0Rpc2NyaW1pbmF0ZWRCeUFuQWxnb3JpdGhtQVN5cy5wZGY1",
      "metadata_author": "Alina Köchling ",
      "metadata_title": "Discriminated by an algorithm: a systematic review of discrimination and fairness by algorithmic decision-making in the context of HR recruitment and HR development",
      "metadata_creation_date": "2020-11-19T15:45:16Z",
      "people": [
        "Alina Köchling1",
        "Marius Claus Wehner1",
        "Alina Köchling",
        "Zalmanson",
        "Chalfin",
        "Lindebaum",
        "Silverman",
        "Waller",
        "Carey",
        "Smith",
        "Savage",
        "Bales",
        "Walker",
        "Wilson",
        "Suen",
        "McDonald",
        "McColl",
        "Michelotti",
        "Woods",
        "Raghavan",
        "Lepri",
        "Lee",
        "Simbeck",
        "Barocas",
        "Selbst",
        "Suresh",
        "Guttag",
        "Chander",
        "Dwork",
        "Miller",
        "Pasquale",
        "Kaibel",
        "Langer",
        "Huselid",
        "Ötting",
        "Maier",
        "Tambe",
        "Cappelli",
        "Möhlmann",
        "Russell",
        "Norvig",
        "Paschen",
        "Shin",
        "Murphy",
        "Kael",
        "bling",
        "Bengio",
        "Deng",
        "Yu",
        "Kauermann",
        "Kuechenhoff",
        "Goodfellow",
        "Kahneman",
        "Friedman",
        "Nissenbaum",
        "Cheng",
        "Hackett",
        "Roscher",
        "Danks",
        "Diakopoulos",
        "Veale",
        "Datta",
        "Barfield",
        "Pagallo",
        "Wolpert",
        "Leventhal",
        "Hardt",
        "Persson",
        "Bertrand",
        "Frijters",
        "Cascio",
        "Aguinis",
        "Meade",
        "Fetzer",
        "Roth",
        "Bobko",
        "Bartlett",
        "Cropanzano",
        "Cohen-Charash",
        "Spector",
        "Gilliland",
        "McCarthy",
        "Hausknecht",
        "Petticrew",
        "Roberts",
        "Crossan",
        "Apaydin",
        "Siddaway",
        "Gough"
      ],
      "organizations": [
        "human resource management",
        "HRM",
        "Administration",
        "Economics",
        "Heinrich-Heine-University Düsseldorf",
        "Möhlmann",
        "Deloitte",
        "Google",
        "IBM",
        "SAP",
        "Microsoft",
        "Vodafone",
        "Intel",
        "Unilever",
        "Ikea",
        "Daugherty",
        "Arrow",
        "Kim",
        "Amazon",
        "Dastin",
        "Citron",
        "Pasquale",
        "company",
        "workplace",
        "Kaplan",
        "Haenlein",
        "department",
        "fairness",
        "Group",
        "opportunity",
        "Business Research",
        "Bauer",
        "procedural justice",
        "fairness measures",
        "EBSCO"
      ],
      "locations": [
        "algo",
        "German",
        "Florentine",
        "Deloitte",
        "Diakopoulos",
        "American",
        "neous state",
        "field",
        "Canhoto",
        "ML",
        "London",
        "Barfield",
        "Binns",
        "Hispanics",
        "Guttag",
        "Bozdag",
        "bY",
        "Van Hoye",
        "Leventhal",
        "Cropanzano",
        "Siddaway",
        "English"
      ],
      "keyphrases": [
        "200 artificial intelligence (AI) specialists",
        "two essential HR functions",
        "Marius Claus Wehner1",
        "Heinrich-Heine-University Düsseldorf",
        "major driving forces",
        "human resource management",
        "Alina Köchling1",
        "routinized workplace decisions",
        "current human resource",
        "crucial future research",
        "HRM � Literature review",
        "Abstract Algorithmic decision-making",
        "Keywords Fairness � Discrimination",
        "human biases",
        "systematic review",
        "HR recruitment",
        "HR development",
        "HR) practices",
        "ORIGINAL RESEARCH",
        "new source",
        "unfair treatment",
        "implicit discrimination",
        "implicit) discrimination",
        "current state",
        "research gaps",
        "36 journal articles",
        "possible pitfalls",
        "important theoretical",
        "practical implications",
        "fruitful avenues",
        "fairness � Ethics",
        "rapid growth",
        "Business Administration",
        "Universitätsstrasse",
        "Business Research",
        "automated decision-making",
        "remote control",
        "Möhlmann",
        "important individual",
        "societal implications",
        "organizational optimization",
        "large number",
        "German companies",
        "competitive advantages",
        "commercial providers",
        "algorithmic platforms",
        "performance measurements",
        "large companies",
        "economic reasons",
        "personal beliefs",
        "doi.org",
        "orcid.org",
        "context",
        "Author",
        "advice",
        "firms",
        "costs",
        "efficiency",
        "objectivity",
        "groups",
        "people",
        "unfairness",
        "knowledge",
        "threats",
        "goal",
        "directions",
        "applications",
        "researchers",
        "practitioners",
        "1 Introduction",
        "information",
        "importance",
        "digitalization",
        "organizations",
        "koechling",
        "hhu",
        "1 Faculty",
        "Economics",
        "40225 Dusseldorf",
        "Germany",
        "crossmark",
        "crossref",
        "standardization",
        "Zalmanson",
        "Algorithms",
        "humans",
        "Chalfin",
        "Lee",
        "Lindebaum",
        "changes",
        "favor",
        "talented",
        "employees",
        "Silverman",
        "Waller",
        "Carey",
        "Smith",
        "Savage",
        "Bales",
        "survey",
        "Deloitte",
        "Several",
        "Google",
        "IBM",
        "SAP",
        "Microsoft",
        "systems",
        "hiring",
        "Walker",
        "turn",
        "Vodafone",
        "Unilever",
        "Ikea",
        "Daugherty",
        "Wilson",
        "Precire",
        "savings",
        "time",
        "risks",
        "productivity",
        "certainty",
        "Suen",
        "McDonald",
        "McColl",
        "Michelotti",
        "Woods",
        "prejudices",
        "15",
        "American e-commerce specialist",
        "algorithmic decision- making",
        "new research avenues",
        "HR development processes",
        "unrepresentative input data",
        "algorithmic decision-making system",
        "complete algorithmic decision-making",
        "training) data",
        "algorithmic outcomes",
        "same attention",
        "same requirements",
        "first glance",
        "human decision-making",
        "unequal treatment",
        "different groups",
        "qualitative differences",
        "individual performance",
        "biased outcomes",
        "biased decisions",
        "current debate",
        "extreme disadvantage",
        "796 Business Research",
        "Previous studies",
        "common procedures",
        "labor shortages",
        "one hand",
        "other side",
        "computer science",
        "neous state",
        "distinct challenges",
        "future research",
        "practical point",
        "known companies",
        "negative consequences",
        "potential downsides",
        "potential dangers",
        "possible threat",
        "prominent example",
        "female applicants",
        "hiring decision",
        "employees’ acceptance",
        "existing knowledge",
        "current literature",
        "hiring algorithms",
        "potential biases",
        "HRM context",
        "consistency",
        "fairness",
        "Langer",
        "Florentine",
        "Raghavan",
        "application",
        "criteria",
        "Lepri",
        "discrimination",
        "Simbeck",
        "gender",
        "ethnicity",
        "Arrow",
        "Kim",
        "Barocas",
        "Selbst",
        "Suresh",
        "Guttag",
        "Chander",
        "issue",
        "transparency",
        "Dwork",
        "Diakopoulos",
        "Amazon",
        "Dastin",
        "Miller",
        "lack",
        "accountability",
        "factors",
        "Citron",
        "Pasquale",
        "question",
        "Kaibel",
        "discrepancy",
        "enthusiasm",
        "panacea",
        "inefficiencies",
        "field",
        "infancy",
        "digitization",
        "automation",
        "view",
        "aim",
        "study",
        "awareness",
        "The Oxford Living Dictionary",
        "two important HR areas",
        "several different research areas",
        "various algorithmic decision-making tools",
        "several AI decision tools",
        "other problem-solving operations",
        "two HR functions",
        "explicit human interference",
        "natural language processing",
        "several research gaps",
        "future research avenues",
        "systematic literature review",
        "HR development methods",
        "future research directions",
        "several ways",
        "workplace decision",
        "human intelligence",
        "algorithmic selection",
        "career development",
        "future performance",
        "person-organization fit",
        "serious consequences",
        "Ötting",
        "existing body",
        "ethical issues",
        "illustrative examples",
        "timely topic",
        "enormous importance",
        "reputational risk",
        "ment process",
        "key terms",
        "descriptive analysis",
        "subsequent discussion",
        "theoretical implications",
        "Conceptual background",
        "computational mechanism",
        "umbrella term",
        "wide array",
        "machine learning",
        "image recognition",
        "existing literature",
        "AI applications",
        "current employees",
        "HRM field",
        "lacking focus",
        "statistical models",
        "new data",
        "present paper",
        "distributive fairness",
        "understanding",
        "end",
        "potential",
        "Huselid",
        "Decisions",
        "algorithms",
        "individuals",
        "company",
        "society",
        "ethics",
        "procedural",
        "Maier",
        "Tambe",
        "Cappelli",
        "bias",
        "fact",
        "Companies",
        "legal",
        "applicants",
        "reason",
        "guidance",
        "detailed",
        "definitions",
        "methodology",
        "illustration",
        "processes",
        "sets",
        "rules",
        "calculations",
        "computer",
        "routinized",
        "basis",
        "prescriptions",
        "acquisition",
        "environment",
        "Russell",
        "Norvig",
        "ML",
        "speech",
        "NLP",
        "Kaplan",
        "Haenlein",
        "Paschen",
        "2.1",
        "many AI decision-making tools",
        "three major types",
        "artificial neural networks",
        "random variable Y",
        "three core elements",
        "three different levels",
        "neural network models",
        "deep learning models",
        "fixed input/output data",
        "reinforcement type learning",
        "Unsupervised ML algorithms",
        "reinforcement learning",
        "ML models",
        "network structures",
        "probabilistic models",
        "unsupervised settings",
        "learning tasks",
        "ML approach",
        "regression-type problems",
        "ground truth",
        "Human experts",
        "human decisions",
        "future instances",
        "same problem",
        "priori labeling",
        "structural behaviors",
        "theme analysis",
        "798 Business Research",
        "separate group",
        "error interactions",
        "dynamic environment",
        "Single nodes",
        "human brain",
        "human thinking",
        "other settings",
        "prediction tasks",
        "expected values",
        "systematic error",
        "human judgment",
        "algorithmic evaluations",
        "computer systems",
        "black box",
        "glass boxes",
        "making sense",
        "human involvement",
        "Cognitive biases",
        "entire model",
        "nonlinear transformation",
        "individual components",
        "input data",
        "Shin",
        "predictions",
        "outputs",
        "labels",
        "patterns",
        "Canhoto",
        "contrast",
        "Murphy",
        "variables",
        "methods",
        "trial",
        "bling",
        "methodologies",
        "Examples",
        "complex",
        "relationship",
        "phases",
        "layers",
        "neurons",
        "Bengio",
        "multiple",
        "stages",
        "features",
        "representations",
        "advantage",
        "Deng",
        "Yu",
        "Reason",
        "estimation",
        "bY",
        "difference",
        "Kauermann",
        "Kuechenhoff",
        "Goodfellow",
        "uncertainty",
        "Kahneman",
        "others",
        "Friedman",
        "Nissenbaum",
        "HRM",
        "Cheng",
        "Hackett",
        "theory",
        "consideration",
        "distinction",
        "interpretability",
        "explainability",
        "Roscher",
        "combination",
        "former",
        "simulatability",
        "parameters",
        "2.2",
        "predictive algorithmic decision-making tool",
        "accurate algorithmic output",
        "explicit human judgments",
        "input data set",
        "historical employment data",
        "algorithmic transparency",
        "historical data",
        "ML model",
        "different sets",
        "HR department",
        "employee satisfaction",
        "turnover intentions",
        "specific criteria",
        "underlying reasons",
        "main reasons",
        "learning process",
        "exposed examples",
        "one way",
        "subsequent analysis",
        "worst case",
        "discriminatory outputs",
        "manual programming",
        "recruitment process",
        "white men",
        "protected group",
        "systematic disadvantage",
        "biased data",
        "historical biases",
        "different biases",
        "preexisting biases",
        "Contextual information",
        "emergent bias",
        "representation bias",
        "specific information",
        "personality characteristics",
        "ML algorithm",
        "valid example",
        "implicit bias",
        "decomposability",
        "level",
        "training",
        "Interpretability",
        "element",
        "domain",
        "interpretations",
        "derive",
        "conclusions",
        "results",
        "prediction",
        "interest",
        "technical",
        "quality",
        "Danks",
        "London",
        "keyword",
        "garbage",
        "stereotypes",
        "Barfield",
        "Pagallo",
        "creation",
        "kind",
        "racist",
        "Veale",
        "Binns",
        "tendencies",
        "past",
        "Datta",
        "Hispanics",
        "applicant",
        "member",
        "job",
        "interview",
        "designer",
        "categories",
        "disadvantages",
        "absence",
        "selection",
        "measurements",
        "information systems Leventhal",
        "new societal knowledge",
        "different fairness definitions",
        "new knowledge",
        "several steps",
        "feature engineering",
        "free lunch",
        "discriminatory outcomes",
        "technical constraints",
        "technical consideration",
        "several reasons",
        "important conditions",
        "human constructs",
        "human interpretation",
        "cultural values",
        "two reasons",
        "different values",
        "design process",
        "cooperative efforts",
        "competitive behavior",
        "equal treatment",
        "meso- level",
        "statistical parity",
        "true outcomes",
        "fair treatment",
        "equal opportunity",
        "individual subjects",
        "representative bias",
        "Technical bias",
        "algorithmic system",
        "system design",
        "measurement data",
        "model testing",
        "best model",
        "800 Business Research",
        "training data",
        "Individual fairness",
        "group membership",
        "computer technology",
        "specific context",
        "cultural context",
        "group fairness",
        "real users",
        "protected) groups",
        "preprocessing",
        "theorems",
        "Wolpert",
        "Macready",
        "choice",
        "benchmark",
        "performance",
        "rotations",
        "example",
        "females",
        "comparison",
        "overrepresented",
        "limited",
        "hardware",
        "software",
        "peripherals",
        "Bozdag",
        "formalization",
        "computers",
        "problem",
        "judgments",
        "intuitions",
        "law",
        "litigation",
        "construction",
        "result",
        "population",
        "shift",
        "mismatch",
        "Table",
        "state",
        "art",
        "competition",
        "individualistic",
        "needs",
        "overview",
        "measures",
        "hand",
        "micro-level",
        "Hardt",
        "notions",
        "sense",
        "positives/negatives",
        "sources",
        "disadvantage",
        "2.3",
        "fairness Name Author Definition Individual fairness Dwork",
        "similar’’ classifications Group fairness",
        "descriptive personal evaluation",
        "considerable adverse consequences",
        "individual differences",
        "actual fairness",
        "fairness perceptions",
        "objective fairness",
        "Subjective fairness",
        "Discriminatory categories",
        "working experience",
        "conscious process",
        "current position",
        "personnel selection",
        "prediction systems",
        "selection context",
        "differential validity",
        "subgroup validity",
        "differential prediction",
        "biased results",
        "Table 1 Definitions",
        "P bY",
        "Pð bY",
        "opportunity Hardt",
        "False-negative rates",
        "1f g",
        "random variable",
        "802 Business Research",
        "selection process",
        "applicant pool",
        "training process",
        "meaningful effects",
        "negative experiences",
        "recruitment context",
        "job offer",
        "job turnover",
        "explicit discrimination",
        "selection measure",
        "essential role",
        "equal probability",
        "conscientious behavior",
        "managerial decisions",
        "Implicit discrimination",
        "implicit attitudes",
        "HR literature",
        "years",
        "Persson",
        "Bertrand",
        "aversion",
        "support",
        "characteristics",
        "Frijters",
        "Cascio",
        "Aguinis",
        "probabilities",
        "estimates",
        "slopes",
        "intercepts",
        "subgroups",
        "Meade",
        "Fetzer",
        "Roth",
        "Bobko",
        "Bartlett",
        "usage",
        "algorithmic",
        "decision-making",
        "regard",
        "justice",
        "reality",
        "Cropanzano",
        "employers",
        "subjects",
        "positive",
        "1jG",
        "recidivism",
        "estimator",
        "likelihood",
        "altruisms",
        "Cohen-Charash",
        "Spector",
        "candidates",
        "Bauer",
        "morale",
        "intentions",
        "acceptance",
        "rejection",
        "dissatisfaction",
        "reduction",
        "elimination",
        "conflicts",
        "Gilliland",
        "McCarthy",
        "Hausknecht",
        "image",
        "systematic literature review approach",
        "systematic literature reviews",
        "Several online platforms",
        "extensive keyword searching",
        "defined individual concepts",
        "three core dimensions",
        "fruitful research avenues",
        "high procedural justice",
        "three fairness dimensions",
        "three dimensions",
        "replicable approach.1",
        "individual fairness",
        "research question",
        "rating companies",
        "Van Hoye",
        "most urgency",
        "equal opportunities",
        "ethical norms",
        "important role",
        "relevant information",
        "algorithmic decision-making",
        "information processing",
        "human raters",
        "employee evaluation",
        "personal contact",
        "reliable picture",
        "discrimination potential",
        "particular field",
        "overall picture",
        "two authors",
        "Distributive justice",
        "informational justice",
        "fairness measures",
        "Search terms",
        "interactional justice",
        "development process",
        "organizational context",
        "evidence-based decisions",
        "decision process",
        "iterative process",
        "interactional fairness",
        "same treatment",
        "possibility",
        "outcome",
        "Rules",
        "equality",
        "equity",
        "accordance",
        "contributions",
        "extent",
        "Leventhal",
        "Consistency",
        "accuracy",
        "representation",
        "parties",
        "correction",
        "appropriateness",
        "dignity",
        "courtesy",
        "respect",
        "share",
        "general",
        "procedures",
        "errors",
        "3 Methods",
        "insights",
        "other",
        "suggestions",
        "Petticrew",
        "Roberts",
        "Crossan",
        "Apaydin",
        "Siddaway",
        "Gough",
        "databases",
        "discussion",
        "keywords",
        "3.1",
        "EBSCO Business Source Premier database",
        "social science citation index",
        "language peer-reviewed journals",
        "first source",
        "singular/plural forms",
        "different spellings",
        "narrow terms",
        "classification terms",
        "complete list",
        "broad coverage",
        "impact factor",
        "reasonable proxy",
        "important publications",
        "reference section",
        "search strings",
        "relevant articles",
        "scholarly literature",
        "electronic databases",
        "terminology",
        "synonyms",
        "contents",
        "priority",
        "balance",
        "sensitivity",
        "specificity",
        "unintentional",
        "omission",
        "SSCI",
        "management",
        "part",
        "Web",
        "Knowledge",
        "breadth",
        "papers"
      ],
      "merged_content": "\nORIGINAL RESEARCH\n\nDiscriminated by an algorithm: a systematic review\nof discrimination and fairness by algorithmic decision-\nmaking in the context of HR recruitment and HR\ndevelopment\n\nAlina Köchling1\n• Marius Claus Wehner1\n\nReceived: 15 October 2019 / Accepted: 1 November 2020 / Published online: 20 November 2020\n\n� The Author(s) 2020\n\nAbstract Algorithmic decision-making is becoming increasingly common as a new\n\nsource of advice in HR recruitment and HR development. While firms implement\n\nalgorithmic decision-making to save costs as well as increase efficiency and\n\nobjectivity, algorithmic decision-making might also lead to the unfair treatment of\n\ncertain groups of people, implicit discrimination, and perceived unfairness. Current\n\nknowledge about the threats of unfairness and (implicit) discrimination by algo-\n\nrithmic decision-making is mostly unexplored in the human resource management\n\ncontext. Our goal is to clarify the current state of research related to HR recruitment\n\nand HR development, identify research gaps, and provide crucial future research\n\ndirections. Based on a systematic review of 36 journal articles from 2014 to 2020,\n\nwe present some applications of algorithmic decision-making and evaluate the\n\npossible pitfalls in these two essential HR functions. In doing this, we inform\n\nresearchers and practitioners, offer important theoretical and practical implications,\n\nand suggest fruitful avenues for future research.\n\nKeywords Fairness � Discrimination � Perceived fairness � Ethics �\nAlgorithmic decision-making in HRM � Literature review\n\n1 Introduction\n\nAlgorithmic decision-making in human resource management (HRM) is becoming\n\nincreasingly common as a new source of information and advice, and it will gain\n\nmore importance due to the rapid growth of digitalization in organizations.\n\n& Alina Köchling\n\nalina.koechling@hhu.de\n\n1 Faculty of Business Administration and Economics, Heinrich-Heine-University Düsseldorf,\n\nUniversitätsstrasse 1, 40225 Dusseldorf, Germany\n\n123\n\nBusiness Research (2020) 13:795–848\n\nhttps://doi.org/10.1007/s40685-020-00134-w\n\nhttp://orcid.org/0000-0001-7039-9852\nhttp://orcid.org/0000-0002-1932-3155\nhttp://crossmark.crossref.org/dialog/?doi=10.1007/s40685-020-00134-w&amp;domain=pdf\nhttps://doi.org/10.1007/s40685-020-00134-w\n\n\nAlgorithmic decision-making is defined as automated decision-making and remote\n\ncontrol, as well as standardization of routinized workplace decisions (Möhlmann\n\nand Zalmanson 2017). Algorithms, instead of humans, make decisions, and this has\n\nimportant individual and societal implications in organizational optimization\n\n(Chalfin et al. 2016; Lee 2018; Lindebaum et al. 2019). These changes in favor\n\nof algorithmic decision-making make it easier to discover hidden talented\n\nemployees in organizations and review a large number of applications automatically\n\n(Silverman and Waller 2015; Carey and Smith 2016; Savage and Bales 2017). In a\n\nsurvey of 200 artificial intelligence (AI) specialists from German companies, 79%\n\nstated that AI is irreplaceable for competitive advantages (Deloitte 2020). Several\n\ncommercial providers, such as Google, IBM, SAP, and Microsoft, already offer\n\nalgorithmic platforms and systems that facilitate current human resource (HR)\n\npractices, such as hiring and performance measurements (Walker 2012). In turn,\n\nwell-known and large companies, such as Vodafone, Intel, Unilever, and Ikea, apply\n\nalgorithmic decision-making in HR recruitment and HR development (Daugherty\n\nand Wilson 2018; Precire 2020).\n\nThe major driving forces for algorithmic decision-making are savings in both\n\ncosts and time, minimizing risks, enhancing productivity, and increasing certainty in\n\ndecision-making (Suen et al. 2019; McDonald et al. 2017; McColl and Michelotti\n\n2019; Woods et al. 2020). Besides these economic reasons, firms seek to diminish\n\nthe human biases (e.g., prejudices and personal beliefs) by applying algorithmic\n\ndecision-making, thereby increasing the objectivity, consistency, and fairness of the\n\nHR recruitment as well as HR development processes (Langer et al. 2019;\n\nFlorentine 2016; Raghavan et al. 2020). For example, Deloitte argues that the\n\nalgorithmic decision-making system always manages each application with the\n\nsame attention according to the same requirements and criteria (Deloitte 2018). At\n\nfirst glance, algorithmic decision-making seems to be more objective and fairer than\n\nhuman decision-making (Lepri et al. 2018).\n\nHowever, there is a possible threat of discrimination and unfairness by relying\n\nsolely on algorithmic decision-making (e.g., (Lee 2018; Lindebaum et al. 2019;\n\nSimbeck 2019)). In general, discrimination is defined as the unequal treatment of\n\ndifferent groups based on gender, age, or ethnicity instead of on qualitative\n\ndifferences, such as individual performance (Arrow 1973). Algorithms produce\n\ndiscrimination or biased outcomes if they are trained on inaccurate (Kim 2016),\n\nbiased (Barocas and Selbst 2016), or unrepresentative input data (Suresh and Guttag\n\n2019). Consequently, algorithms are vulnerable to produce or replicate biased\n\ndecisions if their input (or training) data are biased (Chander 2016).\n\nComplicating this issue, biases and discrimination are often only recognized after\n\nalgorithms have made a decision. As a prominent example stemming from the\n\ncurrent debate around transparency, bias, and fairness in algorithmic decision-\n\nmaking (Dwork et al. 2012; Lepri et al. 2018; Diakopoulos 2015), the hiring\n\nalgorithms applied by the American e-commerce specialist Amazon yielded an\n\nextreme disadvantage of female applicants, which finally led Amazon to shut down\n\nthe complete algorithmic decision-making for their hiring decision (Dastin 2018;\n\nMiller 2015). Thus, the lack of transparency and accountability of the input data, the\n\nalgorithm itself, and the factors influencing algorithmic outcomes are potential\n\n796 Business Research (2020) 13:795–848\n\n123\n\n\n\nissues associated with algorithmic decision-making (Citron and Pasquale 2014;\n\nPasquale 2015). Another question remains whether applicants and/or employees\n\nperceive the algorithmic decision-making to be fair. Previous studies showed that\n\napplicants’ and employees’ acceptance of algorithmic decision-making is lower in\n\nHR recruitment and HR development compared to common procedures conducted\n\nby humans (Kaibel et al. 2019; Langer et al. 2019; Lee 2018).\n\nConsequently, there is a discrepancy between the enthusiasm about algorithmic\n\ndecision-making as a panacea for inefficiencies and labor shortages on one hand and\n\nthe threat of discrimination and unfairness of algorithmic decision-making on the\n\nother side. While the literature in the field of computer science has already\n\naddressed the issues of biases, knowledge about the potential downsides of\n\nalgorithmic decision-making is still in its infancy in the field of HRM despite its\n\nimportance due to increased digitization and automation in HRM. This heteroge-\n\nneous state of research on discrimination and fairness raises distinct challenges for\n\nfuture research. From a practical point of view, it is problematic if large and well-\n\nknown companies implement algorithms without being aware of the possible pitfalls\n\nand negative consequences. Thus, to move the field forward, it is paramount to\n\nsystematically review and synthesize existing knowledge about biases and\n\ndiscrimination in algorithmic decision-making and to offer new research avenues.\n\nThe aim of this study is threefold. First, this review creates an awareness of\n\npotential biases and discrimination resulting from algorithmic decision-making in\n\nthe context of HR recruitment and HR development. Second, this study contributes\n\nto the current literature by informing both researchers and practitioners about the\n\npotential dangers of algorithmic decision-making in the HRM context. Finally, we\n\nguide future research directions with an understanding of existing knowledge and\n\ngaps in the literature. To this end, the present paper conducts a systematic review of\n\nthe current literature with a focus on HR recruitment and HR development. These\n\ntwo HR functions deal with the potential of future and current employees and the\n\n(automatic) prediction of person-organization fit, career development, and future\n\nperformance (Huselid 1995; Walker 2012). Decisions made by algorithms and AI in\n\nthese two important HR areas have serious consequences for individuals, the\n\ncompany, and society concerning ethics and both procedural and distributive\n\nfairness (Ötting and Maier 2018; Lee 2018; Tambe et al. 2019; Cappelli et al. 2020).\n\nOur study contributes to the existing body of research in several ways. First, the\n\nsystematic literature review contributes to the literature by highlighting the current\n\ndebate on ethical issues associated with algorithmic decision-making, including bias\n\nand discrimination (Barocas and Selbst 2016). Second, our research provides\n\nillustrative examples of various algorithmic decision-making tools used in HR\n\nrecruitment, HR development, and their potential for discrimination and perceived\n\nfairness. Moreover, our systematic review underlines the fact that it is a timely topic\n\ngaining enormous importance. Companies will face legal and reputational risk if\n\ntheir HR recruitment and HR development methods turn out to be discriminatory,\n\nand applicants and employees may consider the algorithmic selection or develop-\n\nment process to be unfair.\n\nFor this reason, companies need to know that the use of algorithmic decision-\n\nmaking can yield to discrimination, unfairness, and dissatisfaction in the context of\n\nBusiness Research (2020) 13:795–848 797\n\n123\n\n\n\nHRM. We offer an understanding of how discrimination might arise when\n\nimplementing algorithmic decision-making. We try to give guidance on how\n\ndiscrimination and perceived unfairness could be avoided and provide detailed\n\ndirections for future research in the existing literature, especially in the HRM field.\n\nMoreover, we identify several research gaps, mainly a lacking focus on perceived\n\nfairness.\n\nThe paper is organized as follows: first, we give an understanding of key terms\n\nand definitions. Afterward, we present the methodology of our systematic literature\n\nreview accompanied by a descriptive analysis of the reviewed literature. This is\n\nfollowed by an illustration of the current state of knowledge on algorithmic\n\ndecision-making and subsequent discussion. Finally, we offer practical as well as\n\ntheoretical implications and outline future research avenues.\n\n2 Conceptual background and definitions\n\n2.1 Definition of algorithms\n\nThe Oxford Living Dictionary defines algorithms as ‘‘processes or sets of rules to be\n\nfollowed in calculations or other problem-solving operations, especially by a\n\ncomputer.’’ Möhlmann and Zalmanson (2017) refer to algorithmic decision-making\n\nas automated decision-making and remote control, and standardization of routinized\n\nworkplace decision. Thus, in this paper, we use the term algorithmic decision-\n\nmaking to describe a computational mechanism that autonomously makes decisions\n\nbased on rules and statistical models without explicit human interference (Lee\n\n2018). Algorithms are the basis for several AI decision tools.\n\nAI is an umbrella term for a wide array of models, methods, and prescriptions\n\nused to simulate human intelligence, often when it comes to collecting, processing,\n\nand acting on data. AI applications can apply rules, learn over time through the\n\nacquisition of new data and information, and adapt to changes in the environment\n\n(Russell and Norvig 2016). AI includes several different research areas, such as\n\nmachine learning (ML), speech and image recognition, and natural language\n\nprocessing (NLP) (Kaplan and Haenlein 2019; Paschen et al. 2020).\n\nAs mentioned, the basis for many AI decision-making tools used in HR are ML\n\nalgorithms, which can be categorized into three major types: supervised, unsuper-\n\nvised, and reinforcement learning (Lee and Shin 2020). Supervised ML algorithms\n\naim to make predictions (often divided into classification- or regression-type\n\nproblems), given the input data and desired outputs considered as the ground truth.\n\nHuman experts often provide these labels and thus provide the algorithm with the\n\nground truth. To replicate human decisions or to make predictions, the algorithm\n\nlearns patterns from the labeled data and develops rules, which can be applied for\n\nfuture instances for the same problem (Canhoto and Clear 2020). In contrast, in\n\nunsupervised ML, only input data are given, and the model learns patterns from the\n\ndata without a priori labeling (Murphy 2012). Unsupervised ML algorithms capture\n\nthe structural behaviors of variables in the input data for theme analysis or grouping\n\n798 Business Research (2020) 13:795–848\n\n123\n\n\n\ndata (Canhoto and Clear 2020). Finally, reinforcement learning, as a separate group\n\nof methods, is not based on fixed input/output data. Instead, the ML algorithm learns\n\nbehavior through trial-and-error interactions with a dynamic environment (Kael-\n\nbling et al. 1996).\n\nFurthermore, instead of grouping ML models as supervised, unsupervised, or\n\nreinforcement type learning, the methodologies of algorithms may also be used to\n\ncategorize ML models. Examples are probabilistic models, which may be used in\n\nsupervised or unsupervised settings (Murphy 2012), or deep learning models (Lee\n\nand Shin 2020), which rely on artificial neural networks and perform complex\n\nlearning tasks. In supervised settings, neural network models often determine the\n\nrelationship between input and output using network structures containing the so-\n\ncalled hidden layers, meaning phases of transformation of the input data. Single\n\nnodes of these layers (neurons) were first modeled after neurons in the human brain,\n\nand they resemble human thinking (Bengio et al. 2017). In other settings, deep\n\nlearning may be used, for instance, to (1) process information through multiple\n\nstages of nonlinear transformation; or (2) determine features, representations of the\n\ndata providing an advantage for, e.g., prediction tasks (Deng and Yu 2014).\n\n2.2 Reason for biases\n\nFor any estimation bY of a random variable Y , bias refers to the difference between\n\nthe expected values of bY and Y and is also referred to as systematic error\n\n(Kauermann and Kuechenhoff 2010; Goodfellow et al. 2016). Cognitive biases,\n\nspecifically, are systematic errors in human judgment when dealing with uncertainty\n\n(Kahneman et al. 1982). These cognitive biases are thought to be transferred to\n\nalgorithmic evaluations or predictions, where bias may refer to ‘‘computer systems\n\nthat systematically and unfairly discriminate against certain individuals or groups in\n\nfavor of others’’ (Friedman and Nissenbaum 1996, p. 332).\n\nAlgorithms are often characterized as ‘‘black box’’. In the context of HRM,\n\nCheng and Hackett (2019) characterize algorithms as ‘‘glass boxes’’, since some,\n\nbut not all, components of the theory are reflective. In this context, the consideration\n\nand distinction of the three core elements are necessary, namely, transparency,\n\ninterpretability, and explainability (Roscher et al. 2020). Transparency is concerned\n\nwith the ML approach, while interpretability is concerned with the ML model in\n\ncombination with the data, which means the making sense of the obtained ML\n\nmodel (Roscher et al. 2020). Finally, explainability comprises the model, the data,\n\nand human involvement (Roscher et al. 2020). Concerning the former, transparency\n\ncan be distinguished at three different levels: ‘‘[…] at the level of the entire model\n\n(simulatability), at the level of individual components, such as parameters\n\n(decomposability), and at the level of the training (algorithmic transparency)’’\n\n(Roscher et al. 2020, p. 4). Interpretability concerns the characteristics of an ML\n\nmodel that need to be understood by a human (Roscher et al. 2020). Finally, the\n\nelement of explainability is paramount in HRM. Contextual information of human\n\nand their knowledge from the domain of HRM are necessary to explain the different\n\nsets of interpretations and derive conclusions about the results of the algorithms\n\nBusiness Research (2020) 13:795–848 799\n\n123\n\n\n\n(Roscher et al. 2020). Especially in HRM, in which ML algorithms are increasingly\n\nused for prediction of variables of interest to the HR department (e.g., personality\n\ncharacteristics, employee satisfaction, and turnover intentions), it is essential to\n\nunderstand how the ML algorithm operates (e.g., how the ML algorithm uses data\n\nand weighs specific criteria) and the underlying reasons for the produced decision.\n\nIn the following, we will outline the main reasons for biases in algorithmic\n\ndecision-making and briefly summarize different biases, namely historical, repre-\n\nsentation, technical, and emergent bias. One of the main reasons for bias in\n\nalgorithmic decision-making is the quality of input data, because algorithms learn\n\nfrom historical data as an example; thus, the learning process depends on the\n\nexposed examples (Friedman and Nissenbaum 1996; Barocas and Selbst 2016;\n\nDanks and London 2017). The input data are usually historical. Consequently, if the\n\ninput data set is biased in one way or another, the subsequent analysis is biased, as\n\nwell (keyword: ‘‘garbage in, garbage out’’). For example, if the input data of an\n\nalgorithm include implicit or explicit human judgments, stereotypes, or biases, an\n\naccurate algorithmic output will inevitably entail these human judgments, stereo-\n\ntypes, and prejudices (Diakopoulos 2015; Suresh and Guttag 2019; Barfield and\n\nPagallo 2018). This bias usually exists before the creation of the system and may not\n\nbe apparent at first glance. In turn, the algorithm replicates these preexisting biases,\n\nbecause it treats all information, in which a certain kind of discrimination or bias is\n\nembedded, as a valid example (Barocas and Selbst 2016; Lindebaum et al. 2019). In\n\nthe worst case, the algorithm can yield racist or discriminatory outputs (Veale and\n\nBinns 2017). Algorithms exhibit these tendencies, even if it is not the intention of\n\nthe manual programming since they compound the historical biases of the past.\n\nThus, any predictive algorithmic decision-making tool built on historical data may\n\ninherit historical biases (Datta et al. 2015).\n\nAs an example from the recruitment process, if an algorithm is trained on\n\nhistorical employment data, integrating an implicit bias that favors white men over\n\nHispanics, then, without even being fed data on gender or ethnicity, an algorithm\n\nmay recognize patterns in the data, which expose an applicant as a member of a\n\ncertain protected group, which, historically, is less likely to be chosen for a job\n\ninterview. This, in turn, may lead to a systematic disadvantage of certain groups,\n\neven if the designer has no intention of marginalizing people based on these\n\ncategories and if the algorithm is not directly given this information (Barocas and\n\nSelbst 2016).\n\nAnother reason for biases in algorithms related to the input data is that certain\n\ngroups or characteristics are mostly underrepresented or sometimes overrepre-\n\nsented, which is also called representation bias (Barocas and Selbst 2016; Suresh\n\nand Guttag 2019; Barfield and Pagallo 2018). Any decision based on this kind of\n\nbiased data might lead to disadvantages of groups of individuals who are\n\nunderrepresented or overrepresented (Barocas and Selbst 2016). Another reason\n\nfor representation bias can be the absence of specific information (Barfield and\n\nPagallo 2018). Thus, not only the selection of measurements but also the\n\npreprocessing of the measurement data might yield to bias. ML models often\n\nevolve in several steps of feature engineering or model testing, since there is no\n\nuniversally best model (as shown in the ‘‘no free lunch’’ theorems, [see Wolpert and\n\n800 Business Research (2020) 13:795–848\n\n123\n\n\n\nMacready (1997)]. Here, the choice of the benchmark or rather the value indicating\n\nthe performance of the model is optimized through rotations of different\n\nrepresentations of the data and methods for prediction. For example, representative\n\nbias might occur if females in comparison to males are underrepresented in the\n\ntraining data of an algorithm. Hence, the outcome could be in favor of the\n\noverrepresented group (i.e., males) and, hence, lead to discriminatory outcomes.\n\nTechnical bias may arise from technical constraints or technical consideration for\n\nseveral reasons. For example, technical bias can originate from limited ‘‘[…]\n\ncomputer technology, including hardware, software, and peripherals’’ (Friedman\n\nand Nissenbaum 1996, p. 334). Another reason could be a decontextualized\n\nalgorithm that does not manage to treat all groups fairly under all important\n\nconditions (Friedman and Nissenbaum 1996; Bozdag 2013). The formalization of\n\nhuman constructs to computers can be another problem leading to technical bias.\n\nHuman constructs, such as judgments or intuitions, are often hard to quantify, which\n\nmakes it difficult or even impossible to translate them to the computer (Friedman\n\nand Nissenbaum 1996). As an example, the human interpretation of law can be\n\nambiguous and highly dependent on the specific context, making it difficult for an\n\nalgorithmic system to correctly advise in litigation (c.f., Friedman and Nissenbaum\n\n1996).\n\nIn the context of real users, emergent bias may arise. Typically, this bias occurs\n\nafter the construction as a result of changed societal knowledge, population, or\n\ncultural values (Friedman and Nissenbaum 1996). Consequently, a shift in the\n\ncontext of use might yield to problems and an emergent bias due to two reasons,\n\nnamely ‘‘new societal knowledge’’ and ‘‘mismatch between users and system\n\ndesign’’ (see Table 1 in Friedman and Nissenbaum 1996, p. 335). If it is not possible\n\nto incorporate new knowledge in society into the system design, emergent bias due\n\nto new societal knowledge occurs. The mismatch between users and system design\n\ncan occur due to changes in state-of-the-art-research or due to different values. Also,\n\nemergent bias can occur if a population uses the system with different values than\n\nthose assumed in the design process (Friedman and Nissenbaum 1996). Problems\n\noccur, for example, when users originate from a cultural context that avoids\n\ncompetition and promotes cooperative efforts, while the algorithm is trained to\n\nreward individualistic and competitive behavior (Friedman and Nissenbaum 1996).\n\n2.3 Fairness and discrimination in information systems\n\nLeventhal (1980) describes fairness as equal treatment based on people’s\n\nperformance and needs. Table 1 offers an overview of the different fairness\n\ndefinitions. Individual fairness means that, independent of group membership, two\n\nindividuals who are perceived to be similar by the measures at hand should also be\n\ntreated similarly (Dwork et al. 2012). Rising from the micro-level onto the meso-\n\nlevel, Dwork et al. (2012) also proposed another measure of fairness, that is, group\n\nfairness, in which entire (protected) groups of people are required to be treated\n\nsimilarly (statistical parity). Hardt et al. (2016) extended these notions by including\n\ntrue outcomes of predicted variables to achieve fair treatment. In their sense, false-\n\nBusiness Research (2020) 13:795–848 801\n\n123\n\n\n\npositives/negatives are sources of disadvantage and should be equal among groups\n\nmeans equal opportunity for false-positives/negatives (Hardt et al. 2016).\n\nUnfair treatment of certain groups of people or individual subjects yields to\n\ndiscrimination. Discrimination is defined as the unequal treatment of different\n\ngroups (Arrow 1973). Discrimination is very similar to unfairness. Discriminatory\n\ncategories can be strongly correlated with non-discriminatory categories, such as\n\nage (i.e., discriminatory) and years of working experience (non-discriminatory)\n\n(Persson 2016). Also, there is a difference between implicit and explicit\n\ndiscrimination. Implicit discrimination is based on implicit attitudes or stereotypes\n\nand often unintentional (Bertrand et al. 2005). In contrast, explicit discrimination is\n\na conscious process due to an aversion to certain groups of people. In HR\n\nrecruitment and HR development, discrimination means the not-hiring or support of\n\na person due to characteristics not related to that person’s productivity in the current\n\nposition (Frijters 1998).\n\nThe HR literature, especially the literature on personnel selection, is concerned\n\nwith fairness in hiring decisions, because every selection measure of individual\n\ndifferences is inevitably discriminatory (Cascio and Aguinis 2013). However, the\n\nquestion arises ‘‘whether the measure discriminates unfairly’’ (Cascio and Aguinis\n\n2013, p. 183). Hence, the actual fairness of prediction systems needs to be tested\n\nbased on probabilities and estimates, which we refer to as objective fairness. In the\n\nselection context, the literature distinguishes between differential validity (i.e.,\n\ndifferences in subgroup validity) and differential prediction (i.e., differences in\n\nslopes and intercepts of subgroups), and both might lead to biased results (Meade\n\nand Fetzer 2009; Roth et al. 2017; Bobko and Bartlett 1978).\n\nIn HR recruitment and HR development, both objective fairness and subjective\n\nfairness perceptions of applicants and employees about the usage of algorithmic\n\ndecision-making need to be considered. In this regard, perceived fairness or justice\n\nis more a subjective and descriptive personal evaluation rather than an objective\n\nreality (Cropanzano et al. 2007). Subjective fairness plays an essential role in the\n\nrelationship between humans and their employers. Previous studies showed that the\n\nTable 1 Definitions of fairness\n\nName Author Definition\n\nIndividual\n\nfairness\n\nDwork et al.\n\n(2012)\n\n‘‘Similar’’ subjects should have ‘‘similar’’ classifications\n\nGroup\n\nfairness\n\nSubjects in protected and unprotected groups have an equal probability\n\nof being assigned positive\n\nP bY ¼ 1\n� �\n\n�\n\n�G ¼ 1Þ ¼ Pð bY ¼ 1jG ¼ 0Þ\n\nEqual\n\nopportunity\n\nHardt et al.\n\n(2016)\n\nFalse-negative rates should be equal\n\nP bY ¼ 0\n� �\n\n�\n\n�Y ¼ 1;G ¼ 1Þ ¼ Pð bY ¼ 0jY ¼ 1;G ¼ 0Þ\n\nY 2 0; 1f g is a random variable describing, e.g., the recidivism of a subject, bY its estimator and G 2\nf0; 1g; describes whether a subject is a member of a certain protected group (G ¼ 1Þ or not ðG ¼ 0Þ\n\n802 Business Research (2020) 13:795–848\n\n123\n\n\n\nlikelihood of conscientious behavior and altruisms is higher for employees who feel\n\ntreated fairly (Cohen-Charash and Spector 2001). Conversely, unfairness can have\n\nconsiderable adverse consequences. For example, in the recruitment context,\n\nfairness perceptions of candidates during the selection process have important\n\nconsequences for decision to stay in the applicant pool or accept a job offer (Bauer\n\net al. 2001). Therefore, it is crucial to know how people feel about algorithmic\n\ndecision-making taking over managerial decisions formerly made by humans, since\n\nthe fairness perceptions during the recruitment process and/or training process have\n\nessential and meaningful effects on attitudes, performance, morale, intentions, and\n\nbehavior (e.g., the acceptance or rejection of a job offer or job turnover, job\n\ndissatisfaction, and reduction or elimination of conflicts) (Gilliland 1993; McCarthy\n\net al. 2017; Hausknecht et al. 2004; Cropanzano et al. 2007; Cohen-Charash and\n\nSpector 2001). Moreover, negative experiences might damage the employer�s\nimage. Several online platforms offer the possibility of rating companies and their\n\nrecruitment and development process (Van Hoye 2013; Woods et al. 2020).\n\nConsidering justice and fairness in the organizational context (Gilliland 1993),\n\nthere are three core dimensions of justice: distributive, procedural, and interactional.\n\nThe three dimensions tend to be correlated. Distributive justice deals with the\n\noutcome that some humans receive and some do not (Cropanzano et al. 2007). Rules\n\nthat can lead to distributive justice are ‘‘[…] equality (to each the same), equity (to\n\neach in accordance with contributions, and need (to each in accordance with the\n\nmost urgency)’’ (Cropanzano et al. 2007, p. 37). To some extent, especially\n\nconcerning equity, this can be connected with individual fairness and group fairness\n\nfrom Dwork et al. (2012) and equal opportunities from Hardt et al. (2016).\n\nProcedural justice means that the process is consistent with all humans, not\n\nincluding bias, accurate, and consistent with the ethical norms (Cropanzano et al.\n\n2007; Leventhal 1980). Consistency plays an essential role in procedural justice,\n\nmeaning that all employees and all candidates need to receive the same treatment.\n\nAdditionally, the lack of bias, accuracy, representation of all parties, correction, and\n\nethics play an important role in achieving a high procedural justice (Cropanzano\n\net al. 2007). In contrast, interactional justice is about the treatment of humans,\n\nmeaning the appropriateness of the treatment from another member of the company,\n\nthe treatment with dignity, courtesy, and respect, and informational justice (share of\n\nrelevant information) (Cropanzano et al. 2007).\n\nIn general, algorithmic decision-making increases the standardization of\n\nprocedures, so that decisions should be more objective and less biased, and errors\n\nshould occur less frequently (Kaibel et al. 2019), since information processing by\n\nhuman raters can be unsystematic, leading to contradictory and insufficient\n\nevidence-based decisions (Woods et al. 2020). Consequently, procedural justice and\n\ndistributive justice are higher using algorithmic decision-making, because the\n\nprocess is more standardized, which still not means that it is without bias.\n\nHowever, especially in the context of an application or an employee evaluation, it\n\nis not only about how fair the procedure itself is (according to fairness measures),\n\nbut it is also about how people involved in the decision process perceive the fairness\n\nof the whole process. Often the personal contact, which characterizes the\n\nBusiness Research (2020) 13:795–848 803\n\n123\n\n\n\ninteractional fairness, is missing when using algorithmic decision-making. It is\n\ndifficult to fulfill all three fairness dimensions.\n\n3 Methods\n\nThis systematic literature review aims at offering a coherent, transparent, and\n\nreliable picture of existing knowledge and providing insights into fruitful research\n\navenues about the discrimination potential and fairness when using algorithmic\n\ndecision-making in HR recruitment and HR development. This is in line with other\n\nsystematic literature reviews that organize, evaluate, and synthesize knowledge in a\n\nparticular field and provide an overall picture of knowledge and suggestions for\n\nfuture research (Petticrew and Roberts 2008; Crossan and Apaydin 2010; Siddaway\n\net al. 2019). To this end, we followed the systematic literature review approach\n\ndescribed by Siddaway et al. (2019) and Gough et al. (2017) to ensure a methodical,\n\ntransparent, and replicable approach.1\n\n3.1 Search terms and databases\n\nWe engaged in an extensive keyword searching, which we derived in an iterative\n\nprocess of search and discussion between the two authors of this study (see\n\n‘‘Appendix’’ for the employed keywords). According to our research question, we\n\nfirst defined individual concepts to create search terms. We considered different\n\nterminology, including synonyms, singular/plural forms, different spellings, broader\n\nvs. narrow terms, and classification terms of databases to categorize contents\n\n(Siddaway et al. 2019) (see Table 2 for a complete list of employed keywords and\n\nsearch strings). Our priority was to achieve the balance between sensitivity and\n\nspecificity to get broad coverage of the literature and to avoid the unintentional\n\nomission of relevant articles (Siddaway et al. 2019).\n\nAs the first source of data, we used the social science citation index (SSCI) to\n\nensure broad coverage of scholarly literature. This database covers English-\n\nlanguage peer-reviewed journals in business and management. As part of the Web\n\nof Knowledge, the database includes all journals with an impact factor, which is a\n\nreasonable proxy for the most important publications in the field. We completed our\n\nsearch with the EBSCO Business Source Premier database to add further breadth.\n\nSince electronic databases are not fully comprehensive, we additionally searched in\n\nthe reference section of the considered papers and manually searched for articles\n\n(Siddaway et ",
      "text": [],
      "layoutText": []
    },
    {
      "@search.score": 3.9630344,
      "content": "\nContext‑aware rule learning \nfrom smartphone data: survey, challenges \nand future directions\nIqbal H. Sarker1,2*\n\nIntroduction\nIn recent days, smartphones have become an essential part of our daily life and con-\nsidered as highly personal devices of individuals. These devices are also known as one \nof the most important IoT (Internet of Things) devices, because of their capabilities \nto interconnect their users with the Internet, and corresponding data processing [1]. \nSmartphones are also considered as “next generation, multifunctional cell phones that \nfacilitates data processing as well as enhanced wireless connectivity” [2]. The cellular net-\nwork coverage has reached 96.8% of the world population, and this number even reaches \n100% of the population in the developed countries [3]. In recent statistics, according to \nGoogle Trends [4] we have shown in Fig.  1, that users’ interest on “Mobile Phones” is \nmore and more than other platforms like “Desktop Computer”, “Laptop Computer” or \n\nAbstract \n\nSmartphones are considered as one of the most essential and highly personal devices \nof individuals in our current world. Due to the popularity of context-aware technol-\nogy and recent developments in smartphones, these devices can collect and process \nraw contextual data about users’ surrounding environment and their corresponding \nbehavioral activities with their phones. Thus, smartphone data analytics and building \ndata-driven context-aware systems have gained wide attention from both academia \nand industry in recent days. In order to build intelligent context-aware applications on \nsmartphones, effectively learning a set of context-aware rules from smartphone data \nis the key. This requires advanced data analytical techniques with high precision and \nintelligent decision making strategies based on contexts. In comparison to traditional \napproaches, machine learning based techniques provide more effective and efficient \nresults for smartphone data analytics and corresponding context-aware rule learning. \nThus, this article first makes a survey on previous work in the area of contextual smart-\nphone data analytics and then presents a discussion of challenges and future directions \nfor effectively learning context-aware rules from smartphone data, in order to build \nrule-based automated and intelligent systems.\n\nKeywords: Smartphone data, Machine learning, Data science, Clustering, \nClassification, Association, Rule learning, Personalization, Time-series, User behavior \nmodeling, Predictive analytics, Context-aware computing, Mobile and IoT services, \nIntelligent systems\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nSarker  J Big Data            (2019) 6:95  \nhttps://doi.org/10.1186/s40537‑019‑0258‑4\n\n*Correspondence:   \nmsarker@swin.edu.au \n1 Swinburne University \nof Technology, \nMelbourne VIC-3122, \nAustralia\nFull list of author information \nis available at the end of the \narticle\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-019-0258-4&domain=pdf\n\n\nPage 2 of 25Sarker  J Big Data            (2019) 6:95 \n\n“Tablet Computer” for the last 5 years from 2014 to 2019. Figure 1 represents timestamp \ninformation in terms of particular date in x-axis and corresponding search interests in \nthe range of 0 to 100 in terms of popularity relative to the highest point on the chart in \ny-axis. For instance, a value of 100 (maximum) in y-axis represents the peak popularity \nfor a particular term, while 0 (minimum) means the term was lowest in terms of popu-\nlarity [4].\n\nDue to the advanced features and recent developments in smartphones, these devices \ncan collect raw contextual data about users’ surrounding environment and their corre-\nsponding behavioral activities with their phones in a daily basis [5]. As a result, smart-\nphone data becomes a great source to understand users’ behavioral activity patterns in \ndifferent contexts, and to derive useful information, i.e., context-aware rules, for the pur-\npose of building rule-based intelligent context-aware systems. A context-aware rule has \ntwo parts, which follows “IF-THEN” logical structure to formulate [6]. The antecedent \npart represents users’ surrounding contextual information, e.g., temporal context, spa-\ntial context, social contexts, or others relevant contextual information and the conse-\nquent part represents their corresponding behavioral activities or usage. Let’s consider \nan example of a context-aware mobile notification management system for a smart-\nphone user Alice. A context-aware rule for such system could be “The user typically \ndismisses mobile notifications while at work; however, accepts the notifications in the \nevening from her family members, even though she is in work”. A set of such context-\naware behavioral rules including general and specific exceptions, may vary from user-to-\nuser according to their preferences. In addition to the personalized services mentioned \nabove, the relevant context-aware rules in different surrounding contexts could be appli-\ncable to other broad application areas, like context-aware  software and IoT services, \nintelligent eHealth services, and context-aware smart city services, intelligent cybersecu-\nrity services etc. utilizing the relevant contextual data of that particular domain. Overall, \nthis study is typically for those data science and machine learning researchers, and prac-\ntitioners who particularly want to work on data-driven intelligent context-aware systems \nand services based on machine learning rules.\n\nEffectively learning context-aware rules from smartphone data is challenging because \nof many reasons, ranging from understanding raw data to applications. A number of \nresearch [7–9] has been done on mining context-aware rules from smartphone data for \nvarious purposes. However, to effectively learn such rules for the purpose of building \n\nFig. 1 Users’ interest trends over time, where x-axis and y-axis represent a particular timestamp and \ncorresponding search interests in numeric values in terms of world-wide popularity respectively\n\n\n\n\n\nPage 3 of 25Sarker  J Big Data            (2019) 6:95 \n\nintelligent context-aware systems, a deeper analysis in contextual data patterns and \nlearning according to individuals’ usage is needed. Thus, advanced data analysis based \non machine learning techniques, can be used to make effective and efficient decision-\nmaking capabilities in different context-aware test cases for smartphones. Several \nmachine learning and data mining techniques, such as contextual data clustering, fea-\nture optimization and selection, rule-based classification and association analysis, incre-\nmental learning for dynamic updating and management, and corresponding rule-based \nprediction model can be designed to provide smartphone data analytic solutions. The \nreason is that such machine learning techniques can be more accurate, and more precise \nfor analyzing huge amount of contextual data. The aim of these advanced analytic tech-\nniques is to discover information, hidden patterns, and unknown correlations among the \ncontexts and eventually generate context-aware rules. For instance, a detailed analysis \nof time-series data and corresponding data clustering based on similar behavioral pat-\nterns, could lead to capture the diverse behaviors of an individual’s activities, thereby \nenabling more optimal time-based context-aware rules than the traditional approaches \n[10]. Thus, intelligent data-driven decisions using machine learning techniques can \nprofit better decision making capability over the traditional approaches while consider-\ning the multi-dimensional contexts.\n\nBased on our survey and analysis on existing research, little work has been done in \nterms of how machine learning techniques significantly impact on contextual smart-\nphone data and to learn corresponding context-aware rules. To address this short-\ncoming, this article first makes a survey on previous work in the area of contextual \nsmartphone data analytics in several perspectives involved in context-aware rules, such \nas time-series modeling that is also known as a discretization of temporal context, rule \ndiscovery techniques, and incremental learning and rule updation techniques, which has \nbeen highlighted in our earlier work [6]. After that this article presents a brief discussion \non challenges and future directions to overcome these issues. Based on our discussion, \nfinally we suggest a machine learning based context-aware rule learning framework for \nthe purpose of effectively learning context-aware rules from smartphone data, in order \nto build rule-based automated and intelligent systems.\n\nThe contributions of this paper are summarized as follows.\n\n• We first make a brief survey on previous work in the area of smartphone data analyt-\nics in several perspectives related to context-aware rule learning and summarize the \nshortcomings of these research.\n\n• We then present a brief discussion on the challenges and future directions to over-\ncome the issues to learn context-aware rules from smartphone data.\n\n• Finally, we suggest a machine learning based context-aware rule learning framework \nand briefly discuss the role of various layers associated with the framework, for the \npurpose of building rule-based intelligent context-aware systems.\n\nTo the best of our knowledge, this is the first article surveying context-aware rule learn-\ning strategies from smrtphone data. The remainder of the paper is organized as follows. \n“Background: contexts and smartphone data” section presents background information \non contexts and contextual smartphone data. “Context-aware rule learning strategies” \n\n\n\nPage 4 of 25Sarker  J Big Data            (2019) 6:95 \n\nsection  surveys previous work in various perspectives related to context-aware rule \nlearning. “Challenges and future directions” section briefly discusses the challenges and \nfuture directions of research regarding context-aware rule learning from smartphone \ndata. In “Suggested machine learning based framework” section we suggest a machine \nlearning based context-aware rule learning framework and discuss various layers with \ntheir roles while learning rules. Context-aware rule based applications section summa-\nrizes a number of real world applications based on context-aware rules. Finally, “Conclu-\nsion” section concludes this paper.\n\nBackground: contexts and smartphone data\nThis section reviews background information on the main characteristics of contexts \nand contextual smartphone data that address learning context-aware rules for the pur-\npose of building rule-based intelligent systems.\n\nCharacteristics of contexts\n\nThe term context can be used with a variety of different meanings in different purposes. \nThe notion of context has been used in numerous areas, including Pervasive and Ubiq-\nuitous Computing, Human Computer Interaction, Computer-Supported Collaborative \nWork, and Ambient Intelligence [11]. In this section, first we briefly review what is con-\ntext in the area of mobile and context-aware computing. In Ubiquitous and Pervasive \nComputing area, early works on context-awareness referred to context as primarily \nthe location of people and objects [12]. In recent works, context has been extended to \ninclude a broader collection of factors, such as physical and social aspects of an entity, \nas well as the activities of users [11]. Having examined the definitions and categories of \ncontext given by the pervasive and ubiquitous computing community, this section seeks \nto define our view of context within the scope of smartphone data analytics. As the defi-\nnitions of context to pervasive and ubiquitous computing area are also broad, this dis-\ncussion is intended to be illustrative rather than exhaustive.\n\nSeveral studies have attempted to define and represent the context from different \nperspectives. For instance, the user’s location information, the surrounding people and \nobjects around the user, and the changes to those objects are considered as contexts by \nSchilit et al. [12]. Brown et al. [13] also define contexts as user’s locational information, \ntemporal information, the surrounding people around the user, temperature, etc. Simi-\nlarly, the user’s locational information, environmental information, temporal informa-\ntion, user’s identity, are also taken into account as contexts by Ryan et  al. [14]. Other \ndefinitions of context have simply provided synonyms for context such as context as the \nenvironment or social situation. A number of researchers are taken into account the \ncontext as the environmental information of the user. For instance, in [15], the environ-\nmental information that the user’s computer knows about are taken into account as con-\ntext by Brown et al., whereas the social situation of the user is considered as a context \nin Franklin et al. [16]. On the other hand, a number of other researchers consider it to \nbe the environment related to the applications. For instance, Ward et al. [17] consider \nthe state of the surrounding information of the applications as contexts. Hull et al. [18] \ndefine context as the aspects of the current situation of the user and include the entire \n\n\n\nPage 5 of 25Sarker  J Big Data            (2019) 6:95 \n\nenvironment. The settings of applications are also treated as context in Rodden et  al. \n[19].\n\nAccording to Schilit et  al. [20] the important aspects of context are: (i) where you \nare, (ii) whom you are with, and (iii) what resources are nearby. The information of the \nchanging environment is taken into account as context in their definition. In addition to \nthe user environment (e.g., user location, nearby people around the user, and the cur-\nrent social situation of the user), they also include the computing environment and the \nphysical environment. For instance, connectivity, available processors, user input and \ndisplay, network capacity, and costs of computing can be the examples of the computing \nenvironment, while the noise level, temperature, the lighting level, can be the examples \nof the physical environment. Dey et al. [21] present a survey of alternative view of con-\ntext, which are largely imprecise and indirect, typically defining context by synonym or \nexample. Finally, they offer the following definition of context, which is perhaps now the \nmost widely accepted. According to Dey et al. [21] “Context is any information that can \nbe used to characterize the situation of an entity. An entity is person, place or object \nthat is considered relevant to the interaction between a user and an application, includ-\ning the user and the application themselves”. Thus, based on the definition of Dey et al. \n[21], we can define context in the scope of this work as “Context is any information that \ncan be used to characterize users’ day-to-day situations that have an influence on their \nsmartphone usage”. An example of relevant contexts could be temporal context, spatial \ncontext, or social context etc. that might have an influence to make individuals’ diverse \ndecisions on smartphone usage in their daily life activities.\n\nContextual smartphone data\n\nWe live in the age of data [22], where everything that surrounds us is linked to a data \nsource and everything in our lives is captured digitally. Mobile or cellular phones have \nbecome increasingly ubiquitous and powerful to log user diverse activities for under-\nstanding their preferences and phone usage behavior. For instance, smart mobile phones \nhave the ability to log various types of context data related to a user’s phone call activities \nabout when the user makes outgoing calls, or accepts, rejects, and misses the incoming \ncalls [23–26]. In addition to such call related meta data, other dimensions of contex-\ntual information such as user location [27], user’s day-to-day situation [28], the social \nrelationship between the caller an callee identified by the individual’s unique phone \ncontact number [29] are also recorded by the smart mobile phones. Thus, call log data \ncollected by the smart mobile phone can be used as a context source to modeling indi-\nvidual mobile phone user behavior in smart context-aware mobile communication sys-\ntems [30]. In addition to voice communication, short message service (SMS) is known \nas text communication service allows the exchange of short text messages of individual \nmobile phone users, using standardized communications rules or protocols. According \nto the International Telecommunication Union [31], short messages have become a mas-\nsive commercial industry, worth over 81 billion dollars globally. The numerous growth \nin the number of mobile phone users in the world has lead to a dramatic increasing of \nspam messages [32]. The SMS log contains all the message including the spam and non-\nspam text messages [32, 33], which can be used in the task of automatic spam filtering \n[25, 32], or predicting good time or bad time to deliver such messages [33].\n\n\n\nPage 6 of 25Sarker  J Big Data            (2019) 6:95 \n\nWith the rapid development of smartphones, people use these devices for using vari-\nous categories of apps such as Multimedia, Facebook, Gmail, Youtube, Skype, Game [9, \n34]. Thus, smartphone apps log contains these usage with relevant contextual informa-\ntion [8, 9, 35–37]. Such logs can be used for mining the contextual behavioral patterns of \nindividual mobile phone users that is, which app is preferred by a particular user under \na certain context to provide personalized context-aware recommendation. In the real \nworld, a variety of smart mobile applications use notifications in order to inform the \nusers about various kinds of events, news or just to send them reminders or alerts. For \ninstance, the notifications of inviting games on social networks, social or promotional \nemails, or a number of predictive suggestions by various smart phone applications, \ne.g., Twitter, Facebook, LinkedIN, WhatsApp, Viver, Skype, Youtube [7]. The extracted \ncontextual patterns from smartphone notification logs can be used to build intelligent \nmobile notification management systems according to their preferences.\n\nUser navigation in the web in another major activities of individual users. Thus, web \nlog contains the information about user mobile web navigation, web searching, e-mail, \nentertainment, chat, misc, news, TV, netting, travel, sport, banking, and related contex-\ntual information [38–40]. Mining contextual usage patterns from such log data, can be \nused to make accurate context-aware predictions about user navigation and to adapt the \nportal structure according to the needs of users. Similarly, game log contains the infor-\nmation about playing various types such games such as action, adventure, casual, puzzle, \nRPG, strategy, sports etc. of individual mobile phone users, and related contextual infor-\nmation [41]. The extracted contextual patterns from such logs data, can be used to build \npersonalized mobile game recommendation system for individual mobile phone users \naccording to their own preferences.\n\nThe ubiquity of smart mobile phones and their computing capabilities for various real \nlife purposes provide an opportunity of using these devices as a life-logging device, i.e., \npersonal e-memories [42]. In a more technical sense, life-logs sense and store individ-\nual’s contextual information from their surrounding environment through a variety of \nsensors available in their smart mobile phones, which are the core components of life-\nlogs such as user phone calls, SMS headers (no content), App use (e.g., Skype, What-\nsapp, Youtube etc.), physical activities form Google play API, and related contextual \ninformation such as WiFi and Bluetooth devices in user’s proximity, geographical loca-\ntion, temporal information [42]. The extracted contextual patterns or behavioral rules of \nindividual mobile phone users utilizing such life log data, can be used to improve user \nexperience in their daily life. In addition to these personalized log data, smartphones are \nalso capable for collecting and processing IoT data [1]. Based on such smartphone data \nhaving contextual information, in this paper, we briefly review the existing rule learn-\ning strategies and discuss the open challenges and opportunities by highlighting future \ndirections for context-aware rule learning.\n\nContext‑aware rule learning strategies\nIn this section, we review existing strategies related to learning rules based on contex-\ntual information in various perspectives. This includes time-series modeling that cre-\nates behavioral data clusters for generating temporal context based rules, contextual rule \n\n\n\nPage 7 of 25Sarker  J Big Data            (2019) 6:95 \n\ndiscovery by taking into account multi-dimensional contexts, such as temporal, spatial \nor social contexts, and incremental learning to dynamic updating of rules.\n\nModeling time‑series smartphone data\n\nTime is the most important context that impacts on mobile user behavior for making \ndecisions [38]. Individual’s behaviors vary over time in the real world and the mobile \nphones record the exact time of all diverse activities of the users with their mobile \nphones. A time series is a sequence of data points ordered in time [43]. However, to use \nsuch time-series data into behavioral rules, an effective modeling of temporal context \nis needed. Thus, time-series segmentation becomes one of the research focuses in this \nstudy as exact time in mobile phone data is not very informative to mine behavioral rules \nof individual mobile phone users. According to [44], time-based behavior modeling is an \nopen problem. Hence, we summarize the existing time-series segmentation approaches \n\nTable 1 Various types of static time segments used in different applications\n\nTime interval type Number \nof segments\n\nUsed time interval and segment details References\n\nEqual 3 Morning [7:00–12:00], afternoon [13:00–18:00] and \nevening [19:00–24:00]\n\nSong et al. [46]\n\nEqual 3 [0:00–7:59], [8:00–15:59] and [16:00–23:59] Rawassizadeh et al. [47]\n\nEqual 4 Morning [6:00–12:00], afternoon [12:00–18:00], \nevening [18:00–24:00] and night [0:00–6:00]\n\nMukherji et al. [48]\n\nEqual 4 Morning [6:00–12:00], afternoon [12:00–18:00], \nevening [18:00–24:00] and night [0:00–6:00]\n\nBayir et al. [49]\n\nEqual 4 Morning, afternoon, evening and night Paireekreng et al. [41]\n\nEqual 4 Morning [6:00–11:59], day [12:00–17:59], evening \n[18:00–23:59], overnight [0:00–5:59]\n\nJayarajah et al. [50]\n\nEqual 4 Night [0:00–6:00 a.m.], morning [6:00 a.m.–12:00 \np.m.], afternoon [12:00–6:00 p.m.], and evening \n[6:00 p.m.–0:00 a.m.]\n\nDo et al. [51]\n\nUnequal 3 Morning (beginning at 6:00 a.m. and ending at \nnoon), afternoon (ending at 6:00 p.m.), night (all \nremaining hours)\n\nXu et al. [52]\n\nUnequal 4 Morning [6:00–12:00], afternoon [12:00–16:00], \nevening [16:00–20:00] and night [20:00–24:00 \nand 0:00–6:00]\n\nMehrotra et al. [7]\n\nUnequal 5 Morning [7:00–11:00], noon [11:00–14:00], after-\nnoon [14:00–18:00] and so on\n\nZhu et al. [9]\n\nUnequal 5 Morning, forenoon, afternoon, evening, and night Oulasvirta et al. [53]\n\nUnequal 5 Morning [7:00–11:00], noon [11:00–14:00], after-\nnoon [14:00–18:00], evening [18:00–21:00], and \nnight [21:00–Next day 7:00]\n\nYu et al. [54]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nNaboulsi et al. [55]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nDashdorj et al. [56]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nShin et al. [57]\n\nUnequal 8 S1[0:00–7:00 a.m.], S2[7:00–9:00 a.m.], S3[9:00–\n11:00 a.m.], S4[11:00 a.m.–2:00 p.m.], S5[2:00–\n5:00 p.m.], S6[5:00–7:00 p.m.], S7[7:00–9:00 p.m.] \nand S8[9:00 p.m.–12:00 a.m.]\n\nFarrahi et al. [58]\n\n\n\nPage 8 of 25Sarker  J Big Data            (2019) 6:95 \n\ninto two broad categories; (i) static segmentation, and (ii) dynamic segmentation, that \nare used in various mobile applications.\n\nStatic segmentation\n\nA static segmentation is easy to understand and can be useful to analyze population \nbehavior comparing across the mobile phone users. In order to generate segments, \nrecently, most of the researchers (shown in Table 1) take into account only the temporal \ncoverage (24-h-a-day) and statically segment time into arbitrary categories (e.g., morn-\ning) or periods (e.g., 1 h). Such static segmentation of time mainly focuses on time inter-\nvals. According to [45], there are mainly two types of time intervals: one is equal and \nanother one is unequal. For instance, four different time segments, i.e., morning [6:00–\n12:00], afternoon [12:00–18:00], evening [18:00–24:00] and night [0:00–6:00] can be an \nexample of equal interval based segmentation because of their same interval length. On \nthe other hand, another four time slots such as morning [6:00–12:00], afternoon [12:00–\n16:00], evening [16:00–20:00] and night [20:00–24:00 and 0:00–6:00] can be an example \nof unequal interval based segmentation. For this example, different lengths of time inter-\nval are used to do the segmentation. In Table 1, we have summarized a number of works \nthat use static segmentation considering either equal or unequal time interval in various \npurposes.\n\nAlthough, various time intervals and corresponding segmentation summarized in \nTable 1 are used in different purposes, these approaches take into account a fixed num-\nber of segments for all users. However, while performing such segmentation users’ behav-\nioral evidence that differs from user-to-user over time in the real world, is not taken into \naccount. Thus, these static generation of segments may not suitable for producing high \nconfidence temporal rules for individual smartphone users. For instance, N1 number \nof segments might give meaningful results for one case, while N2 number of segments \ncould give better results for another case, where N1  = N2 . Therefore, a dynamic segmen-\ntation of time rather than statically generation could be able to reflect individuals’ behav-\nioral evidence over time and can play a role to produce high confidence rules according \nto their usage records.\n\nDynamic segmentation\n\nAs discussed above, a segmentation technique that generates variable number of seg-\nments would be more meaningful to model users’ behavior. Thus, dynamic segmenta-\ntion technique rather than static segmentation can be used in order to achieve the goal. \nIn a dynamic segmentation, the number of segments are not fixed and predefined; may \nchange depending on their behavioral characteristics, patterns or preferences. Several \ndynamic segmentation techniques in terms of generating variable number of segments \nexist for modeling users’ behavioral activities in temporal contexts. A number of authors \nsimply take into account a single parameter, e.g., interval length or base period, to gener-\nate the segments. The number of time segments varies according to this period. If Tmax \nrepresents the whole time period of 24-h-a-day and BP is a base period, then the num-\nber of segments will be Tmax/BP [10]. If the base period increases, the number of time \nsegments decreases and vice-versa. For instance, if the base period is 5 min, then the \nnumber of segments will be the division result of 24-h-a-day and 5. In this example, a \n\n\n\nPage 9 of 25Sarker  J Big Data            (2019) 6:95 \n\nbase period, e.g., 5 min, is assumed as the finest granularity to distinguish day-to-day \nactivities of an individual. If the base period incremented to 15 min, then the number \nof segments decreases, where 15 min can be assumed as the finest granularity. Thus the \nnumber of segments varies based on the base time period. Similarly, individuals’ calen-\ndar schedules and corresponding time boundaries can also be used to determine var-\niable length of time segments, in order to model users’ behavior in temporal context, \nwhich may vary according to users’ preferences [59]. For instance, one user may have a \nparticular event between 1 and 2 p.m., while another may have in another time bound-\nary between 1:30 and 2:30 p.m.. Thus, the time segmentation varies according to their \ndaily life activities scheduled in their personal calendars. Similarly, multiple thresholds, \nsliding window, data shape based approaches are used in several applications, shown \nin Table 2. In addition to these approaches, a number of authors use machine learning \ntechniques such as clustering, genetic algorithm etc. In Table  2, we have summarized \na number of works that use such type of dynamic segmentation techniques in various \npurposes.\n\nClustering highlighted in Table  2 is one of the important machine learning tech-\nniques in forming large time segments where certain user behavior patterns are taken \ninto account. Usually, clustering algorithms are designed with certain assumptions and \nfavor certain type of problems. In this sense, it is not accurate to say ‘best’ in the con-\ntext of clustering algorithms; it depends on specific application [75]. Among the cluster-\ning algorithms the K-means algorithm is the best-known squared error-based clustering \nalgorithm [76]. However, this algorithm needs to specify the initial partitions and fixed \nnumber of clusters K. The convergence centroids also vary with different initial points. \nSometimes this algorithm is influenced by outliers because of mean value calculation. \n\nTable 2 Various types of dynamic time segments used in different applications\n\nBase technique Description References\n\nSingle parameter A predefined value of time interval, e.g., 15 min \nis used to generate segments\n\nOzer et al. [60]\n\nA different value of time interval, e.g., 30 min is \nused for segmentation\n\nDo et al. [61], Farrahi et al. [62]\n\nA relatively large value of the parameter, e.g., \n2-h is used to generate time segments\n\nKaratzoglou et al. [63]\n\nAnother large value of time interval, e.g., 3-h is \nused for segmentation to make the number \nof segments small\n\nPhithakkitnukoon et al. [64]\n\nCalendar Various calendar schedules and corresponding \ntime boundaries are used to model users’ \nbehavior in temporal context\n\nKhail et al. [65], Dekel et al. [66], Zulkernain \net al. [67], Seo et al. [68], Sarker et al. [28, \n59]\n\nMulti-thresholds To identify the lower and upper boundary \nof a particular segment for the purpose of \nsegmenting time-series log data\n\nHalvey et al. [38]\n\nData shape A data shape based time-series data analysis Zhang et al. [45], Shokoohi et al. [69]\n\nSliding window A sliding window is used to analyze time-series \ndata\n\nHartono et al. [70], Keogh et al. [71]\n\nClustering A predefined number of clusters is used to \ndiscover rules from time-series data\n\nDas et al. [72]\n\nGenetic algorithm A genetic algorithm is used to analyze time-\nseries data\n\nLu et al. [73], Kandasamy et al. [74]\n\n\n\nPage 10 of 25Sarker  J Big Data            (2019) 6:95 \n\nMore importantly, the characteristic of this algorithm might not be directly applicable \nfor the purpose of learning  context-aware rules. The reason is that users’ behave dif-\nferently in different contexts, which also may vary from user-to-user in the real world. \nThus, it’s difficult to assume a number of clusters K to capture their diverse behaviors \neffectively. Another similar K-medoids method [77] is more robust than K-means algo-\nrithm in the presence of outliers because a medoid is less influenced by outliers than a \nmean. Though it minimizes the outlier problem but the other characteristic mismatches \nexist between K-means and the problem of time-series modeling.\n\nAs the size and number of time segments depend on the user’s behavior and it differs \nfrom user-to-user, a bottom-up hierarchical data processing can help to make behavioral \nclusters. Existing hierarchical algorithms are mainly classified as agglomerative methods \nand device methods. However, the device clustering method is not commonly used in \npractice [75]. The simplest and most popular agglomerative clustering is single linkage \n[78] and complete linkage [79]. Another method, nearest neighbor [75], is also similar to \nthe single linkage agglomerative clustering algorithm. All these hierarchical algorithms \nuse a proximity matrix which is generated by computing the distance between a new \ncluster and other clusters. Then according to the matrix value these algorithms succes-\nsiv",
      "metadata_storage_size": 1660534,
      "metadata_storage_path": "aHR0cHM6Ly9qdHJhaW5pbmdjYXRhbG9nc3RvcmFnZS5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL3M0MDUzNy0wMTktMDI1OC00LnBkZg2",
      "metadata_author": "Iqbal H. Sarker ",
      "metadata_title": "Context-aware rule learning from smartphone data: survey, challenges and future directions",
      "metadata_creation_date": "2019-10-30T14:24:16Z",
      "people": [
        "Iqbal H. Sarker",
        "Sarker  J",
        "Alice",
        "niques",
        "Schilit",
        "Brown",
        "Ryan",
        "Franklin",
        "Ward",
        "Hull",
        "Rodden",
        "Dey",
        "Song",
        "Rawassizadeh",
        "Mukherji",
        "Bayir",
        "Jayarajah",
        "Do",
        "Xu",
        "Mehrotra",
        "Zhu",
        "Yu",
        "Naboulsi",
        "Dashdorj",
        "Shin",
        "Farrahi",
        "Ozer",
        "Karatzoglou",
        "Phithakkitnukoon",
        "Khail",
        "Dekel",
        "Zulkernain",
        "Seo",
        "Sarker",
        "Halvey",
        "Zhang",
        "Shokoohi",
        "Hartono",
        "Keogh",
        "Das",
        "Lu",
        "Kandasamy"
      ],
      "organizations": [
        "future directions",
        "The Author(s",
        "Swinburne University",
        "25Sarker",
        "popu",
        "smart",
        "25Sarker  J Big Data",
        "ics",
        "smrtphone data",
        "25Sarker  J",
        "rizes",
        "International Telecommunication Union",
        "ual",
        "dynamic",
        "Tmax",
        "series data"
      ],
      "locations": [
        "Melbourne",
        "Australia",
        "Conclu",
        "Simi",
        "larly",
        "boundary",
        "siv"
      ],
      "keyphrases": [
        "Creative Commons Attribution 4.0 International License",
        "intelligent decision making strategies",
        "advanced data analytical techniques",
        "25Sarker  J Big Data",
        "Context‑aware rule learning",
        "Intelligent systems Open Access",
        "machine learning based techniques",
        "Creative Commons license",
        "corresponding context-aware rule learning",
        "Iqbal H. Sarker",
        "User behavior modeling",
        "creat iveco mmons",
        "intelligent context-aware applications",
        "raw contextual data",
        "corresponding search interests",
        "data-driven context-aware systems",
        "phone data analytics",
        "original author(s",
        "corresponding data processing",
        "multifunctional cell phones",
        "users’ surrounding environment",
        "smartphone data",
        "Data science",
        "Predictive analytics",
        "context-aware rules",
        "Context-aware computing",
        "author information",
        "future directions",
        "recent days",
        "daily life",
        "important IoT",
        "next generation",
        "wireless connectivity",
        "work coverage",
        "developed countries",
        "recent statistics",
        "Google Trends",
        "users’ interest",
        "other platforms",
        "Desktop Computer",
        "Laptop Computer",
        "current world",
        "recent developments",
        "behavioral activities",
        "wide attention",
        "high precision",
        "traditional approaches",
        "efficient results",
        "previous work",
        "rule-based automated",
        "IoT services",
        "unrestricted use",
        "appropriate credit",
        "doi.org",
        "1 Swinburne University",
        "Full list",
        "Tablet Computer",
        "last 5 years",
        "timestamp information",
        "particular date",
        "highest point",
        "personal devices",
        "Things) devices",
        "essential part",
        "world population",
        "Mobile Phones",
        "particular term",
        "SURVEY PAPER",
        "peak popularity",
        "challenges",
        "Introduction",
        "smartphones",
        "individuals",
        "Internet",
        "capabilities",
        "number",
        "Fig.",
        "Abstract",
        "ogy",
        "academia",
        "industry",
        "order",
        "set",
        "key",
        "contexts",
        "comparison",
        "effective",
        "article",
        "area",
        "discussion",
        "Clustering",
        "Classification",
        "Association",
        "Personalization",
        "Time-series",
        "terms",
        "distribution",
        "reproduction",
        "medium",
        "source",
        "link",
        "changes",
        "Correspondence",
        "msarker",
        "Melbourne",
        "Australia",
        "creativecommons",
        "licenses",
        "crossmark",
        "Page",
        "Figure",
        "x-axis",
        "range",
        "chart",
        "instance",
        "value",
        "maximum",
        "y-axis",
        "minimum",
        "context-aware mobile notification management system",
        "other broad application areas",
        "corresponding rule-based prediction model",
        "data-driven intelligent context-aware systems",
        "different context-aware test cases",
        "rule-based intelligent context-aware systems",
        "smartphone data analytic solutions",
        "context-aware smart city services",
        "users’ behavioral activity patterns",
        "corresponding behavioral activities",
        "THEN” logical structure",
        "intelligent eHealth services",
        "Users’ interest trends",
        "aware behavioral rules",
        "relevant contextual data",
        "contextual data patterns",
        "contextual data clustering",
        "different surrounding contexts",
        "relevant context-aware rules",
        "machine learning researchers",
        "machine learning techniques",
        "relevant contextual information",
        "data mining techniques",
        "advanced data analysis",
        "machine learning rules",
        "different contexts",
        "rule-based classification",
        "raw data",
        "context-aware  software",
        "Mobile Phone",
        "hidden patterns",
        "data science",
        "advanced features",
        "mobile notifications",
        "mental learning",
        "social contexts",
        "personalized services",
        "rity services",
        "deeper analysis",
        "association analysis",
        "daily basis",
        "great source",
        "useful information",
        "two parts",
        "temporal context",
        "tial context",
        "family members",
        "specific exceptions",
        "particular domain",
        "prac- titioners",
        "many reasons",
        "various purposes",
        "particular timestamp",
        "numeric values",
        "world-wide popularity",
        "ture optimization",
        "dynamic updating",
        "The reason",
        "huge amount",
        "unknown correlations",
        "quent part",
        "individuals’ usage",
        "phone user",
        "devices",
        "result",
        "antecedent",
        "others",
        "example",
        "Alice",
        "work",
        "evening",
        "general",
        "preferences",
        "addition",
        "cable",
        "study",
        "applications",
        "building",
        "Apr",
        "Oct",
        "Feb",
        "13-Aug",
        "Desktop",
        "Dec",
        "Tablet",
        "Jun",
        "Laptop",
        "Several",
        "selection",
        "aim",
        "Suggested machine learning based framework",
        "Context-aware rule based applications",
        "optimal time-based context-aware rules",
        "context-aware rule learning framework",
        "smartphone data analyt- ics",
        "Context-aware rule learning strategies",
        "real world applications",
        "rule discovery techniques",
        "intelligent data-driven decisions",
        "decision making capability",
        "rule-based intelligent systems",
        "Human Computer Interaction",
        "learning context-aware rules",
        "corresponding data clustering",
        "corresponding context-aware rules",
        "smartphone data analytics",
        "contextual smartphone data",
        "incremental learning",
        "context-aware computing",
        "updation techniques",
        "time-series data",
        "smrtphone data",
        "diverse behaviors",
        "several perspectives",
        "time-series modeling",
        "various layers",
        "various perspectives",
        "different meanings",
        "different purposes",
        "numerous areas",
        "uitous Computing",
        "Computer-Supported Collaborative",
        "Ambient Intelligence",
        "little work",
        "earlier work",
        "brief discussion",
        "detailed analysis",
        "background information",
        "main characteristics",
        "existing research",
        "brief survey",
        "first article",
        "multi-dimensional contexts",
        "sion” section",
        "terns",
        "individual",
        "activities",
        "profit",
        "discretization",
        "issues",
        "contributions",
        "paper",
        "shortcomings",
        "role",
        "knowledge",
        "remainder",
        "variety",
        "notion",
        "Pervasive",
        "mobile",
        "ubiquitous computing community",
        "rent social situation",
        "ubiquitous computing area",
        "smartphone usage",
        "recent works",
        "broader collection",
        "defi- nitions",
        "dis- cussion",
        "Several studies",
        "temporal informa",
        "other hand",
        "current situation",
        "available processors",
        "network capacity",
        "noise level",
        "lighting level",
        "day situations",
        "social aspects",
        "computing environment",
        "surrounding people",
        "nearby people",
        "locational information",
        "environmental information",
        "surrounding information",
        "important aspects",
        "changing environment",
        "Other definitions",
        "other researchers",
        "alternative view",
        "con- text",
        "location information",
        "physical environment",
        "following definition",
        "social context",
        "relevant contexts",
        "user input",
        "spatial context",
        "user environment",
        "user location",
        "context-awareness",
        "objects",
        "factors",
        "entity",
        "users",
        "categories",
        "pervasive",
        "section",
        "scope",
        "different",
        "perspectives",
        "Schilit",
        "Brown",
        "temperature",
        "Simi",
        "account",
        "Ryan",
        "synonyms",
        "computer",
        "Franklin",
        "Ward",
        "state",
        "Hull",
        "entire",
        "settings",
        "Rodden",
        "resources",
        "connectivity",
        "display",
        "costs",
        "examples",
        "Dey",
        "survey",
        "person",
        "place",
        "interaction",
        "influence",
        "personalized mobile game recommendation system",
        "vidual mobile phone user behavior",
        "relevant contextual informa- tion",
        "mobile notification management systems",
        "related contextual infor- mation",
        "various smart phone applications",
        "individual mobile phone users",
        "personalized context-aware recommendation",
        "user mobile web navigation",
        "smart mobile applications",
        "smart mobile phone",
        "phone usage behavior",
        "standardized communications rules",
        "International Telecommunication Union",
        "sive commercial industry",
        "accurate context-aware predictions",
        "daily life activities",
        "text communication service",
        "contextual behavioral patterns",
        "automatic spam filtering",
        "phone call activities",
        "user diverse activities",
        "smartphone notification logs",
        "short text messages",
        "contextual usage patterns",
        "short message service",
        "Contextual smartphone data",
        "spam text messages",
        "contextual patterns",
        "unique phone",
        "individual users",
        "User navigation",
        "short messages",
        "major activities",
        "cellular phones",
        "game log",
        "various types",
        "voice communication",
        "various kinds",
        "spam messages",
        "particular user",
        "web log",
        "web searching",
        "data source",
        "meta data",
        "log data",
        "outgoing calls",
        "incoming calls",
        "other dimensions",
        "day situation",
        "social relationship",
        "numerous growth",
        "dramatic increasing",
        "good time",
        "bad time",
        "rapid development",
        "smartphone apps",
        "Such logs",
        "social networks",
        "predictive suggestions",
        "portal structure",
        "context data",
        "tual information",
        "context source",
        "SMS log",
        "real world",
        "contact number",
        "decisions",
        "everything",
        "lives",
        "ability",
        "caller",
        "callee",
        "exchange",
        "protocols",
        "81 billion",
        "task",
        "people",
        "Multimedia",
        "Facebook",
        "Gmail",
        "Youtube",
        "Skype",
        "notifications",
        "events",
        "news",
        "reminders",
        "alerts",
        "games",
        "promotional",
        "emails",
        "Twitter",
        "LinkedIN",
        "WhatsApp",
        "Viver",
        "intelligent",
        "entertainment",
        "chat",
        "misc",
        "TV",
        "netting",
        "travel",
        "sport",
        "banking",
        "needs",
        "action",
        "adventure",
        "puzzle",
        "RPG",
        "strategy",
        "Context‑aware rule learning strategies",
        "time‑series smartphone data Time",
        "Time interval type Number",
        "temporal context based rules",
        "existing time-series segmentation approaches",
        "mobile phone data",
        "Google play API",
        "geographical loca- tion",
        "context-aware rule learning",
        "segment details References",
        "personalized log data",
        "A time series",
        "user phone calls",
        "smart mobile phones",
        "mobile user behavior",
        "behavioral data clusters",
        "time-based behavior modeling",
        "life log data",
        "static time segments",
        "related contextual information",
        "existing rule",
        "existing strategies",
        "important context",
        "contextual rule",
        "learning rules",
        "IoT data",
        "data points",
        "exact time",
        "temporal information",
        "temporal, spatial",
        "behavioral rules",
        "user experience",
        "computing capabilities",
        "various real",
        "life purposes",
        "life-logging device",
        "technical sense",
        "surrounding environment",
        "core components",
        "life- logs",
        "SMS headers",
        "App use",
        "physical activities",
        "open challenges",
        "diverse activities",
        "effective modeling",
        "open problem",
        "Various types",
        "different applications",
        "remaining hours",
        "Unequal 3 Morning",
        "Unequal 4 Morning",
        "Unequal 5 Morning",
        "Bluetooth devices",
        "Equal 4 Night",
        "6:00 a",
        "ubiquity",
        "opportunity",
        "memories",
        "sensors",
        "content",
        "sapp",
        "WiFi",
        "proximity",
        "opportunities",
        "future",
        "directions",
        "discovery",
        "behaviors",
        "sequence",
        "research",
        "Table 1",
        "afternoon",
        "Song",
        "Rawassizadeh",
        "Mukherji",
        "Bayir",
        "Paireekreng",
        "day",
        "overnight",
        "Jayarajah",
        "Do",
        "Xu",
        "Mehrotra",
        "Zhu",
        "dynamic segmenta- tion technique",
        "high confidence temporal rules",
        "high confidence rules",
        "four different time segments",
        "various mobile applications",
        "dynamic segmen- tation",
        "mobile phone users",
        "individual smartphone users",
        "four time slots",
        "same interval length",
        "two broad categories",
        "users’ behavioral activities",
        "dynamic segmentation techniques",
        "unequal interval based",
        "various time intervals",
        "Such static segmentation",
        "unequal time interval",
        "temporal coverage",
        "different lengths",
        "temporal contexts",
        "arbitrary categories",
        "two types",
        "behavioral characteristics",
        "population behavior",
        "ioral evidence",
        "usage records",
        "seg- ments",
        "single parameter",
        "corresponding segmentation",
        "base period",
        "static generation",
        "time period",
        "late morning",
        "meaningful results",
        "variable number",
        "N1 number",
        "one case",
        "N2 number",
        "forenoon",
        "night",
        "Oulasvirta",
        "Next",
        "Yu",
        "Naboulsi",
        "Dashdorj",
        "Shin",
        "11:00 a",
        "S5",
        "S8",
        "Farrahi",
        "ii",
        "researchers",
        "Table",
        "periods",
        "1 h",
        "works",
        "approaches",
        "goal",
        "change",
        "patterns",
        "authors",
        "Tmax",
        "24-h",
        "BP",
        "2:00",
        "5:00",
        "7:00",
        "9:00",
        "important machine learning tech- niques",
        "time- series data Lu",
        "time-series log data Halvey",
        "Base technique Description References",
        "data shape based approaches",
        "squared error-based clustering algorithm",
        "time-series data analysis",
        "time-series data Hartono",
        "time-series data Das",
        "cluster- ing algorithms",
        "mean value calculation",
        "temporal context Khail",
        "different initial points",
        "user behavior patterns",
        "dynamic time segments",
        "base time period",
        "Various calendar schedules",
        "corresponding time boundaries",
        "time segments decreases",
        "large time segments",
        "different value",
        "large value",
        "one user",
        "initial partitions",
        "time segmentation",
        "time interval",
        "predefined value",
        "clustering algorithms",
        "division result",
        "finest granularity",
        "iable length",
        "particular event",
        "personal calendars",
        "multiple thresholds",
        "sliding window",
        "several applications",
        "specific application",
        "convergence centroids",
        "segmentation Do",
        "upper boundary",
        "particular segment",
        "segments Ozer",
        "genetic algorithm",
        "K-means algorithm",
        "users’ behavior",
        "users’ preferences",
        "Single parameter",
        "predefined number",
        "Tmax/BP",
        "5 min",
        "assumptions",
        "problems",
        "sense",
        "clusters",
        "K.",
        "outliers",
        "30 min",
        "2-h",
        "Karatzoglou",
        "small",
        "Phithakkitnukoon",
        "Dekel",
        "Zulkernain",
        "Seo",
        "Multi-thresholds",
        "lower",
        "Zhang",
        "Shokoohi",
        "Keogh",
        "Kandasamy",
        "characteristic",
        "1",
        "2:30",
        "single linkage agglomerative clustering algorithm",
        "bottom-up hierarchical data processing",
        "popular agglomerative clustering",
        "other characteristic mismatches",
        "device clustering method",
        "similar K-medoids method",
        "Existing hierarchical algorithms",
        "agglomerative methods",
        "complete linkage",
        "device methods",
        "other clusters",
        "users’ behave",
        "different contexts",
        "time segments",
        "nearest neighbor",
        "proximity matrix",
        "new cluster",
        "matrix value",
        "behavioral clusters",
        "outlier problem",
        "reason",
        "K-means",
        "presence",
        "size",
        "practice",
        "simplest",
        "distance",
        "siv"
      ],
      "merged_content": "\nContext‑aware rule learning \nfrom smartphone data: survey, challenges \nand future directions\nIqbal H. Sarker1,2*\n\nIntroduction\nIn recent days, smartphones have become an essential part of our daily life and con-\nsidered as highly personal devices of individuals. These devices are also known as one \nof the most important IoT (Internet of Things) devices, because of their capabilities \nto interconnect their users with the Internet, and corresponding data processing [1]. \nSmartphones are also considered as “next generation, multifunctional cell phones that \nfacilitates data processing as well as enhanced wireless connectivity” [2]. The cellular net-\nwork coverage has reached 96.8% of the world population, and this number even reaches \n100% of the population in the developed countries [3]. In recent statistics, according to \nGoogle Trends [4] we have shown in Fig.  1, that users’ interest on “Mobile Phones” is \nmore and more than other platforms like “Desktop Computer”, “Laptop Computer” or \n\nAbstract \n\nSmartphones are considered as one of the most essential and highly personal devices \nof individuals in our current world. Due to the popularity of context-aware technol-\nogy and recent developments in smartphones, these devices can collect and process \nraw contextual data about users’ surrounding environment and their corresponding \nbehavioral activities with their phones. Thus, smartphone data analytics and building \ndata-driven context-aware systems have gained wide attention from both academia \nand industry in recent days. In order to build intelligent context-aware applications on \nsmartphones, effectively learning a set of context-aware rules from smartphone data \nis the key. This requires advanced data analytical techniques with high precision and \nintelligent decision making strategies based on contexts. In comparison to traditional \napproaches, machine learning based techniques provide more effective and efficient \nresults for smartphone data analytics and corresponding context-aware rule learning. \nThus, this article first makes a survey on previous work in the area of contextual smart-\nphone data analytics and then presents a discussion of challenges and future directions \nfor effectively learning context-aware rules from smartphone data, in order to build \nrule-based automated and intelligent systems.\n\nKeywords: Smartphone data, Machine learning, Data science, Clustering, \nClassification, Association, Rule learning, Personalization, Time-series, User behavior \nmodeling, Predictive analytics, Context-aware computing, Mobile and IoT services, \nIntelligent systems\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nSarker  J Big Data            (2019) 6:95  \nhttps://doi.org/10.1186/s40537‑019‑0258‑4\n\n*Correspondence:   \nmsarker@swin.edu.au \n1 Swinburne University \nof Technology, \nMelbourne VIC-3122, \nAustralia\nFull list of author information \nis available at the end of the \narticle\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-019-0258-4&domain=pdf\n\n\nPage 2 of 25Sarker  J Big Data            (2019) 6:95 \n\n“Tablet Computer” for the last 5 years from 2014 to 2019. Figure 1 represents timestamp \ninformation in terms of particular date in x-axis and corresponding search interests in \nthe range of 0 to 100 in terms of popularity relative to the highest point on the chart in \ny-axis. For instance, a value of 100 (maximum) in y-axis represents the peak popularity \nfor a particular term, while 0 (minimum) means the term was lowest in terms of popu-\nlarity [4].\n\nDue to the advanced features and recent developments in smartphones, these devices \ncan collect raw contextual data about users’ surrounding environment and their corre-\nsponding behavioral activities with their phones in a daily basis [5]. As a result, smart-\nphone data becomes a great source to understand users’ behavioral activity patterns in \ndifferent contexts, and to derive useful information, i.e., context-aware rules, for the pur-\npose of building rule-based intelligent context-aware systems. A context-aware rule has \ntwo parts, which follows “IF-THEN” logical structure to formulate [6]. The antecedent \npart represents users’ surrounding contextual information, e.g., temporal context, spa-\ntial context, social contexts, or others relevant contextual information and the conse-\nquent part represents their corresponding behavioral activities or usage. Let’s consider \nan example of a context-aware mobile notification management system for a smart-\nphone user Alice. A context-aware rule for such system could be “The user typically \ndismisses mobile notifications while at work; however, accepts the notifications in the \nevening from her family members, even though she is in work”. A set of such context-\naware behavioral rules including general and specific exceptions, may vary from user-to-\nuser according to their preferences. In addition to the personalized services mentioned \nabove, the relevant context-aware rules in different surrounding contexts could be appli-\ncable to other broad application areas, like context-aware  software and IoT services, \nintelligent eHealth services, and context-aware smart city services, intelligent cybersecu-\nrity services etc. utilizing the relevant contextual data of that particular domain. Overall, \nthis study is typically for those data science and machine learning researchers, and prac-\ntitioners who particularly want to work on data-driven intelligent context-aware systems \nand services based on machine learning rules.\n\nEffectively learning context-aware rules from smartphone data is challenging because \nof many reasons, ranging from understanding raw data to applications. A number of \nresearch [7–9] has been done on mining context-aware rules from smartphone data for \nvarious purposes. However, to effectively learn such rules for the purpose of building \n\nFig. 1 Users’ interest trends over time, where x-axis and y-axis represent a particular timestamp and \ncorresponding search interests in numeric values in terms of world-wide popularity respectively\n\n 100 30 10 90 40 20 50 60 70 80 0 13-Apr-2014 + 13-Jun-2014 13-Aug-2014 13-Oct-2014 13-Dec-2014 13-Feb-2015 13-Apr-2015 13-Jun-2015 - 13-Aug-2015 Desktop 13-Oct-2015 13-Dec-2015 1 13-Feb-2016 -Tablet 13-Apr-2016 13-Jun-2016 13-Aug-2016 - 13-Oct-2016 Laptop 13-Dec-2016 13-Feb-2017 13-Apr-2017 -Mobile Phone 13-Jun-2017 13-Aug-2017 13-Oct-2017 13-Dec-2017 13-Feb-2018 13-Apr-2018 13-Jun-2018 13-Aug-2018 13-Oct-2018 13-Dec-2018 13-Feb-2019 \n\n\n\nPage 3 of 25Sarker  J Big Data            (2019) 6:95 \n\nintelligent context-aware systems, a deeper analysis in contextual data patterns and \nlearning according to individuals’ usage is needed. Thus, advanced data analysis based \non machine learning techniques, can be used to make effective and efficient decision-\nmaking capabilities in different context-aware test cases for smartphones. Several \nmachine learning and data mining techniques, such as contextual data clustering, fea-\nture optimization and selection, rule-based classification and association analysis, incre-\nmental learning for dynamic updating and management, and corresponding rule-based \nprediction model can be designed to provide smartphone data analytic solutions. The \nreason is that such machine learning techniques can be more accurate, and more precise \nfor analyzing huge amount of contextual data. The aim of these advanced analytic tech-\nniques is to discover information, hidden patterns, and unknown correlations among the \ncontexts and eventually generate context-aware rules. For instance, a detailed analysis \nof time-series data and corresponding data clustering based on similar behavioral pat-\nterns, could lead to capture the diverse behaviors of an individual’s activities, thereby \nenabling more optimal time-based context-aware rules than the traditional approaches \n[10]. Thus, intelligent data-driven decisions using machine learning techniques can \nprofit better decision making capability over the traditional approaches while consider-\ning the multi-dimensional contexts.\n\nBased on our survey and analysis on existing research, little work has been done in \nterms of how machine learning techniques significantly impact on contextual smart-\nphone data and to learn corresponding context-aware rules. To address this short-\ncoming, this article first makes a survey on previous work in the area of contextual \nsmartphone data analytics in several perspectives involved in context-aware rules, such \nas time-series modeling that is also known as a discretization of temporal context, rule \ndiscovery techniques, and incremental learning and rule updation techniques, which has \nbeen highlighted in our earlier work [6]. After that this article presents a brief discussion \non challenges and future directions to overcome these issues. Based on our discussion, \nfinally we suggest a machine learning based context-aware rule learning framework for \nthe purpose of effectively learning context-aware rules from smartphone data, in order \nto build rule-based automated and intelligent systems.\n\nThe contributions of this paper are summarized as follows.\n\n• We first make a brief survey on previous work in the area of smartphone data analyt-\nics in several perspectives related to context-aware rule learning and summarize the \nshortcomings of these research.\n\n• We then present a brief discussion on the challenges and future directions to over-\ncome the issues to learn context-aware rules from smartphone data.\n\n• Finally, we suggest a machine learning based context-aware rule learning framework \nand briefly discuss the role of various layers associated with the framework, for the \npurpose of building rule-based intelligent context-aware systems.\n\nTo the best of our knowledge, this is the first article surveying context-aware rule learn-\ning strategies from smrtphone data. The remainder of the paper is organized as follows. \n“Background: contexts and smartphone data” section presents background information \non contexts and contextual smartphone data. “Context-aware rule learning strategies” \n\n\n\nPage 4 of 25Sarker  J Big Data            (2019) 6:95 \n\nsection  surveys previous work in various perspectives related to context-aware rule \nlearning. “Challenges and future directions” section briefly discusses the challenges and \nfuture directions of research regarding context-aware rule learning from smartphone \ndata. In “Suggested machine learning based framework” section we suggest a machine \nlearning based context-aware rule learning framework and discuss various layers with \ntheir roles while learning rules. Context-aware rule based applications section summa-\nrizes a number of real world applications based on context-aware rules. Finally, “Conclu-\nsion” section concludes this paper.\n\nBackground: contexts and smartphone data\nThis section reviews background information on the main characteristics of contexts \nand contextual smartphone data that address learning context-aware rules for the pur-\npose of building rule-based intelligent systems.\n\nCharacteristics of contexts\n\nThe term context can be used with a variety of different meanings in different purposes. \nThe notion of context has been used in numerous areas, including Pervasive and Ubiq-\nuitous Computing, Human Computer Interaction, Computer-Supported Collaborative \nWork, and Ambient Intelligence [11]. In this section, first we briefly review what is con-\ntext in the area of mobile and context-aware computing. In Ubiquitous and Pervasive \nComputing area, early works on context-awareness referred to context as primarily \nthe location of people and objects [12]. In recent works, context has been extended to \ninclude a broader collection of factors, such as physical and social aspects of an entity, \nas well as the activities of users [11]. Having examined the definitions and categories of \ncontext given by the pervasive and ubiquitous computing community, this section seeks \nto define our view of context within the scope of smartphone data analytics. As the defi-\nnitions of context to pervasive and ubiquitous computing area are also broad, this dis-\ncussion is intended to be illustrative rather than exhaustive.\n\nSeveral studies have attempted to define and represent the context from different \nperspectives. For instance, the user’s location information, the surrounding people and \nobjects around the user, and the changes to those objects are considered as contexts by \nSchilit et al. [12]. Brown et al. [13] also define contexts as user’s locational information, \ntemporal information, the surrounding people around the user, temperature, etc. Simi-\nlarly, the user’s locational information, environmental information, temporal informa-\ntion, user’s identity, are also taken into account as contexts by Ryan et  al. [14]. Other \ndefinitions of context have simply provided synonyms for context such as context as the \nenvironment or social situation. A number of researchers are taken into account the \ncontext as the environmental information of the user. For instance, in [15], the environ-\nmental information that the user’s computer knows about are taken into account as con-\ntext by Brown et al., whereas the social situation of the user is considered as a context \nin Franklin et al. [16]. On the other hand, a number of other researchers consider it to \nbe the environment related to the applications. For instance, Ward et al. [17] consider \nthe state of the surrounding information of the applications as contexts. Hull et al. [18] \ndefine context as the aspects of the current situation of the user and include the entire \n\n\n\nPage 5 of 25Sarker  J Big Data            (2019) 6:95 \n\nenvironment. The settings of applications are also treated as context in Rodden et  al. \n[19].\n\nAccording to Schilit et  al. [20] the important aspects of context are: (i) where you \nare, (ii) whom you are with, and (iii) what resources are nearby. The information of the \nchanging environment is taken into account as context in their definition. In addition to \nthe user environment (e.g., user location, nearby people around the user, and the cur-\nrent social situation of the user), they also include the computing environment and the \nphysical environment. For instance, connectivity, available processors, user input and \ndisplay, network capacity, and costs of computing can be the examples of the computing \nenvironment, while the noise level, temperature, the lighting level, can be the examples \nof the physical environment. Dey et al. [21] present a survey of alternative view of con-\ntext, which are largely imprecise and indirect, typically defining context by synonym or \nexample. Finally, they offer the following definition of context, which is perhaps now the \nmost widely accepted. According to Dey et al. [21] “Context is any information that can \nbe used to characterize the situation of an entity. An entity is person, place or object \nthat is considered relevant to the interaction between a user and an application, includ-\ning the user and the application themselves”. Thus, based on the definition of Dey et al. \n[21], we can define context in the scope of this work as “Context is any information that \ncan be used to characterize users’ day-to-day situations that have an influence on their \nsmartphone usage”. An example of relevant contexts could be temporal context, spatial \ncontext, or social context etc. that might have an influence to make individuals’ diverse \ndecisions on smartphone usage in their daily life activities.\n\nContextual smartphone data\n\nWe live in the age of data [22], where everything that surrounds us is linked to a data \nsource and everything in our lives is captured digitally. Mobile or cellular phones have \nbecome increasingly ubiquitous and powerful to log user diverse activities for under-\nstanding their preferences and phone usage behavior. For instance, smart mobile phones \nhave the ability to log various types of context data related to a user’s phone call activities \nabout when the user makes outgoing calls, or accepts, rejects, and misses the incoming \ncalls [23–26]. In addition to such call related meta data, other dimensions of contex-\ntual information such as user location [27], user’s day-to-day situation [28], the social \nrelationship between the caller an callee identified by the individual’s unique phone \ncontact number [29] are also recorded by the smart mobile phones. Thus, call log data \ncollected by the smart mobile phone can be used as a context source to modeling indi-\nvidual mobile phone user behavior in smart context-aware mobile communication sys-\ntems [30]. In addition to voice communication, short message service (SMS) is known \nas text communication service allows the exchange of short text messages of individual \nmobile phone users, using standardized communications rules or protocols. According \nto the International Telecommunication Union [31], short messages have become a mas-\nsive commercial industry, worth over 81 billion dollars globally. The numerous growth \nin the number of mobile phone users in the world has lead to a dramatic increasing of \nspam messages [32]. The SMS log contains all the message including the spam and non-\nspam text messages [32, 33], which can be used in the task of automatic spam filtering \n[25, 32], or predicting good time or bad time to deliver such messages [33].\n\n\n\nPage 6 of 25Sarker  J Big Data            (2019) 6:95 \n\nWith the rapid development of smartphones, people use these devices for using vari-\nous categories of apps such as Multimedia, Facebook, Gmail, Youtube, Skype, Game [9, \n34]. Thus, smartphone apps log contains these usage with relevant contextual informa-\ntion [8, 9, 35–37]. Such logs can be used for mining the contextual behavioral patterns of \nindividual mobile phone users that is, which app is preferred by a particular user under \na certain context to provide personalized context-aware recommendation. In the real \nworld, a variety of smart mobile applications use notifications in order to inform the \nusers about various kinds of events, news or just to send them reminders or alerts. For \ninstance, the notifications of inviting games on social networks, social or promotional \nemails, or a number of predictive suggestions by various smart phone applications, \ne.g., Twitter, Facebook, LinkedIN, WhatsApp, Viver, Skype, Youtube [7]. The extracted \ncontextual patterns from smartphone notification logs can be used to build intelligent \nmobile notification management systems according to their preferences.\n\nUser navigation in the web in another major activities of individual users. Thus, web \nlog contains the information about user mobile web navigation, web searching, e-mail, \nentertainment, chat, misc, news, TV, netting, travel, sport, banking, and related contex-\ntual information [38–40]. Mining contextual usage patterns from such log data, can be \nused to make accurate context-aware predictions about user navigation and to adapt the \nportal structure according to the needs of users. Similarly, game log contains the infor-\nmation about playing various types such games such as action, adventure, casual, puzzle, \nRPG, strategy, sports etc. of individual mobile phone users, and related contextual infor-\nmation [41]. The extracted contextual patterns from such logs data, can be used to build \npersonalized mobile game recommendation system for individual mobile phone users \naccording to their own preferences.\n\nThe ubiquity of smart mobile phones and their computing capabilities for various real \nlife purposes provide an opportunity of using these devices as a life-logging device, i.e., \npersonal e-memories [42]. In a more technical sense, life-logs sense and store individ-\nual’s contextual information from their surrounding environment through a variety of \nsensors available in their smart mobile phones, which are the core components of life-\nlogs such as user phone calls, SMS headers (no content), App use (e.g., Skype, What-\nsapp, Youtube etc.), physical activities form Google play API, and related contextual \ninformation such as WiFi and Bluetooth devices in user’s proximity, geographical loca-\ntion, temporal information [42]. The extracted contextual patterns or behavioral rules of \nindividual mobile phone users utilizing such life log data, can be used to improve user \nexperience in their daily life. In addition to these personalized log data, smartphones are \nalso capable for collecting and processing IoT data [1]. Based on such smartphone data \nhaving contextual information, in this paper, we briefly review the existing rule learn-\ning strategies and discuss the open challenges and opportunities by highlighting future \ndirections for context-aware rule learning.\n\nContext‑aware rule learning strategies\nIn this section, we review existing strategies related to learning rules based on contex-\ntual information in various perspectives. This includes time-series modeling that cre-\nates behavioral data clusters for generating temporal context based rules, contextual rule \n\n\n\nPage 7 of 25Sarker  J Big Data            (2019) 6:95 \n\ndiscovery by taking into account multi-dimensional contexts, such as temporal, spatial \nor social contexts, and incremental learning to dynamic updating of rules.\n\nModeling time‑series smartphone data\n\nTime is the most important context that impacts on mobile user behavior for making \ndecisions [38]. Individual’s behaviors vary over time in the real world and the mobile \nphones record the exact time of all diverse activities of the users with their mobile \nphones. A time series is a sequence of data points ordered in time [43]. However, to use \nsuch time-series data into behavioral rules, an effective modeling of temporal context \nis needed. Thus, time-series segmentation becomes one of the research focuses in this \nstudy as exact time in mobile phone data is not very informative to mine behavioral rules \nof individual mobile phone users. According to [44], time-based behavior modeling is an \nopen problem. Hence, we summarize the existing time-series segmentation approaches \n\nTable 1 Various types of static time segments used in different applications\n\nTime interval type Number \nof segments\n\nUsed time interval and segment details References\n\nEqual 3 Morning [7:00–12:00], afternoon [13:00–18:00] and \nevening [19:00–24:00]\n\nSong et al. [46]\n\nEqual 3 [0:00–7:59], [8:00–15:59] and [16:00–23:59] Rawassizadeh et al. [47]\n\nEqual 4 Morning [6:00–12:00], afternoon [12:00–18:00], \nevening [18:00–24:00] and night [0:00–6:00]\n\nMukherji et al. [48]\n\nEqual 4 Morning [6:00–12:00], afternoon [12:00–18:00], \nevening [18:00–24:00] and night [0:00–6:00]\n\nBayir et al. [49]\n\nEqual 4 Morning, afternoon, evening and night Paireekreng et al. [41]\n\nEqual 4 Morning [6:00–11:59], day [12:00–17:59], evening \n[18:00–23:59], overnight [0:00–5:59]\n\nJayarajah et al. [50]\n\nEqual 4 Night [0:00–6:00 a.m.], morning [6:00 a.m.–12:00 \np.m.], afternoon [12:00–6:00 p.m.], and evening \n[6:00 p.m.–0:00 a.m.]\n\nDo et al. [51]\n\nUnequal 3 Morning (beginning at 6:00 a.m. and ending at \nnoon), afternoon (ending at 6:00 p.m.), night (all \nremaining hours)\n\nXu et al. [52]\n\nUnequal 4 Morning [6:00–12:00], afternoon [12:00–16:00], \nevening [16:00–20:00] and night [20:00–24:00 \nand 0:00–6:00]\n\nMehrotra et al. [7]\n\nUnequal 5 Morning [7:00–11:00], noon [11:00–14:00], after-\nnoon [14:00–18:00] and so on\n\nZhu et al. [9]\n\nUnequal 5 Morning, forenoon, afternoon, evening, and night Oulasvirta et al. [53]\n\nUnequal 5 Morning [7:00–11:00], noon [11:00–14:00], after-\nnoon [14:00–18:00], evening [18:00–21:00], and \nnight [21:00–Next day 7:00]\n\nYu et al. [54]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nNaboulsi et al. [55]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nDashdorj et al. [56]\n\nUnequal > 5 Early morning, morning, late morning, midnight \nand so on\n\nShin et al. [57]\n\nUnequal 8 S1[0:00–7:00 a.m.], S2[7:00–9:00 a.m.], S3[9:00–\n11:00 a.m.], S4[11:00 a.m.–2:00 p.m.], S5[2:00–\n5:00 p.m.], S6[5:00–7:00 p.m.], S7[7:00–9:00 p.m.] \nand S8[9:00 p.m.–12:00 a.m.]\n\nFarrahi et al. [58]\n\n\n\nPage 8 of 25Sarker  J Big Data            (2019) 6:95 \n\ninto two broad categories; (i) static segmentation, and (ii) dynamic segmentation, that \nare used in various mobile applications.\n\nStatic segmentation\n\nA static segmentation is easy to understand and can be useful to analyze population \nbehavior comparing across the mobile phone users. In order to generate segments, \nrecently, most of the researchers (shown in Table 1) take into account only the temporal \ncoverage (24-h-a-day) and statically segment time into arbitrary categories (e.g., morn-\ning) or periods (e.g., 1 h). Such static segmentation of time mainly focuses on time inter-\nvals. According to [45], there are mainly two types of time intervals: one is equal and \nanother one is unequal. For instance, four different time segments, i.e., morning [6:00–\n12:00], afternoon [12:00–18:00], evening [18:00–24:00] and night [0:00–6:00] can be an \nexample of equal interval based segmentation because of their same interval length. On \nthe other hand, another four time slots such as morning [6:00–12:00], afternoon [12:00–\n16:00], evening [16:00–20:00] and night [20:00–24:00 and 0:00–6:00] can be an example \nof unequal interval based segmentation. For this example, different lengths of time inter-\nval are used to do the segmentation. In Table 1, we have summarized a number of works \nthat use static segmentation considering either equal or unequal time interval in various \npurposes.\n\nAlthough, various time intervals and corresponding segmentation summarized in \nTable 1 are used in different purposes, these approaches take into account a fixed num-\nber of segments for all users. However, while performing such segmentation users’ behav-\nioral evidence that differs from user-to-user over time in the real world, is not taken into \naccount. Thus, these static generation of segments may not suitable for producing high \nconfidence temporal rules for individual smartphone users. For instance, N1 number \nof segments might give meaningful results for one case, while N2 number of segments \ncould give better results for another case, where N1  = N2 . Therefore, a dynamic segmen-\ntation of time rather than statically generation could be able to reflect individuals’ behav-\nioral evidence over time and can play a role to produce high confidence rules according \nto their usage records.\n\nDynamic segmentation\n\nAs discussed above, a segmentation technique that generates variable number of seg-\nments would be more meaningful to model users’ behavior. Thus, dynamic segmenta-\ntion technique rather than static segmentation can be used in order to achieve the goal. \nIn a dynamic segmentation, the number of segments are not fixed and predefined; may \nchange depending on their behavioral characteristics, patterns or preferences. Several \ndynamic segmentation techniques in terms of generating variable number of segments \nexist for modeling users’ behavioral activities in temporal contexts. A number of authors \nsimply take into account a single parameter, e.g., interval length or base period, to gener-\nate the segments. The number of time segments varies according to this period. If Tmax \nrepresents the whole time period of 24-h-a-day and BP is a base period, then the num-\nber of segments will be Tmax/BP [10]. If the base period increases, the number of time \nsegments decreases and vice-versa. For instance, if the base period is 5 min, then the \nnumber of segments will be the division result of 24-h-a-day and 5. In this example, a \n\n\n\nPage 9 of 25Sarker  J Big Data            (2019) 6:95 \n\nbase period, e.g., 5 min, is assumed as the finest granularity to distinguish day-to-day \nactivities of an individual. If the base period incremented to 15 min, then the number \nof segments decreases, where 15 min can be assumed as the finest granularity. Thus the \nnumber of segments varies based on the base time period. Similarly, individuals’ calen-\ndar schedules and corresponding time boundaries can also be used to determine var-\niable length of time segments, in order to model users’ behavior in temporal context, \nwhich may vary according to users’ preferences [59]. For instance, one user may have a \nparticular event between 1 and 2 p.m., while another may have in another time bound-\nary between 1:30 and 2:30 p.m.. Thus, the time segmentation varies according to their \ndaily life activities scheduled in their personal calendars. Similarly, multiple thresholds, \nsliding window, data shape based approaches are used in several applications, shown \nin Table 2. In addition to these approaches, a number of authors use machine learning \ntechniques such as clustering, genetic algorithm etc. In Table  2, we have summarized \na number of works that use such type of dynamic segmentation techniques in various \npurposes.\n\nClustering highlighted in Table  2 is one of the important machine learning tech-\nniques in forming large time segments where certain user behavior patterns are taken \ninto account. Usually, clustering algorithms are designed with certain assumptions and \nfavor certain type of problems. In this sense, it is not accurate to say ‘best’ in the con-\ntext of clustering algorithms; it depends on specific application [75]. Among the cluster-\ning algorithms the K-means algorithm is the best-known squared error-based clustering \nalgorithm [76]. However, this algorithm needs to specify the initial partitions and fixed \nnumber of clusters K. The convergence centroids also vary with different initial points. \nSometimes this algorithm is influenced by outliers because of mean value calculation. \n\nTable 2 Various types of dynamic time segments used in different applications\n\nBase technique Description References\n\nSingle parameter A predefined value of time interval, e.g., 15 min \nis used to generate segments\n\nOzer et al. [60]\n\nA different value of time interval, e.g., 30 min is \nused for segmentation\n\nDo et al. [61], Farrahi et al. [62]\n\nA relatively large value of the parameter, e.g., \n2-h is used to generate time segments\n\nKaratzoglou et al. [63]\n\nAnother large value of time interval, e.g., 3-h is \nused for segmentation to make the number \nof segments small\n\nPhithakkitnukoon et al. [64]\n\nCalendar Various calendar schedules and corresponding \ntime boundaries are used to model users’ \nbehavior in temporal context\n\nKhail et al. [65], Dekel et al. [66], Zulkernain \net al. [67], Seo et al. [68], Sarker et al. [28, \n59]\n\nMulti-thresholds To identify the lower and upper boundary \nof a particular segment for the purpose of \nsegmenting time-series log data\n\nHalvey et al. [38]\n\nData shape A data shape based time-series data analysis Zhang et al. [45], Shokoohi et al. [69]\n\nSliding window A sliding window is used to analyze time-series \ndata\n\nHartono et al. [70], Keogh et al. [71]\n\nClustering A predefined number of clusters is used to \ndiscover rules from time-series data\n\nDas et al. [72]\n\nGenetic algorithm A genetic algorithm is used to analyze time-\nseries data\n\nLu et al. [73], Kandasamy et al. [74]\n\n\n\nPage 10 of 25Sarker  J Big Data            (2019) 6:95 \n\nMore importantly, the characteristic of this algorithm might not be directly applicable \nfor the purpose of learning  context-aware rules. The reason is that users’ behave dif-\nferently in different contexts, which also may vary from user-to-user in the real world. \nThus, it’s difficult to assume a number of clusters K to capture their diverse behaviors \neffectively. Another similar K-medoids method [77] is more robust than K-means algo-\nrithm in the presence of outliers because a medoid is less influenced by outliers than a \nmean. Though it minimizes the outlier problem but the other characteristic mismatches \nexist between K-means and the problem of time-series modeling.\n\nAs the size and number of time segments depend on the user’s behavior and it differs \nfrom user-to-user, a bottom-up hierarchical data processing can help to make behavioral \nclusters. Existing hierarchical algorithms are mainly classified as agglomerative methods \nand device methods. However, the device clustering method is not commonly used in \npractice [75]. The simplest and most popular agglomerative clustering is single linkage \n[78] and complete linkage [79]. Another method, nearest neighbor [75], is also similar to \nthe single linkage agglomerative clustering algorithm. All these hierarchical algorithms \nuse a proximity matrix which is generated by computing the distance between a new \ncluster and other clusters. Then according to the matrix value these algorithms succes-\nsiv",
      "text": [
        "100 30 10 90 40 20 50 60 70 80 0 13-Apr-2014 + 13-Jun-2014 13-Aug-2014 13-Oct-2014 13-Dec-2014 13-Feb-2015 13-Apr-2015 13-Jun-2015 - 13-Aug-2015 Desktop 13-Oct-2015 13-Dec-2015 1 13-Feb-2016 -Tablet 13-Apr-2016 13-Jun-2016 13-Aug-2016 - 13-Oct-2016 Laptop 13-Dec-2016 13-Feb-2017 13-Apr-2017 -Mobile Phone 13-Jun-2017 13-Aug-2017 13-Oct-2017 13-Dec-2017 13-Feb-2018 13-Apr-2018 13-Jun-2018 13-Aug-2018 13-Oct-2018 13-Dec-2018 13-Feb-2019",
        "Real World Applications and Services Application 1 Application 2 Application N Dynamic Updating and Management Recency Analysis and Layer 4 Mining Rule Updation Rule Discovery Contextual Rule-based Rule Layer 3 Preferences Learning Generalization Context Discretization Time Series Contextual Layer 2 Modeling Data Clustering Contextual Data Acquisition Smartphone External Layer 1 Logs Sensors Sources",
        "Published online: 31 October 2019"
      ],
      "layoutText": [
        "{\"language\":\"en\",\"text\":\"100 30 10 90 40 20 50 60 70 80 0 13-Apr-2014 + 13-Jun-2014 13-Aug-2014 13-Oct-2014 13-Dec-2014 13-Feb-2015 13-Apr-2015 13-Jun-2015 - 13-Aug-2015 Desktop 13-Oct-2015 13-Dec-2015 1 13-Feb-2016 -Tablet 13-Apr-2016 13-Jun-2016 13-Aug-2016 - 13-Oct-2016 Laptop 13-Dec-2016 13-Feb-2017 13-Apr-2017 -Mobile Phone 13-Jun-2017 13-Aug-2017 13-Oct-2017 13-Dec-2017 13-Feb-2018 13-Apr-2018 13-Jun-2018 13-Aug-2018 13-Oct-2018 13-Dec-2018 13-Feb-2019\",\"lines\":[{\"boundingBox\":[{\"x\":0,\"y\":24},{\"x\":37,\"y\":25},{\"x\":37,\"y\":40},{\"x\":0,\"y\":39}],\"text\":\"100\"},{\"boundingBox\":[{\"x\":10,\"y\":247},{\"x\":37,\"y\":247},{\"x\":37,\"y\":263},{\"x\":10,\"y\":263}],\"text\":\"30\"},{\"boundingBox\":[{\"x\":11,\"y\":309},{\"x\":36,\"y\":308},{\"x\":36,\"y\":323},{\"x\":11,\"y\":324}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":10,\"y\":57},{\"x\":38,\"y\":57},{\"x\":38,\"y\":73},{\"x\":9,\"y\":72}],\"text\":\"90\"},{\"boundingBox\":[{\"x\":11,\"y\":215},{\"x\":34,\"y\":215},{\"x\":34,\"y\":230},{\"x\":11,\"y\":230}],\"text\":\"40\"},{\"boundingBox\":[{\"x\":12,\"y\":278},{\"x\":37,\"y\":278},{\"x\":36,\"y\":294},{\"x\":12,\"y\":293}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":12,\"y\":183},{\"x\":37,\"y\":183},{\"x\":37,\"y\":199},{\"x\":12,\"y\":199}],\"text\":\"50\"},{\"boundingBox\":[{\"x\":12,\"y\":152},{\"x\":34,\"y\":152},{\"x\":33,\"y\":167},{\"x\":11,\"y\":167}],\"text\":\"60\"},{\"boundingBox\":[{\"x\":13,\"y\":119},{\"x\":34,\"y\":119},{\"x\":34,\"y\":135},{\"x\":12,\"y\":135}],\"text\":\"70\"},{\"boundingBox\":[{\"x\":13,\"y\":88},{\"x\":36,\"y\":88},{\"x\":36,\"y\":103},{\"x\":13,\"y\":103}],\"text\":\"80\"},{\"boundingBox\":[{\"x\":25,\"y\":340},{\"x\":36,\"y\":340},{\"x\":36,\"y\":355},{\"x\":25,\"y\":355}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":50,\"y\":466},{\"x\":50,\"y\":337},{\"x\":70,\"y\":337},{\"x\":71,\"y\":466}],\"text\":\"13-Apr-2014 +\"},{\"boundingBox\":[{\"x\":96,\"y\":464},{\"x\":96,\"y\":365},{\"x\":115,\"y\":365},{\"x\":116,\"y\":464}],\"text\":\"13-Jun-2014\"},{\"boundingBox\":[{\"x\":142,\"y\":466},{\"x\":142,\"y\":365},{\"x\":162,\"y\":365},{\"x\":161,\"y\":467}],\"text\":\"13-Aug-2014\"},{\"boundingBox\":[{\"x\":187,\"y\":467},{\"x\":187,\"y\":364},{\"x\":206,\"y\":364},{\"x\":207,\"y\":466}],\"text\":\"13-Oct-2014\"},{\"boundingBox\":[{\"x\":234,\"y\":465},{\"x\":233,\"y\":364},{\"x\":252,\"y\":364},{\"x\":253,\"y\":465}],\"text\":\"13-Dec-2014\"},{\"boundingBox\":[{\"x\":279,\"y\":464},{\"x\":278,\"y\":365},{\"x\":298,\"y\":365},{\"x\":299,\"y\":464}],\"text\":\"13-Feb-2015\"},{\"boundingBox\":[{\"x\":324,\"y\":467},{\"x\":323,\"y\":364},{\"x\":343,\"y\":364},{\"x\":344,\"y\":466}],\"text\":\"13-Apr-2015\"},{\"boundingBox\":[{\"x\":369,\"y\":464},{\"x\":368,\"y\":364},{\"x\":388,\"y\":364},{\"x\":389,\"y\":464}],\"text\":\"13-Jun-2015\"},{\"boundingBox\":[{\"x\":402,\"y\":0},{\"x\":429,\"y\":1},{\"x\":428,\"y\":17},{\"x\":401,\"y\":16}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":415,\"y\":467},{\"x\":413,\"y\":364},{\"x\":435,\"y\":363},{\"x\":436,\"y\":466}],\"text\":\"13-Aug-2015\"},{\"boundingBox\":[{\"x\":446,\"y\":1},{\"x\":528,\"y\":3},{\"x\":528,\"y\":19},{\"x\":446,\"y\":18}],\"text\":\"Desktop\"},{\"boundingBox\":[{\"x\":460,\"y\":464},{\"x\":459,\"y\":365},{\"x\":479,\"y\":364},{\"x\":480,\"y\":464}],\"text\":\"13-Oct-2015\"},{\"boundingBox\":[{\"x\":506,\"y\":464},{\"x\":505,\"y\":365},{\"x\":526,\"y\":365},{\"x\":527,\"y\":463}],\"text\":\"13-Dec-2015\"},{\"boundingBox\":[{\"x\":509,\"y\":62},{\"x\":537,\"y\":65},{\"x\":534,\"y\":100},{\"x\":506,\"y\":96}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":552,\"y\":465},{\"x\":552,\"y\":364},{\"x\":572,\"y\":364},{\"x\":572,\"y\":465}],\"text\":\"13-Feb-2016\"},{\"boundingBox\":[{\"x\":551,\"y\":1},{\"x\":667,\"y\":1},{\"x\":667,\"y\":18},{\"x\":551,\"y\":18}],\"text\":\"-Tablet\"},{\"boundingBox\":[{\"x\":596,\"y\":465},{\"x\":596,\"y\":364},{\"x\":617,\"y\":364},{\"x\":618,\"y\":465}],\"text\":\"13-Apr-2016\"},{\"boundingBox\":[{\"x\":643,\"y\":464},{\"x\":643,\"y\":364},{\"x\":663,\"y\":364},{\"x\":663,\"y\":464}],\"text\":\"13-Jun-2016\"},{\"boundingBox\":[{\"x\":689,\"y\":467},{\"x\":688,\"y\":365},{\"x\":708,\"y\":365},{\"x\":709,\"y\":466}],\"text\":\"13-Aug-2016\"},{\"boundingBox\":[{\"x\":690,\"y\":2},{\"x\":728,\"y\":2},{\"x\":727,\"y\":17},{\"x\":690,\"y\":18}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":734,\"y\":467},{\"x\":734,\"y\":364},{\"x\":753,\"y\":364},{\"x\":753,\"y\":466}],\"text\":\"13-Oct-2016\"},{\"boundingBox\":[{\"x\":742,\"y\":1},{\"x\":813,\"y\":3},{\"x\":813,\"y\":19},{\"x\":741,\"y\":17}],\"text\":\"Laptop\"},{\"boundingBox\":[{\"x\":781,\"y\":467},{\"x\":779,\"y\":364},{\"x\":798,\"y\":364},{\"x\":800,\"y\":466}],\"text\":\"13-Dec-2016\"},{\"boundingBox\":[{\"x\":826,\"y\":465},{\"x\":825,\"y\":365},{\"x\":845,\"y\":365},{\"x\":846,\"y\":465}],\"text\":\"13-Feb-2017\"},{\"boundingBox\":[{\"x\":871,\"y\":464},{\"x\":870,\"y\":365},{\"x\":890,\"y\":365},{\"x\":891,\"y\":464}],\"text\":\"13-Apr-2017\"},{\"boundingBox\":[{\"x\":879,\"y\":1},{\"x\":1023,\"y\":1},{\"x\":1023,\"y\":18},{\"x\":879,\"y\":17}],\"text\":\"-Mobile Phone\"},{\"boundingBox\":[{\"x\":916,\"y\":462},{\"x\":916,\"y\":363},{\"x\":935,\"y\":363},{\"x\":936,\"y\":462}],\"text\":\"13-Jun-2017\"},{\"boundingBox\":[{\"x\":962,\"y\":467},{\"x\":961,\"y\":365},{\"x\":982,\"y\":365},{\"x\":983,\"y\":466}],\"text\":\"13-Aug-2017\"},{\"boundingBox\":[{\"x\":1007,\"y\":462},{\"x\":1006,\"y\":365},{\"x\":1027,\"y\":365},{\"x\":1027,\"y\":462}],\"text\":\"13-Oct-2017\"},{\"boundingBox\":[{\"x\":1051,\"y\":465},{\"x\":1051,\"y\":365},{\"x\":1072,\"y\":365},{\"x\":1071,\"y\":465}],\"text\":\"13-Dec-2017\"},{\"boundingBox\":[{\"x\":1099,\"y\":465},{\"x\":1098,\"y\":364},{\"x\":1119,\"y\":364},{\"x\":1120,\"y\":465}],\"text\":\"13-Feb-2018\"},{\"boundingBox\":[{\"x\":1143,\"y\":465},{\"x\":1143,\"y\":363},{\"x\":1163,\"y\":363},{\"x\":1164,\"y\":465}],\"text\":\"13-Apr-2018\"},{\"boundingBox\":[{\"x\":1189,\"y\":462},{\"x\":1189,\"y\":363},{\"x\":1209,\"y\":363},{\"x\":1209,\"y\":462}],\"text\":\"13-Jun-2018\"},{\"boundingBox\":[{\"x\":1235,\"y\":465},{\"x\":1235,\"y\":362},{\"x\":1255,\"y\":362},{\"x\":1255,\"y\":465}],\"text\":\"13-Aug-2018\"},{\"boundingBox\":[{\"x\":1280,\"y\":467},{\"x\":1279,\"y\":363},{\"x\":1297,\"y\":363},{\"x\":1298,\"y\":466}],\"text\":\"13-Oct-2018\"},{\"boundingBox\":[{\"x\":1325,\"y\":466},{\"x\":1325,\"y\":363},{\"x\":1344,\"y\":363},{\"x\":1344,\"y\":467}],\"text\":\"13-Dec-2018\"},{\"boundingBox\":[{\"x\":1373,\"y\":464},{\"x\":1372,\"y\":366},{\"x\":1392,\"y\":366},{\"x\":1393,\"y\":464}],\"text\":\"13-Feb-2019\"}],\"words\":[{\"boundingBox\":[{\"x\":0,\"y\":24},{\"x\":31,\"y\":25},{\"x\":31,\"y\":40},{\"x\":0,\"y\":39}],\"text\":\"100\"},{\"boundingBox\":[{\"x\":11,\"y\":247},{\"x\":32,\"y\":247},{\"x\":32,\"y\":263},{\"x\":11,\"y\":263}],\"text\":\"30\"},{\"boundingBox\":[{\"x\":11,\"y\":309},{\"x\":31,\"y\":308},{\"x\":31,\"y\":323},{\"x\":12,\"y\":324}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":10,\"y\":57},{\"x\":32,\"y\":57},{\"x\":32,\"y\":73},{\"x\":10,\"y\":72}],\"text\":\"90\"},{\"boundingBox\":[{\"x\":12,\"y\":215},{\"x\":32,\"y\":215},{\"x\":32,\"y\":230},{\"x\":12,\"y\":230}],\"text\":\"40\"},{\"boundingBox\":[{\"x\":12,\"y\":278},{\"x\":32,\"y\":278},{\"x\":31,\"y\":294},{\"x\":12,\"y\":293}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":12,\"y\":183},{\"x\":32,\"y\":183},{\"x\":32,\"y\":199},{\"x\":12,\"y\":199}],\"text\":\"50\"},{\"boundingBox\":[{\"x\":12,\"y\":152},{\"x\":32,\"y\":152},{\"x\":32,\"y\":167},{\"x\":12,\"y\":167}],\"text\":\"60\"},{\"boundingBox\":[{\"x\":13,\"y\":119},{\"x\":32,\"y\":119},{\"x\":32,\"y\":135},{\"x\":13,\"y\":135}],\"text\":\"70\"},{\"boundingBox\":[{\"x\":13,\"y\":88},{\"x\":32,\"y\":88},{\"x\":32,\"y\":103},{\"x\":13,\"y\":103}],\"text\":\"80\"},{\"boundingBox\":[{\"x\":25,\"y\":340},{\"x\":34,\"y\":340},{\"x\":34,\"y\":355},{\"x\":25,\"y\":355}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":50,\"y\":466},{\"x\":50,\"y\":365},{\"x\":70,\"y\":365},{\"x\":72,\"y\":466}],\"text\":\"13-Apr-2014\"},{\"boundingBox\":[{\"x\":50,\"y\":356},{\"x\":50,\"y\":345},{\"x\":70,\"y\":345},{\"x\":70,\"y\":356}],\"text\":\"+\"},{\"boundingBox\":[{\"x\":96,\"y\":464},{\"x\":96,\"y\":366},{\"x\":115,\"y\":366},{\"x\":116,\"y\":464}],\"text\":\"13-Jun-2014\"},{\"boundingBox\":[{\"x\":144,\"y\":467},{\"x\":142,\"y\":367},{\"x\":162,\"y\":367},{\"x\":160,\"y\":467}],\"text\":\"13-Aug-2014\"},{\"boundingBox\":[{\"x\":189,\"y\":466},{\"x\":187,\"y\":367},{\"x\":206,\"y\":367},{\"x\":206,\"y\":466}],\"text\":\"13-Oct-2014\"},{\"boundingBox\":[{\"x\":234,\"y\":465},{\"x\":233,\"y\":366},{\"x\":253,\"y\":366},{\"x\":254,\"y\":465}],\"text\":\"13-Dec-2014\"},{\"boundingBox\":[{\"x\":280,\"y\":464},{\"x\":278,\"y\":366},{\"x\":298,\"y\":366},{\"x\":300,\"y\":464}],\"text\":\"13-Feb-2015\"},{\"boundingBox\":[{\"x\":325,\"y\":467},{\"x\":323,\"y\":368},{\"x\":343,\"y\":367},{\"x\":343,\"y\":467}],\"text\":\"13-Apr-2015\"},{\"boundingBox\":[{\"x\":370,\"y\":464},{\"x\":368,\"y\":367},{\"x\":388,\"y\":366},{\"x\":389,\"y\":463}],\"text\":\"13-Jun-2015\"},{\"boundingBox\":[{\"x\":408,\"y\":0},{\"x\":418,\"y\":1},{\"x\":417,\"y\":17},{\"x\":407,\"y\":16}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":417,\"y\":467},{\"x\":414,\"y\":368},{\"x\":434,\"y\":367},{\"x\":434,\"y\":467}],\"text\":\"13-Aug-2015\"},{\"boundingBox\":[{\"x\":448,\"y\":2},{\"x\":523,\"y\":3},{\"x\":522,\"y\":19},{\"x\":447,\"y\":18}],\"text\":\"Desktop\"},{\"boundingBox\":[{\"x\":461,\"y\":465},{\"x\":460,\"y\":367},{\"x\":480,\"y\":367},{\"x\":481,\"y\":464}],\"text\":\"13-Oct-2015\"},{\"boundingBox\":[{\"x\":506,\"y\":463},{\"x\":505,\"y\":366},{\"x\":526,\"y\":367},{\"x\":528,\"y\":464}],\"text\":\"13-Dec-2015\"},{\"boundingBox\":[{\"x\":514,\"y\":62},{\"x\":537,\"y\":65},{\"x\":532,\"y\":100},{\"x\":510,\"y\":97}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":553,\"y\":466},{\"x\":552,\"y\":367},{\"x\":572,\"y\":366},{\"x\":573,\"y\":465}],\"text\":\"13-Feb-2016\"},{\"boundingBox\":[{\"x\":553,\"y\":3},{\"x\":664,\"y\":2},{\"x\":664,\"y\":19},{\"x\":553,\"y\":18}],\"text\":\"-Tablet\"},{\"boundingBox\":[{\"x\":596,\"y\":465},{\"x\":596,\"y\":366},{\"x\":616,\"y\":366},{\"x\":618,\"y\":465}],\"text\":\"13-Apr-2016\"},{\"boundingBox\":[{\"x\":643,\"y\":464},{\"x\":643,\"y\":366},{\"x\":663,\"y\":366},{\"x\":663,\"y\":464}],\"text\":\"13-Jun-2016\"},{\"boundingBox\":[{\"x\":690,\"y\":467},{\"x\":688,\"y\":367},{\"x\":708,\"y\":367},{\"x\":707,\"y\":467}],\"text\":\"13-Aug-2016\"},{\"boundingBox\":[{\"x\":691,\"y\":2},{\"x\":701,\"y\":2},{\"x\":701,\"y\":18},{\"x\":691,\"y\":18}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":735,\"y\":466},{\"x\":734,\"y\":368},{\"x\":753,\"y\":368},{\"x\":753,\"y\":466}],\"text\":\"13-Oct-2016\"},{\"boundingBox\":[{\"x\":743,\"y\":2},{\"x\":806,\"y\":4},{\"x\":806,\"y\":20},{\"x\":743,\"y\":18}],\"text\":\"Laptop\"},{\"boundingBox\":[{\"x\":782,\"y\":467},{\"x\":779,\"y\":367},{\"x\":799,\"y\":367},{\"x\":799,\"y\":467}],\"text\":\"13-Dec-2016\"},{\"boundingBox\":[{\"x\":827,\"y\":465},{\"x\":825,\"y\":367},{\"x\":846,\"y\":366},{\"x\":847,\"y\":465}],\"text\":\"13-Feb-2017\"},{\"boundingBox\":[{\"x\":871,\"y\":465},{\"x\":870,\"y\":366},{\"x\":890,\"y\":366},{\"x\":891,\"y\":464}],\"text\":\"13-Apr-2017\"},{\"boundingBox\":[{\"x\":880,\"y\":1},{\"x\":953,\"y\":2},{\"x\":953,\"y\":18},{\"x\":880,\"y\":18}],\"text\":\"-Mobile\"},{\"boundingBox\":[{\"x\":958,\"y\":2},{\"x\":1018,\"y\":2},{\"x\":1018,\"y\":18},{\"x\":959,\"y\":18}],\"text\":\"Phone\"},{\"boundingBox\":[{\"x\":916,\"y\":462},{\"x\":916,\"y\":366},{\"x\":935,\"y\":364},{\"x\":937,\"y\":462}],\"text\":\"13-Jun-2017\"},{\"boundingBox\":[{\"x\":963,\"y\":467},{\"x\":961,\"y\":366},{\"x\":982,\"y\":366},{\"x\":981,\"y\":467}],\"text\":\"13-Aug-2017\"},{\"boundingBox\":[{\"x\":1007,\"y\":463},{\"x\":1006,\"y\":367},{\"x\":1028,\"y\":367},{\"x\":1028,\"y\":462}],\"text\":\"13-Oct-2017\"},{\"boundingBox\":[{\"x\":1051,\"y\":465},{\"x\":1051,\"y\":367},{\"x\":1072,\"y\":366},{\"x\":1072,\"y\":465}],\"text\":\"13-Dec-2017\"},{\"boundingBox\":[{\"x\":1100,\"y\":465},{\"x\":1099,\"y\":366},{\"x\":1119,\"y\":366},{\"x\":1120,\"y\":464}],\"text\":\"13-Feb-2018\"},{\"boundingBox\":[{\"x\":1143,\"y\":465},{\"x\":1143,\"y\":366},{\"x\":1163,\"y\":366},{\"x\":1164,\"y\":465}],\"text\":\"13-Apr-2018\"},{\"boundingBox\":[{\"x\":1190,\"y\":462},{\"x\":1189,\"y\":367},{\"x\":1209,\"y\":367},{\"x\":1209,\"y\":461}],\"text\":\"13-Jun-2018\"},{\"boundingBox\":[{\"x\":1235,\"y\":465},{\"x\":1235,\"y\":367},{\"x\":1255,\"y\":367},{\"x\":1256,\"y\":465}],\"text\":\"13-Aug-2018\"},{\"boundingBox\":[{\"x\":1281,\"y\":466},{\"x\":1279,\"y\":367},{\"x\":1298,\"y\":367},{\"x\":1298,\"y\":466}],\"text\":\"13-Oct-2018\"},{\"boundingBox\":[{\"x\":1326,\"y\":467},{\"x\":1325,\"y\":367},{\"x\":1344,\"y\":367},{\"x\":1343,\"y\":467}],\"text\":\"13-Dec-2018\"},{\"boundingBox\":[{\"x\":1373,\"y\":465},{\"x\":1372,\"y\":368},{\"x\":1392,\"y\":368},{\"x\":1394,\"y\":463}],\"text\":\"13-Feb-2019\"}]}",
        "{\"language\":\"en\",\"text\":\"Real World Applications and Services Application 1 Application 2 Application N Dynamic Updating and Management Recency Analysis and Layer 4 Mining Rule Updation Rule Discovery Contextual Rule-based Rule Layer 3 Preferences Learning Generalization Context Discretization Time Series Contextual Layer 2 Modeling Data Clustering Contextual Data Acquisition Smartphone External Layer 1 Logs Sensors Sources\",\"lines\":[{\"boundingBox\":[{\"x\":242,\"y\":22},{\"x\":859,\"y\":22},{\"x\":859,\"y\":53},{\"x\":242,\"y\":53}],\"text\":\"Real World Applications and Services\"},{\"boundingBox\":[{\"x\":89,\"y\":101},{\"x\":301,\"y\":99},{\"x\":302,\"y\":129},{\"x\":89,\"y\":133}],\"text\":\"Application 1\"},{\"boundingBox\":[{\"x\":430,\"y\":103},{\"x\":647,\"y\":101},{\"x\":647,\"y\":130},{\"x\":430,\"y\":133}],\"text\":\"Application 2\"},{\"boundingBox\":[{\"x\":762,\"y\":103},{\"x\":983,\"y\":101},{\"x\":983,\"y\":129},{\"x\":762,\"y\":132}],\"text\":\"Application N\"},{\"boundingBox\":[{\"x\":154,\"y\":234},{\"x\":753,\"y\":234},{\"x\":753,\"y\":265},{\"x\":154,\"y\":265}],\"text\":\"Dynamic Updating and Management\"},{\"boundingBox\":[{\"x\":46,\"y\":302},{\"x\":409,\"y\":302},{\"x\":409,\"y\":330},{\"x\":46,\"y\":331}],\"text\":\"Recency Analysis and\"},{\"boundingBox\":[{\"x\":900,\"y\":284},{\"x\":1026,\"y\":283},{\"x\":1027,\"y\":313},{\"x\":900,\"y\":314}],\"text\":\"Layer 4\"},{\"boundingBox\":[{\"x\":175,\"y\":334},{\"x\":284,\"y\":336},{\"x\":283,\"y\":365},{\"x\":175,\"y\":361}],\"text\":\"Mining\"},{\"boundingBox\":[{\"x\":520,\"y\":319},{\"x\":756,\"y\":320},{\"x\":756,\"y\":348},{\"x\":520,\"y\":347}],\"text\":\"Rule Updation\"},{\"boundingBox\":[{\"x\":337,\"y\":454},{\"x\":587,\"y\":456},{\"x\":587,\"y\":483},{\"x\":337,\"y\":480}],\"text\":\"Rule Discovery\"},{\"boundingBox\":[{\"x\":63,\"y\":521},{\"x\":241,\"y\":521},{\"x\":241,\"y\":547},{\"x\":63,\"y\":547}],\"text\":\"Contextual\"},{\"boundingBox\":[{\"x\":319,\"y\":520},{\"x\":507,\"y\":521},{\"x\":507,\"y\":547},{\"x\":319,\"y\":546}],\"text\":\"Rule-based\"},{\"boundingBox\":[{\"x\":660,\"y\":522},{\"x\":737,\"y\":522},{\"x\":737,\"y\":546},{\"x\":659,\"y\":545}],\"text\":\"Rule\"},{\"boundingBox\":[{\"x\":902,\"y\":505},{\"x\":1031,\"y\":503},{\"x\":1031,\"y\":533},{\"x\":902,\"y\":535}],\"text\":\"Layer 3\"},{\"boundingBox\":[{\"x\":53,\"y\":552},{\"x\":254,\"y\":553},{\"x\":254,\"y\":581},{\"x\":53,\"y\":580}],\"text\":\"Preferences\"},{\"boundingBox\":[{\"x\":338,\"y\":553},{\"x\":481,\"y\":554},{\"x\":481,\"y\":582},{\"x\":337,\"y\":581}],\"text\":\"Learning\"},{\"boundingBox\":[{\"x\":578,\"y\":553},{\"x\":816,\"y\":553},{\"x\":816,\"y\":579},{\"x\":578,\"y\":580}],\"text\":\"Generalization\"},{\"boundingBox\":[{\"x\":248,\"y\":665},{\"x\":605,\"y\":665},{\"x\":605,\"y\":693},{\"x\":248,\"y\":693}],\"text\":\"Context Discretization\"},{\"boundingBox\":[{\"x\":129,\"y\":730},{\"x\":325,\"y\":731},{\"x\":325,\"y\":759},{\"x\":129,\"y\":759}],\"text\":\"Time Series\"},{\"boundingBox\":[{\"x\":552,\"y\":734},{\"x\":732,\"y\":733},{\"x\":732,\"y\":759},{\"x\":552,\"y\":760}],\"text\":\"Contextual\"},{\"boundingBox\":[{\"x\":900,\"y\":713},{\"x\":1031,\"y\":712},{\"x\":1031,\"y\":743},{\"x\":900,\"y\":743}],\"text\":\"Layer 2\"},{\"boundingBox\":[{\"x\":152,\"y\":763},{\"x\":303,\"y\":766},{\"x\":302,\"y\":795},{\"x\":152,\"y\":790}],\"text\":\"Modeling\"},{\"boundingBox\":[{\"x\":514,\"y\":765},{\"x\":769,\"y\":766},{\"x\":769,\"y\":796},{\"x\":514,\"y\":794}],\"text\":\"Data Clustering\"},{\"boundingBox\":[{\"x\":203,\"y\":885},{\"x\":655,\"y\":885},{\"x\":655,\"y\":915},{\"x\":203,\"y\":915}],\"text\":\"Contextual Data Acquisition\"},{\"boundingBox\":[{\"x\":76,\"y\":958},{\"x\":278,\"y\":960},{\"x\":278,\"y\":988},{\"x\":76,\"y\":986}],\"text\":\"Smartphone\"},{\"boundingBox\":[{\"x\":633,\"y\":955},{\"x\":768,\"y\":955},{\"x\":768,\"y\":981},{\"x\":633,\"y\":981}],\"text\":\"External\"},{\"boundingBox\":[{\"x\":899,\"y\":932},{\"x\":1029,\"y\":932},{\"x\":1029,\"y\":962},{\"x\":899,\"y\":963}],\"text\":\"Layer 1\"},{\"boundingBox\":[{\"x\":136,\"y\":992},{\"x\":216,\"y\":994},{\"x\":216,\"y\":1020},{\"x\":136,\"y\":1018}],\"text\":\"Logs\"},{\"boundingBox\":[{\"x\":379,\"y\":974},{\"x\":519,\"y\":976},{\"x\":519,\"y\":1001},{\"x\":379,\"y\":999}],\"text\":\"Sensors\"},{\"boundingBox\":[{\"x\":635,\"y\":989},{\"x\":770,\"y\":989},{\"x\":770,\"y\":1012},{\"x\":635,\"y\":1011}],\"text\":\"Sources\"}],\"words\":[{\"boundingBox\":[{\"x\":243,\"y\":23},{\"x\":321,\"y\":23},{\"x\":321,\"y\":53},{\"x\":243,\"y\":52}],\"text\":\"Real\"},{\"boundingBox\":[{\"x\":327,\"y\":23},{\"x\":420,\"y\":22},{\"x\":420,\"y\":54},{\"x\":327,\"y\":53}],\"text\":\"World\"},{\"boundingBox\":[{\"x\":435,\"y\":22},{\"x\":630,\"y\":23},{\"x\":630,\"y\":54},{\"x\":435,\"y\":54}],\"text\":\"Applications\"},{\"boundingBox\":[{\"x\":643,\"y\":23},{\"x\":701,\"y\":23},{\"x\":701,\"y\":53},{\"x\":643,\"y\":53}],\"text\":\"and\"},{\"boundingBox\":[{\"x\":713,\"y\":23},{\"x\":854,\"y\":25},{\"x\":854,\"y\":52},{\"x\":713,\"y\":53}],\"text\":\"Services\"},{\"boundingBox\":[{\"x\":91,\"y\":102},{\"x\":266,\"y\":100},{\"x\":266,\"y\":130},{\"x\":90,\"y\":134}],\"text\":\"Application\"},{\"boundingBox\":[{\"x\":283,\"y\":100},{\"x\":301,\"y\":100},{\"x\":301,\"y\":130},{\"x\":283,\"y\":130}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":434,\"y\":104},{\"x\":607,\"y\":102},{\"x\":607,\"y\":131},{\"x\":432,\"y\":133}],\"text\":\"Application\"},{\"boundingBox\":[{\"x\":623,\"y\":101},{\"x\":640,\"y\":101},{\"x\":640,\"y\":131},{\"x\":623,\"y\":131}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":763,\"y\":104},{\"x\":939,\"y\":102},{\"x\":939,\"y\":131},{\"x\":763,\"y\":133}],\"text\":\"Application\"},{\"boundingBox\":[{\"x\":952,\"y\":102},{\"x\":969,\"y\":102},{\"x\":969,\"y\":130},{\"x\":952,\"y\":131}],\"text\":\"N\"},{\"boundingBox\":[{\"x\":156,\"y\":236},{\"x\":295,\"y\":235},{\"x\":294,\"y\":266},{\"x\":154,\"y\":265}],\"text\":\"Dynamic\"},{\"boundingBox\":[{\"x\":305,\"y\":235},{\"x\":449,\"y\":235},{\"x\":448,\"y\":266},{\"x\":304,\"y\":266}],\"text\":\"Updating\"},{\"boundingBox\":[{\"x\":463,\"y\":235},{\"x\":520,\"y\":235},{\"x\":519,\"y\":266},{\"x\":462,\"y\":266}],\"text\":\"and\"},{\"boundingBox\":[{\"x\":534,\"y\":235},{\"x\":753,\"y\":237},{\"x\":754,\"y\":265},{\"x\":534,\"y\":266}],\"text\":\"Management\"},{\"boundingBox\":[{\"x\":47,\"y\":304},{\"x\":186,\"y\":303},{\"x\":187,\"y\":332},{\"x\":49,\"y\":331}],\"text\":\"Recency\"},{\"boundingBox\":[{\"x\":197,\"y\":303},{\"x\":333,\"y\":302},{\"x\":333,\"y\":331},{\"x\":198,\"y\":332}],\"text\":\"Analysis\"},{\"boundingBox\":[{\"x\":346,\"y\":302},{\"x\":402,\"y\":302},{\"x\":402,\"y\":331},{\"x\":347,\"y\":331}],\"text\":\"and\"},{\"boundingBox\":[{\"x\":901,\"y\":286},{\"x\":996,\"y\":285},{\"x\":996,\"y\":315},{\"x\":901,\"y\":314}],\"text\":\"Layer\"},{\"boundingBox\":[{\"x\":1003,\"y\":284},{\"x\":1019,\"y\":284},{\"x\":1019,\"y\":315},{\"x\":1002,\"y\":315}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":175,\"y\":335},{\"x\":276,\"y\":336},{\"x\":276,\"y\":365},{\"x\":175,\"y\":361}],\"text\":\"Mining\"},{\"boundingBox\":[{\"x\":522,\"y\":319},{\"x\":593,\"y\":320},{\"x\":592,\"y\":348},{\"x\":521,\"y\":347}],\"text\":\"Rule\"},{\"boundingBox\":[{\"x\":606,\"y\":320},{\"x\":748,\"y\":320},{\"x\":748,\"y\":348},{\"x\":605,\"y\":348}],\"text\":\"Updation\"},{\"boundingBox\":[{\"x\":337,\"y\":455},{\"x\":408,\"y\":455},{\"x\":407,\"y\":481},{\"x\":337,\"y\":480}],\"text\":\"Rule\"},{\"boundingBox\":[{\"x\":422,\"y\":456},{\"x\":582,\"y\":456},{\"x\":582,\"y\":484},{\"x\":421,\"y\":482}],\"text\":\"Discovery\"},{\"boundingBox\":[{\"x\":65,\"y\":522},{\"x\":241,\"y\":522},{\"x\":241,\"y\":547},{\"x\":63,\"y\":547}],\"text\":\"Contextual\"},{\"boundingBox\":[{\"x\":319,\"y\":520},{\"x\":497,\"y\":522},{\"x\":497,\"y\":548},{\"x\":319,\"y\":546}],\"text\":\"Rule-based\"},{\"boundingBox\":[{\"x\":660,\"y\":522},{\"x\":727,\"y\":523},{\"x\":727,\"y\":547},{\"x\":660,\"y\":546}],\"text\":\"Rule\"},{\"boundingBox\":[{\"x\":904,\"y\":507},{\"x\":994,\"y\":506},{\"x\":995,\"y\":535},{\"x\":903,\"y\":534}],\"text\":\"Layer\"},{\"boundingBox\":[{\"x\":1002,\"y\":505},{\"x\":1019,\"y\":504},{\"x\":1020,\"y\":534},{\"x\":1003,\"y\":535}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":54,\"y\":552},{\"x\":245,\"y\":555},{\"x\":246,\"y\":581},{\"x\":54,\"y\":581}],\"text\":\"Preferences\"},{\"boundingBox\":[{\"x\":338,\"y\":554},{\"x\":476,\"y\":555},{\"x\":476,\"y\":583},{\"x\":338,\"y\":582}],\"text\":\"Learning\"},{\"boundingBox\":[{\"x\":579,\"y\":554},{\"x\":807,\"y\":553},{\"x\":807,\"y\":580},{\"x\":579,\"y\":580}],\"text\":\"Generalization\"},{\"boundingBox\":[{\"x\":250,\"y\":666},{\"x\":377,\"y\":666},{\"x\":376,\"y\":694},{\"x\":249,\"y\":694}],\"text\":\"Context\"},{\"boundingBox\":[{\"x\":382,\"y\":666},{\"x\":599,\"y\":666},{\"x\":598,\"y\":694},{\"x\":381,\"y\":694}],\"text\":\"Discretization\"},{\"boundingBox\":[{\"x\":131,\"y\":731},{\"x\":201,\"y\":732},{\"x\":202,\"y\":759},{\"x\":131,\"y\":760}],\"text\":\"Time\"},{\"boundingBox\":[{\"x\":217,\"y\":732},{\"x\":319,\"y\":731},{\"x\":319,\"y\":760},{\"x\":217,\"y\":759}],\"text\":\"Series\"},{\"boundingBox\":[{\"x\":555,\"y\":734},{\"x\":732,\"y\":733},{\"x\":731,\"y\":760},{\"x\":553,\"y\":761}],\"text\":\"Contextual\"},{\"boundingBox\":[{\"x\":902,\"y\":714},{\"x\":996,\"y\":714},{\"x\":995,\"y\":744},{\"x\":901,\"y\":743}],\"text\":\"Layer\"},{\"boundingBox\":[{\"x\":1002,\"y\":713},{\"x\":1019,\"y\":713},{\"x\":1019,\"y\":744},{\"x\":1002,\"y\":744}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":153,\"y\":763},{\"x\":293,\"y\":767},{\"x\":293,\"y\":795},{\"x\":153,\"y\":790}],\"text\":\"Modeling\"},{\"boundingBox\":[{\"x\":515,\"y\":765},{\"x\":587,\"y\":766},{\"x\":587,\"y\":794},{\"x\":514,\"y\":794}],\"text\":\"Data\"},{\"boundingBox\":[{\"x\":601,\"y\":766},{\"x\":762,\"y\":766},{\"x\":762,\"y\":797},{\"x\":600,\"y\":794}],\"text\":\"Clustering\"},{\"boundingBox\":[{\"x\":204,\"y\":887},{\"x\":380,\"y\":886},{\"x\":380,\"y\":916},{\"x\":204,\"y\":915}],\"text\":\"Contextual\"},{\"boundingBox\":[{\"x\":385,\"y\":886},{\"x\":462,\"y\":886},{\"x\":462,\"y\":916},{\"x\":386,\"y\":916}],\"text\":\"Data\"},{\"boundingBox\":[{\"x\":474,\"y\":886},{\"x\":648,\"y\":887},{\"x\":648,\"y\":915},{\"x\":474,\"y\":916}],\"text\":\"Acquisition\"},{\"boundingBox\":[{\"x\":76,\"y\":959},{\"x\":270,\"y\":961},{\"x\":270,\"y\":988},{\"x\":77,\"y\":986}],\"text\":\"Smartphone\"},{\"boundingBox\":[{\"x\":634,\"y\":956},{\"x\":768,\"y\":956},{\"x\":767,\"y\":981},{\"x\":634,\"y\":981}],\"text\":\"External\"},{\"boundingBox\":[{\"x\":899,\"y\":933},{\"x\":995,\"y\":934},{\"x\":996,\"y\":963},{\"x\":900,\"y\":963}],\"text\":\"Layer\"},{\"boundingBox\":[{\"x\":1005,\"y\":933},{\"x\":1022,\"y\":933},{\"x\":1024,\"y\":962},{\"x\":1006,\"y\":963}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":137,\"y\":993},{\"x\":212,\"y\":995},{\"x\":210,\"y\":1021},{\"x\":137,\"y\":1019}],\"text\":\"Logs\"},{\"boundingBox\":[{\"x\":380,\"y\":974},{\"x\":509,\"y\":977},{\"x\":510,\"y\":1001},{\"x\":380,\"y\":1000}],\"text\":\"Sensors\"},{\"boundingBox\":[{\"x\":636,\"y\":989},{\"x\":761,\"y\":990},{\"x\":761,\"y\":1013},{\"x\":635,\"y\":1012}],\"text\":\"Sources\"}]}",
        "{\"language\":\"en\",\"text\":\"Published online: 31 October 2019\",\"lines\":[{\"boundingBox\":[{\"x\":4,\"y\":14},{\"x\":992,\"y\":14},{\"x\":992,\"y\":70},{\"x\":4,\"y\":70}],\"text\":\"Published online: 31 October 2019\"}],\"words\":[{\"boundingBox\":[{\"x\":4,\"y\":16},{\"x\":272,\"y\":15},{\"x\":272,\"y\":71},{\"x\":4,\"y\":70}],\"text\":\"Published\"},{\"boundingBox\":[{\"x\":292,\"y\":15},{\"x\":496,\"y\":15},{\"x\":495,\"y\":71},{\"x\":291,\"y\":71}],\"text\":\"online:\"},{\"boundingBox\":[{\"x\":507,\"y\":15},{\"x\":579,\"y\":15},{\"x\":578,\"y\":71},{\"x\":506,\"y\":71}],\"text\":\"31\"},{\"boundingBox\":[{\"x\":594,\"y\":15},{\"x\":834,\"y\":15},{\"x\":833,\"y\":71},{\"x\":593,\"y\":71}],\"text\":\"October\"},{\"boundingBox\":[{\"x\":846,\"y\":15},{\"x\":987,\"y\":16},{\"x\":986,\"y\":70},{\"x\":845,\"y\":71}],\"text\":\"2019\"}]}"
      ]
    },
    {
      "@search.score": 3.6058593,
      "content": "\nMulti technique amalgamation \nfor enhanced information identification \nwith content based image data\nRik Das1*, Sudeep Thepade2 and Saurav Ghosh3\n\nBackground\nRecent years have witnessed the digital photo-capture devices as a ubiquity for the com-\nmon mass (Raventós et al. 2015). The low cost storage, increasing computer power and \never accessible internet have kindled the popularity of digital image acquisition. Efficient \nindexing and identification of image data from these huge image repositories has nur-\ntured new research challenges in computer vision and machine learning (Madireddy \net  al. 2014). Automatic derivation of sematically-meaningful information from image \ncontent has become imperative as the traditional text based annotation technique has \nrevealed severe limitations to fetch information from the gigantic image datasets (Walia \net al. 2014). Conventional techniques of image recognition were based on text or key-\nwords based mapping of images which had limited image information. It was dependent \non the perception and vocabulary of the person performing the annotation. The manual \nprocess was highly time consuming and slow in nature. The aforesaid limitations have \n\nAbstract \n\nImage data has emerged as a resourceful foundation for information with proliferation \nof image capturing devices and social media. Diverse applications of images in areas \nincluding biomedicine, military, commerce, education have resulted in huge image \nrepositories. Semantically analogous images can be fruitfully recognized by means of \ncontent based image identification. However, the success of the technique has been \nlargely dependent on extraction of robust feature vectors from the image content. The \npaper has introduced three different techniques of content based feature extraction \nbased on image binarization, image transform and morphological operator respec-\ntively. The techniques were tested with four public datasets namely, Wang Dataset, \nOliva Torralba (OT Scene) Dataset, Corel Dataset and Caltech Dataset. The multi tech-\nnique feature extraction process was further integrated for decision fusion of image \nidentification to boost up the recognition rate. Classification result with the proposed \ntechnique has shown an average increase of 14.5 % in Precision compared to the exist-\ning techniques and the retrieval result with the introduced technique has shown an \naverage increase of 6.54 % in Precision over state-of-the art techniques.\n\nKeywords: Image classification, Image retrieval, Otsu’s threshold, Slant transform, \nMorphological operator, Fusion, t test\n\nOpen Access\n\n© 2015 Das et al. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://\ncreativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided \nyou give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate \nif changes were made.\n\nRESEARCH\n\nDas et al. SpringerPlus  (2015) 4:749 \nDOI 10.1186/s40064-015-1515-4\n\n*Correspondence:  rikdas78@\ngmail.com \n1 Department of Information \nTechnology, Xavier Institute \nof Social Service, Dr. Camil \nBulcke Path (Purulia Road), \nP.O. Box 7, Ranchi 834001, \nJharkhand, India\nFull list of author information \nis available at the end of the \narticle\n\n\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40064-015-1515-4&domain=pdf\n\n\nPage 2 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nbeen effectively handled with content based image identification which has been exer-\ncised as an effective alternative to the customary text based process (Wang et al. 2013). \nThe competence of the content based image identification technique has been depend-\nent on the extraction of robust feature vectors. Diverse low level features namely, color, \nshape, texture etc. have constituted the process of feature extraction. However, an image \ncomprises of number of features which can hardly be defined by a single feature extrac-\ntion technique (Walia et al. 2014). Therefore, three different techniques of feature extrac-\ntion namely, feature extraction with image transform, feature extraction with image \nmorphology and feature extraction with image binarization have been proposed in this \npaper to leverage fusion of multi-technique feature extraction. The recognition decision \nof three different techniques was further integrated by means of Z score normalization \nto create hybrid architecture for content based image identification. The main contribu-\ntion of the paper has been to propose fusion architecture for content based image recog-\nnition with novel techniques of feature extraction for enhanced recognition rate.\n\nThe research objectives have been enlisted as follows:\n\n  • Reducing the dimension of feature vectors.\n  • Successfully implementing fusion based method of content based image identifica-\n\ntion.\n  • Statistical validation of research results.\n  • Comparison of research results with state-of-the art techniques.\n\nThree different techniques of feature extraction using image binarization, image trans-\nforms and morphological operators have been combined to develop fusion based archi-\ntecture for content based image classification and retrieval. Hence, it is in correlation with \nresearch on binarization based feature extraction, transform based feature extraction and \nmorphology based feature extraction from images. It is also in connection with research \non multi technique fusion for content based image identification. Therefore, the following \nfour subsections have reviewed some contemporary and earlier works on these four topics.\n\nFeature extraction using image transform\n\nChange of domain of the image elements has been carried out by using image trans-\nformation to represent the image by a set of energy spectrum. An image can be repre-\nsented as series of basis images which can be formed by extrapolating the image into a \nseries of basis functions (Annadurai and Shanmugalakshmi 2011). The basis images have \nbeen populated by using orthogonal unitary matrices as image transformation opera-\ntor. This image transformation from one representation to another has advantages in \ntwo aspects. An image can be expanded in the form of a series of waveforms with the \nuse of image transforms. The transformation process has been helpful to differentiate \nthe critical components of image patterns and in making them directly accessible for \nanalysis. Moreover, the transformed image data has a compact structure useful for effi-\ncient storage and transmission. The aforesaid properties of image transforms facilitate \nradical reduction of feature vector dimension to be extracted from the images. Diverse \ntechniques of feature extraction has been proposed by exploiting the properties of image \ntransforms to extract features from images using fractional energy coefficient (Kekre and \n\n\n\nPage 3 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nThepade 2009; Kekre et  al. 2010). The techniques have considered seven image trans-\nforms and fifteen fractional coefficients sets for efficient feature extraction. Original \nimages were divided into subbands by using multiple scales Biorthogonal wavelet trans-\nform and the subband coefficients were used as features for image classification (Prakash \net al. 2013). The feature spaces were reduced by applying Isomap-Hysime random aniso-\ntropic transform for classification of high dimensional data (Luo et al. 2013).\n\nImage binarization techniques for feature extraction\n\nFeature extraction from images has been largely carried out by means of image binariza-\ntion. Appropriate threshold selection has been imperative for execution of efficient image \nbinarization. Nevertheless, various factors including uneven illumination, inadequate \ncontrast etc. can have adverse effect on threshold computation (Valizadeh et  al. 2009). \nContemporary literatures on image binarization techniques have categorized three dif-\nferent techniques for threshold selection namely, mean threshold selection, local thresh-\nold selection and global threshold selection to deal with the unfavourable influences on \nthreshold selection. Enhanced classification results have been comprehended by feature \nextraction from mean threshold and multilevel mean threshold based binarized images \n(Kekre et al. 2013; Thepade et al. 2013a, b). Eventually, it has been identified that selection \nof mean threshold has not dealt with the standard deviation of the gray values and has \nconcentrated only on the average which has prevented the feature extraction techniques \nto take advantage of the spread of data to distinguish distinct features. Therefore, image \nsignature extraction was carried out with local threshold selection and global thresh-\nold selection for binarization, as the techniques were based on calculation of both mean \nand standard deviation of the gray values (Liu 2013; Yanli and Zhenxing 2012; Ramírez-\nOrtegón and Rojas 2010; Otsu 1979; Shaikh et al. 2013; Thepade et al. 2014a).\n\nUse of morphological operators for feature extraction\n\nCommercial viability of shape feature extraction has been well highlighted by systems \nlike Image Content (Flickner et  al. 1995), PicToSeek (Gevers and Smeulders 2000). \nTwo different categorization of shape descriptors namely, contour-based and region-\nbased descriptors have been elaborated in the existing literatures (Mehtre et  al. 1997; \nZhang and Lu 2004). Emphasize of the contour based descriptors has been on bound-\nary lines. Popular contour-based descriptors have embraced Fourier descriptor (Zhang \nand Lu 2003), curvature scale space (Mokhtarian and Mackworth 1992), and chain codes \n(Dubois and Glanz 1986). Feature extraction from complex shapes has been well car-\nried out by means of region-based descriptors, since the feature extraction has been per-\nformed from whole area of object (Kim and Kim 2000).\n\nFusion methodologies and multi technique feature extraction\n\nInformation recognition with image data has utilized the features extracted by means \nof diverse extraction techniques to harmonize each other for enhanced identification \nrate. Recent studies in information fusion have categorized the methodologies typically \ninto four classes, namely, early fusion, late fusion, hybrid fusion and intermediate fusion. \nEarly fusion combines the features of different techniques and produces it as a single \ninput to the learner. The process inherently increases the size of feature vector as the \n\n\n\nPage 4 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nconcentrated features easily correspond to higher dimensions. Late fusion applies sepa-\nrate learner to each feature extraction technique and fuses the decision with a combiner. \nAlthough it offers scalability in comparison to early fusion, still, it cannot explore the \nfeature level correlations, since it has to make local decisions primarily. Hybrid fusion \nmakes a mix of the two above mentioned techniques. Intermediate fusion integrates \nmultiple features by considering a joint model for decision to yield superior prediction \naccuracy (Zhu and Shyu 2015). Color and texture features were extracted by means of \n3 D color histogram and Gabor filters for fusion based image identification. The space \ncomplexity of the feature was further reduced by using genetic algorithm which has also \nobtained the optimum boundaries of numerical intervals. The process has enhanced \nsemantic retrieval by introducing feature selection technique to reduce memory con-\nsumption and to decrease retrieval process complexity (ElAlami 2011). Local descriptors \nbased on color and texture was calculated from Color moments and moments on Gabor \nfilter responses. Gradient vector flow fields were calculated to capture shape information \nin terms of edge images. The shape features were finally depicted by invariant moments. \nThe retrieval decisions with the features were fused for enhanced retrieval performance \n(Hiremath and Pujari 2007). Feature vectors comprising of color histogram and tex-\nture features based on a co-occurrence matrix were extracted from HSV color space \nto facilitate image retrieval (Yue et al. 2011). Visually significant point features chosen \nfrom images by means of fuzzy set theoretic approach. Computation of some invariant \ncolor features from these points was performed to gauge the similarity between images \n(Banerjee et al. 2009). Recognition process was boosted up by combining color layout \ndescriptor and Gabor texture descriptor as image signatures (Jalab 2011). Multi view \nfeatures comprising of color, texture and spatial structure descriptors have contributed \nfor increased retrieval rate (Shen and Wu 2013). Wavelet packets and Eigen values of \nGabor filters were extracted as feature vectors by the authors in (Irtaza et al. 2013) for \nneural network architecture of image identification. The back propagation neural net-\nwork was trained on sub repository of images generated from the main image reposi-\ntory and utilizes the right neighbourhood of the query image. This kind of training was \naimed to insure correct semantic retrieval in response to query images. Higher retrieval \nresults have been apprehended with intra-class and inter-class feature extraction from \nimages (Rahimi and Moghaddam 2013). In (ElAlami 2014), extraction of color and tex-\nture features through color co-occurrence matrix (CCM) and difference between pixels \nof scan pattern (DBPSP) has been demonstrated and an artificial neural network (ANN) \nbased classifier was designed. In (Subrahmanyam et  al. 2013), content-based image \nretrieval was carried out by integrating the modified color motif co-occurrence matrix \n(MCMCM) and difference between the pixels of a scan pattern (DBPSP) features with \nequal weights. Fusion of semantic retrieval results obtained by capturing colour, shape \nand texture with the color moment (CMs), angular radial transform descriptor and edge \nhistogram descriptor (EHD) features respectively had outclassed the Precision values of \nindividual techniques (Walia et al. 2014). Six semantics of local edge bins for EHD were \nconsidered which included the vertical and the horizontal edge (0,0), 45° edge and 135° \nedge of sub-image (0,0), non directional edge of sub-image (0,0) and vertical edge of sub-\nimage at (0,1). Color histogram and spatial orientation tree has been used for unique \nfeature extraction from images for retrieval purpose (Subrahmanyam et al. 2012).\n\n\n\nPage 5 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nMethods\nThree different techniques of feature extraction have been introduced in this work namely, \nfeature extraction with image binarization, feature extraction with image transform and \nfeature extraction with morphological operator. However, there are popular feature extrac-\ntion techniques like GIST descriptor which has much greater feature dimension com-\npared to the proposed techniques in the work. GIST creates 32 feature maps of same \nsize by convolving the image with 32 Gabor filters at 4 scales, 8 orientations (Douze et al. \n2009). It averages the feature values of each region by dividing each feature map into 16 \nregions. Finally, it concatenates the 16 average value of all 32 feature maps resulting in \n16 × 32 = 512 GIST descriptor. On the other hand, our approach has generated a fea-\nture dimension of 6 from each of the binarization and morphological technique. Feature \nextraction by applying image transform has yielded a feature size of 36. On the whole, the \nfeature size for the fusion based classifier was (6 + 36 + 6 = 48) which is far less than GIST \nand has much lesser computational overhead. Furthermore, fusion based architecture for \nclassification and retrieval have been proposed for enhanced identification rate of image \ndata. Each of the techniques of feature extraction as well as the methods for fusion based \narchitecture of classification and retrieval has been discussed in the following four subsec-\ntions and the description of datasets has been given in the fifth subsection.\n\nFeature extraction with image binarization\n\nInitially, the three color components namely, Red (R), Green (G) and Blue (B) were sepa-\nrated in each of the test images. A popular global threshold selection method named \nOtsu’s method has been applied separately on each of the color components for binari-\nzation as in Fig. 1. The above mentioned thresholding method has been largely used for \ndocument image binarzation. Otsu’s technique has been operated directly on the gray \nlevel histogram which has made it fast executable. It has been efficient to remove redun-\ndant details from the image to bring out the necessary image information. The method \nhas been considered as a non-parametric method which has considered two classes of \npixels, namely, the foreground pixels and the background pixels. It has calculated the \noptimal threshold by using the within-class variance and between-class variance. The \nseparation was carried out in such a way so that their combined intra-class variance is \nminimal (Otsu 1979; Shaikh et al. 2013). Comprehensive investigation has been carried \nout for the threshold that minimizes the intra-class variance represented by the weighted \nsum of variances of the two classes of pixels for each of the three color components.\n\nThe weighted within-class variance has been given in Eq. 1.\n\nq1(t) = ∑ ti=0P(i) where the class probabilities of different gray level pixels were estimated \nas shown in Eqs. 2 and 3:\n\n(1)σ 2\nw(t) = q1(t)σ\n\n2\n1 (t)+ q2(t)σ\n\n2\n2 (t)\n\n(2)q1(t) =\n\nt\n∑\n\ni=0\n\np(i)\n\n(3)\nq2(t) =\n\n255\n∑\n\ni=t+1\n\nP(i)\n\n\n\nPage 6 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nThe class means were given as in Eqs. 4 and 5:\n\nTotal variance (σ2) = Within-class variance (σw\n2(t)) + Between-class Variance(σb\n\n2(t)).\nSince the total variance was constant and independent of t, the effect of changing \n\nthe threshold was purely to shift the contributions of the two terms back and forth. \nBetween-class variance has been given in Eq. 6\n\nThus, minimizing the within-class variance was the same as maximizing the between-\nclass variance.\n\nBinarization of the test images was carried out using the Otsu’s local threshold selec-\ntion method. The process has been repeated for all the three color components to gen-\nerate bag of words model (BoW) of features. Conventional BoW model has been based \non SIFT algorithm which has a descriptor dimension of 128 (Zhao et al. 2015). There-\nfore, for three color components the dimension of the descriptor would have been 128 \n× 3 = 384. The size for SIFT descriptor has been huge and it has predestined problem \nfor information losses and omissions as it has been found suitable only for the stability \n\n(4)µ1(t) =\n\nt\n∑\n\ni=0\n\ni ∗ P(i)\n\nq1(t)\n\n(5)µ2(t) =\n\n255\n∑\n\ni=t+1\n\ni ∗ P(i)\n\nq2(t)\n\n(6)σ 2\nb (t) = q1(t)[1− q1(t)][µ1(t)− µ2(t)]\n\n2\n\n   \nRed Component Green Component Blue Component \n\n   \nBinarization of \n\nRed Component \nBinarzation of \n\nGreen Component \nBinarization of \n\nBlue Component \nFig. 1 Binarization using Otsu’s Threshold selection\n\n\n\n\n\n\n\n\n\nPage 7 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nof image feature point extraction and description. Furthermore, the generated SIFT \ndescriptors has to be clustered by k means clustering which has been based on alloca-\ntion of cluster members by means of comparing squared Euclidian distance. The clus-\ntering process has been helpful to generate codewords for codebook generation which \nhas been the final step of BoW. Process of k means clustering has huge computational \noverhead for calculating the squared Euclidian distance which eventually slows down \nthe BoW generation. Hence, in our approach, the grey values higher than the threshold \nwas clustered in higher intensity group and the grey values lower than the cluster was \nclustered in the lower intensity group. The mean of the two groups were calculated to \nformulate the codewords of higher intensity feature vectors and the lower intensity fea-\nture vectors respectively. Thus, each color component of a test image has been mapped \nto two codewords of higher intensity and lower intensity respectively. This has generated \nof codebook of size (3 × 2 = 6) for each image.\n\nThe algorithm for feature extraction has been stated in Algorithm 1 as follows:\n\nAlgorithm 1 \n\nBegin\n\n1. Input an image I with three different color \ncomponents R, G and B respectively of size \nm*n each. \n\n2. Calculate the local threshold value Tx for \neach pixel in each color component R,G and \nB using Otsu's Method.\n\n3. Compute binary image maps for each pixel \nfor the given image.\n\nTxjixif >=),(....1\n\nTxjixif <),(....0\n\n/*x = R, G and B */\n\n4. Generate image features for the given \nimage for each color component.\n\n/*x = R, G and B */\n\nEnd\n\n=),( jiBitmapx\n\nTx\np q\n\nqpxmean\nmean\n\nxhi >== ∑∑ )),((\n\nTx\np q\n\nqpxmean\nmean\n\nxlo <= ∑∑ )),((\n\n\n\nPage 8 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nFeature extraction using image transform\n\nTransforms convert spatial information to frequency domain information, where cer-\ntain operations are easier to perform. Energy compaction property of transforms has \nthe capacity to pack large fraction of the average energy into a few components. This \nhas led to faster execution and efficient algorithm design. Image transforms has the \nproperty to convert the spatial domain information of an image to frequency domain \ninformation, where certain operations are easier to perform. For example, convolu-\ntion operation can be reduced to matrix multiplication in frequency domain. It has the \ncharacteristic of energy compaction which ensures that a large fraction of the average \nenergy of the image remains packed into a few components. This property has led to \nfaster execution and efficient algorithm design by drastic reduction of feature vector \nsize which is achieved by means of discarding insignificant transform coefficients as in \nFig. 2. The approach has been implemented by applying slant transform on each of the \nRed (R), Green (G) and Blue (B) color component of the image for extraction of fea-\nture vectors with smaller dimension. Slant transform has reduced the average coding \nof a monochrome image from 8 bits/pixel to 1 bit/pixel without seriously degrading the \nimage quality. It is an orthogonal transform which has also reduced the coding of color \nimages from 24–2 bits/pixel (Pratt et al. 1974). Slant transform matrices are orthogo-\nnal and it holds all real components. Hence, it has much less computational overhead \ncompared to discrete Fourier transform. Slant transform is an unitary transform and \nfollows energy conservation. It tends to pack a large fraction of signal energy into a few \ntransform coefficients which has a significant role in reducing the feature vector for the \nimage. Let [F] be an N × N matrix of pixel values of an image and let [fi] be an N × 1 \nvector representing the ith. column of [F]. One dimensional transform of the ith. image \nline can be given by\n\n [S] = N × N unitary slant matrix.\n\n[fi] = [S][fi]\n\n0.06 % of (N*N) feature vector\n\n0.012% of (N*N) feature vector\n\n50% of (N*N) feature vector\n\nN*N feature vector\n\nFeature Vector Dimension Reduction with Partial Coefficients\n\nFig. 2 Feature extraction by applying image transform\n\n\n\n\n\n\n\nPage 9 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nA two dimensional slant transform can be performed by sequential transformations \nof row and column of [F] and the forward and inverse transform can be expressed as in \nEqs. 7 and 8.\n\nA transform operation can be conveniently represented in a series. The two dimensional \nforward and inverse transform in series form can be represented as in Eqs. 9 and 10\n\nThe algorithm for feature extraction using slant transform has been given in Algo-\nrithm 2.\n\nAlgorithm 2 \n\n(7)[ℑ] = |S|[F ][S]T\n\n(8)[F ] = [S]T [ℑ][S]\n\n(9)ℑ(u, v) =\n\nN\n∑\n\nj=1\n\nN\n∑\n\nk=1\n\nF(j, k)S(u, j)S(k , v)\n\n(10)F\n(\n\nj, k\n)\n\n=\n\nN\n∑\n\nu=1\n\nN\n∑\n\nv=1\n\nℑ(u, v)S\n(\n\nj,u\n)\n\nS(v, k)\n\nBegin\n\n1. Red, Green and Blue color components were \nextracted from a given image.\n\n2. Slant Transform was applied on each of the \ncomponent to extract feature vectors.\n\n3. The extracted feature vectors from each of the \ncomponent were stored as complete set of feature \nvectors.\n\n4. Further, partial coefficients from the entire \nfeature vector set were extracted to form the \nfeature vector database.\n\n5. Feature vector database with 100% transformed \ncoefficients and partial coefficients ranging from \n50% of the complete set of feature vectors till \n0.06% of the complete set of feature vectors were \nconstructed\n\n6. The feature vectors of the query image for the \nwhole set of feature vectors and for partial \ncoefficient of feature vectors were compared with \nthe database images for classification results.\n\n7. The fractional coefficient of feature vector \nhaving the highest classification result was \nconsidered as the feature set extracted by applying \nimage transform\n\nEnd\n\n\n\nPage 10 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nHere the features were extracted in the form of visual words. Visual words have been \ndefined as a small patch of image which can carry significant image information. The \nenergy compaction property of Slant transform has condensed noteworthy image infor-\nmation in a block of 12 elements for an image of dimension (256 × 256). Thus, the \nfeature vector extracted with slant transform was of size 12 for each color component \nwhich has given the dimension of feature vector as 36 (12 ×  3 =  36) for three color \ncomponents in each test image.\n\nFeature extraction with morphological operator\n\nHuman perception has largely been governed by shape context. It has been helpful to \nrecover the point correspondences from an image which has considerable contribution \nin feature vector formation. A variant of gray scale opening and closing operations has \nbeen termed as the top-hat transformation that has been instrumental in producing only \nthe bright peaks of an image (Sridhar 2011). It has been termed as the peak detector and \nits working process has been given as follows:\n\n1. Apply the gray scale opening operation to an image.\n2. Peak = original image—opened image.\n3. Display the peak.\n4. Exit.\n\nThe top-hat transform technique was applied on each color component Red (R), \nGreen (G) and Blue (B) of the test images for feature extraction using morphologi-\ncal operator as in Fig. 3. After applying the tophat operator, the pixels designated as \nthe foreground pixels were grouped in one cluster and were calculated with mean and \nstandard deviation to formulate the higher intensity feature vector. Similar process \nwas followed with the pixels designated as the background pixels to calculate the lower \nintensity feature vector. The feature vector extraction process has followed the bag of \nwords (BoW) methodology which has generated codewords from the cluster of fore-\nground and background pixels by calculating the mean and the standard deviation of \nboth the clusters and adding the two. Hence, codebook size for each color component \nwas two which have yielded a dimension of 6 (3 × 2 = 6) on the whole for the code-\nbook generated for three color components for each test image.\n\nThe algorithm for feature extraction using morphological operator has been given in \nAlgorithm 3.\n\n\n\nPage 11 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nAlgorithm 3 \n\nSimilarity measures\n\nDetermination of image similarity measures was performed by evaluating distance \nbetween set of image features. Higher similarity has been characterized by shorter dis-\ntance (Dunham 2009). A fusion based classifier, an artificial neural network (ANN) clas-\nsifier and a support vector machine (SVM) classifier was used for the purpose. Each of \nthe classifier types has been discussed in the following sections:\n\nBegin\n\n1. Input an image I with three different color \ncomponents R, G and B respectively of size \nm*n each. \n\n2. Apply tophat transform on each color \ncomponent\n\n3. Cluster the foreground and background \npixels obtained after the morphological \noperation     \n\n4. Generate image features xhiF.V. and xloF.V.\nfor the given image for each color \ncomponent.\n\n/*x = R, G and B */\n\nEnd\n\n∑∑=\np q\n\nqp\nforeground\n\nxmean\nmean\n\nxhi )),((\n\n∑∑=\np q\n\nqp\nforeground\n\nx\nstdev\n\nxhi )),((σ\n\n( )\nstdev\n\nxhi\nmean\n\nxhimeanxhi\nVF\n\nxhi += +\n..\n\n∑∑=\np q\n\nqp\nbackground\n\nxmean\nmean\n\nxlo )),((\n\n∑∑=\np q\n\nqp\nbackground\n\nx\nstdev\n\nxlo )),((σ\n\n( )\nstdev\n\nxlo\nmean\n\nxlomeanxlo\nVF\n\nxlo += +\n..\n\n\n\nPage 12 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nFusion based classifier\n\nThree different distance measures, namely, city block distance, Euclidian distance and \nmean squared error (MSE) distance metric was considered to compute the distance \nbetween query image Q and database image T as in Eqs. 11, 12 and 13\n\nwhere, Qi is the query image and Di is the database image.\nData standardization technique was followed to standardize the calculated distances \n\nfor the individual techniques with Z score normalization which was based on mean and \nstandard deviation of the computed values as in Eq. 14. The normalization process has \nbeen implemented to avoid dependence of the classification decision on a feature vec-\ntor with higher values of attributes which have the possibilities to have greater effect or \n“weight.” The process has normalized the data within a common range such as [−1, 1] or \n[0.0, 1.0].\n\nwhere, µ is the mean and σ is the standard deviation.\n\n(11)Dcityblock =\n\nn\n∑\n\ni−1\n\n|Qi − Di|\n\n(12)Deuclidian =\n\n√\n\n√\n\n√\n\n√\n\nn\n∑\n\ni=1\n\n(Qi − Di)2\n\n(13)DMSE =\n1\n\nn\n\nn\n∑\n\ni=1\n\n(Qi − Di)\n2\n\n(14)distn =\ndisti − µ\n\nσ\n\n   \nRed Component Green Component Blue Component \n\n   \nApplying Top-Hat \noperator on Red \n\nComponent \n\nApplying Top-Hat \noperator on Green \n\nComponent \n\nApplying Top-Hat \noperator on Blue \n\nComponent \nFig. 3 Effect of applying morphological operator\n\n\n\n\n\n\n\n\n\n\n\n\n\nPage 13 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nFurther, the final distance was calculated by adding the weighted sum of individual \ndistances. The weights were calculated from the precision values of corresponding tech-\nniques. Finally, the image was classified based on the class majority of k nearest neigh-\nbors [Sridhar 2011] where value of k was\n\nThe classified image was forwarded for retrieval purpose. The image was a classified \nquery and has searched for similar images only within the class of interest. Ranking of \nthe images was done with Canberra Distance measure as in Eq. 15 and top 20 images \nwere retrieved.\n\nwhere, Qi is the query image and Di is the database image.\nThe process of fusion based classification and then retrieval with classified query has \n\nbeen illustrated in Fig. 4.\n\nArtificial neural network (ANN) classifier\n\nThe set of input features from images were mapped to an appropriate output by a feed \nforward Neural Network Classifier known as Multilayer Perceptron (MLP) as shown in \nFig. 5 (Alsmadi et al. 2009).\n\nThe back propagation technique of multi layer perceptron has a significant role in \nsupervised learning procedure. The network has been trained for optimization of clas-\nsification performance by using the procedure of back propagation. For each training \ntuple, the weights were modified so as to minimize the mean squared error between the \nnetwork prediction and the target value. These modifications have been made in the \nbackward direction through each hidden layer down to the first hidden layer. The input \nfeature vectors have been fed to the input units which comprised the input layer. The \nnumber of input units has been dependent on the summation of the number of attrib-\nutes in the feature vector dataset and the bias node. The subsequent layer has been the \nhidden layer whose number of nodes has to be determined by considering the half of the \nsummation of the number of classes and the number of attributes per class. The inputs \nthat have passed the input layer have to be weighted and fed simultaneously to the hid-\nden layer for further processing. Weighted output of the hidden layer was used as input \nto the final layer which has been named as the output layer. The number of units in the \noutput layer has been denoted by the number of class labels. The feed forward property \nof this architecture does not allow the weights to cycle back to the input units.\n\nSupport vector machine (SVM) classifier\n\nSVM transforms original training data to higher dimension by using nonlinear mapping. \nOptimal separating hyperplane has to be searched by the algorithm within this new \ndimension. Data from two different classes can readily be separated by a hyperplane by \nmeans of an",
      "metadata_storage_size": 2424684,
      "metadata_storage_path": "aHR0cHM6Ly9qdHJhaW5pbmdjYXRhbG9nc3RvcmFnZS5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL3M0MDA2NC0wMTUtMTUxNS00LnBkZg2",
      "metadata_author": "Rik Das",
      "metadata_title": "Multi technique amalgamation for enhanced information identification with content based image data",
      "metadata_creation_date": "2015-11-26T05:08:05Z",
      "people": [
        "Rik Das1",
        "Sudeep Thepade2",
        "Saurav Ghosh3",
        "Raventós",
        "Madireddy",
        "Das",
        "rikdas78",
        "Camil",
        "26Das",
        "Wang",
        "Walia",
        "Annadurai",
        "Shanmugalakshmi",
        "Thepade",
        "Kekre",
        "Prakash",
        "Luo",
        "Valizadeh",
        "Ramírez",
        "Ortegón",
        "Rojas",
        "Shaikh",
        "Flickner",
        "Gevers",
        "Smeulders",
        "Mehtre",
        "Zhang",
        "Lu",
        "Fourier",
        "Dubois",
        "Glanz",
        "Kim",
        "Zhu",
        "Shyu",
        "Hiremath",
        "Pujari",
        "Yue",
        "Banerjee",
        "Shen",
        "Wu",
        "Rahimi",
        "Moghaddam",
        "ElAlami",
        "Subrahmanyam",
        "Douze",
        "Otsu",
        "dant",
        "Zhao",
        "Pratt",
        "j",
        "Sridhar",
        "xhi",
        "niques",
        "bors",
        "Alsmadi"
      ],
      "organizations": [
        "Caltech",
        "Precision",
        "Creative Commons Attribution",
        "International",
        "SpringerPlus",
        "Department of Information",
        "Xavier Institute",
        "Otsu",
        "GIST",
        "i)",
        "(i)",
        "BoW",
        "energy conservation",
        "S(v, k)",
        "Slant transform",
        "foreground",
        "Red",
        "Green",
        "Blue",
        "Artificial neural network",
        "ANN"
      ],
      "locations": [
        "Walia",
        "Oliva Torralba",
        "multi",
        "tech-",
        "Jharkhand",
        "India",
        "tor",
        "Liu",
        "Yanli",
        "Zhenxing",
        "ElAlami",
        "Jalab",
        "In",
        "Euclidian",
        "Tx",
        "Txjixif",
        "p q",
        "line",
        "N",
        "k",
        "j",
        "Dunham",
        "xhimeanxhi",
        "xlo",
        "xlomeanxlo",
        "city",
        "disti",
        "µ",
        "nearest neigh",
        "Canberra",
        "units",
        "layer"
      ],
      "keyphrases": [
        "multi tech- nique feature extraction process",
        "content based image data Rik Das1",
        "Creative Commons Attribution 4.0 International License",
        "traditional text based annotation technique",
        "Dr. Camil Bulcke Path",
        "customary text based process",
        "Diverse low level features",
        "content based feature extraction",
        "content based image identification",
        "Creative Commons license",
        "robust feature vectors",
        "Multi technique amalgamation",
        "low cost storage",
        "digital photo-capture devices",
        "four public datasets",
        "test Open Access",
        "P.O. Box",
        "digital image acquisition",
        "huge image repositories",
        "gigantic image datasets",
        "image capturing devices",
        "new research challenges",
        "OT Scene) Dataset",
        "three different techniques",
        "exist- ing techniques",
        "original author(s",
        "Semantically analogous images",
        "image identification technique",
        "enhanced information identification",
        "manual process",
        "image content",
        "Diverse applications",
        "image recognition",
        "image binarization",
        "image transform",
        "Image classification",
        "Image retrieval",
        "Raventós",
        "RESEARCH Das",
        "image information",
        "author information",
        "Corel Dataset",
        "Caltech Dataset",
        "Conventional techniques",
        "art techniques",
        "Sudeep Thepade2",
        "Saurav Ghosh3",
        "Recent years",
        "computer power",
        "accessible internet",
        "Efficient indexing",
        "computer vision",
        "machine learning",
        "Automatic derivation",
        "severe limitations",
        "aforesaid limitations",
        "resourceful foundation",
        "social media",
        "morphological operator",
        "Oliva Torralba",
        "recognition rate",
        "Classification result",
        "average increase",
        "retrieval result",
        "Slant transform",
        "unrestricted use",
        "appropriate credit",
        "Xavier Institute",
        "Social Service",
        "Purulia Road",
        "Full list",
        "effective alternative",
        "meaningful information",
        "Information Technology",
        "Wang Dataset",
        "decision fusion",
        "Background",
        "ubiquity",
        "mass",
        "popularity",
        "Madireddy",
        "Walia",
        "words",
        "mapping",
        "perception",
        "vocabulary",
        "person",
        "nature",
        "Abstract",
        "proliferation",
        "areas",
        "biomedicine",
        "military",
        "commerce",
        "education",
        "means",
        "success",
        "paper",
        "Precision",
        "state",
        "Otsu",
        "threshold",
        "article",
        "terms",
        "creativecommons",
        "licenses",
        "distribution",
        "reproduction",
        "medium",
        "link",
        "changes",
        "SpringerPlus",
        "DOI",
        "Correspondence",
        "1 Department",
        "Ranchi",
        "Jharkhand",
        "India",
        "end",
        "crossmark",
        "crossref",
        "org",
        "Page",
        "26Das",
        "competence",
        "color",
        "content based image recog",
        "binarization based feature extraction",
        "content based image classification",
        "feature extraction Feature extraction",
        "Z score normalization",
        "orthogonal unitary matrices",
        "Appropriate threshold selection",
        "fusion based method",
        "single feature extrac",
        "fractional energy coefficient",
        "fifteen fractional coefficients",
        "high dimensional data",
        "main contribu- tion",
        "multi-technique feature extraction",
        "efficient feature extraction",
        "feature extrac- tion",
        "efficient image binarization",
        "feature vector dimension",
        "image trans- formation",
        "multi technique fusion",
        "image binariza- tion",
        "Image binarization techniques",
        "feature vectors",
        "feature spaces",
        "image data",
        "energy spectrum",
        "subband coefficients",
        "novel techniques",
        "Diverse techniques",
        "image identification",
        "image elements",
        "image patterns",
        "seven image",
        "recognition decision",
        "hybrid architecture",
        "fusion architecture",
        "Statistical validation",
        "trans- forms",
        "morphological operators",
        "archi- tecture",
        "four subsections",
        "earlier works",
        "four topics",
        "basis functions",
        "one representation",
        "two aspects",
        "critical components",
        "compact structure",
        "cient storage",
        "radical reduction",
        "multiple scales",
        "tropic transform",
        "various factors",
        "uneven illumination",
        "research objectives",
        "research results",
        "transformation process",
        "aforesaid properties",
        "basis images",
        "Original images",
        "shape",
        "texture",
        "number",
        "features",
        "morphology",
        "Comparison",
        "retrieval",
        "correlation",
        "connection",
        "contemporary",
        "Change",
        "domain",
        "set",
        "series",
        "Annadurai",
        "Shanmugalakshmi",
        "advantages",
        "waveforms",
        "use",
        "analysis",
        "transmission",
        "Kekre",
        "Thepade",
        "subbands",
        "Prakash",
        "Luo",
        "execution",
        "inadequate",
        "Ramírez- Ortegón",
        "Gradient vector flow fields",
        "multi technique feature extraction",
        "fusion based image identification",
        "superior prediction accuracy",
        "feature level correlations",
        "image signature extraction",
        "feature extraction technique",
        "Popular contour-based descriptors",
        "Enhanced classification results",
        "curvature scale space",
        "feature selection technique",
        "region- based descriptors",
        "3 D color histogram",
        "diverse extraction techniques",
        "Two different categorization",
        "global threshold selection",
        "shape feature extraction",
        "multilevel mean threshold",
        "image binarization techniques",
        "local threshold selection",
        "retrieval process complexity",
        "feature vector",
        "identification rate",
        "Image Content",
        "different techniques",
        "shape descriptors",
        "semantic retrieval",
        "Local descriptors",
        "local decisions",
        "shape information",
        "region-based descriptors",
        "information fusion",
        "early fusion",
        "late fusion",
        "hybrid fusion",
        "intermediate fusion",
        "adverse effect",
        "Contemporary literatures",
        "unfavourable influences",
        "binarized images",
        "standard deviation",
        "gray values",
        "Commercial viability",
        "existing literatures",
        "ary lines",
        "Fourier descriptor",
        "chain codes",
        "complex shapes",
        "Information recognition",
        "Recent studies",
        "four classes",
        "higher dimensions",
        "joint model",
        "genetic algorithm",
        "optimum boundaries",
        "numerical intervals",
        "memory con",
        "filter responses",
        "distinct features",
        "concentrated features",
        "multiple features",
        "Fusion methodologies",
        "rate learner",
        "Gabor filters",
        "Color moments",
        "texture features",
        "contrast",
        "computation",
        "Valizadeh",
        "average",
        "advantage",
        "spread",
        "calculation",
        "Liu",
        "Yanli",
        "Zhenxing",
        "Rojas",
        "Shaikh",
        "Use",
        "systems",
        "Flickner",
        "PicToSeek",
        "Gevers",
        "Smeulders",
        "Mehtre",
        "Zhang",
        "Emphasize",
        "Mokhtarian",
        "Mackworth",
        "Dubois",
        "Glanz",
        "area",
        "object",
        "Kim",
        "single",
        "input",
        "sepa",
        "combiner",
        "scalability",
        "comparison",
        "mix",
        "Zhu",
        "Shyu",
        "sumption",
        "ElAlami",
        "back propagation neural net- work",
        "fuzzy set theoretic approach",
        "angular radial transform descriptor",
        "artificial neural network",
        "spatial structure descriptors",
        "spatial orientation tree",
        "lesser computational overhead",
        "neural network architecture",
        "correct semantic retrieval",
        "Higher retrieval results",
        "semantic retrieval results",
        "HSV color space",
        "local edge bins",
        "non directional edge",
        "color layout descriptor",
        "significant point features",
        "Three different techniques",
        "greater feature dimension",
        "content-based image retrieval",
        "tex- ture features",
        "edge histogram descriptor",
        "inter-class feature extraction",
        "Gabor texture descriptor",
        "invariant color features",
        "fusion based classifier",
        "color histogram",
        "invariant moments",
        "retrieval decisions",
        "retrieval performance",
        "retrieval rate",
        "retrieval purpose",
        "GIST descriptor",
        "color co",
        "color motif",
        "color moment",
        "horizontal edge",
        "Feature vectors",
        "popular feature",
        "32 feature maps",
        "feature values",
        "feature size",
        "occurrence matrix",
        "Recognition process",
        "image signatures",
        "Multi view",
        "Wavelet packets",
        "Eigen values",
        "sub repository",
        "main image",
        "right neighbourhood",
        "query image",
        "scan pattern",
        "equal weights",
        "Precision values",
        "individual techniques",
        "Six semantics",
        "sub- image",
        "tion techniques",
        "same size",
        "16 average value",
        "other hand",
        "morphological technique",
        "vertical edge",
        "shape features",
        "EHD) features",
        "edge images",
        "45° edge",
        "135° edge",
        "Hiremath",
        "Pujari",
        "Yue",
        "points",
        "similarity",
        "Banerjee",
        "Jalab",
        "increased",
        "Shen",
        "Wu",
        "authors",
        "Irtaza",
        "kind",
        "training",
        "response",
        "intra-class",
        "Rahimi",
        "Moghaddam",
        "CCM",
        "difference",
        "pixels",
        "DBPSP",
        "ANN",
        "Subrahmanyam",
        "MCMCM",
        "colour",
        "CMs",
        "sub-image",
        "unique",
        "Methods",
        "4 scales",
        "8 orientations",
        "Douze",
        "region",
        "Red Component Green Component Blue Component",
        "popular global threshold selection method",
        "local threshold selec- tion method",
        "image feature point extraction",
        "different gray level pixels",
        "four subsec- tions",
        "three color components",
        "necessary image information",
        "squared Euclidian distance",
        "document image binarzation",
        "Conventional BoW model",
        "alloca- tion",
        "feature extraction",
        "level histogram",
        "thresholding method",
        "parametric method",
        "optimal threshold",
        "words model",
        "information losses",
        "fifth subsection",
        "test images",
        "binari- zation",
        "dant details",
        "two classes",
        "foreground pixels",
        "background pixels",
        "class variance",
        "The separation",
        "Comprehensive investigation",
        "class probabilities",
        "Total variance",
        "two terms",
        "erate bag",
        "SIFT algorithm",
        "SIFT descriptors",
        "cluster members",
        "codebook generation",
        "final step",
        "huge computational",
        "BoW generation",
        "class means",
        "tering process",
        "descriptor dimension",
        "classification",
        "techniques",
        "methods",
        "fusion",
        "architecture",
        "following",
        "description",
        "datasets",
        "Fig.",
        "way",
        "combined",
        "sum",
        "variances",
        "Eq.",
        "Eqs.",
        "q1",
        "effect",
        "contributions",
        "Zhao",
        "size",
        "problem",
        "omissions",
        "stability",
        "clustering",
        "codewords",
        "overhead",
        "∑",
        "σ",
        "N*N feature vector Feature Vector Dimension Reduction",
        "Compute binary image maps",
        "N unitary slant matrix",
        "Blue (B) color component",
        "N × N matrix",
        "higher intensity feature vectors",
        "two dimensional slant transform",
        "N × 1 vector",
        "higher intensity group",
        "three different color",
        "discrete Fourier transform",
        "One dimensional transform",
        "lower intensity group",
        "Slant transform matrices",
        "frequency domain information",
        "local threshold value",
        "spatial domain information",
        "efficient algorithm design",
        "insignificant transform coefficients",
        "drastic reduction",
        "smaller dimension",
        "Energy compaction property",
        "unitary transform",
        "spatial information",
        "matrix multiplication",
        "two groups",
        "orthogonal transform",
        "inverse transform",
        "transform operation",
        "grey values",
        "two codewords",
        "large fraction",
        "faster execution",
        "tion operation",
        "computational overhead",
        "energy conservation",
        "signal energy",
        "significant role",
        "Partial Coefficients",
        "sequential transformations",
        "average energy",
        "test image",
        "image features",
        "monochrome image",
        "image quality",
        "image line",
        "components R",
        "tain operations",
        "real components",
        "pixel values",
        "average coding",
        "Transforms",
        "approach",
        "cluster",
        "mean",
        "codebook",
        "Tx",
        "Method",
        "End",
        "xhi",
        "cer",
        "capacity",
        "example",
        "characteristic",
        "Green",
        "8 bits",
        "1 bit",
        "images",
        "24–2 bits",
        "Pratt",
        "less",
        "column",
        "row",
        "forward",
        "Eqs",
        "The energy compaction property",
        "gray scale opening operation",
        "lower intensity feature vector",
        "higher intensity feature vector",
        "entire feature vector set",
        "feature vector extraction process",
        "shorter dis- tance",
        "feature vector formation",
        "highest classification result",
        "Blue color components",
        "top-hat transform technique",
        "feature vector database",
        "significant image information",
        "image transform End",
        "image similarity measures",
        "Higher similarity",
        "database images",
        "working process",
        "Similar process",
        "classification results",
        "slant transform",
        "complete set",
        "partial coefficient",
        "fractional coefficient",
        "small patch",
        "Human perception",
        "shape context",
        "point correspondences",
        "considerable contribution",
        "closing operations",
        "hat transformation",
        "bright peaks",
        "tophat operator",
        "code- book",
        "noteworthy image",
        "original image",
        "visual words",
        "series form",
        "one cluster",
        "codebook size",
        "peak detector",
        "Red, Green",
        "coefficients",
        "2. Peak",
        "algorithm",
        "query",
        "block",
        "12 elements",
        "dimension",
        "variant",
        "Sridhar",
        "Exit",
        "bag",
        "BoW",
        "methodology",
        "clusters",
        "Determination",
        "distance",
        "Dunham",
        "σ   Red Component Green Component Blue Component",
        "Three different distance measures",
        "forward Neural Network Classifier",
        "support vector machine",
        "corresponding tech- niques",
        "city block distance",
        "MSE) distance metric",
        "Canberra Distance measure",
        "fusion based classification",
        "first hidden layer",
        "input feature vectors",
        "mean squared error",
        "Data standardization technique",
        "back propagation technique",
        "supervised learning procedure",
        "multi layer perceptron",
        "database image T",
        "query image Q",
        "color component",
        "SVM) classifier",
        "classifier types",
        "network prediction",
        "Euclidian distance",
        "final distance",
        "classification decision",
        "Multilayer Perceptron",
        "input layer",
        "input features",
        "input units",
        "classified query",
        "clas- sifier",
        "following sections",
        "tophat transform",
        "morphological operation",
        "xloF.V.",
        "common range",
        "Top-Hat operator",
        "weighted sum",
        "appropriate output",
        "sification performance",
        "training tuple",
        "backward direction",
        "normalization process",
        "classified image",
        "higher values",
        "precision values",
        "stdev xhi",
        "qp background",
        "greater effect",
        "individual distances",
        "class majority",
        "similar images",
        "top 20 images",
        "target value",
        "stdev xlo",
        "VF xlo",
        "foreground",
        "xmean",
        "xhimeanxhi",
        "xlomeanxlo",
        "Qi",
        "attributes",
        "possibilities",
        "Dcityblock",
        "Deuclidian",
        "DMSE",
        "distn",
        "disti",
        "weights",
        "bors",
        "interest",
        "Ranking",
        "feed",
        "MLP",
        "Alsmadi",
        "optimization",
        "modifications",
        "The",
        "µ",
        "feature vector dataset",
        "Support vector machine",
        "original training data",
        "Optimal separating hyperplane",
        "two different classes",
        "bias node",
        "subsequent layer",
        "hidden layer",
        "Weighted output",
        "final layer",
        "output layer",
        "forward property",
        "higher dimension",
        "nonlinear mapping",
        "new dimension",
        "class labels",
        "summation",
        "utes",
        "nodes",
        "half",
        "inputs",
        "processing"
      ],
      "merged_content": "\nMulti technique amalgamation \nfor enhanced information identification \nwith content based image data\nRik Das1*, Sudeep Thepade2 and Saurav Ghosh3\n\nBackground\nRecent years have witnessed the digital photo-capture devices as a ubiquity for the com-\nmon mass (Raventós et al. 2015). The low cost storage, increasing computer power and \never accessible internet have kindled the popularity of digital image acquisition. Efficient \nindexing and identification of image data from these huge image repositories has nur-\ntured new research challenges in computer vision and machine learning (Madireddy \net  al. 2014). Automatic derivation of sematically-meaningful information from image \ncontent has become imperative as the traditional text based annotation technique has \nrevealed severe limitations to fetch information from the gigantic image datasets (Walia \net al. 2014). Conventional techniques of image recognition were based on text or key-\nwords based mapping of images which had limited image information. It was dependent \non the perception and vocabulary of the person performing the annotation. The manual \nprocess was highly time consuming and slow in nature. The aforesaid limitations have \n\nAbstract \n\nImage data has emerged as a resourceful foundation for information with proliferation \nof image capturing devices and social media. Diverse applications of images in areas \nincluding biomedicine, military, commerce, education have resulted in huge image \nrepositories. Semantically analogous images can be fruitfully recognized by means of \ncontent based image identification. However, the success of the technique has been \nlargely dependent on extraction of robust feature vectors from the image content. The \npaper has introduced three different techniques of content based feature extraction \nbased on image binarization, image transform and morphological operator respec-\ntively. The techniques were tested with four public datasets namely, Wang Dataset, \nOliva Torralba (OT Scene) Dataset, Corel Dataset and Caltech Dataset. The multi tech-\nnique feature extraction process was further integrated for decision fusion of image \nidentification to boost up the recognition rate. Classification result with the proposed \ntechnique has shown an average increase of 14.5 % in Precision compared to the exist-\ning techniques and the retrieval result with the introduced technique has shown an \naverage increase of 6.54 % in Precision over state-of-the art techniques.\n\nKeywords: Image classification, Image retrieval, Otsu’s threshold, Slant transform, \nMorphological operator, Fusion, t test\n\nOpen Access\n\n© 2015 Das et al. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://\ncreativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided \nyou give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate \nif changes were made.\n\nRESEARCH\n\nDas et al. SpringerPlus  (2015) 4:749 \nDOI 10.1186/s40064-015-1515-4\n\n*Correspondence:  rikdas78@\ngmail.com \n1 Department of Information \nTechnology, Xavier Institute \nof Social Service, Dr. Camil \nBulcke Path (Purulia Road), \nP.O. Box 7, Ranchi 834001, \nJharkhand, India\nFull list of author information \nis available at the end of the \narticle\n\n  \n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40064-015-1515-4&domain=pdf\n\n\nPage 2 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nbeen effectively handled with content based image identification which has been exer-\ncised as an effective alternative to the customary text based process (Wang et al. 2013). \nThe competence of the content based image identification technique has been depend-\nent on the extraction of robust feature vectors. Diverse low level features namely, color, \nshape, texture etc. have constituted the process of feature extraction. However, an image \ncomprises of number of features which can hardly be defined by a single feature extrac-\ntion technique (Walia et al. 2014). Therefore, three different techniques of feature extrac-\ntion namely, feature extraction with image transform, feature extraction with image \nmorphology and feature extraction with image binarization have been proposed in this \npaper to leverage fusion of multi-technique feature extraction. The recognition decision \nof three different techniques was further integrated by means of Z score normalization \nto create hybrid architecture for content based image identification. The main contribu-\ntion of the paper has been to propose fusion architecture for content based image recog-\nnition with novel techniques of feature extraction for enhanced recognition rate.\n\nThe research objectives have been enlisted as follows:\n\n  • Reducing the dimension of feature vectors.\n  • Successfully implementing fusion based method of content based image identifica-\n\ntion.\n  • Statistical validation of research results.\n  • Comparison of research results with state-of-the art techniques.\n\nThree different techniques of feature extraction using image binarization, image trans-\nforms and morphological operators have been combined to develop fusion based archi-\ntecture for content based image classification and retrieval. Hence, it is in correlation with \nresearch on binarization based feature extraction, transform based feature extraction and \nmorphology based feature extraction from images. It is also in connection with research \non multi technique fusion for content based image identification. Therefore, the following \nfour subsections have reviewed some contemporary and earlier works on these four topics.\n\nFeature extraction using image transform\n\nChange of domain of the image elements has been carried out by using image trans-\nformation to represent the image by a set of energy spectrum. An image can be repre-\nsented as series of basis images which can be formed by extrapolating the image into a \nseries of basis functions (Annadurai and Shanmugalakshmi 2011). The basis images have \nbeen populated by using orthogonal unitary matrices as image transformation opera-\ntor. This image transformation from one representation to another has advantages in \ntwo aspects. An image can be expanded in the form of a series of waveforms with the \nuse of image transforms. The transformation process has been helpful to differentiate \nthe critical components of image patterns and in making them directly accessible for \nanalysis. Moreover, the transformed image data has a compact structure useful for effi-\ncient storage and transmission. The aforesaid properties of image transforms facilitate \nradical reduction of feature vector dimension to be extracted from the images. Diverse \ntechniques of feature extraction has been proposed by exploiting the properties of image \ntransforms to extract features from images using fractional energy coefficient (Kekre and \n\n\n\nPage 3 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nThepade 2009; Kekre et  al. 2010). The techniques have considered seven image trans-\nforms and fifteen fractional coefficients sets for efficient feature extraction. Original \nimages were divided into subbands by using multiple scales Biorthogonal wavelet trans-\nform and the subband coefficients were used as features for image classification (Prakash \net al. 2013). The feature spaces were reduced by applying Isomap-Hysime random aniso-\ntropic transform for classification of high dimensional data (Luo et al. 2013).\n\nImage binarization techniques for feature extraction\n\nFeature extraction from images has been largely carried out by means of image binariza-\ntion. Appropriate threshold selection has been imperative for execution of efficient image \nbinarization. Nevertheless, various factors including uneven illumination, inadequate \ncontrast etc. can have adverse effect on threshold computation (Valizadeh et  al. 2009). \nContemporary literatures on image binarization techniques have categorized three dif-\nferent techniques for threshold selection namely, mean threshold selection, local thresh-\nold selection and global threshold selection to deal with the unfavourable influences on \nthreshold selection. Enhanced classification results have been comprehended by feature \nextraction from mean threshold and multilevel mean threshold based binarized images \n(Kekre et al. 2013; Thepade et al. 2013a, b). Eventually, it has been identified that selection \nof mean threshold has not dealt with the standard deviation of the gray values and has \nconcentrated only on the average which has prevented the feature extraction techniques \nto take advantage of the spread of data to distinguish distinct features. Therefore, image \nsignature extraction was carried out with local threshold selection and global thresh-\nold selection for binarization, as the techniques were based on calculation of both mean \nand standard deviation of the gray values (Liu 2013; Yanli and Zhenxing 2012; Ramírez-\nOrtegón and Rojas 2010; Otsu 1979; Shaikh et al. 2013; Thepade et al. 2014a).\n\nUse of morphological operators for feature extraction\n\nCommercial viability of shape feature extraction has been well highlighted by systems \nlike Image Content (Flickner et  al. 1995), PicToSeek (Gevers and Smeulders 2000). \nTwo different categorization of shape descriptors namely, contour-based and region-\nbased descriptors have been elaborated in the existing literatures (Mehtre et  al. 1997; \nZhang and Lu 2004). Emphasize of the contour based descriptors has been on bound-\nary lines. Popular contour-based descriptors have embraced Fourier descriptor (Zhang \nand Lu 2003), curvature scale space (Mokhtarian and Mackworth 1992), and chain codes \n(Dubois and Glanz 1986). Feature extraction from complex shapes has been well car-\nried out by means of region-based descriptors, since the feature extraction has been per-\nformed from whole area of object (Kim and Kim 2000).\n\nFusion methodologies and multi technique feature extraction\n\nInformation recognition with image data has utilized the features extracted by means \nof diverse extraction techniques to harmonize each other for enhanced identification \nrate. Recent studies in information fusion have categorized the methodologies typically \ninto four classes, namely, early fusion, late fusion, hybrid fusion and intermediate fusion. \nEarly fusion combines the features of different techniques and produces it as a single \ninput to the learner. The process inherently increases the size of feature vector as the \n\n\n\nPage 4 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nconcentrated features easily correspond to higher dimensions. Late fusion applies sepa-\nrate learner to each feature extraction technique and fuses the decision with a combiner. \nAlthough it offers scalability in comparison to early fusion, still, it cannot explore the \nfeature level correlations, since it has to make local decisions primarily. Hybrid fusion \nmakes a mix of the two above mentioned techniques. Intermediate fusion integrates \nmultiple features by considering a joint model for decision to yield superior prediction \naccuracy (Zhu and Shyu 2015). Color and texture features were extracted by means of \n3 D color histogram and Gabor filters for fusion based image identification. The space \ncomplexity of the feature was further reduced by using genetic algorithm which has also \nobtained the optimum boundaries of numerical intervals. The process has enhanced \nsemantic retrieval by introducing feature selection technique to reduce memory con-\nsumption and to decrease retrieval process complexity (ElAlami 2011). Local descriptors \nbased on color and texture was calculated from Color moments and moments on Gabor \nfilter responses. Gradient vector flow fields were calculated to capture shape information \nin terms of edge images. The shape features were finally depicted by invariant moments. \nThe retrieval decisions with the features were fused for enhanced retrieval performance \n(Hiremath and Pujari 2007). Feature vectors comprising of color histogram and tex-\nture features based on a co-occurrence matrix were extracted from HSV color space \nto facilitate image retrieval (Yue et al. 2011). Visually significant point features chosen \nfrom images by means of fuzzy set theoretic approach. Computation of some invariant \ncolor features from these points was performed to gauge the similarity between images \n(Banerjee et al. 2009). Recognition process was boosted up by combining color layout \ndescriptor and Gabor texture descriptor as image signatures (Jalab 2011). Multi view \nfeatures comprising of color, texture and spatial structure descriptors have contributed \nfor increased retrieval rate (Shen and Wu 2013). Wavelet packets and Eigen values of \nGabor filters were extracted as feature vectors by the authors in (Irtaza et al. 2013) for \nneural network architecture of image identification. The back propagation neural net-\nwork was trained on sub repository of images generated from the main image reposi-\ntory and utilizes the right neighbourhood of the query image. This kind of training was \naimed to insure correct semantic retrieval in response to query images. Higher retrieval \nresults have been apprehended with intra-class and inter-class feature extraction from \nimages (Rahimi and Moghaddam 2013). In (ElAlami 2014), extraction of color and tex-\nture features through color co-occurrence matrix (CCM) and difference between pixels \nof scan pattern (DBPSP) has been demonstrated and an artificial neural network (ANN) \nbased classifier was designed. In (Subrahmanyam et  al. 2013), content-based image \nretrieval was carried out by integrating the modified color motif co-occurrence matrix \n(MCMCM) and difference between the pixels of a scan pattern (DBPSP) features with \nequal weights. Fusion of semantic retrieval results obtained by capturing colour, shape \nand texture with the color moment (CMs), angular radial transform descriptor and edge \nhistogram descriptor (EHD) features respectively had outclassed the Precision values of \nindividual techniques (Walia et al. 2014). Six semantics of local edge bins for EHD were \nconsidered which included the vertical and the horizontal edge (0,0), 45° edge and 135° \nedge of sub-image (0,0), non directional edge of sub-image (0,0) and vertical edge of sub-\nimage at (0,1). Color histogram and spatial orientation tree has been used for unique \nfeature extraction from images for retrieval purpose (Subrahmanyam et al. 2012).\n\n\n\nPage 5 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nMethods\nThree different techniques of feature extraction have been introduced in this work namely, \nfeature extraction with image binarization, feature extraction with image transform and \nfeature extraction with morphological operator. However, there are popular feature extrac-\ntion techniques like GIST descriptor which has much greater feature dimension com-\npared to the proposed techniques in the work. GIST creates 32 feature maps of same \nsize by convolving the image with 32 Gabor filters at 4 scales, 8 orientations (Douze et al. \n2009). It averages the feature values of each region by dividing each feature map into 16 \nregions. Finally, it concatenates the 16 average value of all 32 feature maps resulting in \n16 × 32 = 512 GIST descriptor. On the other hand, our approach has generated a fea-\nture dimension of 6 from each of the binarization and morphological technique. Feature \nextraction by applying image transform has yielded a feature size of 36. On the whole, the \nfeature size for the fusion based classifier was (6 + 36 + 6 = 48) which is far less than GIST \nand has much lesser computational overhead. Furthermore, fusion based architecture for \nclassification and retrieval have been proposed for enhanced identification rate of image \ndata. Each of the techniques of feature extraction as well as the methods for fusion based \narchitecture of classification and retrieval has been discussed in the following four subsec-\ntions and the description of datasets has been given in the fifth subsection.\n\nFeature extraction with image binarization\n\nInitially, the three color components namely, Red (R), Green (G) and Blue (B) were sepa-\nrated in each of the test images. A popular global threshold selection method named \nOtsu’s method has been applied separately on each of the color components for binari-\nzation as in Fig. 1. The above mentioned thresholding method has been largely used for \ndocument image binarzation. Otsu’s technique has been operated directly on the gray \nlevel histogram which has made it fast executable. It has been efficient to remove redun-\ndant details from the image to bring out the necessary image information. The method \nhas been considered as a non-parametric method which has considered two classes of \npixels, namely, the foreground pixels and the background pixels. It has calculated the \noptimal threshold by using the within-class variance and between-class variance. The \nseparation was carried out in such a way so that their combined intra-class variance is \nminimal (Otsu 1979; Shaikh et al. 2013). Comprehensive investigation has been carried \nout for the threshold that minimizes the intra-class variance represented by the weighted \nsum of variances of the two classes of pixels for each of the three color components.\n\nThe weighted within-class variance has been given in Eq. 1.\n\nq1(t) = ∑ ti=0P(i) where the class probabilities of different gray level pixels were estimated \nas shown in Eqs. 2 and 3:\n\n(1)σ 2\nw(t) = q1(t)σ\n\n2\n1 (t)+ q2(t)σ\n\n2\n2 (t)\n\n(2)q1(t) =\n\nt\n∑\n\ni=0\n\np(i)\n\n(3)\nq2(t) =\n\n255\n∑\n\ni=t+1\n\nP(i)\n\n\n\nPage 6 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nThe class means were given as in Eqs. 4 and 5:\n\nTotal variance (σ2) = Within-class variance (σw\n2(t)) + Between-class Variance(σb\n\n2(t)).\nSince the total variance was constant and independent of t, the effect of changing \n\nthe threshold was purely to shift the contributions of the two terms back and forth. \nBetween-class variance has been given in Eq. 6\n\nThus, minimizing the within-class variance was the same as maximizing the between-\nclass variance.\n\nBinarization of the test images was carried out using the Otsu’s local threshold selec-\ntion method. The process has been repeated for all the three color components to gen-\nerate bag of words model (BoW) of features. Conventional BoW model has been based \non SIFT algorithm which has a descriptor dimension of 128 (Zhao et al. 2015). There-\nfore, for three color components the dimension of the descriptor would have been 128 \n× 3 = 384. The size for SIFT descriptor has been huge and it has predestined problem \nfor information losses and omissions as it has been found suitable only for the stability \n\n(4)µ1(t) =\n\nt\n∑\n\ni=0\n\ni ∗ P(i)\n\nq1(t)\n\n(5)µ2(t) =\n\n255\n∑\n\ni=t+1\n\ni ∗ P(i)\n\nq2(t)\n\n(6)σ 2\nb (t) = q1(t)[1− q1(t)][µ1(t)− µ2(t)]\n\n2\n\n   \nRed Component Green Component Blue Component \n\n   \nBinarization of \n\nRed Component \nBinarzation of \n\nGreen Component \nBinarization of \n\nBlue Component \nFig. 1 Binarization using Otsu’s Threshold selection\n\n  \n\n  \n\n  \n\n\n\nPage 7 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nof image feature point extraction and description. Furthermore, the generated SIFT \ndescriptors has to be clustered by k means clustering which has been based on alloca-\ntion of cluster members by means of comparing squared Euclidian distance. The clus-\ntering process has been helpful to generate codewords for codebook generation which \nhas been the final step of BoW. Process of k means clustering has huge computational \noverhead for calculating the squared Euclidian distance which eventually slows down \nthe BoW generation. Hence, in our approach, the grey values higher than the threshold \nwas clustered in higher intensity group and the grey values lower than the cluster was \nclustered in the lower intensity group. The mean of the two groups were calculated to \nformulate the codewords of higher intensity feature vectors and the lower intensity fea-\nture vectors respectively. Thus, each color component of a test image has been mapped \nto two codewords of higher intensity and lower intensity respectively. This has generated \nof codebook of size (3 × 2 = 6) for each image.\n\nThe algorithm for feature extraction has been stated in Algorithm 1 as follows:\n\nAlgorithm 1 \n\nBegin\n\n1. Input an image I with three different color \ncomponents R, G and B respectively of size \nm*n each. \n\n2. Calculate the local threshold value Tx for \neach pixel in each color component R,G and \nB using Otsu's Method.\n\n3. Compute binary image maps for each pixel \nfor the given image.\n\nTxjixif >=),(....1\n\nTxjixif <),(....0\n\n/*x = R, G and B */\n\n4. Generate image features for the given \nimage for each color component.\n\n/*x = R, G and B */\n\nEnd\n\n=),( jiBitmapx\n\nTx\np q\n\nqpxmean\nmean\n\nxhi >== ∑∑ )),((\n\nTx\np q\n\nqpxmean\nmean\n\nxlo <= ∑∑ )),((\n\n\n\nPage 8 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nFeature extraction using image transform\n\nTransforms convert spatial information to frequency domain information, where cer-\ntain operations are easier to perform. Energy compaction property of transforms has \nthe capacity to pack large fraction of the average energy into a few components. This \nhas led to faster execution and efficient algorithm design. Image transforms has the \nproperty to convert the spatial domain information of an image to frequency domain \ninformation, where certain operations are easier to perform. For example, convolu-\ntion operation can be reduced to matrix multiplication in frequency domain. It has the \ncharacteristic of energy compaction which ensures that a large fraction of the average \nenergy of the image remains packed into a few components. This property has led to \nfaster execution and efficient algorithm design by drastic reduction of feature vector \nsize which is achieved by means of discarding insignificant transform coefficients as in \nFig. 2. The approach has been implemented by applying slant transform on each of the \nRed (R), Green (G) and Blue (B) color component of the image for extraction of fea-\nture vectors with smaller dimension. Slant transform has reduced the average coding \nof a monochrome image from 8 bits/pixel to 1 bit/pixel without seriously degrading the \nimage quality. It is an orthogonal transform which has also reduced the coding of color \nimages from 24–2 bits/pixel (Pratt et al. 1974). Slant transform matrices are orthogo-\nnal and it holds all real components. Hence, it has much less computational overhead \ncompared to discrete Fourier transform. Slant transform is an unitary transform and \nfollows energy conservation. It tends to pack a large fraction of signal energy into a few \ntransform coefficients which has a significant role in reducing the feature vector for the \nimage. Let [F] be an N × N matrix of pixel values of an image and let [fi] be an N × 1 \nvector representing the ith. column of [F]. One dimensional transform of the ith. image \nline can be given by\n\n [S] = N × N unitary slant matrix.\n\n[fi] = [S][fi]\n\n0.06 % of (N*N) feature vector\n\n0.012% of (N*N) feature vector\n\n50% of (N*N) feature vector\n\nN*N feature vector\n\nFeature Vector Dimension Reduction with Partial Coefficients\n\nFig. 2 Feature extraction by applying image transform\n\n  \n\n  \n\n\n\nPage 9 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nA two dimensional slant transform can be performed by sequential transformations \nof row and column of [F] and the forward and inverse transform can be expressed as in \nEqs. 7 and 8.\n\nA transform operation can be conveniently represented in a series. The two dimensional \nforward and inverse transform in series form can be represented as in Eqs. 9 and 10\n\nThe algorithm for feature extraction using slant transform has been given in Algo-\nrithm 2.\n\nAlgorithm 2 \n\n(7)[ℑ] = |S|[F ][S]T\n\n(8)[F ] = [S]T [ℑ][S]\n\n(9)ℑ(u, v) =\n\nN\n∑\n\nj=1\n\nN\n∑\n\nk=1\n\nF(j, k)S(u, j)S(k , v)\n\n(10)F\n(\n\nj, k\n)\n\n=\n\nN\n∑\n\nu=1\n\nN\n∑\n\nv=1\n\nℑ(u, v)S\n(\n\nj,u\n)\n\nS(v, k)\n\nBegin\n\n1. Red, Green and Blue color components were \nextracted from a given image.\n\n2. Slant Transform was applied on each of the \ncomponent to extract feature vectors.\n\n3. The extracted feature vectors from each of the \ncomponent were stored as complete set of feature \nvectors.\n\n4. Further, partial coefficients from the entire \nfeature vector set were extracted to form the \nfeature vector database.\n\n5. Feature vector database with 100% transformed \ncoefficients and partial coefficients ranging from \n50% of the complete set of feature vectors till \n0.06% of the complete set of feature vectors were \nconstructed\n\n6. The feature vectors of the query image for the \nwhole set of feature vectors and for partial \ncoefficient of feature vectors were compared with \nthe database images for classification results.\n\n7. The fractional coefficient of feature vector \nhaving the highest classification result was \nconsidered as the feature set extracted by applying \nimage transform\n\nEnd\n\n\n\nPage 10 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nHere the features were extracted in the form of visual words. Visual words have been \ndefined as a small patch of image which can carry significant image information. The \nenergy compaction property of Slant transform has condensed noteworthy image infor-\nmation in a block of 12 elements for an image of dimension (256 × 256). Thus, the \nfeature vector extracted with slant transform was of size 12 for each color component \nwhich has given the dimension of feature vector as 36 (12 ×  3 =  36) for three color \ncomponents in each test image.\n\nFeature extraction with morphological operator\n\nHuman perception has largely been governed by shape context. It has been helpful to \nrecover the point correspondences from an image which has considerable contribution \nin feature vector formation. A variant of gray scale opening and closing operations has \nbeen termed as the top-hat transformation that has been instrumental in producing only \nthe bright peaks of an image (Sridhar 2011). It has been termed as the peak detector and \nits working process has been given as follows:\n\n1. Apply the gray scale opening operation to an image.\n2. Peak = original image—opened image.\n3. Display the peak.\n4. Exit.\n\nThe top-hat transform technique was applied on each color component Red (R), \nGreen (G) and Blue (B) of the test images for feature extraction using morphologi-\ncal operator as in Fig. 3. After applying the tophat operator, the pixels designated as \nthe foreground pixels were grouped in one cluster and were calculated with mean and \nstandard deviation to formulate the higher intensity feature vector. Similar process \nwas followed with the pixels designated as the background pixels to calculate the lower \nintensity feature vector. The feature vector extraction process has followed the bag of \nwords (BoW) methodology which has generated codewords from the cluster of fore-\nground and background pixels by calculating the mean and the standard deviation of \nboth the clusters and adding the two. Hence, codebook size for each color component \nwas two which have yielded a dimension of 6 (3 × 2 = 6) on the whole for the code-\nbook generated for three color components for each test image.\n\nThe algorithm for feature extraction using morphological operator has been given in \nAlgorithm 3.\n\n\n\nPage 11 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nAlgorithm 3 \n\nSimilarity measures\n\nDetermination of image similarity measures was performed by evaluating distance \nbetween set of image features. Higher similarity has been characterized by shorter dis-\ntance (Dunham 2009). A fusion based classifier, an artificial neural network (ANN) clas-\nsifier and a support vector machine (SVM) classifier was used for the purpose. Each of \nthe classifier types has been discussed in the following sections:\n\nBegin\n\n1. Input an image I with three different color \ncomponents R, G and B respectively of size \nm*n each. \n\n2. Apply tophat transform on each color \ncomponent\n\n3. Cluster the foreground and background \npixels obtained after the morphological \noperation     \n\n4. Generate image features xhiF.V. and xloF.V.\nfor the given image for each color \ncomponent.\n\n/*x = R, G and B */\n\nEnd\n\n∑∑=\np q\n\nqp\nforeground\n\nxmean\nmean\n\nxhi )),((\n\n∑∑=\np q\n\nqp\nforeground\n\nx\nstdev\n\nxhi )),((σ\n\n( )\nstdev\n\nxhi\nmean\n\nxhimeanxhi\nVF\n\nxhi += +\n..\n\n∑∑=\np q\n\nqp\nbackground\n\nxmean\nmean\n\nxlo )),((\n\n∑∑=\np q\n\nqp\nbackground\n\nx\nstdev\n\nxlo )),((σ\n\n( )\nstdev\n\nxlo\nmean\n\nxlomeanxlo\nVF\n\nxlo += +\n..\n\n\n\nPage 12 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nFusion based classifier\n\nThree different distance measures, namely, city block distance, Euclidian distance and \nmean squared error (MSE) distance metric was considered to compute the distance \nbetween query image Q and database image T as in Eqs. 11, 12 and 13\n\nwhere, Qi is the query image and Di is the database image.\nData standardization technique was followed to standardize the calculated distances \n\nfor the individual techniques with Z score normalization which was based on mean and \nstandard deviation of the computed values as in Eq. 14. The normalization process has \nbeen implemented to avoid dependence of the classification decision on a feature vec-\ntor with higher values of attributes which have the possibilities to have greater effect or \n“weight.” The process has normalized the data within a common range such as [−1, 1] or \n[0.0, 1.0].\n\nwhere, µ is the mean and σ is the standard deviation.\n\n(11)Dcityblock =\n\nn\n∑\n\ni−1\n\n|Qi − Di|\n\n(12)Deuclidian =\n\n√\n\n√\n\n√\n\n√\n\nn\n∑\n\ni=1\n\n(Qi − Di)2\n\n(13)DMSE =\n1\n\nn\n\nn\n∑\n\ni=1\n\n(Qi − Di)\n2\n\n(14)distn =\ndisti − µ\n\nσ\n\n   \nRed Component Green Component Blue Component \n\n   \nApplying Top-Hat \noperator on Red \n\nComponent \n\nApplying Top-Hat \noperator on Green \n\nComponent \n\nApplying Top-Hat \noperator on Blue \n\nComponent \nFig. 3 Effect of applying morphological operator\n\n  \n\n  \n\n  \n\n  \n\n - \n\n\n\nPage 13 of 26Das et al. SpringerPlus  (2015) 4:749 \n\nFurther, the final distance was calculated by adding the weighted sum of individual \ndistances. The weights were calculated from the precision values of corresponding tech-\nniques. Finally, the image was classified based on the class majority of k nearest neigh-\nbors [Sridhar 2011] where value of k was\n\nThe classified image was forwarded for retrieval purpose. The image was a classified \nquery and has searched for similar images only within the class of interest. Ranking of \nthe images was done with Canberra Distance measure as in Eq. 15 and top 20 images \nwere retrieved.\n\nwhere, Qi is the query image and Di is the database image.\nThe process of fusion based classification and then retrieval with classified query has \n\nbeen illustrated in Fig. 4.\n\nArtificial neural network (ANN) classifier\n\nThe set of input features from images were mapped to an appropriate output by a feed \nforward Neural Network Classifier known as Multilayer Perceptron (MLP) as shown in \nFig. 5 (Alsmadi et al. 2009).\n\nThe back propagation technique of multi layer perceptron has a significant role in \nsupervised learning procedure. The network has been trained for optimization of clas-\nsification performance by using the procedure of back propagation. For each training \ntuple, the weights were modified so as to minimize the mean squared error between the \nnetwork prediction and the target value. These modifications have been made in the \nbackward direction through each hidden layer down to the first hidden layer. The input \nfeature vectors have been fed to the input units which comprised the input layer. The \nnumber of input units has been dependent on the summation of the number of attrib-\nutes in the feature vector dataset and the bias node. The subsequent layer has been the \nhidden layer whose number of nodes has to be determined by considering the half of the \nsummation of the number of classes and the number of attributes per class. The inputs \nthat have passed the input layer have to be weighted and fed simultaneously to the hid-\nden layer for further processing. Weighted output of the hidden layer was used as input \nto the final layer which has been named as the output layer. The number of units in the \noutput layer has been denoted by the number of class labels. The feed forward property \nof this architecture does not allow the weights to cycle back to the input units.\n\nSupport vector machine (SVM) classifier\n\nSVM transforms original training data to higher dimension by using nonlinear mapping. \nOptimal separating hyperplane has to be searched by the algorithm within this new \ndimension. Data from two different classes can readily be separated by a hyperplane by \nmeans of an",
      "text": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "-",
        "O O O O - O Large Margin - - O",
        "",
        "Lins LaBern TES VA",
        "",
        "IRE-USE THINGS mezanina SITED SERIES OP AMI MATE",
        "",
        "",
        "Published online: 01 December 2015"
      ],
      "layoutText": [
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"-\",\"lines\":[{\"boundingBox\":[{\"x\":32,\"y\":165},{\"x\":34,\"y\":177},{\"x\":28,\"y\":178},{\"x\":26,\"y\":167}],\"text\":\"-\"}],\"words\":[{\"boundingBox\":[{\"x\":33,\"y\":168},{\"x\":33,\"y\":172},{\"x\":27,\"y\":173},{\"x\":27,\"y\":169}],\"text\":\"-\"}]}",
        "{\"language\":\"en\",\"text\":\"O O O O - O Large Margin - - O\",\"lines\":[{\"boundingBox\":[{\"x\":498,\"y\":25},{\"x\":532,\"y\":20},{\"x\":533,\"y\":48},{\"x\":500,\"y\":49}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":564,\"y\":107},{\"x\":599,\"y\":106},{\"x\":596,\"y\":137},{\"x\":571,\"y\":138}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":675,\"y\":102},{\"x\":711,\"y\":102},{\"x\":709,\"y\":136},{\"x\":676,\"y\":137}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":560,\"y\":201},{\"x\":598,\"y\":190},{\"x\":600,\"y\":213},{\"x\":575,\"y\":223}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":503,\"y\":225},{\"x\":517,\"y\":235},{\"x\":512,\"y\":241},{\"x\":498,\"y\":230}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":672,\"y\":248},{\"x\":708,\"y\":237},{\"x\":711,\"y\":262},{\"x\":684,\"y\":268}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":254,\"y\":315},{\"x\":356,\"y\":213},{\"x\":374,\"y\":231},{\"x\":269,\"y\":333}],\"text\":\"Large Margin\"},{\"boundingBox\":[{\"x\":591,\"y\":312},{\"x\":603,\"y\":326},{\"x\":598,\"y\":330},{\"x\":586,\"y\":317}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":607,\"y\":329},{\"x\":623,\"y\":345},{\"x\":617,\"y\":350},{\"x\":601,\"y\":335}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":407,\"y\":680},{\"x\":444,\"y\":679},{\"x\":444,\"y\":717},{\"x\":407,\"y\":718}],\"text\":\"O\"}],\"words\":[{\"boundingBox\":[{\"x\":498,\"y\":23},{\"x\":513,\"y\":22},{\"x\":516,\"y\":50},{\"x\":500,\"y\":50}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":565,\"y\":107},{\"x\":584,\"y\":106},{\"x\":585,\"y\":137},{\"x\":566,\"y\":138}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":675,\"y\":102},{\"x\":694,\"y\":102},{\"x\":695,\"y\":137},{\"x\":675,\"y\":137}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":562,\"y\":200},{\"x\":576,\"y\":195},{\"x\":585,\"y\":219},{\"x\":571,\"y\":224}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":505,\"y\":225},{\"x\":510,\"y\":229},{\"x\":506,\"y\":235},{\"x\":501,\"y\":232}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":672,\"y\":246},{\"x\":686,\"y\":242},{\"x\":693,\"y\":267},{\"x\":679,\"y\":269}],\"text\":\"O\"},{\"boundingBox\":[{\"x\":254,\"y\":314},{\"x\":296,\"y\":273},{\"x\":313,\"y\":291},{\"x\":269,\"y\":332}],\"text\":\"Large\"},{\"boundingBox\":[{\"x\":300,\"y\":269},{\"x\":355,\"y\":214},{\"x\":372,\"y\":232},{\"x\":317,\"y\":287}],\"text\":\"Margin\"},{\"boundingBox\":[{\"x\":592,\"y\":312},{\"x\":595,\"y\":315},{\"x\":590,\"y\":320},{\"x\":587,\"y\":317}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":608,\"y\":330},{\"x\":611,\"y\":333},{\"x\":606,\"y\":339},{\"x\":603,\"y\":336}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":407,\"y\":680},{\"x\":427,\"y\":679},{\"x\":428,\"y\":716},{\"x\":407,\"y\":717}],\"text\":\"O\"}]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"Lins LaBern TES VA\",\"lines\":[{\"boundingBox\":[{\"x\":29,\"y\":276},{\"x\":114,\"y\":266},{\"x\":116,\"y\":278},{\"x\":31,\"y\":288}],\"text\":\"Lins LaBern\"},{\"boundingBox\":[{\"x\":154,\"y\":392},{\"x\":143,\"y\":462},{\"x\":126,\"y\":460},{\"x\":135,\"y\":390}],\"text\":\"TES VA\"}],\"words\":[{\"boundingBox\":[{\"x\":33,\"y\":277},{\"x\":60,\"y\":274},{\"x\":62,\"y\":285},{\"x\":34,\"y\":289}],\"text\":\"Lins\"},{\"boundingBox\":[{\"x\":67,\"y\":273},{\"x\":110,\"y\":268},{\"x\":111,\"y\":279},{\"x\":68,\"y\":284}],\"text\":\"LaBern\"},{\"boundingBox\":[{\"x\":154,\"y\":393},{\"x\":149,\"y\":421},{\"x\":132,\"y\":418},{\"x\":136,\"y\":390}],\"text\":\"TES\"},{\"boundingBox\":[{\"x\":147,\"y\":435},{\"x\":144,\"y\":458},{\"x\":127,\"y\":456},{\"x\":130,\"y\":433}],\"text\":\"VA\"}]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"IRE-USE THINGS mezanina SITED SERIES OP AMI MATE\",\"lines\":[{\"boundingBox\":[{\"x\":620,\"y\":22},{\"x\":659,\"y\":24},{\"x\":658,\"y\":38},{\"x\":619,\"y\":37}],\"text\":\"IRE-USE\"},{\"boundingBox\":[{\"x\":666,\"y\":28},{\"x\":715,\"y\":30},{\"x\":714,\"y\":45},{\"x\":666,\"y\":42}],\"text\":\"THINGS\"},{\"boundingBox\":[{\"x\":774,\"y\":240},{\"x\":823,\"y\":234},{\"x\":825,\"y\":243},{\"x\":775,\"y\":249}],\"text\":\"mezanina\"},{\"boundingBox\":[{\"x\":770,\"y\":505},{\"x\":886,\"y\":517},{\"x\":885,\"y\":527},{\"x\":769,\"y\":514}],\"text\":\"SITED SERIES OP AMI\"},{\"boundingBox\":[{\"x\":358,\"y\":515},{\"x\":399,\"y\":522},{\"x\":397,\"y\":535},{\"x\":355,\"y\":528}],\"text\":\"MATE\"}],\"words\":[{\"boundingBox\":[{\"x\":619,\"y\":22},{\"x\":659,\"y\":23},{\"x\":658,\"y\":38},{\"x\":619,\"y\":36}],\"text\":\"IRE-USE\"},{\"boundingBox\":[{\"x\":681,\"y\":29},{\"x\":714,\"y\":31},{\"x\":714,\"y\":45},{\"x\":681,\"y\":44}],\"text\":\"THINGS\"},{\"boundingBox\":[{\"x\":775,\"y\":240},{\"x\":819,\"y\":235},{\"x\":820,\"y\":244},{\"x\":776,\"y\":249}],\"text\":\"mezanina\"},{\"boundingBox\":[{\"x\":771,\"y\":505},{\"x\":801,\"y\":509},{\"x\":800,\"y\":518},{\"x\":770,\"y\":514}],\"text\":\"SITED\"},{\"boundingBox\":[{\"x\":806,\"y\":509},{\"x\":845,\"y\":513},{\"x\":843,\"y\":522},{\"x\":805,\"y\":518}],\"text\":\"SERIES\"},{\"boundingBox\":[{\"x\":849,\"y\":514},{\"x\":862,\"y\":515},{\"x\":861,\"y\":525},{\"x\":848,\"y\":523}],\"text\":\"OP\"},{\"boundingBox\":[{\"x\":866,\"y\":515},{\"x\":886,\"y\":517},{\"x\":885,\"y\":527},{\"x\":865,\"y\":525}],\"text\":\"AMI\"},{\"boundingBox\":[{\"x\":358,\"y\":516},{\"x\":396,\"y\":522},{\"x\":394,\"y\":535},{\"x\":356,\"y\":528}],\"text\":\"MATE\"}]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"Published online: 01 December 2015\",\"lines\":[{\"boundingBox\":[{\"x\":4,\"y\":15},{\"x\":1051,\"y\":15},{\"x\":1051,\"y\":70},{\"x\":4,\"y\":70}],\"text\":\"Published online: 01 December 2015\"}],\"words\":[{\"boundingBox\":[{\"x\":4,\"y\":15},{\"x\":273,\"y\":15},{\"x\":272,\"y\":71},{\"x\":4,\"y\":70}],\"text\":\"Published\"},{\"boundingBox\":[{\"x\":292,\"y\":15},{\"x\":496,\"y\":15},{\"x\":495,\"y\":71},{\"x\":291,\"y\":71}],\"text\":\"online:\"},{\"boundingBox\":[{\"x\":507,\"y\":15},{\"x\":579,\"y\":15},{\"x\":578,\"y\":71},{\"x\":506,\"y\":71}],\"text\":\"01\"},{\"boundingBox\":[{\"x\":595,\"y\":15},{\"x\":897,\"y\":15},{\"x\":895,\"y\":71},{\"x\":593,\"y\":71}],\"text\":\"December\"},{\"boundingBox\":[{\"x\":909,\"y\":15},{\"x\":1047,\"y\":16},{\"x\":1044,\"y\":70},{\"x\":906,\"y\":71}],\"text\":\"2015\"}]}"
      ]
    },
    {
      "@search.score": 3.6058593,
      "content": "\nBig data stream analysis: a systematic \nliterature review\nTaiwo Kolajo1,2* , Olawande Daramola3  and Ayodele Adebiyi1,4 \n\nIntroduction\nAdvances in information technology have facilitated large volume, high-velocity of data, \nand the ability to store data continuously leading to several computational challenges. \nDue to the nature of big data in terms of volume, velocity, variety, variability, veracity, \nvolatility, and value [1] that are being generated recently, big data computing is a new \ntrend for future computing.\n\nBig data computing can be generally categorized into two types based on the process-\ning requirements, which are big data batch computing and big data stream computing \n\nAbstract \n\nRecently, big data streams have become ubiquitous due to the fact that a number of \napplications generate a huge amount of data at a great velocity. This made it difficult \nfor existing data mining tools, technologies, methods, and techniques to be applied \ndirectly on big data streams due to the inherent dynamic characteristics of big data. In \nthis paper, a systematic review of big data streams analysis which employed a rigorous \nand methodical approach to look at the trends of big data stream tools and technolo-\ngies as well as methods and techniques employed in analysing big data streams. It \nprovides a global view of big data stream tools and technologies and its comparisons. \nThree major databases, Scopus, ScienceDirect and EBSCO, which indexes journals and \nconferences that are promoted by entities such as IEEE, ACM, SpringerLink, and Elsevier \nwere explored as data sources. Out of the initial 2295 papers that resulted from the \nfirst search string, 47 papers were found to be relevant to our research questions after \nimplementing the inclusion and exclusion criteria. The study found that scalability, \nprivacy and load balancing issues as well as empirical analysis of big data streams and \ntechnologies are still open for further research efforts. We also found that although, sig-\nnificant research efforts have been directed to real-time analysis of big data stream not \nmuch attention has been given to the preprocessing stage of big data streams. Only a \nfew big data streaming tools and technologies can do all of the batch, streaming, and \niterative jobs; there seems to be no big data tool and technology that offers all the key \nfeatures required for now and standard benchmark dataset for big data streaming ana-\nlytics has not been widely adopted. In conclusion, it was recommended that research \nefforts should be geared towards developing scalable frameworks and algorithms that \nwill accommodate data stream computing mode, effective resource allocation strategy \nand parallelization issues to cope with the ever-growing size and complexity of data.\n\nKeywords: Big data stream analysis, Stream computing, Big data streaming tools and \ntechnologies\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nKolajo et al. J Big Data            (2019) 6:47  \nhttps://doi.org/10.1186/s40537-019-0210-7\n\n*Correspondence:   \ntaiwo.kolajo@stu.cu.edu.ng; \ntaiwo.kolajo@fulokoja.edu.ng \n1 Department of Computer \nand Information Sciences, \nCovenant University, Ota, \nNigeria\nFull list of author information \nis available at the end of the \narticle\n\nhttp://orcid.org/0000-0001-6780-2495\nhttp://orcid.org/0000-0001-6340-078X\nhttp://orcid.org/0000-0002-3114-6315\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-019-0210-7&domain=pdf\n\n\nPage 2 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\n[2]. Big data batch processing is not sufficient when it comes to analysing real-time \napplication scenarios. Most of the data generated in a real-time data stream need real-\ntime data analysis. In addition, the output must be generated with low-latency and any \nincoming data must be reflected in the newly generated output within seconds. This \nnecessitates big data stream analysis [3].\n\nThe demand for stream processing is increasing. The reason being not only that huge \nvolume of data need to be processed but that data must be speedily processed so that \norganisations or businesses can react to changing conditions in real-time.\n\nThis paper presents a systematic review of big data stream analysis. The purpose is to \npresent an overview of research works, findings, as well as implications for research and \npractice. This is necessary to (1) provide an update about the state of research, (2) iden-\ntify areas that are well researched, (3) showcase areas that are lacking and need further \nresearch, and (4) build a common understanding of the challenges that exist for the ben-\nefit of the scientific community.\n\nThe rest of the paper is organized as follows: “Background and related work” section \nprovides information on stream computing and big data stream analysis and the key \nissues involved in it and presents a review on big data streaming analytics. In “Research \nmethod” section, the adopted research methodology is discussed, while “Result” section \npresents the findings of the study. “Discussion” section presents a detailed evaluation \nperformed on big data stream analysis, “Limitation of the review” section highlights the \nlimitations of the study, while “Conclusion and further work” concludes the paper.\n\nBackground and related work\nStream computing\n\nStream computing refers to the processing of massive amount of data generated at high-\nvelocity from multiple sources with low latency in real-time. It is a new paradigm neces-\nsitated because of new sources of data generating scenarios which include ubiquity of \nlocation services, mobile devices, and sensor pervasiveness [4]. It can be applied to the \nhigh-velocity flow of data from real-time sources such as the Internet of Things, Sensors, \nmarket data, mobile, and clickstream.\n\nThe fundamental assumption of this paradigm is that the potential value of data lies in \nits freshness. As a result, data are analysed as soon as they arrive in a stream to produce \nresult as opposed to what obtains in batch computing where data are first stored before \nthey are analysed. There is a crucial need for parallel architectures and scalable com-\nputing platforms [5]. With stream computing, organisations can analyse and respond in \nreal-time to rapidly changing data. Streaming processing frameworks include Storm, S4, \nKafka, and Spark [6–8]. The real contrasts between the batch processing and the stream \nprocessing paradigms are outlined in Table 1.\n\nIncorporating streaming data into decision-making process necessitates a program-\nming paradigm called stream computing. With stream computing, fairly static questions \ncan be evaluated on data in motion (i.e. real-time data) continuously [9].\n\nBig data stream analysis\n\nThe essence of big data streaming analytics is the need to analyse and respond to real-\ntime streaming data using continuous queries so that it is possible to continuously \n\n\n\nPage 3 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nperform analysis on the fly within the stream. Stream processing solutions must be \nable to handle a real-time, high volume of data from diverse sources putting into con-\nsideration availability, scalability and fault tolerance. Big data stream analysis involves \nassimilation of data as an infinite tuple, analysis and production of actionable results \nusually in a form of stream [10].\n\nIn a stream processor, applications are represented as data flow graph made up of \noperations and interconnected streams as depicted in Fig. 1. In a streaming analytics \nsystem, application comes in a form of continuous queries, data are ingested continu-\nously, analysed and correlated, and stream of results are generated. Streaming analytic \napplications is usually a set of operators connected by streams. Streaming analytics \nsystems must be able to identify new information, incrementally build models and \naccess whether the new incoming data deviate from model predictions [9].\n\nThe idea of streaming analytics is that each of the received data tuples is processed \nin the data processing node. Such processing includes removing duplicates, filling \nmissing data, data normalization, parsing, feature extraction, which are typically done \nin a single pass due to the high data rates of external feeds. When a new tuple arrives, \nthis node is triggered, and it expels tuples older than the time specified in the sliding \nwindow (sliding window is a typical example of windows used in stream computing \nwhich keeps only the latest tuples up to the time specified in the windows). A window \n\nTable 1 Comparison between batch processing and streaming processing [82]\n\nDimension Batch processing Streaming processing\n\nInput Data chunks Stream of new data or updates\n\nData size Known and finite Infinite or unknown in advance\n\nHardware Multiple CPUs Typical single limited amount of memory\n\nStorage Store Not store or store non-trivial portion in memory\n\nProcessing Processed in multiple rounds A single or few passes over data\n\nTime Much longer A few seconds or even milliseconds\n\nApplications Widely adopted in almost every domain Web mining, traffic monitoring, sensor networks\n\nFig. 1 Data flow graph of a stream processor. The figure shows how applications (made up of operations and \ninterconnected streams) are represented as data flow graph in a stream processor [10]\n\n\n\n\n\nPage 4 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nis referred to as a logical container for data tuples received. It defines how frequently \ndata is refreshed in the container as well as when data processing is triggered [4].\n\nKey issues in big data stream analysis\n\nBig data stream analysis is relevant when there is a need to obtain useful knowledge \nfrom current happenings in an efficient and speedy manner in order to enable organisa-\ntions to quickly react to problems, or detect new trends which can help improve their \nperformance. However, there are some challenges such as scalability, integration, fault-\ntolerance, timeliness, consistency, heterogeneity and incompleteness, load balancing, \nprivacy issues, and accuracy [3, 11–18] which arises from the nature of big data streams \nthat must be dealt with.\n\nScalability\n\nOne of the main challenges in big data streaming analysis is the issue of scalability. The \nbig data stream is experiencing exponential growth in a way much faster than computer \nresources. The processors follow Moore’s law, but the size of data is exploding. There-\nfore, research efforts should be geared towards developing scalable frameworks and \nalgorithms that will accommodate data stream computing mode, effective resource allo-\ncation strategy and parallelization issues to cope with the ever-growing size and com-\nplexity of data.\n\nIntegration\n\nBuilding a distributed system where each node has a view of the data flow, that is, every \nnode performing analysis with a small number of sources, then aggregating these views \nto build a global view is non-trivial. An integration technique should be designed to ena-\nble efficient operations across different datasets.\n\nFault‑tolerance\n\nHigh fault-tolerance is required in life-critical systems. As data is real-time and infinite \nin big data stream computing environments, a good scalable high fault-tolerance strat-\negy is required that allows an application to continue working despite component failure \nwithout interruption.\n\nTimeliness\n\nTime is of the essence for time-sensitive processes such as mitigating security threats, \nthwarting fraud, or responding to a natural disaster. There is a need for scalable architec-\ntures or platforms that will enable continuous processing of data streams which can be \nused to maximize the timeliness of data. The main challenge is implementing a distrib-\nuted architecture that will aggregate local views of data into global view with minimal \nlatency between communicating nodes.\n\nConsistency\n\nAchieving high consistency (i.e. stability) in big data stream computing environments is \nnon-trivial as it is difficult to determine which data are needed and which nodes should \nbe consistent. Hence a good system structure is required.\n\n\n\nPage 5 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nHeterogeneity and incompleteness\n\nBig data streams are heterogeneous in structure, organisations, semantics, accessi-\nbility and granularity. The challenge here is how to handle an always ever-increas-\ning data, extract meaningful content out of it, aggregate and correlate streaming \ndata from multiple sources in real-time. A competent data presentation should be \ndesigned to reflect the structure, diversity and hierarchy of the streaming data.\n\nLoad balancing\n\nA big data stream computing system is expected to be self-adaptive to data streams \nchanges and avoid load shedding. This is challenging as dedicating resources to cover \npeak loads 24/7 is impossible and load shedding is not feasible when the variance \nbetween the average load and the peak load is high. As a result, a distributing envi-\nronment that automatically streams partial data streams to a global centre when local \nresources become insufficient is required.\n\nHigh throughput\n\nDecision with respect to identifying the sub-graph that needs replication, how many \nreplicas are needed and the portion of the data stream to assign to each replica is an \nissue in big data stream computing environment. There is a need for good multiple \ninstances replication if high throughput is to be achieved.\n\nPrivacy\n\nBig data stream analytics created opportunities for analyzing a huge amount of data \nin real-time but also created a big threat to individual privacy. According to the Inter-\nnational Data Cooperation (IDC), not more than half of the entire information that \nneeds protection is effectively protected. The main challenge is proposing techniques \nfor protecting a big data stream dataset before its analysis.\n\nAccuracy\n\nOne of the main objectives of big data stream analysis is to develop effective tech-\nniques that can accurately predict future observations. However, as a result of inher-\nent characteristics of big data such as volume, velocity, variety, variability, veracity, \nvolatility, and value, big data analysis strongly constrain processing algorithms spatio-\ntemporally and hence stream-specific requirements must be taken into consideration \nto ensure high accuracy.\n\nRelated work\n\nThis section discusses some of the previous research efforts that relate to big data \nstreaming analytics.\n\nThe work of [13] presented a review of various tools, technologies and methods \nfor big data analytics by categorizing big data analytics literature according to their \nresearch focus. This paper is different in that it presents a systematic literature review \nthat focused on big data “streaming” analytics.\n\n\n\nPage 6 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nAuthors in [19] presented a systematic review of big data analytics in e-commerce. The \nstudy explored characteristics, definitions, business values, types and challenges of big \ndata analytics in the e-commerce landscape. Likewise, [20] conducted a study that is cen-\ntred on big data analytics in technology and organisational resource management specifi-\ncally focusing on reviews that present big data challenges and big data analytics methods. \nAlthough they are systematic reviews, the focus is not, particularly on big data streaming.\n\nAuthors in [21] presented the status of empirical research and application areas in big \ndata by employing a systematic mapping method. In the same vein, authors in [22] also \nconducted a survey on big data technologies and machine learning algorithms with a \nparticular focus on anomaly detection. A systematic review of literature which aims to \ndetermine the scope, application, and challenges of big data analytics in healthcare was \npresented by [23]. The work of [2] presented a review of four big data streaming tools \nand technologies. While the study conducted in this paper provided a comprehensive \nreview of not only big data streaming tools and technologies but also methods and tech-\nniques employed in analyzing big data streams. In addition, authors [2] did not provide a \nclear explanation of the methodical approach for selecting the reviewed papers.\n\nResearch method\nThe study was grounded in a systematic literature review of tools and technologies \nwith methods and techniques used in analysing big data streams by adopting [24, 25] as \nmodels.\n\nResearch question\n\nThe study tries to answer the following research questions:\n\nResearch Question 1: What are the tools and technologies employed for big data \nstream analysis?\nResearch Question 2: What methods and techniques are used in analysing big data \nstreams?\nResearch Question 3: What do these tools and technologies have in common and \ntheir differences in terms of concept, purpose and capabilities?\nResearch Question 4: What are the limitations and strengths of these tools and tech-\nnologies?\nResearch Question 5: What are the evaluation techniques or benchmarks used for \nevaluating big data streaming tools and technology?\n\nSearch string\n\nCreating a good search string requires structuring in terms of population, compari-\nson, intervention and outcome [24]. Relevant publications were identified by forming \na search string that combined keywords driven by the research questions earlier stated. \nThe searches were conducted by employing three standard database indexes, which are \nScopus, Science Direct and EBSCOhost. The search string is “big data stream analysis” \nOR “big data stream technologies” OR “big data stream framework” OR “big data stream \nalgorithms” OR “big data stream analysis tools” OR “big data stream processing” OR “big \n\n\n\nPage 7 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\ndata stream analysis reviews” OR “big data stream literature review” OR “big data stream \nanalytics”.\n\nData sources\n\nAs research becomes increasingly interdisciplinary, global and collaborative, it is expedi-\nent to select from rich and standard databases. The databases consulted are as follows:\n\n i. Scopus1: Scopus is a bibliographic database containing abstracts and citations for \nacademic journal articles launched in 2004. It covers nearly 36,377 titles from over \n11,678 publishers of which 34,346 are peer-reviewed journals, delivering a compre-\nhensive overview of the world’s research output in the scientific, technical, medi-\ncal, and social sciences (including arts and humanities). It is the largest abstract \nand citation database of peer-reviewed literature.\n\n ii. ScienceDirect2: ScienceDirect is Elsevier’s leading information solution for \nresearchers, students, teachers, information professionals and healthcare profes-\nsionals. It provides both subscription-based and open access-based to a large data-\nbase combining authoritative, full-text scientific, technical and health publications \nwith smart intuitive functionality. It covers over 14 million publications from over \n3800 journals and more than 35,000 books. The journals are grouped into four \ncategories: Life Sciences, Physical Sciences and Engineering, Health Sciences, and \nSocial Sciences and Humanities.\n\n iii. EBSCOhost3: EBSCOhost covers a wide range of bibliographic and full-text data-\nbases for researchers, providing electronic journal service available to both cor-\nporate and academic researchers. It has a total of 16,711 journals and magazine \nindexed and abstracted of which 14,914 are peer-reviewed; more than 900,000 \nhigh-quality e-books and titles and over 60,000 audiobooks from more than 1500 \nmajor academic publishers.\n\n iv. ResearchGate4: A free online professional network for scientists and researchers to \nask and answer questions, share papers and find collaborators. It covers over 100 \nmillion publications from over 11 million researchers. ResearchGate was used as \na secondary source where the authors could not access some papers due to lack of \nsubscription.\n\nData retrieval\n\nThe search was conducted in Scopus, ScienceDirect and EBSCOhost since most of \nthe high impact journals and conferences are indexed in these set of rich databases. \nBoolean ‘OR’ was used in combining the nine (9) search strings. A total of 2295 arti-\ncles from the three databases were retrieved as shown in Table 2.\n\n1 http://www.scopu s.com.\n2 http://www.scien cedir ect.com.\n3 https ://www.ebsco host.com.\n4 https ://www.resea archg ate.net.\n\nhttp://www.scopus.com\nhttp://www.sciencedirect.com\nhttps://www.ebscohost.com\nhttps://www.reseaarchgate.net\n\n\nPage 8 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nFurther refinement was performed by (i) limiting the search to journals and confer-\nence papers; (ii) selecting computer science and IT related as the subject domain; (iii) \nselecting ACM, IEEE, SpringerLink, Elsevier as sources; and year of publication to \nbetween 2004 and 2018. The year range was selected due to the fact that interest in \nbig data stream analysis actually started in 2004. At this stage, a total of 1989 papers \nwere excluded leaving a total of 315 papers (see Table  3). The result of the search \nstring was exported to PDF.\n\nBy going through the title of the papers, 111 seemingly relevant papers were extracted \nexcluding a total number of 213 that were not relevant at this stage (see Table 4).\n\nThe abstracts of 111 papers and introduction (for papers that the abstracts were not \nclear enough) were then read to have a quick overview of the paper and to ascertain \nwhether they are suitable or at variance with the research questions. The citations of \nthe papers were exported to Microsoft Excel for easy analysis. The papers were grouped \ninto three categories; “relevant”, “may be relevant” and “irrelevant”. The “relevant” papers \nwere marked with black colour, “may be relevant” and “irrelevant” with green and red \ncolours respectively. At the end of this stage, 45 papers were classified as “relevant”, 9 \npapers as “may be relevant” and 11 as “irrelevant”. Looking critically at the abstract again, \n18 papers were excluded by using the exclusion criteria leaving a total of 47 papers (see \nTable 5) which were manually reviewed in line with the research questions.\n\nInclusion criteria\n\nPapers published in journals, peer-reviewed conferences, workshops, technical and \nsymposium from 2004 and 2018 were included. In addition, the most recent papers \nwere selected in case of papers with similar investigations and results.\n\nTable 2 First search string result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 2097 65 133 2295\n\nTable 3 Second search string result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 196 27 92 315\n\nTable 4 Third Search string refinement result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 64 23 24 111\n\nTable 5 Final Selection\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 25 10 12 47\n\n\n\nPage 9 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nExclusion criteria\n\nPapers that belong to the following categories were excluded from selection as part of \nthe primary study: (i) papers written in source language other than English; (ii) papers \nwith an abstract and or introduction that does not clearly define the contributions of the \nwork; (iii) papers whose abstract do not relate to big data stream analysis.\n\nResult\nThe findings of the study are now presented with respect to the research questions that \nguided the execution of the systematic literature review.\n\nResearch Question 1: What are the tools and technologies employed for big data stream \n\nanalysis?\n\nBig data stream platforms provide functionalities and features that enable big data \nstream applications to develop, operate, deploy, and manage big data streams. Such \nplatforms must be able to pull in streams of data, process the data and stream it back \nas a single flow. Several tools and technologies have been employed to analyse big data \nstreams. In response to the growing demand for big data streaming analytics, a large \nnumber of alternative big data streaming solutions have been developed both by the \nopen source community and enterprise technology vendors. According to [26], there are \nsome factors to consider when selecting big data streaming tools and technologies in \norder to make effective data management decisions. These are briefly described below.\n\nShape of the data\n\nStreaming data sources require serialization technologies for capturing, storing and rep-\nresenting such high-velocity data. For instance, some tools and technologies allow pro-\njection of different structures across data stores, giving room for flexibility for storage \nand access of data in different ways. However, the performance of such platforms may \nnot be suitable for high-velocity data.\n\nData access\n\nThere is a need to put into consideration how the data will be accessed by users and \napplications. For instance, many NoSQL databases require specific application interfaces \nfor data access. Hence there is a need to consider the integration of some other neces-\nsary tools for data access.\n\nAvailability and consistency requirement\n\nIf a distributed system is needed, then CAP theorem states that consistency and avail-\nability cannot be both guaranteed in the presence of network partition (i.e. when there is \na break in the network). In such a scenario, consistency is often traded off for availability \nto ensure that requests can always be processed.\n\nWorkload profile required\n\nPlatform as a service deployment may be appropriate for a spike load profile platform. \nIf platform distribution can be deployed on Infrastructure as a service cloud, then this \noption may be preferred as users will need to pay only when processing. On-premise \n\n\n\nPage 10 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\ndeployment may be considered for predictable or consistent loads. But if workloads are \nmixed (i.e. consistent flows or spikes), a combination of cloud and on-premise approach \nmay be considered so as to give room for easy integration of web-based services or soft-\nware and access to critical functions on the go.\n\nLatency requirement\n\nIf a minimal delay or low latency is required, key-value stores may be considered or bet-\nter still, an in-memory solution which allows the process of large datasets in real-time is \nrequired in order to optimize the data loading procedure.\n\nThe tools and technologies for big data stream analysis can be broadly categorized into \ntwo, which are open source and proprietary solutions. These are listed in Tables 6 and 7.\n\nThe selection of big data streaming tools and technologies should be based on the impor-\ntance of each factor earlier mentioned in this section. Proprietary solutions may not be eas-\nily available because of pricing and licensing issues. While open source supports innovation \nand development at a large scale, careful selection must be made especially when choosing \na recent technology still in production due to limited maturity and lack of support from \nacademic researchers or developer communities. In addition, open source solutions may \nlead to outdating and modification challenges [27]. Moreover, the selection of whether pro-\nprietary or open source or combination of both should depend on the problem to address, \nthe understanding of the true costs, and benefits of both open and proprietary solutions.\n\nTable 6 Open source tools and technologies for big data stream analysis\n\nTools and technology Article\n\nBlockMon [83]\n\nNoSQL [4, 84–86]\n\nSpark streaming [67, 87–91]\n\nApache storm [68, 85, 86, 92–97]\n\nKafka [85, 91, 95, 96, 98]\n\nYahoo! S4 [6, 45, 87, 99]\n\nApache Samza [46, 67, 100]\n\nPhoton [67, 101]\n\nApache Aurora [67, 102]\n\nMavEStream [103]\n\nEsperTech [104, 105]\n\nRedis [106]\n\nC-SPARQL [107, 108]\n\nSAMOA [56, 78, 109]\n\nCQELS [108, 110, 111]\n\nETALIS [112]\n\nXSEQ [73]\n\nApache Kylin [113]\n\nSplunk stream [114]\n\n\n\nPage 11 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nResearch Question 2: What methods and techniques are used in analysing big data \n\nstreams?\n\nGiven the real-time nature, velocity and volume of social media streams, the clus-\ntering algorithms that are applied on streaming data must be highly scalable and \nefficient. Also, the dynamic nature of data makes it difficult to know the required or \ndesirable number of clusters in advance. This renders partitioning clustering tech-\nniques (such as k-median, k-means and k-medoid) or expectation-maximization \n(EM) algorithms-based approaches unsuitable for analysing real-time social media \ndata because they require prior knowledge of clusters in advance. In addition, due \nto concept drift inherent in social media streams, scalable graph partitioning algo-\nrithms are not also suitable because of their tendency towards balanced partitioning. \nSocial media streams must be analysed dynamically in order to provide decisions at \nany given time within a limited space and time window [28–30].\n\nDensity-based clustering algorithm (such as DenStream, OpticStream, Flock-\nStream, Exclusive and Complete Clustering) unlike partitioning algorithms does not \nrequire apriori number of clusters in advance and can detect outliers [31]. However, \nthe issue with density-based clustering algorithms is that most of them except for few \nlike HDDStream, PreDeCon-Stream and PKS-Stream (which are memory intensive) \nperform less efficiently in the face of high dimensional data and as a result are not \nsuitable for analyzing social media streams [32].\n\nThreshold-based techniques, hierarchical clustering, and incremental clustering \nor online clustering are more relevant to social media analysis. Several online thresh-\nold-based stream clustering approaches or incremental clustering approaches such as \nMarkov Random Field [33, 34], Online Spherical K-means [35], and Condensed Clusters \n[36] have been adopted. Incremental approaches are suitable for continuously generated \ndata grouping by setting a maximum similarity threshold between the incoming stream \n\nTable 7 Proprietary tools and technologies for big data stream analysis\n\nTools and technology Article\n\nCodeBlue [115]\n\nAnodot [116]\n\nCloudet [117]\n\nSentiment brand monitoring [118]\n\nNumenta [119]\n\nElastic streaming processing engine [120]\n\nMicrosoft azure stream analytics [121]\n\nIBM InfoSphere streams [8, 122]\n\nGoogle MillWheel [123]\n\nArtemis [124]\n\nWSO2 analytics [125]\n\nMicrosoft StreamInsight [126]\n\nTIBCO StreamBase [127]\n\nStriim [128]\n\nKyvos insights [129]\n\nAtScale [130, 131]\n\nLambda architecture [57]\n\n\n\nPage 12 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nand the existing clusters. Much work has been done in improving the efficiency of online \nclustering algorithms, however, little research efforts have been directed to threshold \nand fragmentation issues. Incremental algorithm threshold setting should employ adap-\ntive approach instead of relying on static values [37, 38]. Some of the methods and tech-\nniques that have been employed in analysing big data streams are outlined in Table 8.\n\nTable 8 Methods and techniques for big data stream analysis\n\nMethods and techniques Article\n\nSPADE [132]\n\nLocally supervised metric learning (LSML) [133]\n\nKTS [106]\n\nMultinomial latent dirichlet allocation [106]\n\nVoltage clustering algorithm [106]\n\nLocality sensitive hashing (LSH) [134]\n\nUser profile vector update algorithm [134]\n\nTag assignment stream clustering (TASC) [134]\n\nStreamMap [117]\n\nDensity cognition [117]\n\nQRS detection algorithm [87]\n\nForward chaining rule [110]\n\nStream [135]\n\nCluStream [136, 137]\n\nHPClustering [138]\n\nDenStream [139]\n\nD-Stream [140]\n\nACluStream [141]\n\nDCStream [142]\n\nP-Stream [143]\n\nADStream [144]\n\nContinuous query processing (CQR) [145]\n\nFPSPAN-growth [146]\n\nOutlier method for cloud computing algorithm (OMCA) [147]\n\nMulti-query optimization strategy (MQOS) [148]\n\nParallel K-means clustering [72]\n\nVisibly push down automata (VPA) [73]\n\nIncremental MI outlier detection algorithm (Inc I-MLOF) [149]\n\nAdaptive windowing based online ensemble (AWOE) [74]\n\nDynamic prime-number based security verification [84]\n\nK-anonymity, I-diversity, t-closeness [90]\n\nSingular spectrum matrix completion (SS-MC) [76]\n\nTemporal fuzzy concept analysis [96]\n\nECM-sketch [77]\n\nNearest neighbour [91]\n\nMarkov chains [91]\n\nBlock-QuickSort-AdjacentJobMatch [86]\n\nBlock-QuickSort-OverlapReplicat",
      "metadata_storage_size": 1344318,
      "metadata_storage_path": "aHR0cHM6Ly9qdHJhaW5pbmdjYXRhbG9nc3RvcmFnZS5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL3M0MDUzNy0wMTktMDIxMC03LnBkZg2",
      "metadata_author": "Taiwo Kolajo ",
      "metadata_title": "Big data stream analysis: a systematic literature review",
      "metadata_creation_date": "2019-06-04T14:40:29Z",
      "people": [
        "Taiwo Kolajo",
        "Olawande Daramola3",
        "Ayodele Adebiyi",
        "Kolajo",
        "30Kolajo",
        "Kafka",
        "Moore",
        "cally",
        "niques",
        "Apache Kylin",
        "Artemis",
        "Striim",
        "Markov"
      ],
      "organizations": [
        "IEEE",
        "ACM",
        "SpringerLink",
        "Elsevier",
        "The Author(s",
        "Information Sciences",
        "Covenant University",
        "ben",
        "big data stream analysis",
        "clickstream",
        "stream computing",
        "NYMEX",
        "envi",
        "Big data",
        "analytics",
        "Inter",
        "national Data Cooperation",
        "IDC",
        "Scopus",
        "Science Direct",
        "ScienceDirect2",
        "ScienceDirect",
        "due",
        "EBSCOhost",
        "resea archg ate",
        "Photon",
        "EsperTech",
        "clus",
        "clusters",
        "Kyvos"
      ],
      "locations": [
        "Ota",
        "Nigeria",
        "stream",
        "Store",
        "uted",
        "world",
        "cor",
        "OR",
        "Platform",
        "stores",
        "SAMOA",
        "Anodot",
        "CluStream",
        "DenStream",
        "D-Stream",
        "P-Stream",
        "MI",
        "Markov"
      ],
      "keyphrases": [
        "Creative Commons Attribution 4.0 International License",
        "effective resource allocation strategy",
        "existing data mining tools",
        "big data stream tools",
        "data stream computing mode",
        "big data streaming tools",
        "big data streaming ana",
        "Big data stream analysis",
        "big data stream computing",
        "big data streams analysis",
        "big data batch computing",
        "Creative Commons license",
        "big data computing",
        "big data tool",
        "J Big Data",
        "several computational challenges",
        "process- ing requirements",
        "inherent dynamic characteristics",
        "Three major databases",
        "first search string",
        "standard benchmark dataset",
        "creat iveco mmons",
        "load balancing issues",
        "nificant research efforts",
        "technologies Open Access",
        "SURVEY PAPER Kolajo",
        "empirical analysis",
        "real-time analysis",
        "future computing",
        "data sources",
        "parallelization issues",
        "research questions",
        "literature review",
        "Olawande Daramola3",
        "Ayodele Adebiyi",
        "two types",
        "huge amount",
        "methodical approach",
        "global view",
        "exclusion criteria",
        "preprocessing stage",
        "iterative jobs",
        "scalable frameworks",
        "growing size",
        "unrestricted use",
        "appropriate credit",
        "original author",
        "Information Sciences",
        "Covenant University",
        "Full list",
        "author information",
        "doi.org",
        "orcid.org",
        "information technology",
        "large volume",
        "great velocity",
        "systematic review",
        "initial 2295 papers",
        "Taiwo Kolajo",
        "47 papers",
        "Introduction",
        "Advances",
        "high-velocity",
        "ability",
        "nature",
        "terms",
        "variety",
        "veracity",
        "volatility",
        "value",
        "new",
        "trend",
        "Abstract",
        "fact",
        "number",
        "applications",
        "methods",
        "techniques",
        "rigorous",
        "comparisons",
        "Scopus",
        "ScienceDirect",
        "EBSCO",
        "journals",
        "conferences",
        "entities",
        "IEEE",
        "ACM",
        "SpringerLink",
        "Elsevier",
        "inclusion",
        "study",
        "privacy",
        "attention",
        "key",
        "features",
        "lytics",
        "conclusion",
        "algorithms",
        "complexity",
        "article",
        "distribution",
        "reproduction",
        "medium",
        "changes",
        "Correspondence",
        "fulokoja",
        "1 Department",
        "Computer",
        "Ota",
        "Nigeria",
        "creativecommons",
        "licenses",
        "crossmark",
        "crossref",
        "Page",
        "30Kolajo",
        "scalable com- puting platforms",
        "big data streaming analytics",
        "big data stream analysis",
        "Big data batch processing",
        "Streaming processing frameworks",
        "stream processing paradigms",
        "Stream processing solutions",
        "data flow graph",
        "real-time application scenarios",
        "real-time, high volume",
        "time data analysis",
        "real-time data stream",
        "batch computing",
        "stream computing",
        "stream processor",
        "high-velocity flow",
        "incoming data",
        "data generating",
        "market data",
        "real-time sources",
        "changing conditions",
        "common understanding",
        "ben- efit",
        "scientific community",
        "key issues",
        "detailed evaluation",
        "massive amount",
        "high- velocity",
        "multiple sources",
        "low latency",
        "new sources",
        "location services",
        "mobile devices",
        "sensor pervasiveness",
        "fundamental assumption",
        "potential value",
        "parallel architectures",
        "decision-making process",
        "static questions",
        "continuous queries",
        "diverse sources",
        "sideration availability",
        "fault tolerance",
        "infinite tuple",
        "actionable results",
        "interconnected streams",
        "related work",
        "research works",
        "Research method",
        "crucial need",
        "real contrasts",
        "ming paradigm",
        "Discussion” section",
        "Result” section",
        "addition",
        "output",
        "low-latency",
        "seconds",
        "demand",
        "reason",
        "huge",
        "organisations",
        "businesses",
        "paper",
        "purpose",
        "overview",
        "findings",
        "implications",
        "practice",
        "update",
        "state",
        "areas",
        "challenges",
        "rest",
        "Background",
        "information",
        "Limitation",
        "Conclusion",
        "ubiquity",
        "Internet",
        "Things",
        "Sensors",
        "freshness",
        "Storm",
        "Kafka",
        "Spark",
        "Table",
        "motion",
        "essence",
        "fly",
        "scalability",
        "assimilation",
        "production",
        "operations",
        "Fig.",
        "Dimension Batch processing Streaming processing Input Data chunks",
        "Hardware Multiple CPUs Typical single limited amount",
        "big data stream computing environments",
        "big data streaming analysis",
        "domain Web mining",
        "streaming analytics system",
        "big data streams",
        "Data flow graph",
        "high data rates",
        "data processing node",
        "memory Storage Store",
        "new incoming data",
        "ble efficient operations",
        "typical example",
        "multiple rounds",
        "Such processing",
        "single pass",
        "new data",
        "operator stream",
        "missing data",
        "data normalization",
        "distributed system",
        "High fault-tolerance",
        "life-critical systems",
        "data tuples",
        "Data size",
        "new information",
        "new tuple",
        "new trends",
        "model predictions",
        "feature extraction",
        "external feeds",
        "non-trivial portion",
        "traffic monitoring",
        "sensor networks",
        "Key issues",
        "useful knowledge",
        "current happenings",
        "speedy manner",
        "organisa- tions",
        "load balancing",
        "privacy issues",
        "exponential growth",
        "computer resources",
        "research efforts",
        "effective resource",
        "cation strategy",
        "small number",
        "different datasets",
        "component failure",
        "time-sensitive processes",
        "security threats",
        "data Time",
        "latest tuples",
        "analytic applications",
        "sliding window",
        "milliseconds Applications",
        "logical container",
        "main challenges",
        "Fault‑tolerance",
        "integration technique",
        "results",
        "operators",
        "models",
        "access",
        "idea",
        "duplicates",
        "parsing",
        "windows",
        "Table 1",
        "Comparison",
        "updates",
        "advance",
        "passes",
        "figure",
        "NYMEX",
        "need",
        "order",
        "problems",
        "performance",
        "timeliness",
        "consistency",
        "heterogeneity",
        "incompleteness",
        "accuracy",
        "The",
        "way",
        "processors",
        "Moore",
        "law",
        "fore",
        "plexity",
        "views",
        "interruption",
        "big data stream computing system",
        "organisational resource management specifi",
        "big data stream dataset",
        "Big data stream analytics",
        "good multiple instances replication",
        "big data analytics literature",
        "big data analytics methods",
        "good system structure",
        "distributing envi- ronment",
        "effective tech- niques",
        "Big data streams",
        "competent data presentation",
        "national Data Cooperation",
        "big data analysis",
        "data streams changes",
        "partial data streams",
        "previous research efforts",
        "big data streaming",
        "big data challenges",
        "systematic literature review",
        "High throughput Decision",
        "big threat",
        "streaming analytics",
        "streaming” analytics",
        "streaming data",
        "natural disaster",
        "continuous processing",
        "local views",
        "accessi- bility",
        "meaningful content",
        "Load balancing",
        "load shedding",
        "peak loads",
        "average load",
        "global centre",
        "entire information",
        "needs protection",
        "main objectives",
        "future observations",
        "processing algorithms",
        "stream-specific requirements",
        "various tools",
        "research focus",
        "business values",
        "high consistency",
        "high accuracy",
        "main challenge",
        "communicating nodes",
        "individual privacy",
        "ent characteristics",
        "Related work",
        "The study",
        "reviews",
        "fraud",
        "tures",
        "platforms",
        "architecture",
        "minimal",
        "latency",
        "stability",
        "Heterogeneity",
        "semantics",
        "granularity",
        "correlate",
        "real-time",
        "diversity",
        "hierarchy",
        "resources",
        "variance",
        "result",
        "respect",
        "sub-graph",
        "replicas",
        "portion",
        "issue",
        "opportunities",
        "IDC",
        "half",
        "volume",
        "velocity",
        "variability",
        "consideration",
        "section",
        "technologies",
        "Authors",
        "definitions",
        "types",
        "technology",
        "cally",
        "four big data streaming tools",
        "big data stream analysis tools",
        "big data stream literature review",
        "authoritative, full-text scientific, technical",
        "data stream analysis reviews",
        "big data stream framework",
        "big data stream processing",
        "big data stream algorithms",
        "big data stream analytics",
        "three standard database indexes",
        "big data stream technologies",
        "big data analytics",
        "machine learning algorithms",
        "full-text data- bases",
        "large data- base",
        "smart intuitive functionality",
        "electronic journal service",
        "big data technologies",
        "academic journal articles",
        "leading information solution",
        "systematic mapping method",
        "following research questions",
        "good search string",
        "Data sources",
        "four categories",
        "peer-reviewed literature",
        "citation database",
        "standard databases",
        "information professionals",
        "bibliographic database",
        "empirical research",
        "same vein",
        "particular focus",
        "anomaly detection",
        "tech- niques",
        "clear explanation",
        "Relevant publications",
        "Science Direct",
        "hensive overview",
        "research output",
        "social sciences",
        "largest abstract",
        "open access",
        "health publications",
        "14 million publications",
        "Life Sciences",
        "Physical Sciences",
        "Health Sciences",
        "wide range",
        "academic researchers",
        "application areas",
        "healthcare profes",
        "evaluation techniques",
        "peer-reviewed journals",
        "3800 journals",
        "status",
        "survey",
        "scope",
        "comprehensive",
        "differences",
        "concept",
        "capabilities",
        "limitations",
        "strengths",
        "benchmarks",
        "population",
        "son",
        "intervention",
        "outcome",
        "keywords",
        "searches",
        "EBSCOhost",
        "rich",
        "abstracts",
        "citations",
        "36,377 titles",
        "11,678 publishers",
        "world",
        "arts",
        "humanities",
        "students",
        "teachers",
        "35,000 books",
        "Engineering",
        "porate",
        "Third Search string refinement result",
        "free online professional network",
        "First search string result",
        "Second search string result",
        "Scopus ScienceDirect EBSCOhost Total",
        "major academic publishers",
        "nine (9) search strings",
        "high impact journals",
        "111 seemingly relevant papers",
        "Inclusion criteria Papers",
        "Table 5 Final Selection",
        "Further refinement",
        "Data retrieval",
        "easy analysis",
        "high-quality e-books",
        "100 million publications",
        "secondary source",
        "rich databases",
        "Boolean ‘OR",
        "2295 arti- cles",
        "three databases",
        "computer science",
        "subject domain",
        "quick overview",
        "Microsoft Excel",
        "three categories",
        "black colour",
        "similar investigations",
        "following categories",
        "primary study",
        "source language",
        "relevant” papers",
        "11 million researchers",
        "year range",
        "total number",
        "peer-reviewed conferences",
        "recent papers",
        "16,711 journals",
        "Table 2",
        "Table 3",
        "Table 4",
        "1989 papers",
        "315 papers",
        "111 papers",
        "45 papers",
        "18 papers",
        "magazine",
        "titles",
        "60,000 audiobooks",
        "iv.",
        "ResearchGate4",
        "scientists",
        "collaborators",
        "authors",
        "subscription",
        "set",
        "reseaarchgate",
        "sources",
        "interest",
        "stage",
        "PDF",
        "introduction",
        "green",
        "red",
        "colours",
        "end",
        "workshops",
        "technical",
        "symposium",
        "case",
        "part",
        "English",
        "contributions",
        "900,000",
        "1500",
        "alternative big data streaming solutions",
        "effective data management decisions",
        "spike load profile platform",
        "Big data stream platforms",
        "Streaming data sources",
        "many NoSQL databases",
        "specific application interfaces",
        "data loading procedure",
        "enterprise technology vendors",
        "open source community",
        "open source solutions",
        "Workload profile",
        "proprietary solutions",
        "stream applications",
        "high-velocity data",
        "data stores",
        "recent technology",
        "Such platforms",
        "platform distribution",
        "Data access",
        "Several tools",
        "sary tools",
        "single flow",
        "growing demand",
        "pro- jection",
        "different structures",
        "different ways",
        "CAP theorem",
        "consistent loads",
        "consistent flows",
        "web-based services",
        "soft- ware",
        "critical functions",
        "Latency requirement",
        "minimal delay",
        "key-value stores",
        "memory solution",
        "licensing issues",
        "limited maturity",
        "developer communities",
        "modification challenges",
        "large datasets",
        "large scale",
        "network partition",
        "service deployment",
        "service cloud",
        "premise approach",
        "easy integration",
        "consistency requirement",
        "careful selection",
        "serialization technologies",
        "execution",
        "functionalities",
        "response",
        "factors",
        "Shape",
        "capturing",
        "storing",
        "rep",
        "instance",
        "room",
        "flexibility",
        "storage",
        "users",
        "Availability",
        "presence",
        "break",
        "scenario",
        "requests",
        "Infrastructure",
        "option",
        "processing",
        "predictable",
        "workloads",
        "spikes",
        "combination",
        "go",
        "Tables",
        "pricing",
        "innovation",
        "development",
        "lack",
        "support",
        "outdating",
        "problem",
        "big data stream analysis Tools",
        "Multinomial latent dirichlet allocation",
        "Elastic streaming processing engine",
        "real-time social media data",
        "Microsoft azure stream analytics",
        "old-based stream clustering approaches",
        "Incremental algorithm threshold setting",
        "Table 6 Open source tools",
        "social media analysis",
        "social media streams",
        "high dimensional data",
        "Markov Random Field",
        "Sentiment brand monitoring",
        "IBM InfoSphere streams",
        "Density-based clustering algorithm",
        "Voltage clustering algorithm",
        "maximum similarity threshold",
        "little research efforts",
        "incremental clustering approaches",
        "Online Spherical K-means",
        "Incremental approaches",
        "Splunk stream",
        "incoming stream",
        "data grouping",
        "Proprietary tools",
        "WSO2 analytics",
        "Microsoft StreamInsight",
        "clustering algorithms",
        "Spark streaming",
        "Complete Clustering",
        "hierarchical clustering",
        "online clustering",
        "Research Question",
        "true costs",
        "Apache storm",
        "Apache Samza",
        "Apache Aurora",
        "Apache Kylin",
        "dynamic nature",
        "desirable number",
        "prior knowledge",
        "scalable graph",
        "limited space",
        "apriori number",
        "Google MillWheel",
        "TIBCO StreamBase",
        "Kyvos insights",
        "Lambda architecture",
        "Much work",
        "fragmentation issues",
        "tive approach",
        "static values",
        "metric learning",
        "partitioning algorithms",
        "technology Article",
        "balanced partitioning",
        "time window",
        "Condensed Clusters",
        "existing clusters",
        "Threshold-based techniques",
        "Table 8 Methods",
        "Table 7",
        "understanding",
        "benefits",
        "BlockMon",
        "NoSQL",
        "Photon",
        "MavEStream",
        "EsperTech",
        "Redis",
        "C-SPARQL",
        "SAMOA",
        "CQELS",
        "ETALIS",
        "XSEQ",
        "k-median",
        "k-medoid",
        "expectation-maximization",
        "tendency",
        "decisions",
        "DenStream",
        "OpticStream",
        "Exclusive",
        "outliers",
        "HDDStream",
        "PreDeCon-Stream",
        "PKS-Stream",
        "memory",
        "face",
        "CodeBlue",
        "Anodot",
        "Cloudet",
        "Numenta",
        "Artemis",
        "Striim",
        "AtScale",
        "efficiency",
        "SPADE",
        "LSML",
        "KTS",
        "Dynamic prime-number based security verification",
        "User profile vector update algorithm",
        "Incremental MI outlier detection algorithm",
        "Singular spectrum matrix completion",
        "Temporal fuzzy concept analysis",
        "Tag assignment stream clustering",
        "QRS detection algorithm",
        "cloud computing algorithm",
        "Parallel K-means clustering",
        "Locality sensitive hashing",
        "Forward chaining rule",
        "Continuous query processing",
        "Multi-query optimization strategy",
        "Outlier method",
        "Density cognition",
        "Inc I-MLOF",
        "Adaptive windowing",
        "online ensemble",
        "Nearest neighbour",
        "Markov chains",
        "LSH",
        "TASC",
        "StreamMap",
        "CluStream",
        "HPClustering",
        "D-Stream",
        "DCStream",
        "P-Stream",
        "ADStream",
        "CQR",
        "FPSPAN-growth",
        "OMCA",
        "MQOS",
        "automata",
        "VPA",
        "AWOE",
        "K-anonymity",
        "closeness",
        "ECM-sketch",
        "Block-QuickSort-AdjacentJobMatch",
        "Block-QuickSort-OverlapReplicat"
      ],
      "merged_content": "\nBig data stream analysis: a systematic \nliterature review\nTaiwo Kolajo1,2* , Olawande Daramola3  and Ayodele Adebiyi1,4 \n\nIntroduction\nAdvances in information technology have facilitated large volume, high-velocity of data, \nand the ability to store data continuously leading to several computational challenges. \nDue to the nature of big data in terms of volume, velocity, variety, variability, veracity, \nvolatility, and value [1] that are being generated recently, big data computing is a new \ntrend for future computing.\n\nBig data computing can be generally categorized into two types based on the process-\ning requirements, which are big data batch computing and big data stream computing \n\nAbstract \n\nRecently, big data streams have become ubiquitous due to the fact that a number of \napplications generate a huge amount of data at a great velocity. This made it difficult \nfor existing data mining tools, technologies, methods, and techniques to be applied \ndirectly on big data streams due to the inherent dynamic characteristics of big data. In \nthis paper, a systematic review of big data streams analysis which employed a rigorous \nand methodical approach to look at the trends of big data stream tools and technolo-\ngies as well as methods and techniques employed in analysing big data streams. It \nprovides a global view of big data stream tools and technologies and its comparisons. \nThree major databases, Scopus, ScienceDirect and EBSCO, which indexes journals and \nconferences that are promoted by entities such as IEEE, ACM, SpringerLink, and Elsevier \nwere explored as data sources. Out of the initial 2295 papers that resulted from the \nfirst search string, 47 papers were found to be relevant to our research questions after \nimplementing the inclusion and exclusion criteria. The study found that scalability, \nprivacy and load balancing issues as well as empirical analysis of big data streams and \ntechnologies are still open for further research efforts. We also found that although, sig-\nnificant research efforts have been directed to real-time analysis of big data stream not \nmuch attention has been given to the preprocessing stage of big data streams. Only a \nfew big data streaming tools and technologies can do all of the batch, streaming, and \niterative jobs; there seems to be no big data tool and technology that offers all the key \nfeatures required for now and standard benchmark dataset for big data streaming ana-\nlytics has not been widely adopted. In conclusion, it was recommended that research \nefforts should be geared towards developing scalable frameworks and algorithms that \nwill accommodate data stream computing mode, effective resource allocation strategy \nand parallelization issues to cope with the ever-growing size and complexity of data.\n\nKeywords: Big data stream analysis, Stream computing, Big data streaming tools and \ntechnologies\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nKolajo et al. J Big Data            (2019) 6:47  \nhttps://doi.org/10.1186/s40537-019-0210-7\n\n*Correspondence:   \ntaiwo.kolajo@stu.cu.edu.ng; \ntaiwo.kolajo@fulokoja.edu.ng \n1 Department of Computer \nand Information Sciences, \nCovenant University, Ota, \nNigeria\nFull list of author information \nis available at the end of the \narticle\n\nhttp://orcid.org/0000-0001-6780-2495\nhttp://orcid.org/0000-0001-6340-078X\nhttp://orcid.org/0000-0002-3114-6315\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-019-0210-7&domain=pdf\n\n\nPage 2 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\n[2]. Big data batch processing is not sufficient when it comes to analysing real-time \napplication scenarios. Most of the data generated in a real-time data stream need real-\ntime data analysis. In addition, the output must be generated with low-latency and any \nincoming data must be reflected in the newly generated output within seconds. This \nnecessitates big data stream analysis [3].\n\nThe demand for stream processing is increasing. The reason being not only that huge \nvolume of data need to be processed but that data must be speedily processed so that \norganisations or businesses can react to changing conditions in real-time.\n\nThis paper presents a systematic review of big data stream analysis. The purpose is to \npresent an overview of research works, findings, as well as implications for research and \npractice. This is necessary to (1) provide an update about the state of research, (2) iden-\ntify areas that are well researched, (3) showcase areas that are lacking and need further \nresearch, and (4) build a common understanding of the challenges that exist for the ben-\nefit of the scientific community.\n\nThe rest of the paper is organized as follows: “Background and related work” section \nprovides information on stream computing and big data stream analysis and the key \nissues involved in it and presents a review on big data streaming analytics. In “Research \nmethod” section, the adopted research methodology is discussed, while “Result” section \npresents the findings of the study. “Discussion” section presents a detailed evaluation \nperformed on big data stream analysis, “Limitation of the review” section highlights the \nlimitations of the study, while “Conclusion and further work” concludes the paper.\n\nBackground and related work\nStream computing\n\nStream computing refers to the processing of massive amount of data generated at high-\nvelocity from multiple sources with low latency in real-time. It is a new paradigm neces-\nsitated because of new sources of data generating scenarios which include ubiquity of \nlocation services, mobile devices, and sensor pervasiveness [4]. It can be applied to the \nhigh-velocity flow of data from real-time sources such as the Internet of Things, Sensors, \nmarket data, mobile, and clickstream.\n\nThe fundamental assumption of this paradigm is that the potential value of data lies in \nits freshness. As a result, data are analysed as soon as they arrive in a stream to produce \nresult as opposed to what obtains in batch computing where data are first stored before \nthey are analysed. There is a crucial need for parallel architectures and scalable com-\nputing platforms [5]. With stream computing, organisations can analyse and respond in \nreal-time to rapidly changing data. Streaming processing frameworks include Storm, S4, \nKafka, and Spark [6–8]. The real contrasts between the batch processing and the stream \nprocessing paradigms are outlined in Table 1.\n\nIncorporating streaming data into decision-making process necessitates a program-\nming paradigm called stream computing. With stream computing, fairly static questions \ncan be evaluated on data in motion (i.e. real-time data) continuously [9].\n\nBig data stream analysis\n\nThe essence of big data streaming analytics is the need to analyse and respond to real-\ntime streaming data using continuous queries so that it is possible to continuously \n\n\n\nPage 3 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nperform analysis on the fly within the stream. Stream processing solutions must be \nable to handle a real-time, high volume of data from diverse sources putting into con-\nsideration availability, scalability and fault tolerance. Big data stream analysis involves \nassimilation of data as an infinite tuple, analysis and production of actionable results \nusually in a form of stream [10].\n\nIn a stream processor, applications are represented as data flow graph made up of \noperations and interconnected streams as depicted in Fig. 1. In a streaming analytics \nsystem, application comes in a form of continuous queries, data are ingested continu-\nously, analysed and correlated, and stream of results are generated. Streaming analytic \napplications is usually a set of operators connected by streams. Streaming analytics \nsystems must be able to identify new information, incrementally build models and \naccess whether the new incoming data deviate from model predictions [9].\n\nThe idea of streaming analytics is that each of the received data tuples is processed \nin the data processing node. Such processing includes removing duplicates, filling \nmissing data, data normalization, parsing, feature extraction, which are typically done \nin a single pass due to the high data rates of external feeds. When a new tuple arrives, \nthis node is triggered, and it expels tuples older than the time specified in the sliding \nwindow (sliding window is a typical example of windows used in stream computing \nwhich keeps only the latest tuples up to the time specified in the windows). A window \n\nTable 1 Comparison between batch processing and streaming processing [82]\n\nDimension Batch processing Streaming processing\n\nInput Data chunks Stream of new data or updates\n\nData size Known and finite Infinite or unknown in advance\n\nHardware Multiple CPUs Typical single limited amount of memory\n\nStorage Store Not store or store non-trivial portion in memory\n\nProcessing Processed in multiple rounds A single or few passes over data\n\nTime Much longer A few seconds or even milliseconds\n\nApplications Widely adopted in almost every domain Web mining, traffic monitoring, sensor networks\n\nFig. 1 Data flow graph of a stream processor. The figure shows how applications (made up of operations and \ninterconnected streams) are represented as data flow graph in a stream processor [10]\n\n operator stream NYMEX \n\n\n\nPage 4 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nis referred to as a logical container for data tuples received. It defines how frequently \ndata is refreshed in the container as well as when data processing is triggered [4].\n\nKey issues in big data stream analysis\n\nBig data stream analysis is relevant when there is a need to obtain useful knowledge \nfrom current happenings in an efficient and speedy manner in order to enable organisa-\ntions to quickly react to problems, or detect new trends which can help improve their \nperformance. However, there are some challenges such as scalability, integration, fault-\ntolerance, timeliness, consistency, heterogeneity and incompleteness, load balancing, \nprivacy issues, and accuracy [3, 11–18] which arises from the nature of big data streams \nthat must be dealt with.\n\nScalability\n\nOne of the main challenges in big data streaming analysis is the issue of scalability. The \nbig data stream is experiencing exponential growth in a way much faster than computer \nresources. The processors follow Moore’s law, but the size of data is exploding. There-\nfore, research efforts should be geared towards developing scalable frameworks and \nalgorithms that will accommodate data stream computing mode, effective resource allo-\ncation strategy and parallelization issues to cope with the ever-growing size and com-\nplexity of data.\n\nIntegration\n\nBuilding a distributed system where each node has a view of the data flow, that is, every \nnode performing analysis with a small number of sources, then aggregating these views \nto build a global view is non-trivial. An integration technique should be designed to ena-\nble efficient operations across different datasets.\n\nFault‑tolerance\n\nHigh fault-tolerance is required in life-critical systems. As data is real-time and infinite \nin big data stream computing environments, a good scalable high fault-tolerance strat-\negy is required that allows an application to continue working despite component failure \nwithout interruption.\n\nTimeliness\n\nTime is of the essence for time-sensitive processes such as mitigating security threats, \nthwarting fraud, or responding to a natural disaster. There is a need for scalable architec-\ntures or platforms that will enable continuous processing of data streams which can be \nused to maximize the timeliness of data. The main challenge is implementing a distrib-\nuted architecture that will aggregate local views of data into global view with minimal \nlatency between communicating nodes.\n\nConsistency\n\nAchieving high consistency (i.e. stability) in big data stream computing environments is \nnon-trivial as it is difficult to determine which data are needed and which nodes should \nbe consistent. Hence a good system structure is required.\n\n\n\nPage 5 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nHeterogeneity and incompleteness\n\nBig data streams are heterogeneous in structure, organisations, semantics, accessi-\nbility and granularity. The challenge here is how to handle an always ever-increas-\ning data, extract meaningful content out of it, aggregate and correlate streaming \ndata from multiple sources in real-time. A competent data presentation should be \ndesigned to reflect the structure, diversity and hierarchy of the streaming data.\n\nLoad balancing\n\nA big data stream computing system is expected to be self-adaptive to data streams \nchanges and avoid load shedding. This is challenging as dedicating resources to cover \npeak loads 24/7 is impossible and load shedding is not feasible when the variance \nbetween the average load and the peak load is high. As a result, a distributing envi-\nronment that automatically streams partial data streams to a global centre when local \nresources become insufficient is required.\n\nHigh throughput\n\nDecision with respect to identifying the sub-graph that needs replication, how many \nreplicas are needed and the portion of the data stream to assign to each replica is an \nissue in big data stream computing environment. There is a need for good multiple \ninstances replication if high throughput is to be achieved.\n\nPrivacy\n\nBig data stream analytics created opportunities for analyzing a huge amount of data \nin real-time but also created a big threat to individual privacy. According to the Inter-\nnational Data Cooperation (IDC), not more than half of the entire information that \nneeds protection is effectively protected. The main challenge is proposing techniques \nfor protecting a big data stream dataset before its analysis.\n\nAccuracy\n\nOne of the main objectives of big data stream analysis is to develop effective tech-\nniques that can accurately predict future observations. However, as a result of inher-\nent characteristics of big data such as volume, velocity, variety, variability, veracity, \nvolatility, and value, big data analysis strongly constrain processing algorithms spatio-\ntemporally and hence stream-specific requirements must be taken into consideration \nto ensure high accuracy.\n\nRelated work\n\nThis section discusses some of the previous research efforts that relate to big data \nstreaming analytics.\n\nThe work of [13] presented a review of various tools, technologies and methods \nfor big data analytics by categorizing big data analytics literature according to their \nresearch focus. This paper is different in that it presents a systematic literature review \nthat focused on big data “streaming” analytics.\n\n\n\nPage 6 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nAuthors in [19] presented a systematic review of big data analytics in e-commerce. The \nstudy explored characteristics, definitions, business values, types and challenges of big \ndata analytics in the e-commerce landscape. Likewise, [20] conducted a study that is cen-\ntred on big data analytics in technology and organisational resource management specifi-\ncally focusing on reviews that present big data challenges and big data analytics methods. \nAlthough they are systematic reviews, the focus is not, particularly on big data streaming.\n\nAuthors in [21] presented the status of empirical research and application areas in big \ndata by employing a systematic mapping method. In the same vein, authors in [22] also \nconducted a survey on big data technologies and machine learning algorithms with a \nparticular focus on anomaly detection. A systematic review of literature which aims to \ndetermine the scope, application, and challenges of big data analytics in healthcare was \npresented by [23]. The work of [2] presented a review of four big data streaming tools \nand technologies. While the study conducted in this paper provided a comprehensive \nreview of not only big data streaming tools and technologies but also methods and tech-\nniques employed in analyzing big data streams. In addition, authors [2] did not provide a \nclear explanation of the methodical approach for selecting the reviewed papers.\n\nResearch method\nThe study was grounded in a systematic literature review of tools and technologies \nwith methods and techniques used in analysing big data streams by adopting [24, 25] as \nmodels.\n\nResearch question\n\nThe study tries to answer the following research questions:\n\nResearch Question 1: What are the tools and technologies employed for big data \nstream analysis?\nResearch Question 2: What methods and techniques are used in analysing big data \nstreams?\nResearch Question 3: What do these tools and technologies have in common and \ntheir differences in terms of concept, purpose and capabilities?\nResearch Question 4: What are the limitations and strengths of these tools and tech-\nnologies?\nResearch Question 5: What are the evaluation techniques or benchmarks used for \nevaluating big data streaming tools and technology?\n\nSearch string\n\nCreating a good search string requires structuring in terms of population, compari-\nson, intervention and outcome [24]. Relevant publications were identified by forming \na search string that combined keywords driven by the research questions earlier stated. \nThe searches were conducted by employing three standard database indexes, which are \nScopus, Science Direct and EBSCOhost. The search string is “big data stream analysis” \nOR “big data stream technologies” OR “big data stream framework” OR “big data stream \nalgorithms” OR “big data stream analysis tools” OR “big data stream processing” OR “big \n\n\n\nPage 7 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\ndata stream analysis reviews” OR “big data stream literature review” OR “big data stream \nanalytics”.\n\nData sources\n\nAs research becomes increasingly interdisciplinary, global and collaborative, it is expedi-\nent to select from rich and standard databases. The databases consulted are as follows:\n\n i. Scopus1: Scopus is a bibliographic database containing abstracts and citations for \nacademic journal articles launched in 2004. It covers nearly 36,377 titles from over \n11,678 publishers of which 34,346 are peer-reviewed journals, delivering a compre-\nhensive overview of the world’s research output in the scientific, technical, medi-\ncal, and social sciences (including arts and humanities). It is the largest abstract \nand citation database of peer-reviewed literature.\n\n ii. ScienceDirect2: ScienceDirect is Elsevier’s leading information solution for \nresearchers, students, teachers, information professionals and healthcare profes-\nsionals. It provides both subscription-based and open access-based to a large data-\nbase combining authoritative, full-text scientific, technical and health publications \nwith smart intuitive functionality. It covers over 14 million publications from over \n3800 journals and more than 35,000 books. The journals are grouped into four \ncategories: Life Sciences, Physical Sciences and Engineering, Health Sciences, and \nSocial Sciences and Humanities.\n\n iii. EBSCOhost3: EBSCOhost covers a wide range of bibliographic and full-text data-\nbases for researchers, providing electronic journal service available to both cor-\nporate and academic researchers. It has a total of 16,711 journals and magazine \nindexed and abstracted of which 14,914 are peer-reviewed; more than 900,000 \nhigh-quality e-books and titles and over 60,000 audiobooks from more than 1500 \nmajor academic publishers.\n\n iv. ResearchGate4: A free online professional network for scientists and researchers to \nask and answer questions, share papers and find collaborators. It covers over 100 \nmillion publications from over 11 million researchers. ResearchGate was used as \na secondary source where the authors could not access some papers due to lack of \nsubscription.\n\nData retrieval\n\nThe search was conducted in Scopus, ScienceDirect and EBSCOhost since most of \nthe high impact journals and conferences are indexed in these set of rich databases. \nBoolean ‘OR’ was used in combining the nine (9) search strings. A total of 2295 arti-\ncles from the three databases were retrieved as shown in Table 2.\n\n1 http://www.scopu s.com.\n2 http://www.scien cedir ect.com.\n3 https ://www.ebsco host.com.\n4 https ://www.resea archg ate.net.\n\nhttp://www.scopus.com\nhttp://www.sciencedirect.com\nhttps://www.ebscohost.com\nhttps://www.reseaarchgate.net\n\n\nPage 8 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nFurther refinement was performed by (i) limiting the search to journals and confer-\nence papers; (ii) selecting computer science and IT related as the subject domain; (iii) \nselecting ACM, IEEE, SpringerLink, Elsevier as sources; and year of publication to \nbetween 2004 and 2018. The year range was selected due to the fact that interest in \nbig data stream analysis actually started in 2004. At this stage, a total of 1989 papers \nwere excluded leaving a total of 315 papers (see Table  3). The result of the search \nstring was exported to PDF.\n\nBy going through the title of the papers, 111 seemingly relevant papers were extracted \nexcluding a total number of 213 that were not relevant at this stage (see Table 4).\n\nThe abstracts of 111 papers and introduction (for papers that the abstracts were not \nclear enough) were then read to have a quick overview of the paper and to ascertain \nwhether they are suitable or at variance with the research questions. The citations of \nthe papers were exported to Microsoft Excel for easy analysis. The papers were grouped \ninto three categories; “relevant”, “may be relevant” and “irrelevant”. The “relevant” papers \nwere marked with black colour, “may be relevant” and “irrelevant” with green and red \ncolours respectively. At the end of this stage, 45 papers were classified as “relevant”, 9 \npapers as “may be relevant” and 11 as “irrelevant”. Looking critically at the abstract again, \n18 papers were excluded by using the exclusion criteria leaving a total of 47 papers (see \nTable 5) which were manually reviewed in line with the research questions.\n\nInclusion criteria\n\nPapers published in journals, peer-reviewed conferences, workshops, technical and \nsymposium from 2004 and 2018 were included. In addition, the most recent papers \nwere selected in case of papers with similar investigations and results.\n\nTable 2 First search string result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 2097 65 133 2295\n\nTable 3 Second search string result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 196 27 92 315\n\nTable 4 Third Search string refinement result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 64 23 24 111\n\nTable 5 Final Selection\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 25 10 12 47\n\n\n\nPage 9 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nExclusion criteria\n\nPapers that belong to the following categories were excluded from selection as part of \nthe primary study: (i) papers written in source language other than English; (ii) papers \nwith an abstract and or introduction that does not clearly define the contributions of the \nwork; (iii) papers whose abstract do not relate to big data stream analysis.\n\nResult\nThe findings of the study are now presented with respect to the research questions that \nguided the execution of the systematic literature review.\n\nResearch Question 1: What are the tools and technologies employed for big data stream \n\nanalysis?\n\nBig data stream platforms provide functionalities and features that enable big data \nstream applications to develop, operate, deploy, and manage big data streams. Such \nplatforms must be able to pull in streams of data, process the data and stream it back \nas a single flow. Several tools and technologies have been employed to analyse big data \nstreams. In response to the growing demand for big data streaming analytics, a large \nnumber of alternative big data streaming solutions have been developed both by the \nopen source community and enterprise technology vendors. According to [26], there are \nsome factors to consider when selecting big data streaming tools and technologies in \norder to make effective data management decisions. These are briefly described below.\n\nShape of the data\n\nStreaming data sources require serialization technologies for capturing, storing and rep-\nresenting such high-velocity data. For instance, some tools and technologies allow pro-\njection of different structures across data stores, giving room for flexibility for storage \nand access of data in different ways. However, the performance of such platforms may \nnot be suitable for high-velocity data.\n\nData access\n\nThere is a need to put into consideration how the data will be accessed by users and \napplications. For instance, many NoSQL databases require specific application interfaces \nfor data access. Hence there is a need to consider the integration of some other neces-\nsary tools for data access.\n\nAvailability and consistency requirement\n\nIf a distributed system is needed, then CAP theorem states that consistency and avail-\nability cannot be both guaranteed in the presence of network partition (i.e. when there is \na break in the network). In such a scenario, consistency is often traded off for availability \nto ensure that requests can always be processed.\n\nWorkload profile required\n\nPlatform as a service deployment may be appropriate for a spike load profile platform. \nIf platform distribution can be deployed on Infrastructure as a service cloud, then this \noption may be preferred as users will need to pay only when processing. On-premise \n\n\n\nPage 10 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\ndeployment may be considered for predictable or consistent loads. But if workloads are \nmixed (i.e. consistent flows or spikes), a combination of cloud and on-premise approach \nmay be considered so as to give room for easy integration of web-based services or soft-\nware and access to critical functions on the go.\n\nLatency requirement\n\nIf a minimal delay or low latency is required, key-value stores may be considered or bet-\nter still, an in-memory solution which allows the process of large datasets in real-time is \nrequired in order to optimize the data loading procedure.\n\nThe tools and technologies for big data stream analysis can be broadly categorized into \ntwo, which are open source and proprietary solutions. These are listed in Tables 6 and 7.\n\nThe selection of big data streaming tools and technologies should be based on the impor-\ntance of each factor earlier mentioned in this section. Proprietary solutions may not be eas-\nily available because of pricing and licensing issues. While open source supports innovation \nand development at a large scale, careful selection must be made especially when choosing \na recent technology still in production due to limited maturity and lack of support from \nacademic researchers or developer communities. In addition, open source solutions may \nlead to outdating and modification challenges [27]. Moreover, the selection of whether pro-\nprietary or open source or combination of both should depend on the problem to address, \nthe understanding of the true costs, and benefits of both open and proprietary solutions.\n\nTable 6 Open source tools and technologies for big data stream analysis\n\nTools and technology Article\n\nBlockMon [83]\n\nNoSQL [4, 84–86]\n\nSpark streaming [67, 87–91]\n\nApache storm [68, 85, 86, 92–97]\n\nKafka [85, 91, 95, 96, 98]\n\nYahoo! S4 [6, 45, 87, 99]\n\nApache Samza [46, 67, 100]\n\nPhoton [67, 101]\n\nApache Aurora [67, 102]\n\nMavEStream [103]\n\nEsperTech [104, 105]\n\nRedis [106]\n\nC-SPARQL [107, 108]\n\nSAMOA [56, 78, 109]\n\nCQELS [108, 110, 111]\n\nETALIS [112]\n\nXSEQ [73]\n\nApache Kylin [113]\n\nSplunk stream [114]\n\n\n\nPage 11 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nResearch Question 2: What methods and techniques are used in analysing big data \n\nstreams?\n\nGiven the real-time nature, velocity and volume of social media streams, the clus-\ntering algorithms that are applied on streaming data must be highly scalable and \nefficient. Also, the dynamic nature of data makes it difficult to know the required or \ndesirable number of clusters in advance. This renders partitioning clustering tech-\nniques (such as k-median, k-means and k-medoid) or expectation-maximization \n(EM) algorithms-based approaches unsuitable for analysing real-time social media \ndata because they require prior knowledge of clusters in advance. In addition, due \nto concept drift inherent in social media streams, scalable graph partitioning algo-\nrithms are not also suitable because of their tendency towards balanced partitioning. \nSocial media streams must be analysed dynamically in order to provide decisions at \nany given time within a limited space and time window [28–30].\n\nDensity-based clustering algorithm (such as DenStream, OpticStream, Flock-\nStream, Exclusive and Complete Clustering) unlike partitioning algorithms does not \nrequire apriori number of clusters in advance and can detect outliers [31]. However, \nthe issue with density-based clustering algorithms is that most of them except for few \nlike HDDStream, PreDeCon-Stream and PKS-Stream (which are memory intensive) \nperform less efficiently in the face of high dimensional data and as a result are not \nsuitable for analyzing social media streams [32].\n\nThreshold-based techniques, hierarchical clustering, and incremental clustering \nor online clustering are more relevant to social media analysis. Several online thresh-\nold-based stream clustering approaches or incremental clustering approaches such as \nMarkov Random Field [33, 34], Online Spherical K-means [35], and Condensed Clusters \n[36] have been adopted. Incremental approaches are suitable for continuously generated \ndata grouping by setting a maximum similarity threshold between the incoming stream \n\nTable 7 Proprietary tools and technologies for big data stream analysis\n\nTools and technology Article\n\nCodeBlue [115]\n\nAnodot [116]\n\nCloudet [117]\n\nSentiment brand monitoring [118]\n\nNumenta [119]\n\nElastic streaming processing engine [120]\n\nMicrosoft azure stream analytics [121]\n\nIBM InfoSphere streams [8, 122]\n\nGoogle MillWheel [123]\n\nArtemis [124]\n\nWSO2 analytics [125]\n\nMicrosoft StreamInsight [126]\n\nTIBCO StreamBase [127]\n\nStriim [128]\n\nKyvos insights [129]\n\nAtScale [130, 131]\n\nLambda architecture [57]\n\n\n\nPage 12 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nand the existing clusters. Much work has been done in improving the efficiency of online \nclustering algorithms, however, little research efforts have been directed to threshold \nand fragmentation issues. Incremental algorithm threshold setting should employ adap-\ntive approach instead of relying on static values [37, 38]. Some of the methods and tech-\nniques that have been employed in analysing big data streams are outlined in Table 8.\n\nTable 8 Methods and techniques for big data stream analysis\n\nMethods and techniques Article\n\nSPADE [132]\n\nLocally supervised metric learning (LSML) [133]\n\nKTS [106]\n\nMultinomial latent dirichlet allocation [106]\n\nVoltage clustering algorithm [106]\n\nLocality sensitive hashing (LSH) [134]\n\nUser profile vector update algorithm [134]\n\nTag assignment stream clustering (TASC) [134]\n\nStreamMap [117]\n\nDensity cognition [117]\n\nQRS detection algorithm [87]\n\nForward chaining rule [110]\n\nStream [135]\n\nCluStream [136, 137]\n\nHPClustering [138]\n\nDenStream [139]\n\nD-Stream [140]\n\nACluStream [141]\n\nDCStream [142]\n\nP-Stream [143]\n\nADStream [144]\n\nContinuous query processing (CQR) [145]\n\nFPSPAN-growth [146]\n\nOutlier method for cloud computing algorithm (OMCA) [147]\n\nMulti-query optimization strategy (MQOS) [148]\n\nParallel K-means clustering [72]\n\nVisibly push down automata (VPA) [73]\n\nIncremental MI outlier detection algorithm (Inc I-MLOF) [149]\n\nAdaptive windowing based online ensemble (AWOE) [74]\n\nDynamic prime-number based security verification [84]\n\nK-anonymity, I-diversity, t-closeness [90]\n\nSingular spectrum matrix completion (SS-MC) [76]\n\nTemporal fuzzy concept analysis [96]\n\nECM-sketch [77]\n\nNearest neighbour [91]\n\nMarkov chains [91]\n\nBlock-QuickSort-AdjacentJobMatch [86]\n\nBlock-QuickSort-OverlapReplicat",
      "text": [
        "operator stream NYMEX",
        "Magnitude of change in paper distribution over the studied years 180 160 140 120 100 80 156 60 40 98 No of Papers 20 22 28 38 02 -1 2 3 5 2 5 4 5 10 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 Years",
        "Percentage of Publication Type 34,9% Journal Conferences 155, 41% 192, 50% . Workshop/Technical/Sym posium",
        "90 80 70 60 50 40 w 20 0 No of Researchers Frequency of Researchers 10 0 Italy Canada China India USA Germany France Japan Turkey Republic of Korea Countries Ireland Spain Poland Los Angeles Switzerland Iran Greece Norway",
        "Published online: 06 June 2019"
      ],
      "layoutText": [
        "{\"language\":\"en\",\"text\":\"operator stream NYMEX\",\"lines\":[{\"boundingBox\":[{\"x\":340,\"y\":4},{\"x\":518,\"y\":2},{\"x\":519,\"y\":43},{\"x\":340,\"y\":45}],\"text\":\"operator\"},{\"boundingBox\":[{\"x\":779,\"y\":107},{\"x\":919,\"y\":107},{\"x\":918,\"y\":143},{\"x\":779,\"y\":143}],\"text\":\"stream\"},{\"boundingBox\":[{\"x\":21,\"y\":615},{\"x\":131,\"y\":612},{\"x\":132,\"y\":634},{\"x\":21,\"y\":639}],\"text\":\"NYMEX\"}],\"words\":[{\"boundingBox\":[{\"x\":342,\"y\":4},{\"x\":518,\"y\":2},{\"x\":516,\"y\":45},{\"x\":340,\"y\":45}],\"text\":\"operator\"},{\"boundingBox\":[{\"x\":781,\"y\":107},{\"x\":899,\"y\":109},{\"x\":899,\"y\":144},{\"x\":779,\"y\":144}],\"text\":\"stream\"},{\"boundingBox\":[{\"x\":47,\"y\":616},{\"x\":124,\"y\":613},{\"x\":124,\"y\":634},{\"x\":46,\"y\":638}],\"text\":\"NYMEX\"}]}",
        "{\"language\":\"en\",\"text\":\"Magnitude of change in paper distribution over the studied years 180 160 140 120 100 80 156 60 40 98 No of Papers 20 22 28 38 02 -1 2 3 5 2 5 4 5 10 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 Years\",\"lines\":[{\"boundingBox\":[{\"x\":203,\"y\":0},{\"x\":1033,\"y\":0},{\"x\":1033,\"y\":34},{\"x\":203,\"y\":38}],\"text\":\"Magnitude of change in paper distribution over the\"},{\"boundingBox\":[{\"x\":507,\"y\":40},{\"x\":725,\"y\":42},{\"x\":725,\"y\":79},{\"x\":506,\"y\":76}],\"text\":\"studied years\"},{\"boundingBox\":[{\"x\":51,\"y\":77},{\"x\":94,\"y\":77},{\"x\":95,\"y\":102},{\"x\":50,\"y\":102}],\"text\":\"180\"},{\"boundingBox\":[{\"x\":52,\"y\":122},{\"x\":96,\"y\":122},{\"x\":96,\"y\":143},{\"x\":52,\"y\":143}],\"text\":\"160\"},{\"boundingBox\":[{\"x\":50,\"y\":165},{\"x\":96,\"y\":165},{\"x\":96,\"y\":187},{\"x\":50,\"y\":187}],\"text\":\"140\"},{\"boundingBox\":[{\"x\":53,\"y\":212},{\"x\":95,\"y\":212},{\"x\":95,\"y\":232},{\"x\":52,\"y\":231}],\"text\":\"120\"},{\"boundingBox\":[{\"x\":52,\"y\":256},{\"x\":96,\"y\":255},{\"x\":96,\"y\":275},{\"x\":51,\"y\":276}],\"text\":\"100\"},{\"boundingBox\":[{\"x\":65,\"y\":299},{\"x\":94,\"y\":299},{\"x\":94,\"y\":319},{\"x\":65,\"y\":319}],\"text\":\"80\"},{\"boundingBox\":[{\"x\":1129,\"y\":304},{\"x\":1173,\"y\":303},{\"x\":1175,\"y\":326},{\"x\":1129,\"y\":325}],\"text\":\"156\"},{\"boundingBox\":[{\"x\":66,\"y\":342},{\"x\":94,\"y\":342},{\"x\":94,\"y\":364},{\"x\":66,\"y\":363}],\"text\":\"60\"},{\"boundingBox\":[{\"x\":65,\"y\":384},{\"x\":95,\"y\":384},{\"x\":95,\"y\":408},{\"x\":65,\"y\":408}],\"text\":\"40\"},{\"boundingBox\":[{\"x\":1060,\"y\":367},{\"x\":1093,\"y\":366},{\"x\":1094,\"y\":390},{\"x\":1059,\"y\":391}],\"text\":\"98\"},{\"boundingBox\":[{\"x\":0,\"y\":387},{\"x\":3,\"y\":187},{\"x\":34,\"y\":188},{\"x\":29,\"y\":388}],\"text\":\"No of Papers\"},{\"boundingBox\":[{\"x\":65,\"y\":430},{\"x\":93,\"y\":431},{\"x\":94,\"y\":453},{\"x\":65,\"y\":453}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":838,\"y\":451},{\"x\":870,\"y\":451},{\"x\":871,\"y\":473},{\"x\":839,\"y\":473}],\"text\":\"22\"},{\"boundingBox\":[{\"x\":910,\"y\":443},{\"x\":945,\"y\":442},{\"x\":946,\"y\":467},{\"x\":910,\"y\":469}],\"text\":\"28\"},{\"boundingBox\":[{\"x\":985,\"y\":432},{\"x\":1018,\"y\":431},{\"x\":1019,\"y\":456},{\"x\":986,\"y\":457}],\"text\":\"38\"},{\"boundingBox\":[{\"x\":78,\"y\":474},{\"x\":124,\"y\":473},{\"x\":124,\"y\":495},{\"x\":78,\"y\":496}],\"text\":\"02\"},{\"boundingBox\":[{\"x\":167,\"y\":472},{\"x\":201,\"y\":471},{\"x\":201,\"y\":499},{\"x\":166,\"y\":500}],\"text\":\"-1\"},{\"boundingBox\":[{\"x\":245,\"y\":468},{\"x\":499,\"y\":467},{\"x\":499,\"y\":496},{\"x\":246,\"y\":497}],\"text\":\"2 3 5 2\"},{\"boundingBox\":[{\"x\":537,\"y\":467},{\"x\":571,\"y\":467},{\"x\":571,\"y\":498},{\"x\":536,\"y\":498}],\"text\":\"5\"},{\"boundingBox\":[{\"x\":613,\"y\":463},{\"x\":654,\"y\":464},{\"x\":653,\"y\":497},{\"x\":612,\"y\":496}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":684,\"y\":467},{\"x\":796,\"y\":461},{\"x\":798,\"y\":489},{\"x\":684,\"y\":496}],\"text\":\"5 10\"},{\"boundingBox\":[{\"x\":82,\"y\":504},{\"x\":1178,\"y\":504},{\"x\":1178,\"y\":531},{\"x\":82,\"y\":531}],\"text\":\"2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018\"},{\"boundingBox\":[{\"x\":591,\"y\":554},{\"x\":678,\"y\":556},{\"x\":677,\"y\":580},{\"x\":591,\"y\":578}],\"text\":\"Years\"}],\"words\":[{\"boundingBox\":[{\"x\":204,\"y\":1},{\"x\":381,\"y\":2},{\"x\":380,\"y\":38},{\"x\":203,\"y\":36}],\"text\":\"Magnitude\"},{\"boundingBox\":[{\"x\":387,\"y\":2},{\"x\":424,\"y\":2},{\"x\":423,\"y\":38},{\"x\":386,\"y\":38}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":431,\"y\":2},{\"x\":545,\"y\":2},{\"x\":544,\"y\":37},{\"x\":430,\"y\":38}],\"text\":\"change\"},{\"boundingBox\":[{\"x\":552,\"y\":2},{\"x\":583,\"y\":2},{\"x\":583,\"y\":37},{\"x\":551,\"y\":37}],\"text\":\"in\"},{\"boundingBox\":[{\"x\":593,\"y\":2},{\"x\":691,\"y\":2},{\"x\":691,\"y\":36},{\"x\":592,\"y\":37}],\"text\":\"paper\"},{\"boundingBox\":[{\"x\":698,\"y\":2},{\"x\":886,\"y\":2},{\"x\":885,\"y\":32},{\"x\":698,\"y\":36}],\"text\":\"distribution\"},{\"boundingBox\":[{\"x\":899,\"y\":2},{\"x\":972,\"y\":1},{\"x\":972,\"y\":29},{\"x\":899,\"y\":31}],\"text\":\"over\"},{\"boundingBox\":[{\"x\":979,\"y\":1},{\"x\":1033,\"y\":1},{\"x\":1032,\"y\":27},{\"x\":979,\"y\":29}],\"text\":\"the\"},{\"boundingBox\":[{\"x\":508,\"y\":40},{\"x\":628,\"y\":42},{\"x\":626,\"y\":79},{\"x\":507,\"y\":78}],\"text\":\"studied\"},{\"boundingBox\":[{\"x\":636,\"y\":42},{\"x\":726,\"y\":44},{\"x\":724,\"y\":79},{\"x\":634,\"y\":79}],\"text\":\"years\"},{\"boundingBox\":[{\"x\":51,\"y\":77},{\"x\":92,\"y\":77},{\"x\":92,\"y\":102},{\"x\":51,\"y\":102}],\"text\":\"180\"},{\"boundingBox\":[{\"x\":52,\"y\":122},{\"x\":90,\"y\":122},{\"x\":90,\"y\":143},{\"x\":52,\"y\":143}],\"text\":\"160\"},{\"boundingBox\":[{\"x\":51,\"y\":165},{\"x\":92,\"y\":165},{\"x\":92,\"y\":187},{\"x\":51,\"y\":187}],\"text\":\"140\"},{\"boundingBox\":[{\"x\":52,\"y\":212},{\"x\":90,\"y\":212},{\"x\":90,\"y\":232},{\"x\":52,\"y\":231}],\"text\":\"120\"},{\"boundingBox\":[{\"x\":52,\"y\":256},{\"x\":90,\"y\":255},{\"x\":90,\"y\":275},{\"x\":52,\"y\":276}],\"text\":\"100\"},{\"boundingBox\":[{\"x\":65,\"y\":299},{\"x\":90,\"y\":299},{\"x\":90,\"y\":319},{\"x\":65,\"y\":319}],\"text\":\"80\"},{\"boundingBox\":[{\"x\":1129,\"y\":303},{\"x\":1171,\"y\":303},{\"x\":1171,\"y\":326},{\"x\":1129,\"y\":326}],\"text\":\"156\"},{\"boundingBox\":[{\"x\":66,\"y\":342},{\"x\":92,\"y\":342},{\"x\":91,\"y\":364},{\"x\":66,\"y\":363}],\"text\":\"60\"},{\"boundingBox\":[{\"x\":65,\"y\":384},{\"x\":91,\"y\":384},{\"x\":91,\"y\":408},{\"x\":65,\"y\":408}],\"text\":\"40\"},{\"boundingBox\":[{\"x\":1059,\"y\":367},{\"x\":1088,\"y\":366},{\"x\":1089,\"y\":390},{\"x\":1060,\"y\":391}],\"text\":\"98\"},{\"boundingBox\":[{\"x\":0,\"y\":387},{\"x\":0,\"y\":347},{\"x\":28,\"y\":347},{\"x\":27,\"y\":387}],\"text\":\"No\"},{\"boundingBox\":[{\"x\":0,\"y\":338},{\"x\":1,\"y\":304},{\"x\":29,\"y\":305},{\"x\":28,\"y\":339}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":1,\"y\":298},{\"x\":3,\"y\":188},{\"x\":35,\"y\":189},{\"x\":30,\"y\":299}],\"text\":\"Papers\"},{\"boundingBox\":[{\"x\":66,\"y\":430},{\"x\":90,\"y\":430},{\"x\":90,\"y\":453},{\"x\":66,\"y\":452}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":839,\"y\":451},{\"x\":867,\"y\":451},{\"x\":867,\"y\":473},{\"x\":839,\"y\":473}],\"text\":\"22\"},{\"boundingBox\":[{\"x\":912,\"y\":443},{\"x\":940,\"y\":442},{\"x\":941,\"y\":467},{\"x\":913,\"y\":468}],\"text\":\"28\"},{\"boundingBox\":[{\"x\":985,\"y\":432},{\"x\":1015,\"y\":431},{\"x\":1016,\"y\":456},{\"x\":986,\"y\":457}],\"text\":\"38\"},{\"boundingBox\":[{\"x\":78,\"y\":474},{\"x\":116,\"y\":473},{\"x\":117,\"y\":495},{\"x\":78,\"y\":496}],\"text\":\"02\"},{\"boundingBox\":[{\"x\":166,\"y\":472},{\"x\":192,\"y\":471},{\"x\":193,\"y\":499},{\"x\":166,\"y\":500}],\"text\":\"-1\"},{\"boundingBox\":[{\"x\":254,\"y\":470},{\"x\":272,\"y\":469},{\"x\":274,\"y\":497},{\"x\":255,\"y\":497}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":326,\"y\":468},{\"x\":344,\"y\":468},{\"x\":345,\"y\":497},{\"x\":327,\"y\":497}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":401,\"y\":467},{\"x\":419,\"y\":467},{\"x\":420,\"y\":497},{\"x\":402,\"y\":497}],\"text\":\"5\"},{\"boundingBox\":[{\"x\":476,\"y\":468},{\"x\":495,\"y\":468},{\"x\":495,\"y\":496},{\"x\":477,\"y\":497}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":545,\"y\":467},{\"x\":565,\"y\":467},{\"x\":565,\"y\":498},{\"x\":545,\"y\":498}],\"text\":\"5\"},{\"boundingBox\":[{\"x\":622,\"y\":463},{\"x\":642,\"y\":464},{\"x\":641,\"y\":497},{\"x\":622,\"y\":496}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":696,\"y\":467},{\"x\":712,\"y\":467},{\"x\":712,\"y\":495},{\"x\":695,\"y\":496}],\"text\":\"5\"},{\"boundingBox\":[{\"x\":764,\"y\":464},{\"x\":793,\"y\":462},{\"x\":794,\"y\":490},{\"x\":765,\"y\":491}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":84,\"y\":505},{\"x\":141,\"y\":505},{\"x\":140,\"y\":532},{\"x\":83,\"y\":532}],\"text\":\"2004\"},{\"boundingBox\":[{\"x\":156,\"y\":505},{\"x\":213,\"y\":505},{\"x\":212,\"y\":532},{\"x\":155,\"y\":532}],\"text\":\"2005\"},{\"boundingBox\":[{\"x\":230,\"y\":505},{\"x\":289,\"y\":505},{\"x\":288,\"y\":532},{\"x\":228,\"y\":532}],\"text\":\"2006\"},{\"boundingBox\":[{\"x\":303,\"y\":505},{\"x\":363,\"y\":505},{\"x\":362,\"y\":532},{\"x\":302,\"y\":532}],\"text\":\"2007\"},{\"boundingBox\":[{\"x\":377,\"y\":505},{\"x\":436,\"y\":505},{\"x\":435,\"y\":531},{\"x\":376,\"y\":532}],\"text\":\"2008\"},{\"boundingBox\":[{\"x\":453,\"y\":505},{\"x\":512,\"y\":505},{\"x\":511,\"y\":531},{\"x\":452,\"y\":531}],\"text\":\"2009\"},{\"boundingBox\":[{\"x\":527,\"y\":505},{\"x\":586,\"y\":505},{\"x\":585,\"y\":531},{\"x\":526,\"y\":531}],\"text\":\"2010\"},{\"boundingBox\":[{\"x\":600,\"y\":505},{\"x\":660,\"y\":505},{\"x\":659,\"y\":531},{\"x\":599,\"y\":531}],\"text\":\"2011\"},{\"boundingBox\":[{\"x\":676,\"y\":505},{\"x\":735,\"y\":505},{\"x\":734,\"y\":531},{\"x\":675,\"y\":531}],\"text\":\"2012\"},{\"boundingBox\":[{\"x\":750,\"y\":505},{\"x\":809,\"y\":505},{\"x\":808,\"y\":531},{\"x\":749,\"y\":531}],\"text\":\"2013\"},{\"boundingBox\":[{\"x\":824,\"y\":505},{\"x\":883,\"y\":505},{\"x\":882,\"y\":531},{\"x\":823,\"y\":531}],\"text\":\"2014\"},{\"boundingBox\":[{\"x\":899,\"y\":505},{\"x\":957,\"y\":505},{\"x\":956,\"y\":531},{\"x\":898,\"y\":531}],\"text\":\"2015\"},{\"boundingBox\":[{\"x\":973,\"y\":505},{\"x\":1032,\"y\":505},{\"x\":1032,\"y\":531},{\"x\":972,\"y\":531}],\"text\":\"2016\"},{\"boundingBox\":[{\"x\":1047,\"y\":505},{\"x\":1108,\"y\":505},{\"x\":1107,\"y\":531},{\"x\":1046,\"y\":531}],\"text\":\"2017\"},{\"boundingBox\":[{\"x\":1122,\"y\":505},{\"x\":1179,\"y\":505},{\"x\":1178,\"y\":531},{\"x\":1122,\"y\":531}],\"text\":\"2018\"},{\"boundingBox\":[{\"x\":593,\"y\":554},{\"x\":673,\"y\":558},{\"x\":673,\"y\":580},{\"x\":592,\"y\":579}],\"text\":\"Years\"}]}",
        "{\"language\":\"en\",\"text\":\"Percentage of Publication Type 34,9% Journal Conferences 155, 41% 192, 50% . Workshop/Technical/Sym posium\",\"lines\":[{\"boundingBox\":[{\"x\":153,\"y\":2},{\"x\":611,\"y\":3},{\"x\":610,\"y\":31},{\"x\":153,\"y\":29}],\"text\":\"Percentage of Publication Type\"},{\"boundingBox\":[{\"x\":122,\"y\":79},{\"x\":210,\"y\":79},{\"x\":210,\"y\":105},{\"x\":122,\"y\":106}],\"text\":\"34,9%\"},{\"boundingBox\":[{\"x\":503,\"y\":123},{\"x\":610,\"y\":122},{\"x\":611,\"y\":145},{\"x\":503,\"y\":146}],\"text\":\"Journal\"},{\"boundingBox\":[{\"x\":502,\"y\":210},{\"x\":672,\"y\":210},{\"x\":672,\"y\":237},{\"x\":502,\"y\":236}],\"text\":\"Conferences\"},{\"boundingBox\":[{\"x\":20,\"y\":280},{\"x\":143,\"y\":279},{\"x\":143,\"y\":307},{\"x\":20,\"y\":307}],\"text\":\"155, 41%\"},{\"boundingBox\":[{\"x\":281,\"y\":259},{\"x\":403,\"y\":260},{\"x\":403,\"y\":286},{\"x\":281,\"y\":285}],\"text\":\"192, 50%\"},{\"boundingBox\":[{\"x\":502,\"y\":304},{\"x\":520,\"y\":305},{\"x\":519,\"y\":326},{\"x\":501,\"y\":326}],\"text\":\".\"},{\"boundingBox\":[{\"x\":521,\"y\":302},{\"x\":824,\"y\":301},{\"x\":824,\"y\":330},{\"x\":521,\"y\":331}],\"text\":\"Workshop/Technical/Sym\"},{\"boundingBox\":[{\"x\":522,\"y\":340},{\"x\":612,\"y\":338},{\"x\":612,\"y\":363},{\"x\":523,\"y\":365}],\"text\":\"posium\"}],\"words\":[{\"boundingBox\":[{\"x\":154,\"y\":4},{\"x\":313,\"y\":3},{\"x\":313,\"y\":30},{\"x\":154,\"y\":29}],\"text\":\"Percentage\"},{\"boundingBox\":[{\"x\":322,\"y\":3},{\"x\":356,\"y\":3},{\"x\":356,\"y\":30},{\"x\":322,\"y\":30}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":361,\"y\":3},{\"x\":525,\"y\":4},{\"x\":524,\"y\":31},{\"x\":361,\"y\":31}],\"text\":\"Publication\"},{\"boundingBox\":[{\"x\":539,\"y\":4},{\"x\":605,\"y\":5},{\"x\":604,\"y\":32},{\"x\":539,\"y\":31}],\"text\":\"Type\"},{\"boundingBox\":[{\"x\":122,\"y\":80},{\"x\":207,\"y\":79},{\"x\":207,\"y\":106},{\"x\":122,\"y\":107}],\"text\":\"34,9%\"},{\"boundingBox\":[{\"x\":520,\"y\":124},{\"x\":610,\"y\":123},{\"x\":611,\"y\":145},{\"x\":520,\"y\":147}],\"text\":\"Journal\"},{\"boundingBox\":[{\"x\":520,\"y\":211},{\"x\":670,\"y\":212},{\"x\":671,\"y\":237},{\"x\":521,\"y\":237}],\"text\":\"Conferences\"},{\"boundingBox\":[{\"x\":20,\"y\":280},{\"x\":76,\"y\":280},{\"x\":76,\"y\":308},{\"x\":20,\"y\":308}],\"text\":\"155,\"},{\"boundingBox\":[{\"x\":82,\"y\":280},{\"x\":137,\"y\":280},{\"x\":137,\"y\":308},{\"x\":81,\"y\":308}],\"text\":\"41%\"},{\"boundingBox\":[{\"x\":282,\"y\":260},{\"x\":337,\"y\":260},{\"x\":337,\"y\":286},{\"x\":281,\"y\":286}],\"text\":\"192,\"},{\"boundingBox\":[{\"x\":342,\"y\":260},{\"x\":397,\"y\":260},{\"x\":397,\"y\":287},{\"x\":342,\"y\":286}],\"text\":\"50%\"},{\"boundingBox\":[{\"x\":501,\"y\":304},{\"x\":513,\"y\":304},{\"x\":513,\"y\":326},{\"x\":501,\"y\":325}],\"text\":\".\"},{\"boundingBox\":[{\"x\":522,\"y\":303},{\"x\":819,\"y\":302},{\"x\":819,\"y\":331},{\"x\":521,\"y\":331}],\"text\":\"Workshop/Technical/Sym\"},{\"boundingBox\":[{\"x\":523,\"y\":340},{\"x\":600,\"y\":338},{\"x\":601,\"y\":364},{\"x\":523,\"y\":366}],\"text\":\"posium\"}]}",
        "{\"language\":\"en\",\"text\":\"90 80 70 60 50 40 w 20 0 No of Researchers Frequency of Researchers 10 0 Italy Canada China India USA Germany France Japan Turkey Republic of Korea Countries Ireland Spain Poland Los Angeles Switzerland Iran Greece Norway\",\"lines\":[{\"boundingBox\":[{\"x\":52,\"y\":40},{\"x\":87,\"y\":38},{\"x\":88,\"y\":69},{\"x\":53,\"y\":71}],\"text\":\"90\"},{\"boundingBox\":[{\"x\":54,\"y\":78},{\"x\":86,\"y\":78},{\"x\":86,\"y\":102},{\"x\":54,\"y\":103}],\"text\":\"80\"},{\"boundingBox\":[{\"x\":54,\"y\":114},{\"x\":86,\"y\":113},{\"x\":85,\"y\":137},{\"x\":53,\"y\":137}],\"text\":\"70\"},{\"boundingBox\":[{\"x\":55,\"y\":149},{\"x\":85,\"y\":148},{\"x\":84,\"y\":173},{\"x\":54,\"y\":173}],\"text\":\"60\"},{\"boundingBox\":[{\"x\":55,\"y\":187},{\"x\":86,\"y\":186},{\"x\":85,\"y\":211},{\"x\":53,\"y\":211}],\"text\":\"50\"},{\"boundingBox\":[{\"x\":55,\"y\":222},{\"x\":85,\"y\":222},{\"x\":84,\"y\":246},{\"x\":55,\"y\":246}],\"text\":\"40\"},{\"boundingBox\":[{\"x\":56,\"y\":281},{\"x\":55,\"y\":257},{\"x\":72,\"y\":257},{\"x\":72,\"y\":282}],\"text\":\"w\"},{\"boundingBox\":[{\"x\":53,\"y\":295},{\"x\":85,\"y\":294},{\"x\":85,\"y\":318},{\"x\":53,\"y\":319}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":65,\"y\":285},{\"x\":66,\"y\":258},{\"x\":83,\"y\":258},{\"x\":82,\"y\":285}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":1,\"y\":357},{\"x\":2,\"y\":58},{\"x\":30,\"y\":58},{\"x\":29,\"y\":357}],\"text\":\"No of Researchers\"},{\"boundingBox\":[{\"x\":393,\"y\":2},{\"x\":833,\"y\":1},{\"x\":833,\"y\":35},{\"x\":393,\"y\":39}],\"text\":\"Frequency of Researchers\"},{\"boundingBox\":[{\"x\":52,\"y\":334},{\"x\":86,\"y\":333},{\"x\":85,\"y\":356},{\"x\":53,\"y\":357}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":69,\"y\":394},{\"x\":67,\"y\":366},{\"x\":85,\"y\":366},{\"x\":85,\"y\":394}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":92,\"y\":432},{\"x\":134,\"y\":397},{\"x\":151,\"y\":416},{\"x\":108,\"y\":453}],\"text\":\"Italy\"},{\"boundingBox\":[{\"x\":124,\"y\":465},{\"x\":192,\"y\":395},{\"x\":209,\"y\":410},{\"x\":139,\"y\":482}],\"text\":\"Canada\"},{\"boundingBox\":[{\"x\":200,\"y\":446},{\"x\":250,\"y\":395},{\"x\":266,\"y\":412},{\"x\":215,\"y\":463}],\"text\":\"China\"},{\"boundingBox\":[{\"x\":263,\"y\":438},{\"x\":309,\"y\":395},{\"x\":325,\"y\":412},{\"x\":279,\"y\":457}],\"text\":\"India\"},{\"boundingBox\":[{\"x\":331,\"y\":432},{\"x\":369,\"y\":393},{\"x\":387,\"y\":413},{\"x\":351,\"y\":449}],\"text\":\"USA\"},{\"boundingBox\":[{\"x\":345,\"y\":478},{\"x\":431,\"y\":399},{\"x\":446,\"y\":417},{\"x\":360,\"y\":495}],\"text\":\"Germany\"},{\"boundingBox\":[{\"x\":427,\"y\":458},{\"x\":489,\"y\":396},{\"x\":505,\"y\":411},{\"x\":443,\"y\":474}],\"text\":\"France\"},{\"boundingBox\":[{\"x\":494,\"y\":449},{\"x\":548,\"y\":396},{\"x\":566,\"y\":414},{\"x\":511,\"y\":467}],\"text\":\"Japan\"},{\"boundingBox\":[{\"x\":544,\"y\":456},{\"x\":607,\"y\":398},{\"x\":624,\"y\":417},{\"x\":561,\"y\":475}],\"text\":\"Turkey\"},{\"boundingBox\":[{\"x\":505,\"y\":556},{\"x\":664,\"y\":395},{\"x\":685,\"y\":414},{\"x\":524,\"y\":577}],\"text\":\"Republic of Korea\"},{\"boundingBox\":[{\"x\":507,\"y\":597},{\"x\":664,\"y\":597},{\"x\":664,\"y\":624},{\"x\":507,\"y\":625}],\"text\":\"Countries\"},{\"boundingBox\":[{\"x\":657,\"y\":459},{\"x\":723,\"y\":392},{\"x\":744,\"y\":411},{\"x\":677,\"y\":480}],\"text\":\"Ireland\"},{\"boundingBox\":[{\"x\":734,\"y\":445},{\"x\":783,\"y\":396},{\"x\":801,\"y\":415},{\"x\":751,\"y\":465}],\"text\":\"Spain\"},{\"boundingBox\":[{\"x\":781,\"y\":457},{\"x\":844,\"y\":393},{\"x\":861,\"y\":410},{\"x\":798,\"y\":474}],\"text\":\"Poland\"},{\"boundingBox\":[{\"x\":796,\"y\":500},{\"x\":904,\"y\":393},{\"x\":924,\"y\":413},{\"x\":816,\"y\":520}],\"text\":\"Los Angeles\"},{\"boundingBox\":[{\"x\":853,\"y\":502},{\"x\":963,\"y\":392},{\"x\":983,\"y\":412},{\"x\":872,\"y\":521}],\"text\":\"Switzerland\"},{\"boundingBox\":[{\"x\":987,\"y\":431},{\"x\":1026,\"y\":396},{\"x\":1039,\"y\":411},{\"x\":1001,\"y\":448}],\"text\":\"Iran\"},{\"boundingBox\":[{\"x\":1018,\"y\":462},{\"x\":1083,\"y\":397},{\"x\":1098,\"y\":412},{\"x\":1033,\"y\":477}],\"text\":\"Greece\"},{\"boundingBox\":[{\"x\":1070,\"y\":463},{\"x\":1145,\"y\":396},{\"x\":1164,\"y\":416},{\"x\":1088,\"y\":484}],\"text\":\"Norway\"}],\"words\":[{\"boundingBox\":[{\"x\":52,\"y\":40},{\"x\":83,\"y\":38},{\"x\":85,\"y\":69},{\"x\":53,\"y\":71}],\"text\":\"90\"},{\"boundingBox\":[{\"x\":54,\"y\":78},{\"x\":81,\"y\":78},{\"x\":81,\"y\":103},{\"x\":54,\"y\":103}],\"text\":\"80\"},{\"boundingBox\":[{\"x\":54,\"y\":113},{\"x\":81,\"y\":113},{\"x\":81,\"y\":137},{\"x\":54,\"y\":137}],\"text\":\"70\"},{\"boundingBox\":[{\"x\":54,\"y\":148},{\"x\":81,\"y\":148},{\"x\":81,\"y\":173},{\"x\":54,\"y\":173}],\"text\":\"60\"},{\"boundingBox\":[{\"x\":53,\"y\":186},{\"x\":80,\"y\":186},{\"x\":80,\"y\":211},{\"x\":53,\"y\":211}],\"text\":\"50\"},{\"boundingBox\":[{\"x\":55,\"y\":222},{\"x\":81,\"y\":222},{\"x\":81,\"y\":246},{\"x\":55,\"y\":246}],\"text\":\"40\"},{\"boundingBox\":[{\"x\":56,\"y\":281},{\"x\":55,\"y\":271},{\"x\":72,\"y\":270},{\"x\":73,\"y\":281}],\"text\":\"w\"},{\"boundingBox\":[{\"x\":53,\"y\":295},{\"x\":80,\"y\":294},{\"x\":81,\"y\":318},{\"x\":54,\"y\":319}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":66,\"y\":270},{\"x\":66,\"y\":259},{\"x\":83,\"y\":260},{\"x\":83,\"y\":271}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":1,\"y\":357},{\"x\":1,\"y\":314},{\"x\":28,\"y\":314},{\"x\":28,\"y\":357}],\"text\":\"No\"},{\"boundingBox\":[{\"x\":1,\"y\":302},{\"x\":1,\"y\":268},{\"x\":29,\"y\":269},{\"x\":29,\"y\":303}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":1,\"y\":262},{\"x\":2,\"y\":60},{\"x\":29,\"y\":62},{\"x\":29,\"y\":262}],\"text\":\"Researchers\"},{\"boundingBox\":[{\"x\":395,\"y\":2},{\"x\":572,\"y\":3},{\"x\":572,\"y\":39},{\"x\":393,\"y\":39}],\"text\":\"Frequency\"},{\"boundingBox\":[{\"x\":582,\"y\":3},{\"x\":618,\"y\":3},{\"x\":617,\"y\":38},{\"x\":581,\"y\":38}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":624,\"y\":3},{\"x\":833,\"y\":2},{\"x\":833,\"y\":30},{\"x\":624,\"y\":38}],\"text\":\"Researchers\"},{\"boundingBox\":[{\"x\":52,\"y\":334},{\"x\":80,\"y\":333},{\"x\":80,\"y\":356},{\"x\":53,\"y\":357}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":68,\"y\":394},{\"x\":68,\"y\":384},{\"x\":86,\"y\":383},{\"x\":86,\"y\":393}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":93,\"y\":432},{\"x\":133,\"y\":399},{\"x\":149,\"y\":418},{\"x\":109,\"y\":452}],\"text\":\"Italy\"},{\"boundingBox\":[{\"x\":124,\"y\":464},{\"x\":190,\"y\":398},{\"x\":206,\"y\":415},{\"x\":140,\"y\":482}],\"text\":\"Canada\"},{\"boundingBox\":[{\"x\":200,\"y\":445},{\"x\":248,\"y\":398},{\"x\":264,\"y\":415},{\"x\":215,\"y\":462}],\"text\":\"China\"},{\"boundingBox\":[{\"x\":263,\"y\":439},{\"x\":307,\"y\":396},{\"x\":324,\"y\":414},{\"x\":280,\"y\":457}],\"text\":\"India\"},{\"boundingBox\":[{\"x\":332,\"y\":432},{\"x\":364,\"y\":400},{\"x\":383,\"y\":419},{\"x\":351,\"y\":450}],\"text\":\"USA\"},{\"boundingBox\":[{\"x\":346,\"y\":480},{\"x\":430,\"y\":400},{\"x\":447,\"y\":418},{\"x\":362,\"y\":495}],\"text\":\"Germany\"},{\"boundingBox\":[{\"x\":428,\"y\":458},{\"x\":486,\"y\":401},{\"x\":500,\"y\":418},{\"x\":444,\"y\":474}],\"text\":\"France\"},{\"boundingBox\":[{\"x\":494,\"y\":448},{\"x\":545,\"y\":399},{\"x\":563,\"y\":417},{\"x\":511,\"y\":467}],\"text\":\"Japan\"},{\"boundingBox\":[{\"x\":544,\"y\":457},{\"x\":606,\"y\":400},{\"x\":623,\"y\":418},{\"x\":563,\"y\":475}],\"text\":\"Turkey\"},{\"boundingBox\":[{\"x\":505,\"y\":555},{\"x\":582,\"y\":478},{\"x\":601,\"y\":498},{\"x\":525,\"y\":577}],\"text\":\"Republic\"},{\"boundingBox\":[{\"x\":587,\"y\":473},{\"x\":606,\"y\":454},{\"x\":625,\"y\":474},{\"x\":606,\"y\":494}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":610,\"y\":450},{\"x\":664,\"y\":396},{\"x\":683,\"y\":415},{\"x\":629,\"y\":470}],\"text\":\"Korea\"},{\"boundingBox\":[{\"x\":507,\"y\":600},{\"x\":661,\"y\":598},{\"x\":660,\"y\":625},{\"x\":508,\"y\":625}],\"text\":\"Countries\"},{\"boundingBox\":[{\"x\":658,\"y\":459},{\"x\":722,\"y\":395},{\"x\":741,\"y\":415},{\"x\":678,\"y\":480}],\"text\":\"Ireland\"},{\"boundingBox\":[{\"x\":734,\"y\":446},{\"x\":782,\"y\":398},{\"x\":801,\"y\":417},{\"x\":752,\"y\":465}],\"text\":\"Spain\"},{\"boundingBox\":[{\"x\":782,\"y\":457},{\"x\":841,\"y\":398},{\"x\":858,\"y\":415},{\"x\":798,\"y\":474}],\"text\":\"Poland\"},{\"boundingBox\":[{\"x\":797,\"y\":501},{\"x\":824,\"y\":475},{\"x\":844,\"y\":493},{\"x\":817,\"y\":520}],\"text\":\"Los\"},{\"boundingBox\":[{\"x\":828,\"y\":471},{\"x\":904,\"y\":394},{\"x\":925,\"y\":415},{\"x\":848,\"y\":489}],\"text\":\"Angeles\"},{\"boundingBox\":[{\"x\":853,\"y\":503},{\"x\":960,\"y\":396},{\"x\":979,\"y\":416},{\"x\":873,\"y\":521}],\"text\":\"Switzerland\"},{\"boundingBox\":[{\"x\":987,\"y\":432},{\"x\":1019,\"y\":402},{\"x\":1034,\"y\":418},{\"x\":1002,\"y\":448}],\"text\":\"Iran\"},{\"boundingBox\":[{\"x\":1019,\"y\":462},{\"x\":1080,\"y\":401},{\"x\":1094,\"y\":417},{\"x\":1034,\"y\":476}],\"text\":\"Greece\"},{\"boundingBox\":[{\"x\":1070,\"y\":464},{\"x\":1143,\"y\":398},{\"x\":1161,\"y\":420},{\"x\":1089,\"y\":484}],\"text\":\"Norway\"}]}",
        "{\"language\":\"en\",\"text\":\"Published online: 06 June 2019\",\"lines\":[{\"boundingBox\":[{\"x\":4,\"y\":14},{\"x\":889,\"y\":14},{\"x\":889,\"y\":70},{\"x\":4,\"y\":70}],\"text\":\"Published online: 06 June 2019\"}],\"words\":[{\"boundingBox\":[{\"x\":4,\"y\":15},{\"x\":270,\"y\":15},{\"x\":270,\"y\":71},{\"x\":4,\"y\":70}],\"text\":\"Published\"},{\"boundingBox\":[{\"x\":289,\"y\":15},{\"x\":495,\"y\":15},{\"x\":495,\"y\":71},{\"x\":290,\"y\":71}],\"text\":\"online:\"},{\"boundingBox\":[{\"x\":506,\"y\":15},{\"x\":574,\"y\":15},{\"x\":575,\"y\":71},{\"x\":506,\"y\":71}],\"text\":\"06\"},{\"boundingBox\":[{\"x\":594,\"y\":15},{\"x\":725,\"y\":15},{\"x\":726,\"y\":71},{\"x\":594,\"y\":71}],\"text\":\"June\"},{\"boundingBox\":[{\"x\":744,\"y\":15},{\"x\":886,\"y\":15},{\"x\":887,\"y\":70},{\"x\":745,\"y\":71}],\"text\":\"2019\"}]}"
      ]
    },
    {
      "@search.score": 3.4890108,
      "content": "\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 \nDOI 10.1186/s40493-015-0019-z\n\nRESEARCH Open Access\n\nToward a testbed for evaluating\ncomputational trust models: experiments\nand analysis\nPartheeban Chandrasekaran and Babak Esfandiari*\n\n*Correspondence:\nbabak@sce.carleton.ca\nDepartment of Systems and\nComputer Engineering, Carleton\nUniversity, 1125 Colonel By Drive,\nOttawa, Ontario K1s5B6, Canada\n\nAbstract\nWe propose a generic testbed for evaluating social trust models and we show how\nexisting models can fit our tesbed. To showcase the flexibility of our design, we\nimplemented a prototype and evaluated three trust algorithms, namely EigenTrust,\nPeerTrust and Appleseed, for their vulnerabilites to attacks and compliance to various\ntrust properties. For example, we were able to exhibit discrepancies between\nEigenTrust and PeerTrust, as well as trade-offs between resistance to slandering attacks\nversus self-promotion.\n\nKeywords: Trust testbed; Reputation; Multi-agent systems\n\nIntroduction\nMotivation\n\nWith the growth of online community-based systems such as peer-to-peer file-sharing\napplications, e-commerce and social networking websites, there is an increasing need to\nprovide computational trust mechanisms to determine which users or agents are honest\nand which ones are malicious. Many models calculate trust by relying on analyzing a\nhistory of interactions. The calculations can range from the simple averaging of ratings\non eBay to flow-based scores in the Advogato website. Thus for a researcher to evaluate\nand compare his or her latest model against existing ones, a comprehensive test tool is\nneeded. However, our research shows that the tools that exist to assist researchers are not\nflexible enough to include different trust models and their evaluations. Moreover, these\ntools use their own set of application-dependent metrics to evaluate a reputation system.\nThis means that a number of trust models cannot be evaluated for vulnerabilities against\ncertain types of attacks. Thus, there is still a need for a generic testbed to evaluate and\ncompare computational trust models.\n\nOverview of our solution and contributions\n\nIn this paper, we present a model and a testbed for evaluating a family of trust algo-\nrithms that rely on past transactions between agents. Trust assessment is viewed as a\nprocess consisting of a succession of graph transformations, where the agents form the\nvertices of the graph. The meaning of the edges depends on the transformation stage,\n\n© 2015 Chandrasekaran and Esfandiari. Open Access This article is distributed under the terms of the Creative Commons\nAttribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution,\nand reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to\nthe Creative Commons license, and indicate if changes were made.\n\n\n\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40493-015-0019-z-x&domain=pdf\nmailto: babak@sce.carleton.ca\nhttp://creativecommons.org/licenses/by/4.0/\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 2 of 27\n\nand can refer to the presence of transactions between the two agents or the existence\nof a trust relationship between them. Our first contribution is to show that with this\nview, existing reputation systems can be adopted under a single model, but they work at\ndifferent stages of the trust assessment workflow. This allows us to present a new classi-\nfication scheme for a number of trust models based on where they fit in the assessment\nworkflow. The second contribution of our work is that this workflow can be described\nformally, and by doing this, we show that it is possible to model a variety of attacks\nand evaluation schemes. Finally, out of the larger number of systems we classified, we\nselected three reputation systems, namely EigenTrust [1], PeerTrust [2] and Appleseed\n[3], to exemplify the range and variety of reputation systems that our testbed can accom-\nmodate. We evaluated these three systems in our testbed against simple attacks and\nwe validated their compliance to basic trust properties. In particular, we were able to\nexhibit differences in the way EigenTrust and PeerTrust rank the agents, we observed\nthe subtle interplay between slandering and self-promoting attacks (higher sensitivity\nto one attack can lead to lower sensitivity to the other), and we verified that trust\nweakens along a friend-of-a-friend chain and that it is more easily lost than gained\n(as it should be).\n\nOrganization\n\nThis article is organized as follows: section ‘Background and literature review’ provides\nbackground and state of the art on trust models, attacks against them, and existing\ntestbeds for evaluation. Section ‘Problem description and model’ formulates the research\nproblem of this article and proposes our model for a testbed. Section ‘Classifying and\nchaining algorithms’ shows how some of existing trust algorithms can fit our model, and\nhow one can combine or compare them using our model and testbed. Section ‘Results and\ndiscussion’ describes the implementation details of our testbed prototype and presents\nevaluation results of three different trust algorithms, namely EigenTrust, PeerTrust, and\nAppleseed. Section ‘Conclusions’ concludes this article and summarizes the contributions\nand limitations of our work.\n\nBackground and literature review\nSocial trust models\n\nTrust management systems aid agents in establishing and assessing mutual trust. How-\never, the actual mechanisms used in these systems vary. For example, public key infras-\ntructures [4] rely on certificates whereas reputation-based trust management systems are\nbased on experiences of earlier direct and indirect interactions [5].\nIn this paper we will focus on social trust models based on reputation. The trust model\n\nshould provide a means to compare the trustworthiness of agents in order to choose a\nparticular agent to perform an action. For instance, on an e-commerce website like eBay,\nwe need to be able to compare the trustworthiness of sellers in order to pick the most\ntrustworthy one to buy a product from.\nSocial trust models rely on past experiences of agents to produce trust assertions. That\n\nis, the agents in the system interact with each other and record their experiences, which\nare then used to determine whether a particular agent is trustworthy. This model is self-\nsufficient because it does not rely on a third party to propagate trust, like it would in\ncertificate authority-based PKI trust models. However, there are drawbacks to having no\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 3 of 27\n\nroot of trust. For instance, agents evaluating the trustworthiness of agents with whom\nthere has been no interaction must use recommendations from others and, in turn,\nevaluate the trustworthiness of the recommenders. Social trust models must address this\nproblem.\n\nNature of input\n\nVarious inputs are used by social trust algorithms to measure the trustworthiness of\nagents. In EigenTrust [1], PeerTrust [2], TRAVOS [6] and Beta Reputation System (BRS)\n[7], agents rate their satisfaction after a transaction (e.g., downloading a file in a P2P\nfile-sharing network). These ratings are used to obtain a trust score that represents the\ntrustworthiness of the agent. In Aberer and Despotovic’s system [5]1, agents may file com-\nplaints (can be seen as dissatisfaction) about each other after a transaction. In Advogato\n[8], whose goal is to discourage spam on its blogging website, users explicitly certify\neach other as belonging to a particular level in the community. Trust algorithms may\nalso directly use trust scores among agents to compute an aggregated trustworthiness\nof agents, as in TidalTrust [9] and Appleseed [3]. In the specific context of P2P file-\nsharing, Credence [10] uses the votes on file authenticity to calculate a similarity score\nbetween agents and uses it to measure trust. The trust score is then used to recommend\nfiles.\n\nDirect vs. indirect trust\n\nThe truster may use some or all of its own and other agents’ past experiences with the\ntrustee to obtain a trust score. Trust algorithms often use gossiping to poll agents with\nwhom the truster has had interactions in the past.\nThe trust score calculated using only the experiences from direct interactions is\n\ncalled the direct trust score, while the trust score calculated using the recommenda-\ntions from other agents is called the indirect trust score [11]. As mentioned earlier,\nreputation systems use different inputs (satisfaction ratings, votes, certificates, etc.) to\ncalculate direct trust scores and indirect trust scores. PeerTrust uses satisfaction ratings\nto calculate both direct and indirect trust scores, whereas EigenTrust and TRAVOS\nuse satisfaction ratings to calculate direct trust scores, which they then use to calcu-\nlate indirect trust scores. Therefore, we can categorize the trust algorithms based on\nthe input required. But how do trust algorithms calculate the trust scores of agents\nusing the above information? It again varies from algorithm to algorithm. For instance,\nPeerTrust, EigenTrust, and Aberer use simple averaging of ratings, TRAVOS and BRS\nuse the beta probability density function, and Appleseed uses the Spreading Activation\nmodel.\n\nGlobal vs. local trust\n\nThe trust algorithm may output a global trust score or a local trust score [3, 12]. A global\ntrust score is one that represents the general trust that all agents have on a particular\nagent, whereas local trust scores represents the trust from the perspective of the truster\nand thus each truster may trust an agent differently. In our survey, we found PeerTrust,\nEigenTrust, and Aberer to be global trust algorithms whereas TRAVOS, BRS, Credence,\nAdvogato, TidalTrust, Appleseed, Marsh [13] and Abdul-Rahman [14] are local trust\nalgorithms.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 4 of 27\n\nTo trust or not to trust\n\nOnce the trust score is calculated, it can be used to decide whether to trust the agent. It\ncan be as simple as comparing the trust score against a threshold: if the trust score is above\na certain threshold, then the agent is trusted. Marsh [13], and Aberer [5] use thresholding\ntechniques. If the trust algorithm outputs normalized trust scores of agents as in Eigen-\nTrust, then the trust scores of agents are ranked. In this case, one may consider a certain\npercentage of the top ranked agents as trustworthy. In Appleseed, a graph is first obtained\nwith trust scores of agents as edge weights, and then, the truster agent is “injected” with\na value called the activation energy. This energy is spread to agents with a spreading fac-\ntor along the edges in the graph and the algorithm ranks the agents according to their\ntrust scores. Trust decisions can also be flow-based such as in Advogato, which calculates\na maximum “flow of trust” in the trust graph to determine which agents are trustworthy\nand which are not.\nIn short, social trust models focus on the following:\n\n1. What is the input to calculate the trust score of an agent?\n2. Does the trust algorithm use only direct experience or does it also rely on third\n\nparty recommendations?\n3. Is the trust score of an agent global or local?\n4. How does one decide whether to trust an agent?\n\nGiven the above discussion, and to assess the scope of our testbed, we propose tomodel,\nevaluate and compare three algorithms from fairly different families. The next sections\nprovide detailed descriptions of the trust models we selected and that we implemented in\nour testbed. The details are given to help understand the output of our experiments, but\nreaders familiar with EigenTrust, PeerTrust and/or AppleSeed may skip those respective\nsections.\n\nPeerTrust\n\nIn PeerTrust, agents rate each other in terms of the satisfaction received. These ratings\nare weighted by trust scores of the raters, and a global trust score is computed recursively\nusing Eq. 2.1, where:\n\n• T(u) is the trust score of agent u\n• I(u) is the set of transactions that agent u had with all the agents in the system\n• S(u, i) is the satisfaction rating on u for transaction i\n• p(u, i) is the agent that provided the rating.\n\nT(u) =\nI(u)∑\ni=1\n\nS(u, i) × T(p(u, i))∑I(u)\nj=1 T(p(u, j))\n\n(2.1)\n\nPeerTrust also provides a method for calculating local trust scores. In both local and\nglobal trust score computations, the trust score is compared against a threshold to decide\nwhether to trust or not.\n\nEigenTrust\n\nAgents in EigenTrust rate transactions as satisfactory or unsatisfactory [1]. These trans-\naction ratings are used as input, to calculate a local direct trust score, from which a global\ntrust score is then calculated.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 5 of 27\n\nAn agent i calculates the normalized local trust score of agent j, as shown in Eq. 2.2,\nwhere tij ∈ {+1,−1} is the transaction rating, and sij is the sum of ratings.\n\nsij =\n∑\nTij\n\ntrij\n\ncij = max(sij, 0)∑\nk max(sik , 0)\n\n(2.2)\n\nNote that we cannot use sij as the local trust score without normalizing, because mali-\ncious agents can arbitrarily assign high local trust values to fellow malicious agents and\nlow local trust values to honest agents.\nTo calculate the global trust score of an agent, the truster queries his friends for their\n\ntrust scores on the trustee. These local trust scores are aggregated, as shown in Eq. 2.3.\n\ntik =\n∑\nj\ncijcjk (2.3)\n\nIf we let C be the matrix containing cij elements, �ci be the local trust vector for i (each\nelement corresponds to the trust that i has in j), and �ti the vector containing tik , then,\n\n�ti = CT �ci (2.4)\n\nBy asking a friend’s friend’s opinion, Eq. 2.4 becomes �ti = (CT )2 �ci. If an agent keeps\nasking the opinions of its friends of friends, the whole trust graph can be explored, and\nEq. 2.4 becomes Eq. 2.5, where n is the number of hops from i.\n\n�t = (CT )n �ci (2.5)\n\nThe trust scores of the agents converge to a global value irrespective of the trustee.\nBecause EigenTrust outputs global trust scores (normalized over the sum of all agents),\n\nagents are ranked according to their trust scores (unlike PeerTrust). Therefore, an agent\nis considered trustworthy if it is within a certain rank.\n\nAppleseed\n\nAppleseed is a flow-based algorithm [3]. Assuming that we are given a directed weighted\ngraph with agents as nodes, edges as trust relationships, and the weight of an edge as\ntrustworthiness of the sink, we can determine the amount of trust that flows in the graph.\nThat is, given a trust seed, an energy in ∈ R\n\n+\n0 , spreading factor decay ∈[ 0, 1], and conver-\n\ngence threshold Tc, Appleseed returns a trust score of agents from the perspective of the\ntrust seed.\nThe trust propagation from agent a to agent b is determined using Eq. 2.6, where the\n\nweight of edge (a, b) represents the amount of trust a places in b, and in(a) and in(b)\nrepresent the flow of trust into a and b, respectively.\n\nin(b) = decay ×\n∑\n\n(a,b)∈E\nin(a) × weight(a, b)∑\n\n(a,c)∈E weight(a, c)\n(2.6)\n\nThe trust of an agent b (trust(b)) is then updated using Eq. 2.7, where the decay factor\nensures that trust in an agent decreases as the path length from the seed increases.\n\ntrust(b) := trust(b) + (1 − decay) × in(b) (2.7)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 6 of 27\n\nGenerally, trust graphs have loops, which makes Eq. 2.7 recursive. Thus a termination\ncondition like the one below is required, where Ai ⊆ A is the set of nodes that were\ndiscovered until step i and trusti(x) is the current trust scores for all x ∈ Ai:\n\n∀x ∈ Ai : trusti(x) − trusti−1(x) ≤ Tc (2.8)\n\nAfter Eq. 2.7 terminates, the trust scores of agents are ranked. Since this set is ranked\nfrom the perspective of the seed, Appleseed is a local trust algorithm.\nAs our brief survey shows, the trust models vary in terms of their input, output, and\n\nthe methods they use. To evaluate and compare them, testbeds are needed. In the next\nsection we take a look at existing testbeds.\n\nTestbeds\n\nWe investigated two testbed models, namely Guha’s [15] andMacau [16], and two testbed\nimplementations, namely ART [17] and TREET [18], which are used to evaluate trust\nalgorithms. This section provides details of our investigation.\n\nGuha\n\nGuha [15] proposes a model to capture document recommendation systems, where trust\nand reputation play an important role. The model relies on a graph of agents where the\nedges can be weighted based on their mutual ratings, and a rating function for documents\nby agents. Guha then discusses how trust can be calculated based on those ratings, and\nevaluates a few case studies of real systems that can be accommodated by the model.\nGuha’s model can capture trust systems that take a set of documents and their ratings\n\nas input (such as Credence [10]), but it cannot accommodate systems where the only\ninput consists of direct feedbacks between agents, such as in PeerTrust (global) [2] or\nEigenTrust [1]. Also, the rating of documents is itself an output of Guha’s model, and that\nis often not the purpose or output of many more general-purpose trust models.\nIn short, document recommendation systems can be viewed as a specialization or\n\nsubclass of more general trust systems, and Guha’s model is suitable for that subclass.\n\nMacau\n\nHazard and Singh’s Macau [16] is a model for evaluating reputation systems. The authors\ndistinguish two roles for any agent: a rater that evaluates a target. Transactions are viewed\nas a favor provided by the target to the rater. The target’s reputation, local to each rater-\ntarget pairing, is updated after each transaction and depends on the previous reputation\nvalue. The target’s payoff in giving a favor is also dependent on its current reputation but\nalso on its belief of the likelihood that the rater will in turn return the favor in the future.\nBased on the above definitions, the authors define a set of desirable properties for a\n\nreputation system:\n\n• Monotonicity: given two different targets a and b, the computed reputation of a\nshould be higher than that of b if the predicted payoff of a transaction with a is\nhigher than with b.\n\n• Unambiguity and convergence: the reputation should converge over time to a single\nfixpoint, regardless of its initial value.\n\n• Accuracy: this convergence should happen quickly, thus minimizing the total\nreputation estimation errors in the meantime.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 7 of 27\n\nMacau thus captures an important stage in trust assessment, i.e. the update of one-to-\none trustworthiness based on past transactions. It has been used to evaluate, in terms of\ntheir compliance to the properties defined above, algorithms such as TRAVOS [6] and the\nBeta Reputation System (BRS) [7] that model positive and negative experiences as ran-\ndom variables following a beta probability distribution. The comparison of trust models\nrelying on the beta distribution and their resilience to various attacks has also recently\nbeen explored in [19].\n\nART\n\nThe Agent Reputation and Trust testbed (ART) [17] provides an open-source message-\ndriven simulation engine for implementing and comparing the performance of reputation\nsystems. ART uses art painting sales as the domain.\nEach client has to sell paintings belonging to a particular era. To determine their\n\nmarket values, clients refer to agents for appraisals for a fee. Because each agent\nis an expert only in a specific era, it may not be able to provide appraisals for\npaintings from other eras and therefore refers to other agents for a fee. After such\ninteractions, agents record their experiences, calculate their reputation scores, and\nuse them to choose the most trustworthy agents for future interactions. The goal\nof each agent is to finish the simulation with the highest bank balance, and, intu-\nitively, the winning agent’s trust mechanism knows the right agents to trust for\nrecommendations.\nThe ART testbed provides a protocol that each agent must implement. The protocol\n\nspecifies the possible messages that agents can send to each other. Themessages are deliv-\nered by the simulation engine, which loops over each agent at every time interval. The\nengine is also responsible for keeping track of the bank balance of the agents, and assign-\ning new clients to agents. All results are collected and stored in a database and displayed\non a graphical user interface (GUI) at runtime.\nART is best suited for evaluating trust calculation schemes from a first person point\n\nof view. It is not meant as a platform for testing trust management as a service provided\nby the system. For example, to evaluate EigenTrust in ART, one would either need to\nconsiderably modify ART itself (for the centralized version of EigenTrust) or to require\ncooperation from the participating agents and an additional dedicated distributed infras-\ntructure (for the distributed version). Furthermore, as also pointed out in [16] and [20],\nthe comparison of the performance of different agents is not necessarily based on their\ncorrect ability to assess the reputation of other agents, but rather based on how well they\nmodel and exploit the problem domain.\n\nTREET\n\nThe Trust and Reputation Experimentation and Evaluation Testbed (TREET) [18] mod-\nels a general marketplace scenario where there are buyers, sellers, and 1,000 different\nproducts with varying prices, such that there are more inexpensive items than expensive\nones. The sale price of the products is fixed, to avoid the influence of market competition.\nThe cost of producing an item is 75% of the selling price, and the seller incurs this cost.\nTo lower this cost and increase profit, a seller can cheat by not shipping the item. Each\nproduct also has a utility value of 110% of the selling price, which encourages buyers to\npurchase.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 8 of 27\n\nAgents join or exit after 100 simulation days or after a day with a probability of 0.05,\nbut to keep the number of buyers and sellers constant, an agent is introduced for each\ndeparting agent. At initialization, each seller is assigned a random number of products\nto sell. Buyers evaluate the offers from each seller and pick a seller. Sellers are informed\nof the accepted offers and are paid. Fourteen days after a sale, the buyer knows whether\nhe has been cheated or not, depending on whether he receives the purchased item. The\nbuyer then provides feedback based on his experience of the transaction. The feedback is\nin turn used to choose sellers for future transactions.\nTREET evaluates the performance of various reputation systems under Reputation Lag\n\nattack, Proliferation attack, and Value Imbalance attack using the following metrics:\n\n1. cheater sales over honest sales ratio\n2. cheater profit over honest profit ratio\n\nMultiple seller accounts are needed to orchestrate a Proliferation Attack, but TREET\ndoes not consider attacks such as White-Washing and Self-Promoting, which require\ncreating multiple buyer accounts.\nTREET addresses many of ART’s limitation in a marketplace scenario. To name a\n\nfew [21], TREET supports both centralized and decentralized trust algorithms, allows\ncollusion attacks to be implemented, and does not put a restriction on trust score rep-\nresentation. However, like ART, the evaluation metrics in TREET are tightly coupled to\nthe marketplace domain. It is unclear how ART or TREET can be used to evaluate trust\nmodels used in other systems, such as P2P file-sharing networks, online product review\nwebsites and others that use trust. To our knowledge, there is no testbed that provides\ngeneric evaluation metrics and that is independent of the application domain.\n\nSummary\n\nTrust is a tool used in the decision-making process and it can be computed. There are\nmanymodels based on social trust that attempt to aid agents in making rational decisions.\nHowever, these models vary in terms of their input and output requirements. This makes\nevaluations against a common set of attacks difficult.\n\nProblem description andmodel\nOur goal is to have a testbed that is generic enough to accommodate as many trust\nmanagement systems and models as possible. Our requirements are:\n\n1. A model that provides an abstraction layer for developers to incorporate existing\nand new systems that match the input and output of the model.\n\n2. An evaluation framework to measure and compare the performance of trust models\nagainst trust properties and attacks independently of the application domain.\n\nIn this section, we introduce an abstract model for trust management systems. This\nmodel will be the foundation of our testbed. Our model is essentially based on the\nfollowing stages:\n\n1. In stage 1 of the trust assessment process, the feedback provided by agents on other\nagents is represented as a feedback history graph.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 9 of 27\n\n2. In stage 2, a reputation graph is produced, where the weight of an arc denotes the\nreputation of the target agent. “Reputation” here follows [14], as “an expectation\nabout an individual’s behavior based on information about or observations of its\npast behavior”. It is viewed as an estimation of trustworthiness based on a\ncombination of direct and indirect feedback.\n\n3. In the final stage, a trust graph is produced, where the existence of an arc implies\ntrust in the target agent. We take “trust” here to mean the “belief by agent A that\nagent B is trustworthy” [2, 22], and so it is boolean and subjective in our model.\n\nIn the rest of this section, we define the aforementioned graphs in stages.\n\nStage 1—obtain feedback history graph\n\nWe first define a feedback, f (a, b) ∈ R as an assessment made by agent a of an action or\ngroup of actions performed by agent b, where a and b belong to the set A of all the agents\nin the system. The list of n feedbacks by a on b, FHG(a, b), is called a feedback history,\nrepresented as follows:\n\nFHG(a, b) �→ (f1(a, b), f2(a, b), . . . , fn(a, b)) (3.1)\n\nThe feedback fi(a, b) indicates the ith satisfaction received by a from b’s action. For\nexample, in a file-sharing network, the feedback by a downloader may indicate the sat-\nisfaction received from downloading a file from an uploader in terms of a value in R.\nExisting trust models use different ranges of values for feedback, and letting the feedback\nvalue be in R allows us to include these reputation systems in our testbed.\nIf A is the set of agents, E is the set of labelled arcs (a, b), and the label is FHG(a, b)\n\nwhen FHG(a, b) \t= ∅, then the feedback histories for all agents in A are represented in a\ndirected and labelled graph called Feedback History Graph (FHG)2, FHG = (A,E):\n\nFHG : A × A → R\nN\n\n∗\n(3.2)\n\nNote that we have not included timestamps associated with each feedback (which would\nbe useful for, among other things, running our testbed as a discrete event simulator), but\nour model can be expanded to accommodate it.\nOnce the feedback history graph is obtained, the next step is to produce a reputation\n\ngraph.\n\nStage 2—obtain reputation graph\n\nA Reputation Graph (RG), RG = (A,E′\n), is a directed and weighted graph, where the\n\nweight on an arc, RG(a, b), is the trustworthiness of b from a’s perspective:\n\nRG : A × A → R (3.3)\n\nThe edges are added by computing second and nth-hand trust via transitive closure of\nedges in E. That is: if (a, b) ∈ E and (b, c) ∈ E ⇒ (a, b), (b, c), and (a, c) ∈ E′ (the value of\nthe weight of the edges, however, depends on the particular trust algorithm).\nReputation algorithms may also exhibit the reflexive property by adding looping arcs to\n\nindicate that the truster trusts itself to a certain degree for a particular task [1–3].\nThe existing literature categorizes reputation algorithms into two groups: local and\n\nglobal (Figs. 1(a) and (b), respectively) [3, 5]. Global algorithms assign a single reputa-\ntion score to each agent. Therefore, if a global algorithm is used, then the weights of the\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 10 of 27\n\nFig. 1 Examples of reputation graphs output respectively by a local and global algorithm\n\nincoming arcs of an agent should be the same, as shown in Fig. 1(b) (although for clar-\nity’s sake we will often present the graph simply as a ranking of agents in the rest of this\narticle). There is no such property for local algorithms.\nReputation algorithms may also differ in how the graphs is produced. One method is\n\nto first calculate one-to-one scores of agents using direct feedbacks and then use them\nto calculate the trustworthiness of agents previously unknown to the truster (e.g., Eigen-\nTrust). This is shown as 1a and 1b in Fig. 2. The other method (#2 in Fig. 2) skips the\nintermediate graph in the aforementioned method and produces a reputation graph (e.g.,\nPeerTrust).\n\nStage 3—obtain trust graph\n\nThe graph obtained in stage 2 contains information about the trustworthiness of agents.\nBut to use this information to make a decision about a transaction in the future, agents\nmust convert trustworthiness to boolean trust (see [23] for an example), which can also\nbe expressed as a graph. We refer to this directed graph as the Trust Graph (TG) TG =\n(A, F), where a directed edge ab ∈ F represents agent a trusting agent b.\nTo summarize ourmodel, we can represent the stages as part of a workflow as illustrated\n\nin Fig. 3.\n\nFig. 2 Two methods to obtain a reputation graph\n\n\n\n\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 11 of 27\n\nFig. 3 Overview of the stages in our model\n\nIn the next section, we see at what stages in our model do various algorithms fit, and\ndescribe criteria for chaining different algorithms.\n\nClassifying and chaining algorithms\nBy refactoring the trust models according to the stages presented in the above sections,\nwe start to see a new classification scheme. Let us take EigenTrust, PeerTrust, and Apple-\nseed as examples and describe them using our model. EigenTrust takes an FHG with\nedge labels in {0, 1}∗ as input and outputs an RG with edge labels in [ 0, 1]. PeerTrust,\non the other hand, takes an FHG with edge labels in [ 0, 1]∗ as input and outputs an\nRG with edge labels in [ 0, 1]. Meanwhile, Appleseed requires an RG with edge labels in\n[ 0, 1] as input and outputs another RG′ in the same codomain. It is also possible for an\nalgorithm to skip some stages. For example, according to our model, Aberer [5] skips\nstage 2 and does not output a reputation graph. One can also represent simple mecha-\nnisms to generate a trust graph by applying a threshold on reputation values (as output\nfor example by EigenTrust), or by selecting the top k agents. This stage transitions of\nalgorithms are depicted3 in Fig. 4. In addition to the existing classification criteria in the\nstate of the art, trust algorithms can now be classified according to their stage transi-\ntions (i.e., from one stage to another as well as transitioning within a stage) as shown in\nTable 1.\nIt is important to note that although these three algorithms output a reputation\n\ngraph with continuous reputation values between 0 and 1, the semantics of these val-\nues are different. EigenTrust outputs relative (among agents) global reputation scores,\nPeerTrust outputs an absolute global reputation score, and Appleseed produces relative\nlocal reputation scores. In other words, EigenTrust and Appleseed are ranking algorithms\n(global and local, respectively), whereas PeerTrust is not.\n\n\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 12 of 27\n\nFig. 4 Stage transitions of Trust algorithms\n\nAs we can see, each step of the trust assessment process can be viewed as a\ngraph transformation function, and we can use this functional view to easily describe\nevaluation mechanisms as well. Suppose an experimenter wants to compare PeerTrust\nand EigenTrust. The inputs and outputs of these algorithms are semantically different.\nTo match the input, we can use a function that discretizes continuous feedback values\n(f (a, b)) in [0, 1] to {-1, 1}, using some threshold t:\n\nTable 1 A classification for trust models\n\nStage Global or\nAbsolute or\n\nTrust Algorithm\nTransitions\n\nInput\nLocal\n\nRelative\nReputation Scores\n\nEigenTrust 0 → 2\nsatisfaction\n\nglobal relativeratings\n\nPeerTrust 0 → 2\nsatisfaction\n\nglobal absoluteratings\n\nAppleSeed 2 → 2\nreputation\n\nlocal absolutescores\n\nAberer & Despotovic 0 → 3 complaints global N/A\n\nAdvogato 3 → 3 certificates local N/A\n\nTRAVOS 0 → 2\nsatisfaction\n\nlocal absoluteratings\n\nRanking 2 → 3\nreputation\n\nN/A r",
      "metadata_storage_size": 2986829,
      "metadata_storage_path": "aHR0cHM6Ly9qdHJhaW5pbmdjYXRhbG9nc3RvcmFnZS5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL3M0MDQ5My0wMTUtMDAxOS16LnBkZg2",
      "metadata_author": "Partheeban Chandrasekaran",
      "metadata_title": "Toward a testbed for evaluating computational trust models: experiments and analysis",
      "metadata_creation_date": "2015-09-04T09:59:41Z",
      "people": [
        "Chandrasekaran",
        "Esfandiari",
        "Partheeban Chandrasekaran",
        "Babak Esfandiari",
        "rithms",
        "Aberer",
        "Despotovic",
        "Guha",
        "Hazard",
        "Singh"
      ],
      "organizations": [
        "Department of Systems",
        "University",
        "PeerTrust",
        "Appleseed",
        "EigenTrust",
        "Trust testbed",
        "eBay",
        "Advogato",
        "Creative Commons",
        "trust assessment",
        "Organization",
        "Trust management",
        "public key infras-",
        "certificate authority",
        "In EigenTrust",
        "TRAVOS",
        "Beta Reputation System",
        "TidalTrust",
        "Credence",
        "Aberer",
        "Marsh",
        "Abdul-Rahman",
        "AppleSeed",
        "trust",
        "global trust",
        "cijcjk",
        "trust graph",
        "trust seed",
        "reputation system",
        "trust models",
        "ART",
        "intu",
        "engine",
        "distributed infras-",
        "Trust and Reputation Experimentation and Evaluation Testbed",
        "TREET",
        "els",
        "feedback",
        "Apple",
        "ues",
        "Stage Global",
        "Trust Algorithm",
        "global",
        "absolutescores",
        "Aberer & Despotovic",
        "N/"
      ],
      "locations": [
        "Carleton",
        "Ottawa",
        "Ontario",
        "Canada",
        "Appleseed",
        "Tij",
        "trij",
        "mali",
        "Guha",
        "Macau",
        "bank",
        "N",
        "mecha",
        "satisfaction",
        "TRAVOS"
      ],
      "keyphrases": [
        "new classi- fication scheme",
        "peer file-sharing applications",
        "social networking websites",
        "comprehensive test tool",
        "Attribution 4.0 International License",
        "original author(s",
        "three trust algorithms",
        "various trust properties",
        "computational trust mechanisms",
        "online community-based systems",
        "Creative Commons license",
        "computational trust models",
        "social trust models",
        "three reputation systems",
        "different trust models",
        "RESEARCH Open Access",
        "trust assessment workflow",
        "existing reputation systems",
        "existing models",
        "Many models",
        "different stages",
        "Trust Management",
        "trust relationship",
        "Multi-agent systems",
        "Computer Engineering",
        "Introduction Motivation",
        "simple averaging",
        "based scores",
        "Advogato website",
        "application-dependent metrics",
        "transformation stage",
        "unrestricted use",
        "appropriate credit",
        "first contribution",
        "second contribution",
        "evaluation schemes",
        "Trust testbed",
        "Esfandiari Journal",
        "latest model",
        "single model",
        "generic testbed",
        "increasing need",
        "past transactions",
        "graph transformations",
        "Carleton University",
        "larger number",
        "Partheeban Chandrasekaran",
        "slandering attacks",
        "two agents",
        "Babak Esfandiari",
        "DOI",
        "experiments",
        "analysis",
        "Correspondence",
        "Department",
        "1125 Colonel",
        "Drive",
        "Ottawa",
        "Ontario",
        "Canada",
        "Abstract",
        "tesbed",
        "flexibility",
        "design",
        "prototype",
        "EigenTrust",
        "PeerTrust",
        "Appleseed",
        "vulnerabilites",
        "compliance",
        "example",
        "discrepancies",
        "trade-offs",
        "resistance",
        "self-promotion",
        "Keywords",
        "growth",
        "users",
        "history",
        "interactions",
        "calculations",
        "ratings",
        "eBay",
        "researcher",
        "tools",
        "evaluations",
        "set",
        "vulnerabilities",
        "types",
        "Overview",
        "solution",
        "contributions",
        "paper",
        "family",
        "process",
        "succession",
        "vertices",
        "meaning",
        "edges",
        "article",
        "terms",
        "creativecommons",
        "licenses",
        "distribution",
        "reproduction",
        "medium",
        "source",
        "link",
        "changes",
        "crossmark",
        "org",
        "dialog",
        "mailto",
        "Page",
        "presence",
        "existence",
        "variety",
        "certificate authority-based PKI trust models",
        "Trust management systems aid agents",
        "reputation-based trust management systems",
        "three different trust algorithms",
        "public key infras",
        "Social trust models",
        "basic trust properties",
        "social trust algorithms",
        "existing trust algorithms",
        "Beta Reputation System",
        "three systems",
        "reputation systems",
        "chaining algorithms",
        "mutual trust",
        "trust assertions",
        "trust score",
        "existing testbeds",
        "subtle interplay",
        "higher sensitivity",
        "lower sensitivity",
        "literature review",
        "implementation details",
        "actual mechanisms",
        "earlier direct",
        "indirect interactions",
        "e-commerce website",
        "third party",
        "Various inputs",
        "file-sharing network",
        "blogging website",
        "particular level",
        "specific context",
        "simple attacks",
        "self-promoting attacks",
        "Problem description",
        "research problem",
        "particular agent",
        "one attack",
        "friend chain",
        "past experiences",
        "testbed prototype",
        "aggregated trustworthiness",
        "evaluation results",
        "range",
        "differences",
        "way",
        "slandering",
        "Organization",
        "section",
        "Background",
        "state",
        "discussion",
        "Conclusions",
        "limitations",
        "tructures",
        "certificates",
        "The",
        "means",
        "order",
        "instance",
        "sellers",
        "trustworthy",
        "product",
        "drawbacks",
        "Chandrasekaran",
        "root",
        "recommendations",
        "turn",
        "recommenders",
        "Nature",
        "TRAVOS",
        "BRS",
        "satisfaction",
        "transaction",
        "P2P",
        "Aberer",
        "Despotovic",
        "plaints",
        "Advogato",
        "goal",
        "spam",
        "community",
        "TidalTrust",
        "beta probability density function",
        "late indirect trust scores",
        "other agents’ past experiences",
        "Spreading Activation model",
        "local trust scores",
        "global trust algorithms",
        "global trust score",
        "local trust algorithms",
        "three algorithms",
        "general trust",
        "Eigen- Trust",
        "Trust decisions",
        "similarity score",
        "file authenticity",
        "recommenda- tions",
        "different inputs",
        "thresholding techniques",
        "edge weights",
        "maximum “flow",
        "direct experience",
        "party recommendations",
        "different families",
        "next sections",
        "detailed descriptions",
        "respective sections",
        "satisfaction ratings",
        "trust graph",
        "direct interactions",
        "truster agent",
        "Credence",
        "votes",
        "files",
        "trustee",
        "gossiping",
        "information",
        "perspective",
        "survey",
        "Marsh",
        "Abdul-Rahman",
        "case",
        "percentage",
        "top",
        "value",
        "energy",
        "tor",
        "short",
        "third",
        "one",
        "scope",
        "testbed",
        "details",
        "output",
        "readers",
        "high local trust values",
        "low local trust values",
        "local direct trust score",
        "normalized local trust score",
        "global trust score computations",
        "current trust scores",
        "trans- action ratings",
        "local trust vector",
        "global trust scores",
        "fellow malicious agents",
        "gence threshold Tc",
        "global value",
        "trust relationships",
        "trust propagation",
        "trust graphs",
        "flow-based algorithm",
        "trust seed",
        "path length",
        "termination condition",
        "weighted graph",
        "Tij trij",
        "cij elements",
        "factor decay",
        "decay factor",
        "honest agents",
        "agent u",
        "agent j",
        "satisfaction rating",
        "transaction rating",
        "raters",
        "Eq.",
        "transactions",
        "system",
        "method",
        "input",
        "sij",
        "sum",
        "truster",
        "friends",
        "cijcjk",
        "matrix",
        "tik",
        "opinion",
        "number",
        "hops",
        "i.",
        "rank",
        "nodes",
        "trustworthiness",
        "sink",
        "amount",
        "places",
        "loops",
        "Ai",
        "step",
        "∑",
        "∈",
        "open-source message- driven simulation engine",
        "two different targets",
        "two testbed implementations",
        "document recommendation systems",
        "beta probability distribution",
        "local trust algorithm",
        "reputation estimation errors",
        "two testbed models",
        "general-purpose trust models",
        "previous reputation value",
        "art painting sales",
        "general trust systems",
        "The Agent Reputation",
        "beta distribution",
        "two roles",
        "initial value",
        "real systems",
        "trust assessment",
        "brief survey",
        "important role",
        "case studies",
        "direct feedbacks",
        "current reputation",
        "single fixpoint",
        "important stage",
        "one trustworthiness",
        "dom variables",
        "various attacks",
        "particular era",
        "market values",
        "specific era",
        "other eras",
        "reputation scores",
        "trust algorithms",
        "rating function",
        "desirable properties",
        "negative experiences",
        "mutual ratings",
        "target pairing",
        "other agents",
        "Guha Guha",
        "seed",
        "methods",
        "next",
        "look",
        "andMacau",
        "TREET",
        "investigation",
        "graph",
        "documents",
        "many",
        "specialization",
        "subclass",
        "Hazard",
        "Singh",
        "authors",
        "rater",
        "favor",
        "payoff",
        "belief",
        "likelihood",
        "future",
        "definitions",
        "Monotonicity",
        "computed",
        "b.",
        "Unambiguity",
        "convergence",
        "time",
        "Accuracy",
        "total",
        "update",
        "positive",
        "comparison",
        "resilience",
        "performance",
        "domain",
        "client",
        "paintings",
        "appraisals",
        "expert",
        "dedicated distributed infras- tructure",
        "online product review websites",
        "trust score rep- resentation",
        "graphical user interface",
        "first person point",
        "P2P file-sharing networks",
        "honest sales ratio",
        "trust calculation schemes",
        "decentralized trust algorithms",
        "highest bank balance",
        "Value Imbalance attack",
        "general marketplace scenario",
        "various reputation systems",
        "Reputation Lag attack",
        "honest profit ratio",
        "multiple buyer accounts",
        "Multiple seller accounts",
        "The ART testbed",
        "distributed version",
        "utility value",
        "Proliferation attack",
        "cheater sales",
        "other systems",
        "marketplace domain",
        "Reputation Experimentation",
        "trust mechanism",
        "trust management",
        "The Trust",
        "future interactions",
        "possible messages",
        "time interval",
        "The engine",
        "new clients",
        "correct ability",
        "problem domain",
        "Evaluation Testbed",
        "varying prices",
        "inexpensive items",
        "market competition",
        "selling price",
        "future transactions",
        "following metrics",
        "evaluation metrics",
        "simulation engine",
        "simulation days",
        "trustworthy agents",
        "right agents",
        "participating agents",
        "different agents",
        "centralized version",
        "sale price",
        "random number",
        "collusion attacks",
        "winning agent",
        "1,000 different products",
        "departing agent",
        "protocol",
        "Themessages",
        "track",
        "results",
        "database",
        "GUI",
        "runtime",
        "platform",
        "service",
        "cooperation",
        "additional",
        "model",
        "buyers",
        "influence",
        "cost",
        "purchase",
        "probability",
        "initialization",
        "offers",
        "feedback",
        "experience",
        "White-Washing",
        "Self-Promoting",
        "limitation",
        "restriction",
        "others",
        "knowledge",
        "100",
        "many trust management systems",
        "obtain feedback history graph",
        "discrete event simulator",
        "generic evaluation metrics",
        "particular trust algorithm",
        "A Reputation Graph",
        "trust assessment process",
        "Existing trust models",
        "new systems",
        "decision-making process",
        "evaluation framework",
        "labelled graph",
        "agent A",
        "Summary Trust",
        "social trust",
        "trust properties",
        "nth-hand trust",
        "application domain",
        "rational decisions",
        "abstraction layer",
        "n feedbacks",
        "ith satisfaction",
        "different ranges",
        "labelled arcs",
        "other things",
        "next step",
        "transitive closure",
        "target agent",
        "agent B",
        "indirect feedback",
        "feedback histories",
        "following stages",
        "past behavior",
        "R N",
        "common set",
        "final stage",
        "abstract model",
        "feedback value",
        "output requirements",
        "R.",
        "tool",
        "manymodels",
        "attacks",
        "andmodel",
        "developers",
        "foundation",
        "expectation",
        "individual",
        "observations",
        "estimation",
        "combination",
        "rest",
        "graphs",
        "group",
        "actions",
        "list",
        "FHG",
        "downloader",
        "uploader",
        "values",
        "timestamps",
        "directed",
        "second",
        "E.",
        "∅",
        "single reputa- tion score",
        "absolute global reputation score",
        "R b R",
        "G R b",
        "new classification scheme",
        "continuous reputation values",
        "global reputation scores",
        "existing classification criteria",
        "stage transi- tions",
        "top k agents",
        "local reputation scores",
        "obtain trust graph",
        "Global algorithms",
        "existing literature",
        "one scores",
        "Reputation algorithms",
        "particular task",
        "two groups",
        "clar- ity",
        "Two methods",
        "1a 1b",
        "next section",
        "trust models",
        "above sections",
        "Apple- seed",
        "other hand",
        "same codomain",
        "reputation graph",
        "various algorithms",
        "different algorithms",
        "edge labels",
        "other method",
        "intermediate graph",
        "local algorithms",
        "reflexive property",
        "incoming arcs",
        "among agents",
        "One method",
        "trusting agent",
        "one stage",
        "EigenTrust outputs",
        "looping",
        "degree",
        "Figs",
        "weights",
        "Fig.",
        "Examples",
        "ranking",
        "decision",
        "TG",
        "ourmodel",
        "stages",
        "workflow",
        "Classifying",
        "RG",
        "nisms",
        "threshold",
        "transitions",
        "addition",
        "Table",
        "semantics",
        "relative",
        "0.",
        "End Feedback history Trust Graph Stage",
        "Trust Algorithm Transitions Input",
        "satisfaction local absoluteratings Ranking",
        "continuous feedback values",
        "History Ax A",
        "trust models Stage",
        "RG Feedback Preconditions",
        "Graph Ax A",
        "graph transformation function",
        "Reputation Graph Post-conditions",
        "Stage transitions",
        "Trust algorithms",
        "global absoluteratings",
        "local absolutescores",
        "FHG Stage",
        "ranking algorithms",
        "other words",
        "TG Preconditions",
        "R Post-conditions",
        "functional view",
        "evaluation mechanisms",
        "global relativeratings",
        "Reputation Scores",
        "N/A r",
        "RR",
        "experimenter",
        "inputs",
        "outputs",
        "classification",
        "3 complaints",
        "3 certificates",
        "1",
        "4"
      ],
      "merged_content": "\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 \nDOI 10.1186/s40493-015-0019-z\n\nRESEARCH Open Access\n\nToward a testbed for evaluating\ncomputational trust models: experiments\nand analysis\nPartheeban Chandrasekaran and Babak Esfandiari*\n\n*Correspondence:\nbabak@sce.carleton.ca\nDepartment of Systems and\nComputer Engineering, Carleton\nUniversity, 1125 Colonel By Drive,\nOttawa, Ontario K1s5B6, Canada\n\nAbstract\nWe propose a generic testbed for evaluating social trust models and we show how\nexisting models can fit our tesbed. To showcase the flexibility of our design, we\nimplemented a prototype and evaluated three trust algorithms, namely EigenTrust,\nPeerTrust and Appleseed, for their vulnerabilites to attacks and compliance to various\ntrust properties. For example, we were able to exhibit discrepancies between\nEigenTrust and PeerTrust, as well as trade-offs between resistance to slandering attacks\nversus self-promotion.\n\nKeywords: Trust testbed; Reputation; Multi-agent systems\n\nIntroduction\nMotivation\n\nWith the growth of online community-based systems such as peer-to-peer file-sharing\napplications, e-commerce and social networking websites, there is an increasing need to\nprovide computational trust mechanisms to determine which users or agents are honest\nand which ones are malicious. Many models calculate trust by relying on analyzing a\nhistory of interactions. The calculations can range from the simple averaging of ratings\non eBay to flow-based scores in the Advogato website. Thus for a researcher to evaluate\nand compare his or her latest model against existing ones, a comprehensive test tool is\nneeded. However, our research shows that the tools that exist to assist researchers are not\nflexible enough to include different trust models and their evaluations. Moreover, these\ntools use their own set of application-dependent metrics to evaluate a reputation system.\nThis means that a number of trust models cannot be evaluated for vulnerabilities against\ncertain types of attacks. Thus, there is still a need for a generic testbed to evaluate and\ncompare computational trust models.\n\nOverview of our solution and contributions\n\nIn this paper, we present a model and a testbed for evaluating a family of trust algo-\nrithms that rely on past transactions between agents. Trust assessment is viewed as a\nprocess consisting of a succession of graph transformations, where the agents form the\nvertices of the graph. The meaning of the edges depends on the transformation stage,\n\n© 2015 Chandrasekaran and Esfandiari. Open Access This article is distributed under the terms of the Creative Commons\nAttribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution,\nand reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to\nthe Creative Commons license, and indicate if changes were made.\n\n  \n\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40493-015-0019-z-x&domain=pdf\nmailto: babak@sce.carleton.ca\nhttp://creativecommons.org/licenses/by/4.0/\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 2 of 27\n\nand can refer to the presence of transactions between the two agents or the existence\nof a trust relationship between them. Our first contribution is to show that with this\nview, existing reputation systems can be adopted under a single model, but they work at\ndifferent stages of the trust assessment workflow. This allows us to present a new classi-\nfication scheme for a number of trust models based on where they fit in the assessment\nworkflow. The second contribution of our work is that this workflow can be described\nformally, and by doing this, we show that it is possible to model a variety of attacks\nand evaluation schemes. Finally, out of the larger number of systems we classified, we\nselected three reputation systems, namely EigenTrust [1], PeerTrust [2] and Appleseed\n[3], to exemplify the range and variety of reputation systems that our testbed can accom-\nmodate. We evaluated these three systems in our testbed against simple attacks and\nwe validated their compliance to basic trust properties. In particular, we were able to\nexhibit differences in the way EigenTrust and PeerTrust rank the agents, we observed\nthe subtle interplay between slandering and self-promoting attacks (higher sensitivity\nto one attack can lead to lower sensitivity to the other), and we verified that trust\nweakens along a friend-of-a-friend chain and that it is more easily lost than gained\n(as it should be).\n\nOrganization\n\nThis article is organized as follows: section ‘Background and literature review’ provides\nbackground and state of the art on trust models, attacks against them, and existing\ntestbeds for evaluation. Section ‘Problem description and model’ formulates the research\nproblem of this article and proposes our model for a testbed. Section ‘Classifying and\nchaining algorithms’ shows how some of existing trust algorithms can fit our model, and\nhow one can combine or compare them using our model and testbed. Section ‘Results and\ndiscussion’ describes the implementation details of our testbed prototype and presents\nevaluation results of three different trust algorithms, namely EigenTrust, PeerTrust, and\nAppleseed. Section ‘Conclusions’ concludes this article and summarizes the contributions\nand limitations of our work.\n\nBackground and literature review\nSocial trust models\n\nTrust management systems aid agents in establishing and assessing mutual trust. How-\never, the actual mechanisms used in these systems vary. For example, public key infras-\ntructures [4] rely on certificates whereas reputation-based trust management systems are\nbased on experiences of earlier direct and indirect interactions [5].\nIn this paper we will focus on social trust models based on reputation. The trust model\n\nshould provide a means to compare the trustworthiness of agents in order to choose a\nparticular agent to perform an action. For instance, on an e-commerce website like eBay,\nwe need to be able to compare the trustworthiness of sellers in order to pick the most\ntrustworthy one to buy a product from.\nSocial trust models rely on past experiences of agents to produce trust assertions. That\n\nis, the agents in the system interact with each other and record their experiences, which\nare then used to determine whether a particular agent is trustworthy. This model is self-\nsufficient because it does not rely on a third party to propagate trust, like it would in\ncertificate authority-based PKI trust models. However, there are drawbacks to having no\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 3 of 27\n\nroot of trust. For instance, agents evaluating the trustworthiness of agents with whom\nthere has been no interaction must use recommendations from others and, in turn,\nevaluate the trustworthiness of the recommenders. Social trust models must address this\nproblem.\n\nNature of input\n\nVarious inputs are used by social trust algorithms to measure the trustworthiness of\nagents. In EigenTrust [1], PeerTrust [2], TRAVOS [6] and Beta Reputation System (BRS)\n[7], agents rate their satisfaction after a transaction (e.g., downloading a file in a P2P\nfile-sharing network). These ratings are used to obtain a trust score that represents the\ntrustworthiness of the agent. In Aberer and Despotovic’s system [5]1, agents may file com-\nplaints (can be seen as dissatisfaction) about each other after a transaction. In Advogato\n[8], whose goal is to discourage spam on its blogging website, users explicitly certify\neach other as belonging to a particular level in the community. Trust algorithms may\nalso directly use trust scores among agents to compute an aggregated trustworthiness\nof agents, as in TidalTrust [9] and Appleseed [3]. In the specific context of P2P file-\nsharing, Credence [10] uses the votes on file authenticity to calculate a similarity score\nbetween agents and uses it to measure trust. The trust score is then used to recommend\nfiles.\n\nDirect vs. indirect trust\n\nThe truster may use some or all of its own and other agents’ past experiences with the\ntrustee to obtain a trust score. Trust algorithms often use gossiping to poll agents with\nwhom the truster has had interactions in the past.\nThe trust score calculated using only the experiences from direct interactions is\n\ncalled the direct trust score, while the trust score calculated using the recommenda-\ntions from other agents is called the indirect trust score [11]. As mentioned earlier,\nreputation systems use different inputs (satisfaction ratings, votes, certificates, etc.) to\ncalculate direct trust scores and indirect trust scores. PeerTrust uses satisfaction ratings\nto calculate both direct and indirect trust scores, whereas EigenTrust and TRAVOS\nuse satisfaction ratings to calculate direct trust scores, which they then use to calcu-\nlate indirect trust scores. Therefore, we can categorize the trust algorithms based on\nthe input required. But how do trust algorithms calculate the trust scores of agents\nusing the above information? It again varies from algorithm to algorithm. For instance,\nPeerTrust, EigenTrust, and Aberer use simple averaging of ratings, TRAVOS and BRS\nuse the beta probability density function, and Appleseed uses the Spreading Activation\nmodel.\n\nGlobal vs. local trust\n\nThe trust algorithm may output a global trust score or a local trust score [3, 12]. A global\ntrust score is one that represents the general trust that all agents have on a particular\nagent, whereas local trust scores represents the trust from the perspective of the truster\nand thus each truster may trust an agent differently. In our survey, we found PeerTrust,\nEigenTrust, and Aberer to be global trust algorithms whereas TRAVOS, BRS, Credence,\nAdvogato, TidalTrust, Appleseed, Marsh [13] and Abdul-Rahman [14] are local trust\nalgorithms.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 4 of 27\n\nTo trust or not to trust\n\nOnce the trust score is calculated, it can be used to decide whether to trust the agent. It\ncan be as simple as comparing the trust score against a threshold: if the trust score is above\na certain threshold, then the agent is trusted. Marsh [13], and Aberer [5] use thresholding\ntechniques. If the trust algorithm outputs normalized trust scores of agents as in Eigen-\nTrust, then the trust scores of agents are ranked. In this case, one may consider a certain\npercentage of the top ranked agents as trustworthy. In Appleseed, a graph is first obtained\nwith trust scores of agents as edge weights, and then, the truster agent is “injected” with\na value called the activation energy. This energy is spread to agents with a spreading fac-\ntor along the edges in the graph and the algorithm ranks the agents according to their\ntrust scores. Trust decisions can also be flow-based such as in Advogato, which calculates\na maximum “flow of trust” in the trust graph to determine which agents are trustworthy\nand which are not.\nIn short, social trust models focus on the following:\n\n1. What is the input to calculate the trust score of an agent?\n2. Does the trust algorithm use only direct experience or does it also rely on third\n\nparty recommendations?\n3. Is the trust score of an agent global or local?\n4. How does one decide whether to trust an agent?\n\nGiven the above discussion, and to assess the scope of our testbed, we propose tomodel,\nevaluate and compare three algorithms from fairly different families. The next sections\nprovide detailed descriptions of the trust models we selected and that we implemented in\nour testbed. The details are given to help understand the output of our experiments, but\nreaders familiar with EigenTrust, PeerTrust and/or AppleSeed may skip those respective\nsections.\n\nPeerTrust\n\nIn PeerTrust, agents rate each other in terms of the satisfaction received. These ratings\nare weighted by trust scores of the raters, and a global trust score is computed recursively\nusing Eq. 2.1, where:\n\n• T(u) is the trust score of agent u\n• I(u) is the set of transactions that agent u had with all the agents in the system\n• S(u, i) is the satisfaction rating on u for transaction i\n• p(u, i) is the agent that provided the rating.\n\nT(u) =\nI(u)∑\ni=1\n\nS(u, i) × T(p(u, i))∑I(u)\nj=1 T(p(u, j))\n\n(2.1)\n\nPeerTrust also provides a method for calculating local trust scores. In both local and\nglobal trust score computations, the trust score is compared against a threshold to decide\nwhether to trust or not.\n\nEigenTrust\n\nAgents in EigenTrust rate transactions as satisfactory or unsatisfactory [1]. These trans-\naction ratings are used as input, to calculate a local direct trust score, from which a global\ntrust score is then calculated.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 5 of 27\n\nAn agent i calculates the normalized local trust score of agent j, as shown in Eq. 2.2,\nwhere tij ∈ {+1,−1} is the transaction rating, and sij is the sum of ratings.\n\nsij =\n∑\nTij\n\ntrij\n\ncij = max(sij, 0)∑\nk max(sik , 0)\n\n(2.2)\n\nNote that we cannot use sij as the local trust score without normalizing, because mali-\ncious agents can arbitrarily assign high local trust values to fellow malicious agents and\nlow local trust values to honest agents.\nTo calculate the global trust score of an agent, the truster queries his friends for their\n\ntrust scores on the trustee. These local trust scores are aggregated, as shown in Eq. 2.3.\n\ntik =\n∑\nj\ncijcjk (2.3)\n\nIf we let C be the matrix containing cij elements, �ci be the local trust vector for i (each\nelement corresponds to the trust that i has in j), and �ti the vector containing tik , then,\n\n�ti = CT �ci (2.4)\n\nBy asking a friend’s friend’s opinion, Eq. 2.4 becomes �ti = (CT )2 �ci. If an agent keeps\nasking the opinions of its friends of friends, the whole trust graph can be explored, and\nEq. 2.4 becomes Eq. 2.5, where n is the number of hops from i.\n\n�t = (CT )n �ci (2.5)\n\nThe trust scores of the agents converge to a global value irrespective of the trustee.\nBecause EigenTrust outputs global trust scores (normalized over the sum of all agents),\n\nagents are ranked according to their trust scores (unlike PeerTrust). Therefore, an agent\nis considered trustworthy if it is within a certain rank.\n\nAppleseed\n\nAppleseed is a flow-based algorithm [3]. Assuming that we are given a directed weighted\ngraph with agents as nodes, edges as trust relationships, and the weight of an edge as\ntrustworthiness of the sink, we can determine the amount of trust that flows in the graph.\nThat is, given a trust seed, an energy in ∈ R\n\n+\n0 , spreading factor decay ∈[ 0, 1], and conver-\n\ngence threshold Tc, Appleseed returns a trust score of agents from the perspective of the\ntrust seed.\nThe trust propagation from agent a to agent b is determined using Eq. 2.6, where the\n\nweight of edge (a, b) represents the amount of trust a places in b, and in(a) and in(b)\nrepresent the flow of trust into a and b, respectively.\n\nin(b) = decay ×\n∑\n\n(a,b)∈E\nin(a) × weight(a, b)∑\n\n(a,c)∈E weight(a, c)\n(2.6)\n\nThe trust of an agent b (trust(b)) is then updated using Eq. 2.7, where the decay factor\nensures that trust in an agent decreases as the path length from the seed increases.\n\ntrust(b) := trust(b) + (1 − decay) × in(b) (2.7)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 6 of 27\n\nGenerally, trust graphs have loops, which makes Eq. 2.7 recursive. Thus a termination\ncondition like the one below is required, where Ai ⊆ A is the set of nodes that were\ndiscovered until step i and trusti(x) is the current trust scores for all x ∈ Ai:\n\n∀x ∈ Ai : trusti(x) − trusti−1(x) ≤ Tc (2.8)\n\nAfter Eq. 2.7 terminates, the trust scores of agents are ranked. Since this set is ranked\nfrom the perspective of the seed, Appleseed is a local trust algorithm.\nAs our brief survey shows, the trust models vary in terms of their input, output, and\n\nthe methods they use. To evaluate and compare them, testbeds are needed. In the next\nsection we take a look at existing testbeds.\n\nTestbeds\n\nWe investigated two testbed models, namely Guha’s [15] andMacau [16], and two testbed\nimplementations, namely ART [17] and TREET [18], which are used to evaluate trust\nalgorithms. This section provides details of our investigation.\n\nGuha\n\nGuha [15] proposes a model to capture document recommendation systems, where trust\nand reputation play an important role. The model relies on a graph of agents where the\nedges can be weighted based on their mutual ratings, and a rating function for documents\nby agents. Guha then discusses how trust can be calculated based on those ratings, and\nevaluates a few case studies of real systems that can be accommodated by the model.\nGuha’s model can capture trust systems that take a set of documents and their ratings\n\nas input (such as Credence [10]), but it cannot accommodate systems where the only\ninput consists of direct feedbacks between agents, such as in PeerTrust (global) [2] or\nEigenTrust [1]. Also, the rating of documents is itself an output of Guha’s model, and that\nis often not the purpose or output of many more general-purpose trust models.\nIn short, document recommendation systems can be viewed as a specialization or\n\nsubclass of more general trust systems, and Guha’s model is suitable for that subclass.\n\nMacau\n\nHazard and Singh’s Macau [16] is a model for evaluating reputation systems. The authors\ndistinguish two roles for any agent: a rater that evaluates a target. Transactions are viewed\nas a favor provided by the target to the rater. The target’s reputation, local to each rater-\ntarget pairing, is updated after each transaction and depends on the previous reputation\nvalue. The target’s payoff in giving a favor is also dependent on its current reputation but\nalso on its belief of the likelihood that the rater will in turn return the favor in the future.\nBased on the above definitions, the authors define a set of desirable properties for a\n\nreputation system:\n\n• Monotonicity: given two different targets a and b, the computed reputation of a\nshould be higher than that of b if the predicted payoff of a transaction with a is\nhigher than with b.\n\n• Unambiguity and convergence: the reputation should converge over time to a single\nfixpoint, regardless of its initial value.\n\n• Accuracy: this convergence should happen quickly, thus minimizing the total\nreputation estimation errors in the meantime.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 7 of 27\n\nMacau thus captures an important stage in trust assessment, i.e. the update of one-to-\none trustworthiness based on past transactions. It has been used to evaluate, in terms of\ntheir compliance to the properties defined above, algorithms such as TRAVOS [6] and the\nBeta Reputation System (BRS) [7] that model positive and negative experiences as ran-\ndom variables following a beta probability distribution. The comparison of trust models\nrelying on the beta distribution and their resilience to various attacks has also recently\nbeen explored in [19].\n\nART\n\nThe Agent Reputation and Trust testbed (ART) [17] provides an open-source message-\ndriven simulation engine for implementing and comparing the performance of reputation\nsystems. ART uses art painting sales as the domain.\nEach client has to sell paintings belonging to a particular era. To determine their\n\nmarket values, clients refer to agents for appraisals for a fee. Because each agent\nis an expert only in a specific era, it may not be able to provide appraisals for\npaintings from other eras and therefore refers to other agents for a fee. After such\ninteractions, agents record their experiences, calculate their reputation scores, and\nuse them to choose the most trustworthy agents for future interactions. The goal\nof each agent is to finish the simulation with the highest bank balance, and, intu-\nitively, the winning agent’s trust mechanism knows the right agents to trust for\nrecommendations.\nThe ART testbed provides a protocol that each agent must implement. The protocol\n\nspecifies the possible messages that agents can send to each other. Themessages are deliv-\nered by the simulation engine, which loops over each agent at every time interval. The\nengine is also responsible for keeping track of the bank balance of the agents, and assign-\ning new clients to agents. All results are collected and stored in a database and displayed\non a graphical user interface (GUI) at runtime.\nART is best suited for evaluating trust calculation schemes from a first person point\n\nof view. It is not meant as a platform for testing trust management as a service provided\nby the system. For example, to evaluate EigenTrust in ART, one would either need to\nconsiderably modify ART itself (for the centralized version of EigenTrust) or to require\ncooperation from the participating agents and an additional dedicated distributed infras-\ntructure (for the distributed version). Furthermore, as also pointed out in [16] and [20],\nthe comparison of the performance of different agents is not necessarily based on their\ncorrect ability to assess the reputation of other agents, but rather based on how well they\nmodel and exploit the problem domain.\n\nTREET\n\nThe Trust and Reputation Experimentation and Evaluation Testbed (TREET) [18] mod-\nels a general marketplace scenario where there are buyers, sellers, and 1,000 different\nproducts with varying prices, such that there are more inexpensive items than expensive\nones. The sale price of the products is fixed, to avoid the influence of market competition.\nThe cost of producing an item is 75% of the selling price, and the seller incurs this cost.\nTo lower this cost and increase profit, a seller can cheat by not shipping the item. Each\nproduct also has a utility value of 110% of the selling price, which encourages buyers to\npurchase.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 8 of 27\n\nAgents join or exit after 100 simulation days or after a day with a probability of 0.05,\nbut to keep the number of buyers and sellers constant, an agent is introduced for each\ndeparting agent. At initialization, each seller is assigned a random number of products\nto sell. Buyers evaluate the offers from each seller and pick a seller. Sellers are informed\nof the accepted offers and are paid. Fourteen days after a sale, the buyer knows whether\nhe has been cheated or not, depending on whether he receives the purchased item. The\nbuyer then provides feedback based on his experience of the transaction. The feedback is\nin turn used to choose sellers for future transactions.\nTREET evaluates the performance of various reputation systems under Reputation Lag\n\nattack, Proliferation attack, and Value Imbalance attack using the following metrics:\n\n1. cheater sales over honest sales ratio\n2. cheater profit over honest profit ratio\n\nMultiple seller accounts are needed to orchestrate a Proliferation Attack, but TREET\ndoes not consider attacks such as White-Washing and Self-Promoting, which require\ncreating multiple buyer accounts.\nTREET addresses many of ART’s limitation in a marketplace scenario. To name a\n\nfew [21], TREET supports both centralized and decentralized trust algorithms, allows\ncollusion attacks to be implemented, and does not put a restriction on trust score rep-\nresentation. However, like ART, the evaluation metrics in TREET are tightly coupled to\nthe marketplace domain. It is unclear how ART or TREET can be used to evaluate trust\nmodels used in other systems, such as P2P file-sharing networks, online product review\nwebsites and others that use trust. To our knowledge, there is no testbed that provides\ngeneric evaluation metrics and that is independent of the application domain.\n\nSummary\n\nTrust is a tool used in the decision-making process and it can be computed. There are\nmanymodels based on social trust that attempt to aid agents in making rational decisions.\nHowever, these models vary in terms of their input and output requirements. This makes\nevaluations against a common set of attacks difficult.\n\nProblem description andmodel\nOur goal is to have a testbed that is generic enough to accommodate as many trust\nmanagement systems and models as possible. Our requirements are:\n\n1. A model that provides an abstraction layer for developers to incorporate existing\nand new systems that match the input and output of the model.\n\n2. An evaluation framework to measure and compare the performance of trust models\nagainst trust properties and attacks independently of the application domain.\n\nIn this section, we introduce an abstract model for trust management systems. This\nmodel will be the foundation of our testbed. Our model is essentially based on the\nfollowing stages:\n\n1. In stage 1 of the trust assessment process, the feedback provided by agents on other\nagents is represented as a feedback history graph.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 9 of 27\n\n2. In stage 2, a reputation graph is produced, where the weight of an arc denotes the\nreputation of the target agent. “Reputation” here follows [14], as “an expectation\nabout an individual’s behavior based on information about or observations of its\npast behavior”. It is viewed as an estimation of trustworthiness based on a\ncombination of direct and indirect feedback.\n\n3. In the final stage, a trust graph is produced, where the existence of an arc implies\ntrust in the target agent. We take “trust” here to mean the “belief by agent A that\nagent B is trustworthy” [2, 22], and so it is boolean and subjective in our model.\n\nIn the rest of this section, we define the aforementioned graphs in stages.\n\nStage 1—obtain feedback history graph\n\nWe first define a feedback, f (a, b) ∈ R as an assessment made by agent a of an action or\ngroup of actions performed by agent b, where a and b belong to the set A of all the agents\nin the system. The list of n feedbacks by a on b, FHG(a, b), is called a feedback history,\nrepresented as follows:\n\nFHG(a, b) �→ (f1(a, b), f2(a, b), . . . , fn(a, b)) (3.1)\n\nThe feedback fi(a, b) indicates the ith satisfaction received by a from b’s action. For\nexample, in a file-sharing network, the feedback by a downloader may indicate the sat-\nisfaction received from downloading a file from an uploader in terms of a value in R.\nExisting trust models use different ranges of values for feedback, and letting the feedback\nvalue be in R allows us to include these reputation systems in our testbed.\nIf A is the set of agents, E is the set of labelled arcs (a, b), and the label is FHG(a, b)\n\nwhen FHG(a, b) \t= ∅, then the feedback histories for all agents in A are represented in a\ndirected and labelled graph called Feedback History Graph (FHG)2, FHG = (A,E):\n\nFHG : A × A → R\nN\n\n∗\n(3.2)\n\nNote that we have not included timestamps associated with each feedback (which would\nbe useful for, among other things, running our testbed as a discrete event simulator), but\nour model can be expanded to accommodate it.\nOnce the feedback history graph is obtained, the next step is to produce a reputation\n\ngraph.\n\nStage 2—obtain reputation graph\n\nA Reputation Graph (RG), RG = (A,E′\n), is a directed and weighted graph, where the\n\nweight on an arc, RG(a, b), is the trustworthiness of b from a’s perspective:\n\nRG : A × A → R (3.3)\n\nThe edges are added by computing second and nth-hand trust via transitive closure of\nedges in E. That is: if (a, b) ∈ E and (b, c) ∈ E ⇒ (a, b), (b, c), and (a, c) ∈ E′ (the value of\nthe weight of the edges, however, depends on the particular trust algorithm).\nReputation algorithms may also exhibit the reflexive property by adding looping arcs to\n\nindicate that the truster trusts itself to a certain degree for a particular task [1–3].\nThe existing literature categorizes reputation algorithms into two groups: local and\n\nglobal (Figs. 1(a) and (b), respectively) [3, 5]. Global algorithms assign a single reputa-\ntion score to each agent. Therefore, if a global algorithm is used, then the weights of the\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 10 of 27\n\nFig. 1 Examples of reputation graphs output respectively by a local and global algorithm\n\nincoming arcs of an agent should be the same, as shown in Fig. 1(b) (although for clar-\nity’s sake we will often present the graph simply as a ranking of agents in the rest of this\narticle). There is no such property for local algorithms.\nReputation algorithms may also differ in how the graphs is produced. One method is\n\nto first calculate one-to-one scores of agents using direct feedbacks and then use them\nto calculate the trustworthiness of agents previously unknown to the truster (e.g., Eigen-\nTrust). This is shown as 1a and 1b in Fig. 2. The other method (#2 in Fig. 2) skips the\nintermediate graph in the aforementioned method and produces a reputation graph (e.g.,\nPeerTrust).\n\nStage 3—obtain trust graph\n\nThe graph obtained in stage 2 contains information about the trustworthiness of agents.\nBut to use this information to make a decision about a transaction in the future, agents\nmust convert trustworthiness to boolean trust (see [23] for an example), which can also\nbe expressed as a graph. We refer to this directed graph as the Trust Graph (TG) TG =\n(A, F), where a directed edge ab ∈ F represents agent a trusting agent b.\nTo summarize ourmodel, we can represent the stages as part of a workflow as illustrated\n\nin Fig. 3.\n\nFig. 2 Two methods to obtain a reputation graph\n\n R b R b 0.7 0.8 0.8 1.0 0.2 0.2 0.2 0.8 a 0.6 0.4 C a C 1.0 1.0 a b \n\n G R b (0.7, 0.8, 0.9) b 2 (1.0, 1.0) 0.8 1.0 C a C a 0.7 1a 1b b 0.8 1.0 a C \n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 11 of 27\n\nFig. 3 Overview of the stages in our model\n\nIn the next section, we see at what stages in our model do various algorithms fit, and\ndescribe criteria for chaining different algorithms.\n\nClassifying and chaining algorithms\nBy refactoring the trust models according to the stages presented in the above sections,\nwe start to see a new classification scheme. Let us take EigenTrust, PeerTrust, and Apple-\nseed as examples and describe them using our model. EigenTrust takes an FHG with\nedge labels in {0, 1}∗ as input and outputs an RG with edge labels in [ 0, 1]. PeerTrust,\non the other hand, takes an FHG with edge labels in [ 0, 1]∗ as input and outputs an\nRG with edge labels in [ 0, 1]. Meanwhile, Appleseed requires an RG with edge labels in\n[ 0, 1] as input and outputs another RG′ in the same codomain. It is also possible for an\nalgorithm to skip some stages. For example, according to our model, Aberer [5] skips\nstage 2 and does not output a reputation graph. One can also represent simple mecha-\nnisms to generate a trust graph by applying a threshold on reputation values (as output\nfor example by EigenTrust), or by selecting the top k agents. This stage transitions of\nalgorithms are depicted3 in Fig. 4. In addition to the existing classification criteria in the\nstate of the art, trust algorithms can now be classified according to their stage transi-\ntions (i.e., from one stage to another as well as transitioning within a stage) as shown in\nTable 1.\nIt is important to note that although these three algorithms output a reputation\n\ngraph with continuous reputation values between 0 and 1, the semantics of these val-\nues are different. EigenTrust outputs relative (among agents) global reputation scores,\nPeerTrust outputs an absolute global reputation score, and Appleseed produces relative\nlocal reputation scores. In other words, EigenTrust and Appleseed are ranking algorithms\n(global and local, respectively), whereas PeerTrust is not.\n\n Start End Feedback history Trust Graph Stage 1: Obtain FHG Stage 3: Obtain TG Preconditions: Preconditions: {fı(a, b), f2(a, b), ..., fn (a, b)} Ax A - R Post-conditions: Post-conditions: Ax A - RR\" A x A -+ [0, 1] Stage 2: Obtain RG Feedback Preconditions: History Ax A - R\" Reputation Graph Post-conditions: Graph Ax A - R \n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 12 of 27\n\nFig. 4 Stage transitions of Trust algorithms\n\nAs we can see, each step of the trust assessment process can be viewed as a\ngraph transformation function, and we can use this functional view to easily describe\nevaluation mechanisms as well. Suppose an experimenter wants to compare PeerTrust\nand EigenTrust. The inputs and outputs of these algorithms are semantically different.\nTo match the input, we can use a function that discretizes continuous feedback values\n(f (a, b)) in [0, 1] to {-1, 1}, using some threshold t:\n\nTable 1 A classification for trust models\n\nStage Global or\nAbsolute or\n\nTrust Algorithm\nTransitions\n\nInput\nLocal\n\nRelative\nReputation Scores\n\nEigenTrust 0 → 2\nsatisfaction\n\nglobal relativeratings\n\nPeerTrust 0 → 2\nsatisfaction\n\nglobal absoluteratings\n\nAppleSeed 2 → 2\nreputation\n\nlocal absolutescores\n\nAberer & Despotovic 0 → 3 complaints global N/A\n\nAdvogato 3 → 3 certificates local N/A\n\nTRAVOS 0 → 2\nsatisfaction\n\nlocal absoluteratings\n\nRanking 2 → 3\nreputation\n\nN/A r",
      "text": [
        "",
        "R b R b 0.7 0.8 0.8 1.0 0.2 0.2 0.2 0.8 a 0.6 0.4 C a C 1.0 1.0 a b",
        "G R b (0.7, 0.8, 0.9) b 2 (1.0, 1.0) 0.8 1.0 C a C a 0.7 1a 1b b 0.8 1.0 a C",
        "Start End Feedback history Trust Graph Stage 1: Obtain FHG Stage 3: Obtain TG Preconditions: Preconditions: {fı(a, b), f2(a, b), ..., fn (a, b)} Ax A - R Post-conditions: Post-conditions: Ax A - RR\" A x A -+ [0, 1] Stage 2: Obtain RG Feedback Preconditions: History Ax A - R\" Reputation Graph Post-conditions: Graph Ax A - R",
        "Stage transitions Feedback History Output: A x A => [0, 1] Input: A x A => {-1, 1]* FHG RG TG fully connected global relative rep. scores Input: A x A => [0, 1]* Ouput: A x A => [0, 1] Feedback History FHG RG TG fully connected global absolute rep. scores Input: A x A => [0, 1] Output: Ax A => [0, 1] local Feedback History FHG RG TG partially connected local absolute rep.scores Appleseed | PeerTrust | EigenTrust Input: A x A => {-1, 1]* Feedback History FHG DO TG Output: Ax A => {0, 1} fully connected global Aberer & Despotovic Input: Ax A => {0, 1} Feedback History Ouput: Ax A => {0, 1} FHG RG TG partially connected, local Input: A x A => {0, 1]* Feedback History FHG RG TG Ouput: Ax A => [0, 1] local absolute rep. scores TRAVOS |Advogato Input: A x A => [0, 1] relative rep. scores Feedback History FHG RG TG Output: A x A => {0, 1} partially connected Input: A x A => [0, 1] absolute rep. scores Feedback History FHG RG TG Output: A x A => {0, 1} partially connected Thresholding Ranking",
        "FHGO PeerTrust Preconditions: A x A + [0,1]* Post-conditions: RG2 Discretizer Fully connected, global, Preconditions: A x A + [0, 1]* absolute r(a,b) A x A ++ [0, 1] Post-conditions Normalizer Ax A ++ {-1,1}* Preconditions: A x A ++ [0, 1] Post-conditions: Fully connected, global, FHG1 relative r(a, b) A x A ++ [0, 1] EigenTrust Preconditions: RG3 Ax A ++ {-1,1}* RG1 Post-conditions: Fully connected, global, relative r(a, b) Spearman A x A ++ [0, 1] Correlation coefficient",
        "0 0 {1.0, 1.0, 1.0} 1.0, 1.0, 1.0} 1 1 {1.0, 1.0, 1.0} (1.0, 1.0, 0.0} 2 2 [0.0, 0.0, 0.0} 10.0, 0.0, 0.0} 3 3",
        "0 0 0 0.22 (1.0, 1.0, 1.0} {1.0, 1.0, 1.0} 0.3 0.22 1 1 1 0.3 0.22 0.12 {1.0, 1.0, 1.0} {1.0, 1.0, 1.0} K1.0, 1.0, 1.0} 0.3 0.12 0.36 0.22 2 2 0.36 0.3 3 0.12 K0.0, 0.0, 0.0} {0.0, 0.0, 0.0} 0.36 /0.12 3 3 2 00.36",
        "0 0 {1.0, 1.0, 1.0} {1.0, 1.0, 1.0} 1 1 {1.0, 1.0, 1.0} {1.0, 1.0, 1.0} K0.0, 0.0, 0.0} 2 2 (0.0, 0.0, 0.0} {0.0, 0.0, 0.0} 3 3",
        "0 0 (1.0, 1.0, 1.0} {1.0, 1.0, 1.0} 1 1 {1.0, 1.0, 1.0} {1.0, 1.0, 1.0} 2 2 [0.0, 0.0, 0.0} {0.0, 0.0, 0.0}[0.0, 0.0. 0.0} 3 3",
        "1.0 1.0 2 0.0 1.0 3",
        "0 1.0 1 1.0 0.0 0.0 0.0 0.0 0.0 0.0 2 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 6 4 3 11 5 12 9 13 8 10",
        "1.0 1 1.0 1.0 2 3",
        "? 1 2 3",
        "0 1.0 1.0 1 4 1.0 1.0 1.0 2 3",
        "0 1 2 3 5",
        "1.0 1 1.0 2 1.0 1.0 3",
        "0 1 2 3",
        "4 2 r 1.5 1 0.5 Feedback value,f & Reputation,r 0 2 3 4 15 1 Feedback, i",
        "Published online: 07 September 2015"
      ],
      "layoutText": [
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"R b R b 0.7 0.8 0.8 1.0 0.2 0.2 0.2 0.8 a 0.6 0.4 C a C 1.0 1.0 a b\",\"lines\":[{\"boundingBox\":[{\"x\":135,\"y\":88},{\"x\":165,\"y\":87},{\"x\":166,\"y\":116},{\"x\":135,\"y\":117}],\"text\":\"R\"},{\"boundingBox\":[{\"x\":272,\"y\":110},{\"x\":299,\"y\":109},{\"x\":299,\"y\":135},{\"x\":274,\"y\":135}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":720,\"y\":88},{\"x\":747,\"y\":87},{\"x\":749,\"y\":115},{\"x\":721,\"y\":116}],\"text\":\"R\"},{\"boundingBox\":[{\"x\":860,\"y\":100},{\"x\":883,\"y\":101},{\"x\":883,\"y\":130},{\"x\":861,\"y\":129}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":417,\"y\":138},{\"x\":466,\"y\":142},{\"x\":466,\"y\":170},{\"x\":415,\"y\":168}],\"text\":\"0.7\"},{\"boundingBox\":[{\"x\":109,\"y\":170},{\"x\":157,\"y\":169},{\"x\":157,\"y\":198},{\"x\":110,\"y\":197}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":723,\"y\":148},{\"x\":770,\"y\":147},{\"x\":771,\"y\":174},{\"x\":723,\"y\":176}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":1005,\"y\":139},{\"x\":1050,\"y\":141},{\"x\":1050,\"y\":169},{\"x\":1004,\"y\":168}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":204,\"y\":206},{\"x\":252,\"y\":205},{\"x\":251,\"y\":234},{\"x\":202,\"y\":233}],\"text\":\"0.2\"},{\"boundingBox\":[{\"x\":779,\"y\":201},{\"x\":831,\"y\":201},{\"x\":830,\"y\":232},{\"x\":779,\"y\":232}],\"text\":\"0.2\"},{\"boundingBox\":[{\"x\":863,\"y\":245},{\"x\":912,\"y\":245},{\"x\":912,\"y\":273},{\"x\":862,\"y\":274}],\"text\":\"0.2\"},{\"boundingBox\":[{\"x\":926,\"y\":220},{\"x\":975,\"y\":220},{\"x\":975,\"y\":248},{\"x\":926,\"y\":249}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":96,\"y\":284},{\"x\":115,\"y\":283},{\"x\":117,\"y\":306},{\"x\":98,\"y\":306}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":268,\"y\":269},{\"x\":389,\"y\":260},{\"x\":391,\"y\":292},{\"x\":269,\"y\":301}],\"text\":\"0.6 0.4\"},{\"boundingBox\":[{\"x\":471,\"y\":284},{\"x\":494,\"y\":283},{\"x\":494,\"y\":307},{\"x\":471,\"y\":307}],\"text\":\"C\"},{\"boundingBox\":[{\"x\":684,\"y\":284},{\"x\":701,\"y\":283},{\"x\":703,\"y\":307},{\"x\":686,\"y\":307}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":1065,\"y\":283},{\"x\":1086,\"y\":284},{\"x\":1086,\"y\":308},{\"x\":1065,\"y\":308}],\"text\":\"C\"},{\"boundingBox\":[{\"x\":254,\"y\":395},{\"x\":301,\"y\":395},{\"x\":301,\"y\":424},{\"x\":253,\"y\":424}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":863,\"y\":370},{\"x\":912,\"y\":370},{\"x\":912,\"y\":398},{\"x\":863,\"y\":397}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":295,\"y\":508},{\"x\":327,\"y\":506},{\"x\":327,\"y\":539},{\"x\":295,\"y\":541}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":845,\"y\":495},{\"x\":881,\"y\":494},{\"x\":883,\"y\":542},{\"x\":847,\"y\":543}],\"text\":\"b\"}],\"words\":[{\"boundingBox\":[{\"x\":135,\"y\":87},{\"x\":153,\"y\":87},{\"x\":154,\"y\":116},{\"x\":136,\"y\":117}],\"text\":\"R\"},{\"boundingBox\":[{\"x\":275,\"y\":109},{\"x\":290,\"y\":109},{\"x\":290,\"y\":135},{\"x\":275,\"y\":135}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":720,\"y\":87},{\"x\":738,\"y\":87},{\"x\":739,\"y\":115},{\"x\":721,\"y\":116}],\"text\":\"R\"},{\"boundingBox\":[{\"x\":861,\"y\":100},{\"x\":878,\"y\":101},{\"x\":877,\"y\":130},{\"x\":860,\"y\":129}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":416,\"y\":138},{\"x\":463,\"y\":141},{\"x\":461,\"y\":171},{\"x\":415,\"y\":168}],\"text\":\"0.7\"},{\"boundingBox\":[{\"x\":109,\"y\":169},{\"x\":152,\"y\":169},{\"x\":152,\"y\":198},{\"x\":109,\"y\":198}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":723,\"y\":148},{\"x\":766,\"y\":147},{\"x\":767,\"y\":175},{\"x\":724,\"y\":176}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":1004,\"y\":139},{\"x\":1046,\"y\":140},{\"x\":1045,\"y\":169},{\"x\":1004,\"y\":167}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":202,\"y\":205},{\"x\":245,\"y\":205},{\"x\":245,\"y\":234},{\"x\":202,\"y\":234}],\"text\":\"0.2\"},{\"boundingBox\":[{\"x\":779,\"y\":201},{\"x\":828,\"y\":201},{\"x\":828,\"y\":232},{\"x\":779,\"y\":232}],\"text\":\"0.2\"},{\"boundingBox\":[{\"x\":862,\"y\":245},{\"x\":907,\"y\":245},{\"x\":907,\"y\":274},{\"x\":862,\"y\":274}],\"text\":\"0.2\"},{\"boundingBox\":[{\"x\":926,\"y\":220},{\"x\":971,\"y\":220},{\"x\":971,\"y\":249},{\"x\":926,\"y\":249}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":97,\"y\":283},{\"x\":110,\"y\":283},{\"x\":111,\"y\":306},{\"x\":97,\"y\":306}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":268,\"y\":270},{\"x\":313,\"y\":266},{\"x\":314,\"y\":298},{\"x\":270,\"y\":301}],\"text\":\"0.6\"},{\"boundingBox\":[{\"x\":337,\"y\":265},{\"x\":386,\"y\":261},{\"x\":387,\"y\":293},{\"x\":338,\"y\":296}],\"text\":\"0.4\"},{\"boundingBox\":[{\"x\":472,\"y\":283},{\"x\":486,\"y\":283},{\"x\":486,\"y\":307},{\"x\":472,\"y\":307}],\"text\":\"C\"},{\"boundingBox\":[{\"x\":684,\"y\":283},{\"x\":698,\"y\":283},{\"x\":699,\"y\":307},{\"x\":685,\"y\":307}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":1066,\"y\":283},{\"x\":1081,\"y\":283},{\"x\":1080,\"y\":308},{\"x\":1066,\"y\":307}],\"text\":\"C\"},{\"boundingBox\":[{\"x\":253,\"y\":395},{\"x\":295,\"y\":395},{\"x\":295,\"y\":424},{\"x\":253,\"y\":424}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":864,\"y\":370},{\"x\":905,\"y\":370},{\"x\":905,\"y\":398},{\"x\":864,\"y\":397}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":297,\"y\":508},{\"x\":315,\"y\":507},{\"x\":317,\"y\":539},{\"x\":299,\"y\":540}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":845,\"y\":495},{\"x\":875,\"y\":494},{\"x\":876,\"y\":542},{\"x\":846,\"y\":543}],\"text\":\"b\"}]}",
        "{\"language\":\"en\",\"text\":\"G R b (0.7, 0.8, 0.9) b 2 (1.0, 1.0) 0.8 1.0 C a C a 0.7 1a 1b b 0.8 1.0 a C\",\"lines\":[{\"boundingBox\":[{\"x\":307,\"y\":48},{\"x\":331,\"y\":48},{\"x\":333,\"y\":77},{\"x\":309,\"y\":77}],\"text\":\"G\"},{\"boundingBox\":[{\"x\":1035,\"y\":48},{\"x\":1056,\"y\":48},{\"x\":1057,\"y\":76},{\"x\":1036,\"y\":75}],\"text\":\"R\"},{\"boundingBox\":[{\"x\":1175,\"y\":71},{\"x\":1194,\"y\":72},{\"x\":1194,\"y\":95},{\"x\":1175,\"y\":94}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":28,\"y\":96},{\"x\":251,\"y\":94},{\"x\":252,\"y\":129},{\"x\":28,\"y\":131}],\"text\":\"(0.7, 0.8, 0.9) b\"},{\"boundingBox\":[{\"x\":695,\"y\":90},{\"x\":715,\"y\":88},{\"x\":716,\"y\":116},{\"x\":697,\"y\":117}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":311,\"y\":126},{\"x\":442,\"y\":128},{\"x\":441,\"y\":161},{\"x\":310,\"y\":160}],\"text\":\"(1.0, 1.0)\"},{\"boundingBox\":[{\"x\":1011,\"y\":122},{\"x\":1055,\"y\":122},{\"x\":1055,\"y\":148},{\"x\":1011,\"y\":147}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":1316,\"y\":123},{\"x\":1361,\"y\":122},{\"x\":1362,\"y\":147},{\"x\":1317,\"y\":149}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":370,\"y\":228},{\"x\":389,\"y\":229},{\"x\":388,\"y\":252},{\"x\":369,\"y\":251}],\"text\":\"C\"},{\"boundingBox\":[{\"x\":1031,\"y\":209},{\"x\":1049,\"y\":209},{\"x\":1051,\"y\":231},{\"x\":1032,\"y\":231}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":1311,\"y\":208},{\"x\":1330,\"y\":208},{\"x\":1332,\"y\":230},{\"x\":1313,\"y\":231}],\"text\":\"C\"},{\"boundingBox\":[{\"x\":85,\"y\":231},{\"x\":101,\"y\":231},{\"x\":102,\"y\":250},{\"x\":85,\"y\":250}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":1163,\"y\":291},{\"x\":1207,\"y\":291},{\"x\":1208,\"y\":318},{\"x\":1162,\"y\":317}],\"text\":\"0.7\"},{\"boundingBox\":[{\"x\":489,\"y\":322},{\"x\":524,\"y\":322},{\"x\":524,\"y\":348},{\"x\":489,\"y\":346}],\"text\":\"1a\"},{\"boundingBox\":[{\"x\":910,\"y\":322},{\"x\":941,\"y\":320},{\"x\":944,\"y\":345},{\"x\":911,\"y\":347}],\"text\":\"1b\"},{\"boundingBox\":[{\"x\":692,\"y\":372},{\"x\":708,\"y\":374},{\"x\":708,\"y\":398},{\"x\":691,\"y\":396}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":573,\"y\":418},{\"x\":619,\"y\":420},{\"x\":618,\"y\":447},{\"x\":572,\"y\":445}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":783,\"y\":417},{\"x\":829,\"y\":412},{\"x\":834,\"y\":443},{\"x\":786,\"y\":448}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":580,\"y\":505},{\"x\":614,\"y\":502},{\"x\":616,\"y\":538},{\"x\":582,\"y\":540}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":797,\"y\":505},{\"x\":832,\"y\":504},{\"x\":833,\"y\":535},{\"x\":800,\"y\":534}],\"text\":\"C\"}],\"words\":[{\"boundingBox\":[{\"x\":307,\"y\":48},{\"x\":325,\"y\":48},{\"x\":325,\"y\":77},{\"x\":307,\"y\":77}],\"text\":\"G\"},{\"boundingBox\":[{\"x\":1035,\"y\":48},{\"x\":1051,\"y\":48},{\"x\":1050,\"y\":76},{\"x\":1035,\"y\":75}],\"text\":\"R\"},{\"boundingBox\":[{\"x\":1176,\"y\":71},{\"x\":1190,\"y\":72},{\"x\":1188,\"y\":95},{\"x\":1175,\"y\":94}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":29,\"y\":96},{\"x\":85,\"y\":96},{\"x\":84,\"y\":131},{\"x\":28,\"y\":131}],\"text\":\"(0.7,\"},{\"boundingBox\":[{\"x\":92,\"y\":96},{\"x\":146,\"y\":96},{\"x\":145,\"y\":130},{\"x\":91,\"y\":131}],\"text\":\"0.8,\"},{\"boundingBox\":[{\"x\":153,\"y\":96},{\"x\":218,\"y\":96},{\"x\":217,\"y\":130},{\"x\":152,\"y\":130}],\"text\":\"0.9)\"},{\"boundingBox\":[{\"x\":228,\"y\":95},{\"x\":247,\"y\":95},{\"x\":246,\"y\":130},{\"x\":227,\"y\":130}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":695,\"y\":89},{\"x\":712,\"y\":88},{\"x\":715,\"y\":116},{\"x\":697,\"y\":117}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":314,\"y\":127},{\"x\":380,\"y\":127},{\"x\":379,\"y\":161},{\"x\":312,\"y\":160}],\"text\":\"(1.0,\"},{\"boundingBox\":[{\"x\":387,\"y\":128},{\"x\":442,\"y\":129},{\"x\":441,\"y\":162},{\"x\":385,\"y\":161}],\"text\":\"1.0)\"},{\"boundingBox\":[{\"x\":1011,\"y\":122},{\"x\":1050,\"y\":122},{\"x\":1050,\"y\":148},{\"x\":1011,\"y\":147}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":1316,\"y\":123},{\"x\":1354,\"y\":122},{\"x\":1355,\"y\":148},{\"x\":1317,\"y\":149}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":370,\"y\":228},{\"x\":383,\"y\":229},{\"x\":382,\"y\":252},{\"x\":369,\"y\":251}],\"text\":\"C\"},{\"boundingBox\":[{\"x\":1032,\"y\":209},{\"x\":1045,\"y\":209},{\"x\":1045,\"y\":231},{\"x\":1032,\"y\":231}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":1312,\"y\":208},{\"x\":1325,\"y\":208},{\"x\":1326,\"y\":231},{\"x\":1312,\"y\":231}],\"text\":\"C\"},{\"boundingBox\":[{\"x\":86,\"y\":231},{\"x\":97,\"y\":231},{\"x\":97,\"y\":250},{\"x\":86,\"y\":250}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":1162,\"y\":291},{\"x\":1204,\"y\":291},{\"x\":1204,\"y\":318},{\"x\":1162,\"y\":317}],\"text\":\"0.7\"},{\"boundingBox\":[{\"x\":490,\"y\":322},{\"x\":519,\"y\":322},{\"x\":519,\"y\":348},{\"x\":490,\"y\":347}],\"text\":\"1a\"},{\"boundingBox\":[{\"x\":910,\"y\":321},{\"x\":938,\"y\":320},{\"x\":939,\"y\":345},{\"x\":911,\"y\":347}],\"text\":\"1b\"},{\"boundingBox\":[{\"x\":693,\"y\":372},{\"x\":707,\"y\":374},{\"x\":704,\"y\":398},{\"x\":691,\"y\":396}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":573,\"y\":418},{\"x\":615,\"y\":420},{\"x\":614,\"y\":447},{\"x\":572,\"y\":445}],\"text\":\"0.8\"},{\"boundingBox\":[{\"x\":784,\"y\":416},{\"x\":826,\"y\":412},{\"x\":829,\"y\":443},{\"x\":787,\"y\":448}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":588,\"y\":503},{\"x\":609,\"y\":502},{\"x\":612,\"y\":538},{\"x\":591,\"y\":539}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":799,\"y\":504},{\"x\":817,\"y\":504},{\"x\":817,\"y\":535},{\"x\":799,\"y\":535}],\"text\":\"C\"}]}",
        "{\"language\":\"en\",\"text\":\"Start End Feedback history Trust Graph Stage 1: Obtain FHG Stage 3: Obtain TG Preconditions: Preconditions: {fı(a, b), f2(a, b), ..., fn (a, b)} Ax A - R Post-conditions: Post-conditions: Ax A - RR\\\" A x A -+ [0, 1] Stage 2: Obtain RG Feedback Preconditions: History Ax A - R\\\" Reputation Graph Post-conditions: Graph Ax A - R\",\"lines\":[{\"boundingBox\":[{\"x\":156,\"y\":36},{\"x\":230,\"y\":37},{\"x\":229,\"y\":65},{\"x\":154,\"y\":64}],\"text\":\"Start\"},{\"boundingBox\":[{\"x\":1205,\"y\":49},{\"x\":1266,\"y\":50},{\"x\":1266,\"y\":79},{\"x\":1205,\"y\":79}],\"text\":\"End\"},{\"boundingBox\":[{\"x\":121,\"y\":185},{\"x\":268,\"y\":186},{\"x\":268,\"y\":216},{\"x\":121,\"y\":215}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":141,\"y\":231},{\"x\":249,\"y\":233},{\"x\":248,\"y\":265},{\"x\":140,\"y\":261}],\"text\":\"history\"},{\"boundingBox\":[{\"x\":1197,\"y\":226},{\"x\":1279,\"y\":227},{\"x\":1280,\"y\":257},{\"x\":1197,\"y\":254}],\"text\":\"Trust\"},{\"boundingBox\":[{\"x\":1190,\"y\":268},{\"x\":1286,\"y\":271},{\"x\":1287,\"y\":306},{\"x\":1189,\"y\":304}],\"text\":\"Graph\"},{\"boundingBox\":[{\"x\":39,\"y\":406},{\"x\":347,\"y\":403},{\"x\":347,\"y\":439},{\"x\":39,\"y\":441}],\"text\":\"Stage 1: Obtain FHG\"},{\"boundingBox\":[{\"x\":1061,\"y\":411},{\"x\":1345,\"y\":410},{\"x\":1345,\"y\":445},{\"x\":1061,\"y\":447}],\"text\":\"Stage 3: Obtain TG\"},{\"boundingBox\":[{\"x\":78,\"y\":449},{\"x\":310,\"y\":450},{\"x\":310,\"y\":484},{\"x\":78,\"y\":483}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":1095,\"y\":457},{\"x\":1317,\"y\":457},{\"x\":1317,\"y\":490},{\"x\":1094,\"y\":489}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":15,\"y\":487},{\"x\":371,\"y\":488},{\"x\":371,\"y\":526},{\"x\":15,\"y\":525}],\"text\":\"{fı(a, b), f2(a, b), ..., fn (a, b)}\"},{\"boundingBox\":[{\"x\":1136,\"y\":496},{\"x\":1311,\"y\":495},{\"x\":1311,\"y\":529},{\"x\":1136,\"y\":530}],\"text\":\"Ax A - R\"},{\"boundingBox\":[{\"x\":70,\"y\":539},{\"x\":324,\"y\":539},{\"x\":324,\"y\":575},{\"x\":70,\"y\":574}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":1079,\"y\":545},{\"x\":1328,\"y\":546},{\"x\":1328,\"y\":579},{\"x\":1079,\"y\":578}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":89,\"y\":592},{\"x\":292,\"y\":591},{\"x\":292,\"y\":626},{\"x\":89,\"y\":629}],\"text\":\"Ax A - RR\\\"\"},{\"boundingBox\":[{\"x\":1122,\"y\":590},{\"x\":1327,\"y\":590},{\"x\":1327,\"y\":626},{\"x\":1121,\"y\":625}],\"text\":\"A x A -+ [0, 1]\"},{\"boundingBox\":[{\"x\":569,\"y\":738},{\"x\":856,\"y\":736},{\"x\":856,\"y\":772},{\"x\":569,\"y\":774}],\"text\":\"Stage 2: Obtain RG\"},{\"boundingBox\":[{\"x\":120,\"y\":785},{\"x\":264,\"y\":785},{\"x\":264,\"y\":818},{\"x\":120,\"y\":818}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":604,\"y\":784},{\"x\":826,\"y\":784},{\"x\":825,\"y\":818},{\"x\":604,\"y\":816}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":136,\"y\":833},{\"x\":250,\"y\":836},{\"x\":249,\"y\":865},{\"x\":136,\"y\":862}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":611,\"y\":831},{\"x\":807,\"y\":830},{\"x\":808,\"y\":861},{\"x\":611,\"y\":863}],\"text\":\"Ax A - R\\\"\"},{\"boundingBox\":[{\"x\":1117,\"y\":805},{\"x\":1286,\"y\":805},{\"x\":1286,\"y\":841},{\"x\":1117,\"y\":840}],\"text\":\"Reputation\"},{\"boundingBox\":[{\"x\":144,\"y\":875},{\"x\":239,\"y\":877},{\"x\":239,\"y\":910},{\"x\":143,\"y\":909}],\"text\":\"Graph\"},{\"boundingBox\":[{\"x\":589,\"y\":872},{\"x\":839,\"y\":873},{\"x\":839,\"y\":906},{\"x\":589,\"y\":905}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":1154,\"y\":851},{\"x\":1251,\"y\":851},{\"x\":1251,\"y\":882},{\"x\":1154,\"y\":882}],\"text\":\"Graph\"},{\"boundingBox\":[{\"x\":613,\"y\":923},{\"x\":786,\"y\":922},{\"x\":787,\"y\":954},{\"x\":613,\"y\":956}],\"text\":\"Ax A - R\"}],\"words\":[{\"boundingBox\":[{\"x\":155,\"y\":36},{\"x\":229,\"y\":37},{\"x\":228,\"y\":65},{\"x\":155,\"y\":64}],\"text\":\"Start\"},{\"boundingBox\":[{\"x\":1206,\"y\":49},{\"x\":1262,\"y\":49},{\"x\":1262,\"y\":79},{\"x\":1206,\"y\":78}],\"text\":\"End\"},{\"boundingBox\":[{\"x\":121,\"y\":186},{\"x\":264,\"y\":186},{\"x\":265,\"y\":217},{\"x\":121,\"y\":216}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":142,\"y\":231},{\"x\":245,\"y\":235},{\"x\":245,\"y\":265},{\"x\":141,\"y\":262}],\"text\":\"history\"},{\"boundingBox\":[{\"x\":1199,\"y\":226},{\"x\":1278,\"y\":227},{\"x\":1277,\"y\":257},{\"x\":1198,\"y\":255}],\"text\":\"Trust\"},{\"boundingBox\":[{\"x\":1191,\"y\":268},{\"x\":1281,\"y\":270},{\"x\":1280,\"y\":306},{\"x\":1190,\"y\":303}],\"text\":\"Graph\"},{\"boundingBox\":[{\"x\":42,\"y\":406},{\"x\":126,\"y\":407},{\"x\":126,\"y\":441},{\"x\":42,\"y\":442}],\"text\":\"Stage\"},{\"boundingBox\":[{\"x\":133,\"y\":407},{\"x\":163,\"y\":407},{\"x\":163,\"y\":440},{\"x\":133,\"y\":441}],\"text\":\"1:\"},{\"boundingBox\":[{\"x\":170,\"y\":407},{\"x\":272,\"y\":405},{\"x\":273,\"y\":440},{\"x\":170,\"y\":440}],\"text\":\"Obtain\"},{\"boundingBox\":[{\"x\":279,\"y\":405},{\"x\":340,\"y\":404},{\"x\":341,\"y\":440},{\"x\":280,\"y\":440}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":1063,\"y\":411},{\"x\":1146,\"y\":412},{\"x\":1145,\"y\":447},{\"x\":1062,\"y\":447}],\"text\":\"Stage\"},{\"boundingBox\":[{\"x\":1152,\"y\":412},{\"x\":1182,\"y\":412},{\"x\":1181,\"y\":447},{\"x\":1152,\"y\":447}],\"text\":\"3:\"},{\"boundingBox\":[{\"x\":1188,\"y\":412},{\"x\":1294,\"y\":412},{\"x\":1294,\"y\":445},{\"x\":1188,\"y\":447}],\"text\":\"Obtain\"},{\"boundingBox\":[{\"x\":1301,\"y\":412},{\"x\":1339,\"y\":411},{\"x\":1340,\"y\":444},{\"x\":1302,\"y\":445}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":81,\"y\":449},{\"x\":310,\"y\":452},{\"x\":311,\"y\":484},{\"x\":80,\"y\":484}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":1095,\"y\":458},{\"x\":1316,\"y\":457},{\"x\":1315,\"y\":491},{\"x\":1095,\"y\":489}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":15,\"y\":488},{\"x\":82,\"y\":489},{\"x\":82,\"y\":526},{\"x\":15,\"y\":525}],\"text\":\"{fı(a,\"},{\"boundingBox\":[{\"x\":90,\"y\":489},{\"x\":121,\"y\":490},{\"x\":121,\"y\":526},{\"x\":90,\"y\":526}],\"text\":\"b),\"},{\"boundingBox\":[{\"x\":128,\"y\":490},{\"x\":184,\"y\":490},{\"x\":184,\"y\":526},{\"x\":128,\"y\":526}],\"text\":\"f2(a,\"},{\"boundingBox\":[{\"x\":191,\"y\":490},{\"x\":223,\"y\":490},{\"x\":222,\"y\":526},{\"x\":191,\"y\":526}],\"text\":\"b),\"},{\"boundingBox\":[{\"x\":230,\"y\":490},{\"x\":259,\"y\":490},{\"x\":259,\"y\":526},{\"x\":230,\"y\":526}],\"text\":\"...,\"},{\"boundingBox\":[{\"x\":266,\"y\":490},{\"x\":288,\"y\":490},{\"x\":288,\"y\":526},{\"x\":266,\"y\":526}],\"text\":\"fn\"},{\"boundingBox\":[{\"x\":295,\"y\":490},{\"x\":327,\"y\":489},{\"x\":326,\"y\":526},{\"x\":295,\"y\":526}],\"text\":\"(a,\"},{\"boundingBox\":[{\"x\":334,\"y\":489},{\"x\":371,\"y\":489},{\"x\":370,\"y\":526},{\"x\":333,\"y\":526}],\"text\":\"b)}\"},{\"boundingBox\":[{\"x\":1142,\"y\":497},{\"x\":1190,\"y\":497},{\"x\":1189,\"y\":529},{\"x\":1140,\"y\":530}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":1203,\"y\":497},{\"x\":1224,\"y\":497},{\"x\":1223,\"y\":528},{\"x\":1202,\"y\":529}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1239,\"y\":497},{\"x\":1258,\"y\":497},{\"x\":1257,\"y\":529},{\"x\":1238,\"y\":529}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":1279,\"y\":496},{\"x\":1298,\"y\":496},{\"x\":1297,\"y\":529},{\"x\":1278,\"y\":529}],\"text\":\"R\"},{\"boundingBox\":[{\"x\":72,\"y\":540},{\"x\":323,\"y\":540},{\"x\":324,\"y\":576},{\"x\":70,\"y\":574}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":1080,\"y\":545},{\"x\":1327,\"y\":548},{\"x\":1327,\"y\":579},{\"x\":1080,\"y\":579}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":96,\"y\":593},{\"x\":148,\"y\":593},{\"x\":147,\"y\":628},{\"x\":94,\"y\":629}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":165,\"y\":593},{\"x\":185,\"y\":593},{\"x\":184,\"y\":628},{\"x\":164,\"y\":628}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":198,\"y\":593},{\"x\":218,\"y\":593},{\"x\":216,\"y\":627},{\"x\":196,\"y\":628}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":242,\"y\":593},{\"x\":290,\"y\":591},{\"x\":288,\"y\":627},{\"x\":240,\"y\":627}],\"text\":\"RR\\\"\"},{\"boundingBox\":[{\"x\":1126,\"y\":591},{\"x\":1146,\"y\":591},{\"x\":1146,\"y\":624},{\"x\":1126,\"y\":624}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1156,\"y\":591},{\"x\":1176,\"y\":591},{\"x\":1176,\"y\":625},{\"x\":1156,\"y\":624}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":1188,\"y\":591},{\"x\":1208,\"y\":591},{\"x\":1208,\"y\":625},{\"x\":1188,\"y\":625}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1218,\"y\":591},{\"x\":1250,\"y\":591},{\"x\":1250,\"y\":626},{\"x\":1218,\"y\":625}],\"text\":\"-+\"},{\"boundingBox\":[{\"x\":1256,\"y\":591},{\"x\":1291,\"y\":591},{\"x\":1291,\"y\":626},{\"x\":1256,\"y\":626}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":1297,\"y\":591},{\"x\":1325,\"y\":590},{\"x\":1326,\"y\":627},{\"x\":1298,\"y\":626}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":571,\"y\":740},{\"x\":653,\"y\":740},{\"x\":652,\"y\":774},{\"x\":569,\"y\":774}],\"text\":\"Stage\"},{\"boundingBox\":[{\"x\":660,\"y\":740},{\"x\":690,\"y\":740},{\"x\":689,\"y\":774},{\"x\":659,\"y\":774}],\"text\":\"2:\"},{\"boundingBox\":[{\"x\":697,\"y\":740},{\"x\":800,\"y\":738},{\"x\":801,\"y\":774},{\"x\":696,\"y\":774}],\"text\":\"Obtain\"},{\"boundingBox\":[{\"x\":807,\"y\":738},{\"x\":850,\"y\":737},{\"x\":851,\"y\":773},{\"x\":808,\"y\":774}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":121,\"y\":788},{\"x\":263,\"y\":785},{\"x\":264,\"y\":819},{\"x\":120,\"y\":818}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":606,\"y\":785},{\"x\":826,\"y\":784},{\"x\":826,\"y\":819},{\"x\":604,\"y\":815}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":137,\"y\":834},{\"x\":246,\"y\":836},{\"x\":246,\"y\":866},{\"x\":136,\"y\":863}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":614,\"y\":831},{\"x\":666,\"y\":831},{\"x\":665,\"y\":863},{\"x\":613,\"y\":864}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":684,\"y\":831},{\"x\":702,\"y\":831},{\"x\":701,\"y\":863},{\"x\":683,\"y\":863}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":719,\"y\":831},{\"x\":738,\"y\":831},{\"x\":737,\"y\":862},{\"x\":718,\"y\":863}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":761,\"y\":831},{\"x\":807,\"y\":830},{\"x\":806,\"y\":862},{\"x\":760,\"y\":862}],\"text\":\"R\\\"\"},{\"boundingBox\":[{\"x\":1118,\"y\":805},{\"x\":1285,\"y\":806},{\"x\":1284,\"y\":842},{\"x\":1117,\"y\":841}],\"text\":\"Reputation\"},{\"boundingBox\":[{\"x\":143,\"y\":875},{\"x\":235,\"y\":876},{\"x\":234,\"y\":910},{\"x\":143,\"y\":908}],\"text\":\"Graph\"},{\"boundingBox\":[{\"x\":590,\"y\":873},{\"x\":838,\"y\":873},{\"x\":838,\"y\":907},{\"x\":590,\"y\":906}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":1157,\"y\":851},{\"x\":1244,\"y\":852},{\"x\":1244,\"y\":883},{\"x\":1155,\"y\":883}],\"text\":\"Graph\"},{\"boundingBox\":[{\"x\":617,\"y\":923},{\"x\":666,\"y\":923},{\"x\":665,\"y\":956},{\"x\":615,\"y\":957}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":680,\"y\":923},{\"x\":699,\"y\":923},{\"x\":698,\"y\":956},{\"x\":678,\"y\":956}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":714,\"y\":923},{\"x\":733,\"y\":923},{\"x\":732,\"y\":955},{\"x\":713,\"y\":955}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":755,\"y\":923},{\"x\":774,\"y\":923},{\"x\":774,\"y\":955},{\"x\":755,\"y\":955}],\"text\":\"R\"}]}",
        "{\"language\":\"en\",\"text\":\"Stage transitions Feedback History Output: A x A => [0, 1] Input: A x A => {-1, 1]* FHG RG TG fully connected global relative rep. scores Input: A x A => [0, 1]* Ouput: A x A => [0, 1] Feedback History FHG RG TG fully connected global absolute rep. scores Input: A x A => [0, 1] Output: Ax A => [0, 1] local Feedback History FHG RG TG partially connected local absolute rep.scores Appleseed | PeerTrust | EigenTrust Input: A x A => {-1, 1]* Feedback History FHG DO TG Output: Ax A => {0, 1} fully connected global Aberer & Despotovic Input: Ax A => {0, 1} Feedback History Ouput: Ax A => {0, 1} FHG RG TG partially connected, local Input: A x A => {0, 1]* Feedback History FHG RG TG Ouput: Ax A => [0, 1] local absolute rep. scores TRAVOS |Advogato Input: A x A => [0, 1] relative rep. scores Feedback History FHG RG TG Output: A x A => {0, 1} partially connected Input: A x A => [0, 1] absolute rep. scores Feedback History FHG RG TG Output: A x A => {0, 1} partially connected Thresholding Ranking\",\"lines\":[{\"boundingBox\":[{\"x\":577,\"y\":1},{\"x\":817,\"y\":1},{\"x\":817,\"y\":30},{\"x\":577,\"y\":31}],\"text\":\"Stage transitions\"},{\"boundingBox\":[{\"x\":341,\"y\":112},{\"x\":512,\"y\":112},{\"x\":512,\"y\":136},{\"x\":341,\"y\":136}],\"text\":\"Feedback History\"},{\"boundingBox\":[{\"x\":1141,\"y\":90},{\"x\":1367,\"y\":91},{\"x\":1367,\"y\":116},{\"x\":1141,\"y\":115}],\"text\":\"Output: A x A => [0, 1]\"},{\"boundingBox\":[{\"x\":94,\"y\":119},{\"x\":319,\"y\":120},{\"x\":319,\"y\":145},{\"x\":94,\"y\":144}],\"text\":\"Input: A x A => {-1, 1]*\"},{\"boundingBox\":[{\"x\":608,\"y\":114},{\"x\":659,\"y\":112},{\"x\":659,\"y\":132},{\"x\":608,\"y\":133}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":826,\"y\":114},{\"x\":861,\"y\":113},{\"x\":862,\"y\":134},{\"x\":827,\"y\":135}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1020,\"y\":114},{\"x\":1053,\"y\":112},{\"x\":1054,\"y\":133},{\"x\":1021,\"y\":135}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1144,\"y\":117},{\"x\":1428,\"y\":117},{\"x\":1428,\"y\":140},{\"x\":1144,\"y\":140}],\"text\":\"fully connected global relative\"},{\"boundingBox\":[{\"x\":1145,\"y\":145},{\"x\":1254,\"y\":144},{\"x\":1255,\"y\":165},{\"x\":1145,\"y\":168}],\"text\":\"rep. scores\"},{\"boundingBox\":[{\"x\":101,\"y\":257},{\"x\":316,\"y\":257},{\"x\":316,\"y\":284},{\"x\":101,\"y\":283}],\"text\":\"Input: A x A => [0, 1]*\"},{\"boundingBox\":[{\"x\":1154,\"y\":230},{\"x\":1370,\"y\":230},{\"x\":1370,\"y\":255},{\"x\":1154,\"y\":255}],\"text\":\"Ouput: A x A => [0, 1]\"},{\"boundingBox\":[{\"x\":341,\"y\":257},{\"x\":514,\"y\":257},{\"x\":513,\"y\":282},{\"x\":341,\"y\":280}],\"text\":\"Feedback History\"},{\"boundingBox\":[{\"x\":608,\"y\":257},{\"x\":658,\"y\":256},{\"x\":658,\"y\":276},{\"x\":609,\"y\":276}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":825,\"y\":259},{\"x\":859,\"y\":257},{\"x\":861,\"y\":278},{\"x\":827,\"y\":279}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1021,\"y\":258},{\"x\":1050,\"y\":256},{\"x\":1052,\"y\":276},{\"x\":1023,\"y\":279}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1153,\"y\":257},{\"x\":1366,\"y\":257},{\"x\":1366,\"y\":282},{\"x\":1153,\"y\":281}],\"text\":\"fully connected global\"},{\"boundingBox\":[{\"x\":1155,\"y\":283},{\"x\":1351,\"y\":284},{\"x\":1351,\"y\":308},{\"x\":1155,\"y\":307}],\"text\":\"absolute rep. scores\"},{\"boundingBox\":[{\"x\":94,\"y\":408},{\"x\":301,\"y\":408},{\"x\":301,\"y\":434},{\"x\":94,\"y\":433}],\"text\":\"Input: A x A => [0, 1]\"},{\"boundingBox\":[{\"x\":1153,\"y\":395},{\"x\":1385,\"y\":395},{\"x\":1385,\"y\":420},{\"x\":1153,\"y\":420}],\"text\":\"Output: Ax A => [0, 1]\"},{\"boundingBox\":[{\"x\":100,\"y\":436},{\"x\":147,\"y\":436},{\"x\":147,\"y\":456},{\"x\":100,\"y\":455}],\"text\":\"local\"},{\"boundingBox\":[{\"x\":345,\"y\":420},{\"x\":517,\"y\":421},{\"x\":516,\"y\":444},{\"x\":345,\"y\":442}],\"text\":\"Feedback History\"},{\"boundingBox\":[{\"x\":609,\"y\":422},{\"x\":659,\"y\":421},{\"x\":659,\"y\":441},{\"x\":609,\"y\":441}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":824,\"y\":423},{\"x\":858,\"y\":420},{\"x\":860,\"y\":440},{\"x\":826,\"y\":442}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1023,\"y\":422},{\"x\":1054,\"y\":420},{\"x\":1056,\"y\":441},{\"x\":1024,\"y\":443}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1158,\"y\":422},{\"x\":1394,\"y\":422},{\"x\":1394,\"y\":444},{\"x\":1158,\"y\":445}],\"text\":\"partially connected local\"},{\"boundingBox\":[{\"x\":1154,\"y\":448},{\"x\":1344,\"y\":448},{\"x\":1344,\"y\":472},{\"x\":1154,\"y\":471}],\"text\":\"absolute rep.scores\"},{\"boundingBox\":[{\"x\":23,\"y\":513},{\"x\":26,\"y\":56},{\"x\":55,\"y\":56},{\"x\":52,\"y\":514}],\"text\":\"Appleseed | PeerTrust | EigenTrust\"},{\"boundingBox\":[{\"x\":95,\"y\":556},{\"x\":320,\"y\":556},{\"x\":320,\"y\":582},{\"x\":95,\"y\":583}],\"text\":\"Input: A x A => {-1, 1]*\"},{\"boundingBox\":[{\"x\":342,\"y\":555},{\"x\":513,\"y\":555},{\"x\":513,\"y\":580},{\"x\":342,\"y\":580}],\"text\":\"Feedback History\"},{\"boundingBox\":[{\"x\":611,\"y\":557},{\"x\":658,\"y\":555},{\"x\":658,\"y\":576},{\"x\":611,\"y\":576}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":823,\"y\":555},{\"x\":866,\"y\":556},{\"x\":866,\"y\":569},{\"x\":823,\"y\":567}],\"text\":\"DO\"},{\"boundingBox\":[{\"x\":1024,\"y\":556},{\"x\":1052,\"y\":554},{\"x\":1054,\"y\":575},{\"x\":1025,\"y\":577}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1152,\"y\":546},{\"x\":1386,\"y\":546},{\"x\":1386,\"y\":571},{\"x\":1152,\"y\":571}],\"text\":\"Output: Ax A => {0, 1}\"},{\"boundingBox\":[{\"x\":1155,\"y\":572},{\"x\":1370,\"y\":573},{\"x\":1369,\"y\":597},{\"x\":1154,\"y\":596}],\"text\":\"fully connected global\"},{\"boundingBox\":[{\"x\":10,\"y\":642},{\"x\":12,\"y\":503},{\"x\":40,\"y\":503},{\"x\":37,\"y\":643}],\"text\":\"Aberer &\"},{\"boundingBox\":[{\"x\":40,\"y\":654},{\"x\":42,\"y\":503},{\"x\":69,\"y\":503},{\"x\":67,\"y\":654}],\"text\":\"Despotovic\"},{\"boundingBox\":[{\"x\":94,\"y\":710},{\"x\":314,\"y\":709},{\"x\":314,\"y\":738},{\"x\":94,\"y\":739}],\"text\":\"Input: Ax A => {0, 1}\"},{\"boundingBox\":[{\"x\":338,\"y\":710},{\"x\":515,\"y\":710},{\"x\":515,\"y\":734},{\"x\":338,\"y\":733}],\"text\":\"Feedback History\"},{\"boundingBox\":[{\"x\":1156,\"y\":687},{\"x\":1379,\"y\":687},{\"x\":1379,\"y\":712},{\"x\":1156,\"y\":713}],\"text\":\"Ouput: Ax A => {0, 1}\"},{\"boundingBox\":[{\"x\":608,\"y\":712},{\"x\":658,\"y\":709},{\"x\":659,\"y\":731},{\"x\":609,\"y\":732}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":828,\"y\":712},{\"x\":861,\"y\":709},{\"x\":862,\"y\":730},{\"x\":829,\"y\":733}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1021,\"y\":712},{\"x\":1052,\"y\":709},{\"x\":1055,\"y\":730},{\"x\":1024,\"y\":733}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1156,\"y\":714},{\"x\":1396,\"y\":714},{\"x\":1396,\"y\":738},{\"x\":1156,\"y\":739}],\"text\":\"partially connected, local\"},{\"boundingBox\":[{\"x\":94,\"y\":870},{\"x\":313,\"y\":868},{\"x\":313,\"y\":896},{\"x\":94,\"y\":897}],\"text\":\"Input: A x A => {0, 1]*\"},{\"boundingBox\":[{\"x\":344,\"y\":869},{\"x\":516,\"y\":870},{\"x\":515,\"y\":896},{\"x\":343,\"y\":892}],\"text\":\"Feedback History\"},{\"boundingBox\":[{\"x\":608,\"y\":871},{\"x\":658,\"y\":870},{\"x\":660,\"y\":891},{\"x\":609,\"y\":891}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":825,\"y\":872},{\"x\":859,\"y\":869},{\"x\":860,\"y\":889},{\"x\":827,\"y\":892}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1022,\"y\":871},{\"x\":1052,\"y\":869},{\"x\":1054,\"y\":892},{\"x\":1024,\"y\":894}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1143,\"y\":856},{\"x\":1365,\"y\":857},{\"x\":1365,\"y\":881},{\"x\":1143,\"y\":880}],\"text\":\"Ouput: Ax A => [0, 1]\"},{\"boundingBox\":[{\"x\":1144,\"y\":882},{\"x\":1397,\"y\":884},{\"x\":1397,\"y\":908},{\"x\":1144,\"y\":906}],\"text\":\"local absolute rep. scores\"},{\"boundingBox\":[{\"x\":24,\"y\":937},{\"x\":27,\"y\":663},{\"x\":54,\"y\":663},{\"x\":51,\"y\":937}],\"text\":\"TRAVOS |Advogato\"},{\"boundingBox\":[{\"x\":94,\"y\":1002},{\"x\":301,\"y\":1001},{\"x\":301,\"y\":1028},{\"x\":94,\"y\":1028}],\"text\":\"Input: A x A => [0, 1]\"},{\"boundingBox\":[{\"x\":95,\"y\":1029},{\"x\":283,\"y\":1029},{\"x\":283,\"y\":1053},{\"x\":95,\"y\":1052}],\"text\":\"relative rep. scores\"},{\"boundingBox\":[{\"x\":340,\"y\":1013},{\"x\":518,\"y\":1015},{\"x\":518,\"y\":1039},{\"x\":340,\"y\":1036}],\"text\":\"Feedback History\"},{\"boundingBox\":[{\"x\":607,\"y\":1015},{\"x\":659,\"y\":1014},{\"x\":659,\"y\":1035},{\"x\":608,\"y\":1035}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":825,\"y\":1015},{\"x\":859,\"y\":1013},{\"x\":860,\"y\":1035},{\"x\":826,\"y\":1036}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1020,\"y\":1017},{\"x\":1052,\"y\":1014},{\"x\":1054,\"y\":1035},{\"x\":1023,\"y\":1037}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1142,\"y\":1001},{\"x\":1371,\"y\":1001},{\"x\":1371,\"y\":1028},{\"x\":1142,\"y\":1028}],\"text\":\"Output: A x A => {0, 1}\"},{\"boundingBox\":[{\"x\":1144,\"y\":1029},{\"x\":1329,\"y\":1029},{\"x\":1329,\"y\":1052},{\"x\":1144,\"y\":1053}],\"text\":\"partially connected\"},{\"boundingBox\":[{\"x\":94,\"y\":1160},{\"x\":299,\"y\":1160},{\"x\":299,\"y\":1186},{\"x\":94,\"y\":1186}],\"text\":\"Input: A x A => [0, 1]\"},{\"boundingBox\":[{\"x\":105,\"y\":1187},{\"x\":301,\"y\":1187},{\"x\":301,\"y\":1210},{\"x\":105,\"y\":1210}],\"text\":\"absolute rep. scores\"},{\"boundingBox\":[{\"x\":340,\"y\":1172},{\"x\":514,\"y\":1172},{\"x\":514,\"y\":1195},{\"x\":340,\"y\":1194}],\"text\":\"Feedback History\"},{\"boundingBox\":[{\"x\":609,\"y\":1172},{\"x\":660,\"y\":1172},{\"x\":659,\"y\":1192},{\"x\":610,\"y\":1192}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":826,\"y\":1173},{\"x\":857,\"y\":1171},{\"x\":859,\"y\":1192},{\"x\":827,\"y\":1194}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1020,\"y\":1173},{\"x\":1052,\"y\":1171},{\"x\":1054,\"y\":1191},{\"x\":1023,\"y\":1193}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1155,\"y\":1158},{\"x\":1383,\"y\":1158},{\"x\":1383,\"y\":1186},{\"x\":1154,\"y\":1185}],\"text\":\"Output: A x A => {0, 1}\"},{\"boundingBox\":[{\"x\":1155,\"y\":1187},{\"x\":1338,\"y\":1184},{\"x\":1338,\"y\":1209},{\"x\":1155,\"y\":1212}],\"text\":\"partially connected\"},{\"boundingBox\":[{\"x\":25,\"y\":1264},{\"x\":26,\"y\":962},{\"x\":55,\"y\":962},{\"x\":53,\"y\":1264}],\"text\":\"Thresholding Ranking\"}],\"words\":[{\"boundingBox\":[{\"x\":580,\"y\":1},{\"x\":660,\"y\":2},{\"x\":660,\"y\":30},{\"x\":579,\"y\":32}],\"text\":\"Stage\"},{\"boundingBox\":[{\"x\":670,\"y\":2},{\"x\":817,\"y\":2},{\"x\":817,\"y\":30},{\"x\":669,\"y\":30}],\"text\":\"transitions\"},{\"boundingBox\":[{\"x\":342,\"y\":113},{\"x\":439,\"y\":113},{\"x\":439,\"y\":137},{\"x\":342,\"y\":137}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":443,\"y\":113},{\"x\":512,\"y\":113},{\"x\":513,\"y\":136},{\"x\":444,\"y\":137}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":1143,\"y\":92},{\"x\":1224,\"y\":91},{\"x\":1224,\"y\":114},{\"x\":1142,\"y\":114}],\"text\":\"Output:\"},{\"boundingBox\":[{\"x\":1229,\"y\":91},{\"x\":1241,\"y\":91},{\"x\":1240,\"y\":114},{\"x\":1228,\"y\":114}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1246,\"y\":91},{\"x\":1259,\"y\":91},{\"x\":1259,\"y\":114},{\"x\":1245,\"y\":114}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":1264,\"y\":91},{\"x\":1278,\"y\":91},{\"x\":1277,\"y\":114},{\"x\":1264,\"y\":114}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1284,\"y\":91},{\"x\":1309,\"y\":91},{\"x\":1308,\"y\":115},{\"x\":1283,\"y\":115}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":1314,\"y\":91},{\"x\":1341,\"y\":92},{\"x\":1340,\"y\":116},{\"x\":1313,\"y\":115}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":1346,\"y\":92},{\"x\":1368,\"y\":92},{\"x\":1367,\"y\":117},{\"x\":1345,\"y\":116}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":95,\"y\":120},{\"x\":156,\"y\":120},{\"x\":156,\"y\":145},{\"x\":95,\"y\":145}],\"text\":\"Input:\"},{\"boundingBox\":[{\"x\":161,\"y\":120},{\"x\":174,\"y\":120},{\"x\":174,\"y\":145},{\"x\":161,\"y\":145}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":179,\"y\":120},{\"x\":192,\"y\":120},{\"x\":192,\"y\":145},{\"x\":179,\"y\":145}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":197,\"y\":120},{\"x\":212,\"y\":120},{\"x\":211,\"y\":145},{\"x\":197,\"y\":145}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":217,\"y\":120},{\"x\":241,\"y\":120},{\"x\":241,\"y\":145},{\"x\":217,\"y\":145}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":246,\"y\":120},{\"x\":282,\"y\":121},{\"x\":282,\"y\":145},{\"x\":246,\"y\":145}],\"text\":\"{-1,\"},{\"boundingBox\":[{\"x\":287,\"y\":121},{\"x\":318,\"y\":121},{\"x\":318,\"y\":145},{\"x\":287,\"y\":145}],\"text\":\"1]*\"},{\"boundingBox\":[{\"x\":610,\"y\":113},{\"x\":651,\"y\":112},{\"x\":651,\"y\":132},{\"x\":610,\"y\":133}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":826,\"y\":114},{\"x\":853,\"y\":113},{\"x\":853,\"y\":134},{\"x\":827,\"y\":135}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1021,\"y\":114},{\"x\":1044,\"y\":113},{\"x\":1045,\"y\":133},{\"x\":1022,\"y\":135}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1144,\"y\":118},{\"x\":1182,\"y\":118},{\"x\":1182,\"y\":141},{\"x\":1144,\"y\":141}],\"text\":\"fully\"},{\"boundingBox\":[{\"x\":1187,\"y\":118},{\"x\":1288,\"y\":118},{\"x\":1288,\"y\":140},{\"x\":1187,\"y\":141}],\"text\":\"connected\"},{\"boundingBox\":[{\"x\":1293,\"y\":118},{\"x\":1352,\"y\":118},{\"x\":1352,\"y\":140},{\"x\":1293,\"y\":140}],\"text\":\"global\"},{\"boundingBox\":[{\"x\":1357,\"y\":118},{\"x\":1428,\"y\":118},{\"x\":1428,\"y\":141},{\"x\":1357,\"y\":140}],\"text\":\"relative\"},{\"boundingBox\":[{\"x\":1146,\"y\":146},{\"x\":1182,\"y\":145},{\"x\":1182,\"y\":168},{\"x\":1146,\"y\":168}],\"text\":\"rep.\"},{\"boundingBox\":[{\"x\":1187,\"y\":145},{\"x\":1253,\"y\":144},{\"x\":1253,\"y\":166},{\"x\":1186,\"y\":168}],\"text\":\"scores\"},{\"boundingBox\":[{\"x\":101,\"y\":258},{\"x\":162,\"y\":258},{\"x\":163,\"y\":283},{\"x\":102,\"y\":282}],\"text\":\"Input:\"},{\"boundingBox\":[{\"x\":168,\"y\":258},{\"x\":180,\"y\":257},{\"x\":180,\"y\":284},{\"x\":168,\"y\":283}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":185,\"y\":257},{\"x\":198,\"y\":257},{\"x\":199,\"y\":284},{\"x\":185,\"y\":284}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":204,\"y\":257},{\"x\":217,\"y\":257},{\"x\":217,\"y\":284},{\"x\":204,\"y\":284}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":222,\"y\":257},{\"x\":248,\"y\":257},{\"x\":248,\"y\":285},{\"x\":223,\"y\":284}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":253,\"y\":257},{\"x\":279,\"y\":257},{\"x\":279,\"y\":285},{\"x\":253,\"y\":285}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":284,\"y\":258},{\"x\":315,\"y\":258},{\"x\":315,\"y\":285},{\"x\":284,\"y\":285}],\"text\":\"1]*\"},{\"boundingBox\":[{\"x\":1156,\"y\":232},{\"x\":1225,\"y\":231},{\"x\":1224,\"y\":256},{\"x\":1155,\"y\":256}],\"text\":\"Ouput:\"},{\"boundingBox\":[{\"x\":1230,\"y\":231},{\"x\":1244,\"y\":231},{\"x\":1243,\"y\":256},{\"x\":1229,\"y\":256}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1250,\"y\":231},{\"x\":1262,\"y\":231},{\"x\":1261,\"y\":256},{\"x\":1248,\"y\":256}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":1267,\"y\":231},{\"x\":1281,\"y\":231},{\"x\":1280,\"y\":256},{\"x\":1266,\"y\":256}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1287,\"y\":231},{\"x\":1313,\"y\":231},{\"x\":1311,\"y\":256},{\"x\":1285,\"y\":256}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":1317,\"y\":231},{\"x\":1343,\"y\":231},{\"x\":1342,\"y\":256},{\"x\":1316,\"y\":256}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":1348,\"y\":231},{\"x\":1371,\"y\":231},{\"x\":1369,\"y\":256},{\"x\":1346,\"y\":256}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":342,\"y\":257},{\"x\":440,\"y\":257},{\"x\":440,\"y\":282},{\"x\":342,\"y\":279}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":444,\"y\":257},{\"x\":514,\"y\":258},{\"x\":514,\"y\":283},{\"x\":444,\"y\":282}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":609,\"y\":256},{\"x\":650,\"y\":256},{\"x\":650,\"y\":276},{\"x\":609,\"y\":276}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":825,\"y\":258},{\"x\":853,\"y\":257},{\"x\":854,\"y\":278},{\"x\":826,\"y\":279}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1021,\"y\":258},{\"x\":1043,\"y\":256},{\"x\":1045,\"y\":277},{\"x\":1023,\"y\":279}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1155,\"y\":258},{\"x\":1193,\"y\":258},{\"x\":1192,\"y\":281},{\"x\":1153,\"y\":281}],\"text\":\"fully\"},{\"boundingBox\":[{\"x\":1198,\"y\":258},{\"x\":1299,\"y\":258},{\"x\":1298,\"y\":281},{\"x\":1196,\"y\":281}],\"text\":\"connected\"},{\"boundingBox\":[{\"x\":1304,\"y\":258},{\"x\":1366,\"y\":258},{\"x\":1365,\"y\":282},{\"x\":1303,\"y\":281}],\"text\":\"global\"},{\"boundingBox\":[{\"x\":1157,\"y\":284},{\"x\":1236,\"y\":285},{\"x\":1236,\"y\":308},{\"x\":1156,\"y\":308}],\"text\":\"absolute\"},{\"boundingBox\":[{\"x\":1241,\"y\":285},{\"x\":1280,\"y\":285},{\"x\":1279,\"y\":308},{\"x\":1240,\"y\":308}],\"text\":\"rep.\"},{\"boundingBox\":[{\"x\":1284,\"y\":285},{\"x\":1351,\"y\":286},{\"x\":1350,\"y\":308},{\"x\":1283,\"y\":308}],\"text\":\"scores\"},{\"boundingBox\":[{\"x\":96,\"y\":408},{\"x\":156,\"y\":409},{\"x\":155,\"y\":434},{\"x\":94,\"y\":433}],\"text\":\"Input:\"},{\"boundingBox\":[{\"x\":161,\"y\":409},{\"x\":175,\"y\":409},{\"x\":174,\"y\":434},{\"x\":160,\"y\":434}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":180,\"y\":409},{\"x\":193,\"y\":409},{\"x\":192,\"y\":434},{\"x\":179,\"y\":434}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":198,\"y\":409},{\"x\":212,\"y\":409},{\"x\":211,\"y\":435},{\"x\":197,\"y\":434}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":218,\"y\":409},{\"x\":242,\"y\":409},{\"x\":242,\"y\":435},{\"x\":217,\"y\":435}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":247,\"y\":409},{\"x\":274,\"y\":409},{\"x\":273,\"y\":434},{\"x\":247,\"y\":434}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":279,\"y\":409},{\"x\":301,\"y\":409},{\"x\":300,\"y\":434},{\"x\":278,\"y\":434}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":1156,\"y\":396},{\"x\":1239,\"y\":396},{\"x\":1238,\"y\":420},{\"x\":1154,\"y\":420}],\"text\":\"Output:\"},{\"boundingBox\":[{\"x\":1244,\"y\":396},{\"x\":1275,\"y\":396},{\"x\":1274,\"y\":420},{\"x\":1243,\"y\":420}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":1280,\"y\":396},{\"x\":1294,\"y\":396},{\"x\":1294,\"y\":420},{\"x\":1280,\"y\":420}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1299,\"y\":396},{\"x\":1325,\"y\":396},{\"x\":1324,\"y\":420},{\"x\":1299,\"y\":420}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":1329,\"y\":396},{\"x\":1356,\"y\":396},{\"x\":1356,\"y\":420},{\"x\":1329,\"y\":420}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":1361,\"y\":396},{\"x\":1385,\"y\":396},{\"x\":1385,\"y\":420},{\"x\":1361,\"y\":420}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":100,\"y\":436},{\"x\":147,\"y\":436},{\"x\":146,\"y\":456},{\"x\":100,\"y\":455}],\"text\":\"local\"},{\"boundingBox\":[{\"x\":346,\"y\":420},{\"x\":440,\"y\":421},{\"x\":439,\"y\":444},{\"x\":346,\"y\":442}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":444,\"y\":421},{\"x\":516,\"y\":422},{\"x\":515,\"y\":445},{\"x\":444,\"y\":444}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":610,\"y\":421},{\"x\":651,\"y\":421},{\"x\":651,\"y\":441},{\"x\":610,\"y\":441}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":824,\"y\":422},{\"x\":852,\"y\":420},{\"x\":853,\"y\":440},{\"x\":826,\"y\":442}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1023,\"y\":421},{\"x\":1044,\"y\":420},{\"x\":1045,\"y\":442},{\"x\":1024,\"y\":443}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1159,\"y\":422},{\"x\":1234,\"y\":422},{\"x\":1234,\"y\":446},{\"x\":1159,\"y\":446}],\"text\":\"partially\"},{\"boundingBox\":[{\"x\":1239,\"y\":422},{\"x\":1341,\"y\":422},{\"x\":1341,\"y\":445},{\"x\":1239,\"y\":445}],\"text\":\"connected\"},{\"boundingBox\":[{\"x\":1346,\"y\":422},{\"x\":1395,\"y\":422},{\"x\":1394,\"y\":445},{\"x\":1345,\"y\":445}],\"text\":\"local\"},{\"boundingBox\":[{\"x\":1156,\"y\":448},{\"x\":1236,\"y\":449},{\"x\":1236,\"y\":472},{\"x\":1156,\"y\":471}],\"text\":\"absolute\"},{\"boundingBox\":[{\"x\":1240,\"y\":449},{\"x\":1344,\"y\":449},{\"x\":1344,\"y\":471},{\"x\":1240,\"y\":472}],\"text\":\"rep.scores\"},{\"boundingBox\":[{\"x\":23,\"y\":495},{\"x\":24,\"y\":372},{\"x\":52,\"y\":372},{\"x\":52,\"y\":496}],\"text\":\"Appleseed\"},{\"boundingBox\":[{\"x\":24,\"y\":366},{\"x\":24,\"y\":350},{\"x\":52,\"y\":350},{\"x\":52,\"y\":366}],\"text\":\"|\"},{\"boundingBox\":[{\"x\":24,\"y\":342},{\"x\":25,\"y\":217},{\"x\":53,\"y\":216},{\"x\":52,\"y\":342}],\"text\":\"PeerTrust\"},{\"boundingBox\":[{\"x\":25,\"y\":209},{\"x\":26,\"y\":202},{\"x\":53,\"y\":201},{\"x\":53,\"y\":208}],\"text\":\"|\"},{\"boundingBox\":[{\"x\":26,\"y\":196},{\"x\":27,\"y\":60},{\"x\":55,\"y\":58},{\"x\":53,\"y\":195}],\"text\":\"EigenTrust\"},{\"boundingBox\":[{\"x\":96,\"y\":557},{\"x\":156,\"y\":557},{\"x\":155,\"y\":582},{\"x\":95,\"y\":582}],\"text\":\"Input:\"},{\"boundingBox\":[{\"x\":161,\"y\":557},{\"x\":175,\"y\":557},{\"x\":174,\"y\":582},{\"x\":160,\"y\":582}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":180,\"y\":557},{\"x\":193,\"y\":557},{\"x\":192,\"y\":582},{\"x\":179,\"y\":582}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":198,\"y\":557},{\"x\":212,\"y\":557},{\"x\":210,\"y\":582},{\"x\":197,\"y\":582}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":217,\"y\":557},{\"x\":242,\"y\":557},{\"x\":240,\"y\":582},{\"x\":215,\"y\":582}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":247,\"y\":557},{\"x\":282,\"y\":557},{\"x\":281,\"y\":583},{\"x\":245,\"y\":582}],\"text\":\"{-1,\"},{\"boundingBox\":[{\"x\":287,\"y\":557},{\"x\":319,\"y\":556},{\"x\":318,\"y\":583},{\"x\":286,\"y\":583}],\"text\":\"1]*\"},{\"boundingBox\":[{\"x\":344,\"y\":557},{\"x\":440,\"y\":556},{\"x\":439,\"y\":580},{\"x\":342,\"y\":578}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":445,\"y\":556},{\"x\":513,\"y\":556},{\"x\":512,\"y\":579},{\"x\":444,\"y\":580}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":611,\"y\":556},{\"x\":650,\"y\":555},{\"x\":651,\"y\":576},{\"x\":611,\"y\":577}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":825,\"y\":556},{\"x\":848,\"y\":556},{\"x\":849,\"y\":569},{\"x\":826,\"y\":568}],\"text\":\"DO\"},{\"boundingBox\":[{\"x\":1024,\"y\":555},{\"x\":1043,\"y\":554},{\"x\":1045,\"y\":576},{\"x\":1025,\"y\":577}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1155,\"y\":546},{\"x\":1239,\"y\":547},{\"x\":1238,\"y\":572},{\"x\":1153,\"y\":572}],\"text\":\"Output:\"},{\"boundingBox\":[{\"x\":1244,\"y\":547},{\"x\":1275,\"y\":547},{\"x\":1274,\"y\":572},{\"x\":1243,\"y\":572}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":1280,\"y\":547},{\"x\":1293,\"y\":547},{\"x\":1293,\"y\":572},{\"x\":1279,\"y\":572}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1298,\"y\":547},{\"x\":1325,\"y\":547},{\"x\":1324,\"y\":572},{\"x\":1298,\"y\":572}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":1330,\"y\":547},{\"x\":1358,\"y\":547},{\"x\":1358,\"y\":572},{\"x\":1329,\"y\":572}],\"text\":\"{0,\"},{\"boundingBox\":[{\"x\":1363,\"y\":547},{\"x\":1386,\"y\":546},{\"x\":1387,\"y\":572},{\"x\":1363,\"y\":572}],\"text\":\"1}\"},{\"boundingBox\":[{\"x\":1156,\"y\":572},{\"x\":1193,\"y\":573},{\"x\":1192,\"y\":596},{\"x\":1155,\"y\":596}],\"text\":\"fully\"},{\"boundingBox\":[{\"x\":1197,\"y\":573},{\"x\":1299,\"y\":574},{\"x\":1298,\"y\":597},{\"x\":1196,\"y\":596}],\"text\":\"connected\"},{\"boundingBox\":[{\"x\":1304,\"y\":574},{\"x\":1369,\"y\":574},{\"x\":1369,\"y\":598},{\"x\":1303,\"y\":597}],\"text\":\"global\"},{\"boundingBox\":[{\"x\":11,\"y\":634},{\"x\":11,\"y\":552},{\"x\":38,\"y\":552},{\"x\":37,\"y\":635}],\"text\":\"Aberer\"},{\"boundingBox\":[{\"x\":12,\"y\":546},{\"x\":12,\"y\":532},{\"x\":39,\"y\":531},{\"x\":38,\"y\":546}],\"text\":\"&\"},{\"boundingBox\":[{\"x\":40,\"y\":647},{\"x\":43,\"y\":513},{\"x\":68,\"y\":512},{\"x\":66,\"y\":650}],\"text\":\"Despotovic\"},{\"boundingBox\":[{\"x\":95,\"y\":711},{\"x\":162,\"y\":711},{\"x\":161,\"y\":739},{\"x\":94,\"y\":738}],\"text\":\"Input:\"},{\"boundingBox\":[{\"x\":168,\"y\":711},{\"x\":198,\"y\":711},{\"x\":197,\"y\":740},{\"x\":167,\"y\":739}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":203,\"y\":711},{\"x\":216,\"y\":711},{\"x\":216,\"y\":740},{\"x\":202,\"y\":740}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":222,\"y\":711},{\"x\":248,\"y\":711},{\"x\":247,\"y\":740},{\"x\":221,\"y\":740}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":254,\"y\":710},{\"x\":280,\"y\":710},{\"x\":279,\"y\":739},{\"x\":253,\"y\":740}],\"text\":\"{0,\"},{\"boundingBox\":[{\"x\":285,\"y\":710},{\"x\":314,\"y\":710},{\"x\":313,\"y\":739},{\"x\":285,\"y\":739}],\"text\":\"1}\"},{\"boundingBox\":[{\"x\":344,\"y\":711},{\"x\":440,\"y\":710},{\"x\":439,\"y\":734},{\"x\":342,\"y\":732}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":444,\"y\":710},{\"x\":515,\"y\":711},{\"x\":514,\"y\":735},{\"x\":443,\"y\":734}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":1157,\"y\":688},{\"x\":1231,\"y\":688},{\"x\":1230,\"y\":712},{\"x\":1157,\"y\":713}],\"text\":\"Ouput:\"},{\"boundingBox\":[{\"x\":1236,\"y\":688},{\"x\":1268,\"y\":687},{\"x\":1267,\"y\":712},{\"x\":1235,\"y\":712}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":1273,\"y\":687},{\"x\":1286,\"y\":687},{\"x\":1285,\"y\":712},{\"x\":1272,\"y\":712}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1291,\"y\":687},{\"x\":1319,\"y\":687},{\"x\":1317,\"y\":712},{\"x\":1290,\"y\":712}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":1324,\"y\":687},{\"x\":1351,\"y\":687},{\"x\":1350,\"y\":713},{\"x\":1322,\"y\":712}],\"text\":\"{0,\"},{\"boundingBox\":[{\"x\":1356,\"y\":687},{\"x\":1379,\"y\":687},{\"x\":1377,\"y\":713},{\"x\":1354,\"y\":713}],\"text\":\"1}\"},{\"boundingBox\":[{\"x\":608,\"y\":711},{\"x\":650,\"y\":709},{\"x\":651,\"y\":731},{\"x\":609,\"y\":733}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":828,\"y\":712},{\"x\":853,\"y\":710},{\"x\":855,\"y\":731},{\"x\":829,\"y\":733}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1021,\"y\":712},{\"x\":1042,\"y\":710},{\"x\":1044,\"y\":731},{\"x\":1023,\"y\":733}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1156,\"y\":716},{\"x\":1229,\"y\":715},{\"x\":1228,\"y\":738},{\"x\":1156,\"y\":740}],\"text\":\"partially\"},{\"boundingBox\":[{\"x\":1233,\"y\":714},{\"x\":1340,\"y\":715},{\"x\":1339,\"y\":738},{\"x\":1233,\"y\":738}],\"text\":\"connected,\"},{\"boundingBox\":[{\"x\":1345,\"y\":715},{\"x\":1396,\"y\":716},{\"x\":1395,\"y\":739},{\"x\":1344,\"y\":738}],\"text\":\"local\"},{\"boundingBox\":[{\"x\":95,\"y\":870},{\"x\":156,\"y\":871},{\"x\":156,\"y\":897},{\"x\":95,\"y\":896}],\"text\":\"Input:\"},{\"boundingBox\":[{\"x\":162,\"y\":871},{\"x\":174,\"y\":871},{\"x\":173,\"y\":898},{\"x\":161,\"y\":897}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":179,\"y\":871},{\"x\":192,\"y\":871},{\"x\":191,\"y\":898},{\"x\":179,\"y\":898}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":197,\"y\":871},{\"x\":212,\"y\":871},{\"x\":211,\"y\":898},{\"x\":196,\"y\":898}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":218,\"y\":870},{\"x\":243,\"y\":870},{\"x\":242,\"y\":897},{\"x\":217,\"y\":898}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":248,\"y\":870},{\"x\":274,\"y\":870},{\"x\":273,\"y\":897},{\"x\":247,\"y\":897}],\"text\":\"{0,\"},{\"boundingBox\":[{\"x\":279,\"y\":870},{\"x\":313,\"y\":869},{\"x\":312,\"y\":896},{\"x\":278,\"y\":897}],\"text\":\"1]*\"},{\"boundingBox\":[{\"x\":344,\"y\":870},{\"x\":439,\"y\":870},{\"x\":439,\"y\":894},{\"x\":344,\"y\":891}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":444,\"y\":870},{\"x\":515,\"y\":871},{\"x\":515,\"y\":897},{\"x\":444,\"y\":894}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":609,\"y\":870},{\"x\":652,\"y\":870},{\"x\":652,\"y\":891},{\"x\":609,\"y\":891}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":825,\"y\":872},{\"x\":853,\"y\":869},{\"x\":854,\"y\":889},{\"x\":827,\"y\":892}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1023,\"y\":871},{\"x\":1045,\"y\":869},{\"x\":1047,\"y\":892},{\"x\":1024,\"y\":894}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1144,\"y\":857},{\"x\":1222,\"y\":858},{\"x\":1221,\"y\":881},{\"x\":1144,\"y\":880}],\"text\":\"Ouput:\"},{\"boundingBox\":[{\"x\":1227,\"y\":858},{\"x\":1259,\"y\":858},{\"x\":1258,\"y\":881},{\"x\":1226,\"y\":881}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":1264,\"y\":858},{\"x\":1277,\"y\":858},{\"x\":1276,\"y\":881},{\"x\":1263,\"y\":881}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1282,\"y\":858},{\"x\":1309,\"y\":858},{\"x\":1308,\"y\":881},{\"x\":1281,\"y\":881}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":1314,\"y\":858},{\"x\":1340,\"y\":858},{\"x\":1338,\"y\":881},{\"x\":1313,\"y\":881}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":1344,\"y\":858},{\"x\":1366,\"y\":857},{\"x\":1364,\"y\":881},{\"x\":1343,\"y\":881}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":1145,\"y\":883},{\"x\":1191,\"y\":884},{\"x\":1190,\"y\":907},{\"x\":1144,\"y\":907}],\"text\":\"local\"},{\"boundingBox\":[{\"x\":1195,\"y\":884},{\"x\":1277,\"y\":885},{\"x\":1276,\"y\":907},{\"x\":1194,\"y\":907}],\"text\":\"absolute\"},{\"boundingBox\":[{\"x\":1281,\"y\":885},{\"x\":1321,\"y\":885},{\"x\":1321,\"y\":907},{\"x\":1281,\"y\":907}],\"text\":\"rep.\"},{\"boundingBox\":[{\"x\":1326,\"y\":885},{\"x\":1392,\"y\":886},{\"x\":1392,\"y\":908},{\"x\":1325,\"y\":907}],\"text\":\"scores\"},{\"boundingBox\":[{\"x\":24,\"y\":931},{\"x\":25,\"y\":827},{\"x\":52,\"y\":827},{\"x\":51,\"y\":930}],\"text\":\"TRAVOS\"},{\"boundingBox\":[{\"x\":26,\"y\":807},{\"x\":28,\"y\":671},{\"x\":53,\"y\":671},{\"x\":52,\"y\":807}],\"text\":\"|Advogato\"},{\"boundingBox\":[{\"x\":95,\"y\":1003},{\"x\":156,\"y\":1002},{\"x\":155,\"y\":1028},{\"x\":94,\"y\":1029}],\"text\":\"Input:\"},{\"boundingBox\":[{\"x\":161,\"y\":1002},{\"x\":175,\"y\":1002},{\"x\":174,\"y\":1028},{\"x\":161,\"y\":1028}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":180,\"y\":1002},{\"x\":193,\"y\":1002},{\"x\":193,\"y\":1028},{\"x\":179,\"y\":1028}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":199,\"y\":1002},{\"x\":212,\"y\":1002},{\"x\":212,\"y\":1028},{\"x\":198,\"y\":1028}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":217,\"y\":1002},{\"x\":243,\"y\":1002},{\"x\":243,\"y\":1028},{\"x\":217,\"y\":1028}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":248,\"y\":1002},{\"x\":274,\"y\":1002},{\"x\":274,\"y\":1028},{\"x\":248,\"y\":1028}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":279,\"y\":1002},{\"x\":301,\"y\":1002},{\"x\":301,\"y\":1029},{\"x\":279,\"y\":1028}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":97,\"y\":1031},{\"x\":167,\"y\":1030},{\"x\":166,\"y\":1053},{\"x\":96,\"y\":1051}],\"text\":\"relative\"},{\"boundingBox\":[{\"x\":172,\"y\":1030},{\"x\":210,\"y\":1030},{\"x\":209,\"y\":1053},{\"x\":171,\"y\":1053}],\"text\":\"rep.\"},{\"boundingBox\":[{\"x\":214,\"y\":1030},{\"x\":280,\"y\":1030},{\"x\":280,\"y\":1053},{\"x\":214,\"y\":1053}],\"text\":\"scores\"},{\"boundingBox\":[{\"x\":343,\"y\":1014},{\"x\":440,\"y\":1014},{\"x\":440,\"y\":1037},{\"x\":341,\"y\":1036}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":445,\"y\":1014},{\"x\":516,\"y\":1015},{\"x\":516,\"y\":1040},{\"x\":444,\"y\":1037}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":609,\"y\":1014},{\"x\":651,\"y\":1014},{\"x\":651,\"y\":1035},{\"x\":609,\"y\":1035}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":825,\"y\":1014},{\"x\":853,\"y\":1013},{\"x\":854,\"y\":1035},{\"x\":826,\"y\":1036}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1020,\"y\":1016},{\"x\":1044,\"y\":1014},{\"x\":1045,\"y\":1035},{\"x\":1022,\"y\":1037}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1145,\"y\":1003},{\"x\":1223,\"y\":1003},{\"x\":1222,\"y\":1027},{\"x\":1144,\"y\":1027}],\"text\":\"Output:\"},{\"boundingBox\":[{\"x\":1228,\"y\":1003},{\"x\":1241,\"y\":1003},{\"x\":1241,\"y\":1028},{\"x\":1227,\"y\":1027}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1246,\"y\":1003},{\"x\":1260,\"y\":1003},{\"x\":1259,\"y\":1028},{\"x\":1246,\"y\":1028}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":1265,\"y\":1003},{\"x\":1278,\"y\":1003},{\"x\":1277,\"y\":1028},{\"x\":1264,\"y\":1028}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1283,\"y\":1003},{\"x\":1310,\"y\":1002},{\"x\":1309,\"y\":1028},{\"x\":1282,\"y\":1028}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":1315,\"y\":1002},{\"x\":1341,\"y\":1002},{\"x\":1341,\"y\":1029},{\"x\":1314,\"y\":1028}],\"text\":\"{0,\"},{\"boundingBox\":[{\"x\":1346,\"y\":1002},{\"x\":1371,\"y\":1001},{\"x\":1371,\"y\":1029},{\"x\":1346,\"y\":1029}],\"text\":\"1}\"},{\"boundingBox\":[{\"x\":1144,\"y\":1030},{\"x\":1218,\"y\":1030},{\"x\":1219,\"y\":1053},{\"x\":1145,\"y\":1053}],\"text\":\"partially\"},{\"boundingBox\":[{\"x\":1223,\"y\":1030},{\"x\":1326,\"y\":1029},{\"x\":1327,\"y\":1052},{\"x\":1223,\"y\":1053}],\"text\":\"connected\"},{\"boundingBox\":[{\"x\":96,\"y\":1162},{\"x\":158,\"y\":1161},{\"x\":157,\"y\":1185},{\"x\":95,\"y\":1185}],\"text\":\"Input:\"},{\"boundingBox\":[{\"x\":163,\"y\":1161},{\"x\":176,\"y\":1161},{\"x\":175,\"y\":1185},{\"x\":162,\"y\":1185}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":180,\"y\":1161},{\"x\":193,\"y\":1161},{\"x\":193,\"y\":1185},{\"x\":180,\"y\":1185}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":198,\"y\":1161},{\"x\":212,\"y\":1161},{\"x\":211,\"y\":1186},{\"x\":197,\"y\":1186}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":217,\"y\":1161},{\"x\":243,\"y\":1161},{\"x\":242,\"y\":1186},{\"x\":217,\"y\":1186}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":248,\"y\":1161},{\"x\":275,\"y\":1161},{\"x\":275,\"y\":1186},{\"x\":247,\"y\":1186}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":280,\"y\":1161},{\"x\":299,\"y\":1161},{\"x\":299,\"y\":1187},{\"x\":279,\"y\":1186}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":105,\"y\":1188},{\"x\":184,\"y\":1188},{\"x\":184,\"y\":1211},{\"x\":105,\"y\":1209}],\"text\":\"absolute\"},{\"boundingBox\":[{\"x\":189,\"y\":1188},{\"x\":228,\"y\":1188},{\"x\":228,\"y\":1211},{\"x\":189,\"y\":1211}],\"text\":\"rep.\"},{\"boundingBox\":[{\"x\":232,\"y\":1188},{\"x\":299,\"y\":1187},{\"x\":299,\"y\":1210},{\"x\":232,\"y\":1211}],\"text\":\"scores\"},{\"boundingBox\":[{\"x\":343,\"y\":1173},{\"x\":440,\"y\":1172},{\"x\":439,\"y\":1194},{\"x\":341,\"y\":1194}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":444,\"y\":1172},{\"x\":513,\"y\":1173},{\"x\":513,\"y\":1196},{\"x\":444,\"y\":1194}],\"text\":\"History\"},{\"boundingBox\":[{\"x\":610,\"y\":1172},{\"x\":651,\"y\":1172},{\"x\":651,\"y\":1192},{\"x\":610,\"y\":1192}],\"text\":\"FHG\"},{\"boundingBox\":[{\"x\":826,\"y\":1172},{\"x\":853,\"y\":1171},{\"x\":854,\"y\":1192},{\"x\":827,\"y\":1194}],\"text\":\"RG\"},{\"boundingBox\":[{\"x\":1021,\"y\":1173},{\"x\":1043,\"y\":1172},{\"x\":1044,\"y\":1191},{\"x\":1022,\"y\":1193}],\"text\":\"TG\"},{\"boundingBox\":[{\"x\":1156,\"y\":1160},{\"x\":1232,\"y\":1160},{\"x\":1231,\"y\":1186},{\"x\":1155,\"y\":1184}],\"text\":\"Output:\"},{\"boundingBox\":[{\"x\":1237,\"y\":1160},{\"x\":1250,\"y\":1160},{\"x\":1250,\"y\":1186},{\"x\":1237,\"y\":1186}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1255,\"y\":1160},{\"x\":1267,\"y\":1160},{\"x\":1267,\"y\":1186},{\"x\":1255,\"y\":1186}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":1272,\"y\":1160},{\"x\":1286,\"y\":1160},{\"x\":1286,\"y\":1186},{\"x\":1272,\"y\":1186}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1291,\"y\":1160},{\"x\":1317,\"y\":1159},{\"x\":1317,\"y\":1187},{\"x\":1291,\"y\":1186}],\"text\":\"=>\"},{\"boundingBox\":[{\"x\":1322,\"y\":1159},{\"x\":1349,\"y\":1159},{\"x\":1349,\"y\":1187},{\"x\":1322,\"y\":1187}],\"text\":\"{0,\"},{\"boundingBox\":[{\"x\":1354,\"y\":1159},{\"x\":1381,\"y\":1159},{\"x\":1381,\"y\":1186},{\"x\":1354,\"y\":1187}],\"text\":\"1}\"},{\"boundingBox\":[{\"x\":1157,\"y\":1188},{\"x\":1229,\"y\":1188},{\"x\":1228,\"y\":1212},{\"x\":1156,\"y\":1210}],\"text\":\"partially\"},{\"boundingBox\":[{\"x\":1234,\"y\":1188},{\"x\":1335,\"y\":1185},{\"x\":1335,\"y\":1208},{\"x\":1233,\"y\":1212}],\"text\":\"connected\"},{\"boundingBox\":[{\"x\":26,\"y\":1259},{\"x\":26,\"y\":1111},{\"x\":54,\"y\":1111},{\"x\":52,\"y\":1259}],\"text\":\"Thresholding\"},{\"boundingBox\":[{\"x\":26,\"y\":1082},{\"x\":26,\"y\":983},{\"x\":55,\"y\":984},{\"x\":54,\"y\":1082}],\"text\":\"Ranking\"}]}",
        "{\"language\":\"en\",\"text\":\"FHGO PeerTrust Preconditions: A x A + [0,1]* Post-conditions: RG2 Discretizer Fully connected, global, Preconditions: A x A + [0, 1]* absolute r(a,b) A x A ++ [0, 1] Post-conditions Normalizer Ax A ++ {-1,1}* Preconditions: A x A ++ [0, 1] Post-conditions: Fully connected, global, FHG1 relative r(a, b) A x A ++ [0, 1] EigenTrust Preconditions: RG3 Ax A ++ {-1,1}* RG1 Post-conditions: Fully connected, global, relative r(a, b) Spearman A x A ++ [0, 1] Correlation coefficient\",\"lines\":[{\"boundingBox\":[{\"x\":100,\"y\":36},{\"x\":182,\"y\":37},{\"x\":182,\"y\":67},{\"x\":98,\"y\":65}],\"text\":\"FHGO\"},{\"boundingBox\":[{\"x\":616,\"y\":60},{\"x\":768,\"y\":60},{\"x\":768,\"y\":93},{\"x\":616,\"y\":92}],\"text\":\"PeerTrust\"},{\"boundingBox\":[{\"x\":503,\"y\":105},{\"x\":728,\"y\":105},{\"x\":728,\"y\":138},{\"x\":503,\"y\":137}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":507,\"y\":147},{\"x\":718,\"y\":148},{\"x\":717,\"y\":185},{\"x\":507,\"y\":182}],\"text\":\"A x A + [0,1]*\"},{\"boundingBox\":[{\"x\":506,\"y\":194},{\"x\":757,\"y\":195},{\"x\":757,\"y\":228},{\"x\":506,\"y\":227}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":1036,\"y\":172},{\"x\":1103,\"y\":174},{\"x\":1103,\"y\":203},{\"x\":1037,\"y\":201}],\"text\":\"RG2\"},{\"boundingBox\":[{\"x\":70,\"y\":230},{\"x\":234,\"y\":231},{\"x\":234,\"y\":260},{\"x\":70,\"y\":259}],\"text\":\"Discretizer\"},{\"boundingBox\":[{\"x\":502,\"y\":238},{\"x\":866,\"y\":238},{\"x\":866,\"y\":276},{\"x\":502,\"y\":276}],\"text\":\"Fully connected, global,\"},{\"boundingBox\":[{\"x\":20,\"y\":274},{\"x\":242,\"y\":275},{\"x\":242,\"y\":305},{\"x\":20,\"y\":304}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":24,\"y\":306},{\"x\":237,\"y\":308},{\"x\":236,\"y\":345},{\"x\":23,\"y\":340}],\"text\":\"A x A + [0, 1]*\"},{\"boundingBox\":[{\"x\":503,\"y\":282},{\"x\":733,\"y\":283},{\"x\":732,\"y\":322},{\"x\":503,\"y\":320}],\"text\":\"absolute r(a,b)\"},{\"boundingBox\":[{\"x\":519,\"y\":329},{\"x\":741,\"y\":330},{\"x\":741,\"y\":362},{\"x\":519,\"y\":360}],\"text\":\"A x A ++ [0, 1]\"},{\"boundingBox\":[{\"x\":17,\"y\":362},{\"x\":261,\"y\":363},{\"x\":261,\"y\":396},{\"x\":17,\"y\":395}],\"text\":\"Post-conditions\"},{\"boundingBox\":[{\"x\":1109,\"y\":352},{\"x\":1280,\"y\":352},{\"x\":1280,\"y\":388},{\"x\":1109,\"y\":387}],\"text\":\"Normalizer\"},{\"boundingBox\":[{\"x\":14,\"y\":403},{\"x\":251,\"y\":405},{\"x\":251,\"y\":440},{\"x\":14,\"y\":438}],\"text\":\"Ax A ++ {-1,1}*\"},{\"boundingBox\":[{\"x\":989,\"y\":399},{\"x\":1214,\"y\":399},{\"x\":1214,\"y\":432},{\"x\":989,\"y\":431}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":1005,\"y\":441},{\"x\":1229,\"y\":443},{\"x\":1229,\"y\":476},{\"x\":1005,\"y\":473}],\"text\":\"A x A ++ [0, 1]\"},{\"boundingBox\":[{\"x\":990,\"y\":488},{\"x\":1241,\"y\":490},{\"x\":1241,\"y\":523},{\"x\":989,\"y\":520}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":989,\"y\":531},{\"x\":1352,\"y\":533},{\"x\":1351,\"y\":573},{\"x\":989,\"y\":570}],\"text\":\"Fully connected, global,\"},{\"boundingBox\":[{\"x\":196,\"y\":579},{\"x\":282,\"y\":579},{\"x\":282,\"y\":609},{\"x\":196,\"y\":608}],\"text\":\"FHG1\"},{\"boundingBox\":[{\"x\":990,\"y\":577},{\"x\":1208,\"y\":579},{\"x\":1207,\"y\":616},{\"x\":990,\"y\":613}],\"text\":\"relative r(a, b)\"},{\"boundingBox\":[{\"x\":1012,\"y\":628},{\"x\":1236,\"y\":630},{\"x\":1235,\"y\":665},{\"x\":1012,\"y\":661}],\"text\":\"A x A ++ [0, 1]\"},{\"boundingBox\":[{\"x\":156,\"y\":733},{\"x\":321,\"y\":732},{\"x\":322,\"y\":769},{\"x\":156,\"y\":770}],\"text\":\"EigenTrust\"},{\"boundingBox\":[{\"x\":34,\"y\":778},{\"x\":261,\"y\":778},{\"x\":261,\"y\":812},{\"x\":34,\"y\":812}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":1130,\"y\":787},{\"x\":1197,\"y\":789},{\"x\":1197,\"y\":821},{\"x\":1131,\"y\":820}],\"text\":\"RG3\"},{\"boundingBox\":[{\"x\":67,\"y\":817},{\"x\":299,\"y\":818},{\"x\":299,\"y\":853},{\"x\":67,\"y\":852}],\"text\":\"Ax A ++ {-1,1}*\"},{\"boundingBox\":[{\"x\":659,\"y\":792},{\"x\":727,\"y\":791},{\"x\":727,\"y\":823},{\"x\":659,\"y\":823}],\"text\":\"RG1\"},{\"boundingBox\":[{\"x\":33,\"y\":867},{\"x\":288,\"y\":868},{\"x\":288,\"y\":902},{\"x\":33,\"y\":901}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":36,\"y\":910},{\"x\":399,\"y\":910},{\"x\":399,\"y\":949},{\"x\":36,\"y\":949}],\"text\":\"Fully connected, global,\"},{\"boundingBox\":[{\"x\":36,\"y\":956},{\"x\":254,\"y\":958},{\"x\":253,\"y\":995},{\"x\":35,\"y\":992}],\"text\":\"relative r(a, b)\"},{\"boundingBox\":[{\"x\":859,\"y\":943},{\"x\":1017,\"y\":942},{\"x\":1017,\"y\":975},{\"x\":859,\"y\":977}],\"text\":\"Spearman\"},{\"boundingBox\":[{\"x\":49,\"y\":1007},{\"x\":280,\"y\":1008},{\"x\":279,\"y\":1042},{\"x\":48,\"y\":1041}],\"text\":\"A x A ++ [0, 1]\"},{\"boundingBox\":[{\"x\":1154,\"y\":999},{\"x\":1330,\"y\":999},{\"x\":1329,\"y\":1033},{\"x\":1154,\"y\":1031}],\"text\":\"Correlation\"},{\"boundingBox\":[{\"x\":1158,\"y\":1045},{\"x\":1324,\"y\":1045},{\"x\":1325,\"y\":1077},{\"x\":1158,\"y\":1078}],\"text\":\"coefficient\"}],\"words\":[{\"boundingBox\":[{\"x\":98,\"y\":36},{\"x\":177,\"y\":37},{\"x\":176,\"y\":67},{\"x\":98,\"y\":65}],\"text\":\"FHGO\"},{\"boundingBox\":[{\"x\":618,\"y\":60},{\"x\":768,\"y\":61},{\"x\":768,\"y\":94},{\"x\":616,\"y\":92}],\"text\":\"PeerTrust\"},{\"boundingBox\":[{\"x\":504,\"y\":105},{\"x\":729,\"y\":106},{\"x\":728,\"y\":139},{\"x\":503,\"y\":138}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":509,\"y\":148},{\"x\":529,\"y\":148},{\"x\":529,\"y\":182},{\"x\":509,\"y\":182}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":537,\"y\":148},{\"x\":557,\"y\":148},{\"x\":556,\"y\":182},{\"x\":536,\"y\":182}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":571,\"y\":148},{\"x\":591,\"y\":148},{\"x\":591,\"y\":183},{\"x\":571,\"y\":182}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":599,\"y\":148},{\"x\":619,\"y\":148},{\"x\":618,\"y\":183},{\"x\":598,\"y\":183}],\"text\":\"+\"},{\"boundingBox\":[{\"x\":643,\"y\":149},{\"x\":719,\"y\":149},{\"x\":718,\"y\":186},{\"x\":642,\"y\":184}],\"text\":\"[0,1]*\"},{\"boundingBox\":[{\"x\":507,\"y\":195},{\"x\":756,\"y\":196},{\"x\":757,\"y\":229},{\"x\":506,\"y\":228}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":1037,\"y\":172},{\"x\":1099,\"y\":174},{\"x\":1098,\"y\":203},{\"x\":1037,\"y\":201}],\"text\":\"RG2\"},{\"boundingBox\":[{\"x\":71,\"y\":231},{\"x\":234,\"y\":231},{\"x\":234,\"y\":260},{\"x\":71,\"y\":260}],\"text\":\"Discretizer\"},{\"boundingBox\":[{\"x\":504,\"y\":239},{\"x\":575,\"y\":239},{\"x\":574,\"y\":276},{\"x\":502,\"y\":276}],\"text\":\"Fully\"},{\"boundingBox\":[{\"x\":583,\"y\":239},{\"x\":754,\"y\":239},{\"x\":754,\"y\":277},{\"x\":582,\"y\":277}],\"text\":\"connected,\"},{\"boundingBox\":[{\"x\":762,\"y\":239},{\"x\":867,\"y\":239},{\"x\":867,\"y\":277},{\"x\":761,\"y\":277}],\"text\":\"global,\"},{\"boundingBox\":[{\"x\":22,\"y\":274},{\"x\":241,\"y\":276},{\"x\":242,\"y\":306},{\"x\":20,\"y\":305}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":26,\"y\":307},{\"x\":45,\"y\":307},{\"x\":45,\"y\":339},{\"x\":25,\"y\":339}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":53,\"y\":307},{\"x\":72,\"y\":307},{\"x\":72,\"y\":340},{\"x\":52,\"y\":339}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":86,\"y\":307},{\"x\":106,\"y\":308},{\"x\":105,\"y\":341},{\"x\":86,\"y\":340}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":115,\"y\":308},{\"x\":135,\"y\":308},{\"x\":134,\"y\":341},{\"x\":115,\"y\":341}],\"text\":\"+\"},{\"boundingBox\":[{\"x\":160,\"y\":308},{\"x\":193,\"y\":308},{\"x\":193,\"y\":344},{\"x\":159,\"y\":342}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":200,\"y\":309},{\"x\":236,\"y\":309},{\"x\":236,\"y\":346},{\"x\":200,\"y\":344}],\"text\":\"1]*\"},{\"boundingBox\":[{\"x\":506,\"y\":283},{\"x\":634,\"y\":283},{\"x\":634,\"y\":321},{\"x\":505,\"y\":321}],\"text\":\"absolute\"},{\"boundingBox\":[{\"x\":642,\"y\":283},{\"x\":731,\"y\":285},{\"x\":732,\"y\":323},{\"x\":642,\"y\":321}],\"text\":\"r(a,b)\"},{\"boundingBox\":[{\"x\":522,\"y\":329},{\"x\":540,\"y\":329},{\"x\":539,\"y\":361},{\"x\":521,\"y\":361}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":553,\"y\":330},{\"x\":572,\"y\":330},{\"x\":571,\"y\":361},{\"x\":552,\"y\":361}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":589,\"y\":330},{\"x\":607,\"y\":330},{\"x\":607,\"y\":362},{\"x\":588,\"y\":362}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":618,\"y\":330},{\"x\":658,\"y\":330},{\"x\":658,\"y\":362},{\"x\":618,\"y\":362}],\"text\":\"++\"},{\"boundingBox\":[{\"x\":665,\"y\":330},{\"x\":704,\"y\":330},{\"x\":704,\"y\":363},{\"x\":664,\"y\":362}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":711,\"y\":330},{\"x\":741,\"y\":330},{\"x\":741,\"y\":363},{\"x\":711,\"y\":363}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":19,\"y\":363},{\"x\":260,\"y\":365},{\"x\":260,\"y\":397},{\"x\":17,\"y\":396}],\"text\":\"Post-conditions\"},{\"boundingBox\":[{\"x\":1110,\"y\":354},{\"x\":1280,\"y\":353},{\"x\":1280,\"y\":389},{\"x\":1110,\"y\":386}],\"text\":\"Normalizer\"},{\"boundingBox\":[{\"x\":19,\"y\":403},{\"x\":65,\"y\":405},{\"x\":65,\"y\":440},{\"x\":19,\"y\":439}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":77,\"y\":405},{\"x\":95,\"y\":405},{\"x\":95,\"y\":440},{\"x\":77,\"y\":440}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":101,\"y\":406},{\"x\":137,\"y\":406},{\"x\":137,\"y\":440},{\"x\":101,\"y\":440}],\"text\":\"++\"},{\"boundingBox\":[{\"x\":144,\"y\":406},{\"x\":252,\"y\":407},{\"x\":251,\"y\":439},{\"x\":143,\"y\":440}],\"text\":\"{-1,1}*\"},{\"boundingBox\":[{\"x\":990,\"y\":400},{\"x\":1213,\"y\":399},{\"x\":1212,\"y\":433},{\"x\":989,\"y\":431}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":1010,\"y\":442},{\"x\":1028,\"y\":442},{\"x\":1027,\"y\":473},{\"x\":1010,\"y\":474}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1042,\"y\":442},{\"x\":1060,\"y\":442},{\"x\":1060,\"y\":473},{\"x\":1042,\"y\":473}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":1077,\"y\":443},{\"x\":1095,\"y\":443},{\"x\":1095,\"y\":473},{\"x\":1077,\"y\":473}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1108,\"y\":443},{\"x\":1149,\"y\":443},{\"x\":1149,\"y\":474},{\"x\":1108,\"y\":473}],\"text\":\"++\"},{\"boundingBox\":[{\"x\":1155,\"y\":443},{\"x\":1195,\"y\":444},{\"x\":1194,\"y\":475},{\"x\":1155,\"y\":474}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":1201,\"y\":444},{\"x\":1230,\"y\":444},{\"x\":1229,\"y\":477},{\"x\":1200,\"y\":476}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":991,\"y\":488},{\"x\":1241,\"y\":491},{\"x\":1240,\"y\":524},{\"x\":990,\"y\":521}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":990,\"y\":532},{\"x\":1058,\"y\":532},{\"x\":1058,\"y\":570},{\"x\":990,\"y\":570}],\"text\":\"Fully\"},{\"boundingBox\":[{\"x\":1066,\"y\":532},{\"x\":1237,\"y\":532},{\"x\":1237,\"y\":572},{\"x\":1066,\"y\":570}],\"text\":\"connected,\"},{\"boundingBox\":[{\"x\":1245,\"y\":533},{\"x\":1350,\"y\":533},{\"x\":1350,\"y\":574},{\"x\":1245,\"y\":572}],\"text\":\"global,\"},{\"boundingBox\":[{\"x\":197,\"y\":580},{\"x\":279,\"y\":579},{\"x\":280,\"y\":610},{\"x\":197,\"y\":608}],\"text\":\"FHG1\"},{\"boundingBox\":[{\"x\":990,\"y\":578},{\"x\":1101,\"y\":578},{\"x\":1101,\"y\":614},{\"x\":990,\"y\":614}],\"text\":\"relative\"},{\"boundingBox\":[{\"x\":1108,\"y\":578},{\"x\":1165,\"y\":579},{\"x\":1164,\"y\":615},{\"x\":1108,\"y\":614}],\"text\":\"r(a,\"},{\"boundingBox\":[{\"x\":1172,\"y\":580},{\"x\":1208,\"y\":581},{\"x\":1207,\"y\":617},{\"x\":1171,\"y\":616}],\"text\":\"b)\"},{\"boundingBox\":[{\"x\":1014,\"y\":628},{\"x\":1033,\"y\":628},{\"x\":1033,\"y\":660},{\"x\":1015,\"y\":660}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1047,\"y\":628},{\"x\":1066,\"y\":628},{\"x\":1066,\"y\":660},{\"x\":1047,\"y\":660}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":1081,\"y\":629},{\"x\":1100,\"y\":629},{\"x\":1100,\"y\":661},{\"x\":1081,\"y\":661}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":1112,\"y\":629},{\"x\":1153,\"y\":629},{\"x\":1152,\"y\":662},{\"x\":1111,\"y\":661}],\"text\":\"++\"},{\"boundingBox\":[{\"x\":1159,\"y\":629},{\"x\":1198,\"y\":630},{\"x\":1197,\"y\":664},{\"x\":1159,\"y\":663}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":1205,\"y\":630},{\"x\":1236,\"y\":631},{\"x\":1235,\"y\":666},{\"x\":1204,\"y\":665}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":156,\"y\":734},{\"x\":321,\"y\":733},{\"x\":321,\"y\":770},{\"x\":157,\"y\":771}],\"text\":\"EigenTrust\"},{\"boundingBox\":[{\"x\":34,\"y\":778},{\"x\":262,\"y\":779},{\"x\":261,\"y\":812},{\"x\":34,\"y\":813}],\"text\":\"Preconditions:\"},{\"boundingBox\":[{\"x\":1132,\"y\":787},{\"x\":1193,\"y\":788},{\"x\":1192,\"y\":821},{\"x\":1131,\"y\":819}],\"text\":\"RG3\"},{\"boundingBox\":[{\"x\":69,\"y\":817},{\"x\":113,\"y\":818},{\"x\":112,\"y\":853},{\"x\":68,\"y\":853}],\"text\":\"Ax\"},{\"boundingBox\":[{\"x\":125,\"y\":818},{\"x\":144,\"y\":818},{\"x\":143,\"y\":853},{\"x\":124,\"y\":853}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":151,\"y\":818},{\"x\":185,\"y\":818},{\"x\":184,\"y\":853},{\"x\":149,\"y\":853}],\"text\":\"++\"},{\"boundingBox\":[{\"x\":192,\"y\":819},{\"x\":300,\"y\":820},{\"x\":298,\"y\":854},{\"x\":190,\"y\":853}],\"text\":\"{-1,1}*\"},{\"boundingBox\":[{\"x\":659,\"y\":791},{\"x\":722,\"y\":791},{\"x\":722,\"y\":823},{\"x\":659,\"y\":823}],\"text\":\"RG1\"},{\"boundingBox\":[{\"x\":33,\"y\":867},{\"x\":288,\"y\":870},{\"x\":289,\"y\":902},{\"x\":34,\"y\":902}],\"text\":\"Post-conditions:\"},{\"boundingBox\":[{\"x\":38,\"y\":910},{\"x\":106,\"y\":913},{\"x\":104,\"y\":949},{\"x\":36,\"y\":949}],\"text\":\"Fully\"},{\"boundingBox\":[{\"x\":113,\"y\":913},{\"x\":282,\"y\":914},{\"x\":282,\"y\":950},{\"x\":112,\"y\":949}],\"text\":\"connected,\"},{\"boundingBox\":[{\"x\":289,\"y\":914},{\"x\":397,\"y\":910},{\"x\":398,\"y\":950},{\"x\":289,\"y\":950}],\"text\":\"global,\"},{\"boundingBox\":[{\"x\":38,\"y\":957},{\"x\":149,\"y\":957},{\"x\":148,\"y\":995},{\"x\":36,\"y\":993}],\"text\":\"relative\"},{\"boundingBox\":[{\"x\":156,\"y\":957},{\"x\":209,\"y\":958},{\"x\":209,\"y\":995},{\"x\":155,\"y\":995}],\"text\":\"r(a,\"},{\"boundingBox\":[{\"x\":216,\"y\":958},{\"x\":253,\"y\":959},{\"x\":254,\"y\":996},{\"x\":216,\"y\":996}],\"text\":\"b)\"},{\"boundingBox\":[{\"x\":861,\"y\":944},{\"x\":1012,\"y\":944},{\"x\":1012,\"y\":976},{\"x\":860,\"y\":978}],\"text\":\"Spearman\"},{\"boundingBox\":[{\"x\":60,\"y\":1008},{\"x\":79,\"y\":1008},{\"x\":78,\"y\":1041},{\"x\":59,\"y\":1041}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":92,\"y\":1008},{\"x\":111,\"y\":1008},{\"x\":111,\"y\":1041},{\"x\":92,\"y\":1041}],\"text\":\"x\"},{\"boundingBox\":[{\"x\":129,\"y\":1009},{\"x\":148,\"y\":1009},{\"x\":148,\"y\":1041},{\"x\":129,\"y\":1041}],\"text\":\"A\"},{\"boundingBox\":[{\"x\":159,\"y\":1009},{\"x\":198,\"y\":1009},{\"x\":199,\"y\":1041},{\"x\":159,\"y\":1041}],\"text\":\"++\"},{\"boundingBox\":[{\"x\":205,\"y\":1009},{\"x\":244,\"y\":1009},{\"x\":244,\"y\":1042},{\"x\":205,\"y\":1041}],\"text\":\"[0,\"},{\"boundingBox\":[{\"x\":250,\"y\":1009},{\"x\":279,\"y\":1008},{\"x\":280,\"y\":1043},{\"x\":251,\"y\":1042}],\"text\":\"1]\"},{\"boundingBox\":[{\"x\":1155,\"y\":1000},{\"x\":1323,\"y\":1000},{\"x\":1323,\"y\":1034},{\"x\":1155,\"y\":1031}],\"text\":\"Correlation\"},{\"boundingBox\":[{\"x\":1160,\"y\":1047},{\"x\":1324,\"y\":1046},{\"x\":1324,\"y\":1078},{\"x\":1158,\"y\":1079}],\"text\":\"coefficient\"}]}",
        "{\"language\":\"en\",\"text\":\"0 0 {1.0, 1.0, 1.0} 1.0, 1.0, 1.0} 1 1 {1.0, 1.0, 1.0} (1.0, 1.0, 0.0} 2 2 [0.0, 0.0, 0.0} 10.0, 0.0, 0.0} 3 3\",\"lines\":[{\"boundingBox\":[{\"x\":76,\"y\":39},{\"x\":97,\"y\":41},{\"x\":95,\"y\":68},{\"x\":75,\"y\":66}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":448,\"y\":43},{\"x\":469,\"y\":41},{\"x\":470,\"y\":67},{\"x\":448,\"y\":69}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":87,\"y\":177},{\"x\":334,\"y\":177},{\"x\":334,\"y\":216},{\"x\":86,\"y\":214}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":471,\"y\":177},{\"x\":707,\"y\":178},{\"x\":706,\"y\":217},{\"x\":470,\"y\":215}],\"text\":\"1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":73,\"y\":318},{\"x\":94,\"y\":318},{\"x\":95,\"y\":345},{\"x\":75,\"y\":345}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":446,\"y\":317},{\"x\":469,\"y\":317},{\"x\":469,\"y\":346},{\"x\":447,\"y\":346}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":86,\"y\":448},{\"x\":335,\"y\":448},{\"x\":335,\"y\":487},{\"x\":86,\"y\":487}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":462,\"y\":449},{\"x\":707,\"y\":450},{\"x\":706,\"y\":486},{\"x\":462,\"y\":485}],\"text\":\"(1.0, 1.0, 0.0}\"},{\"boundingBox\":[{\"x\":76,\"y\":588},{\"x\":95,\"y\":590},{\"x\":93,\"y\":620},{\"x\":73,\"y\":619}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":448,\"y\":586},{\"x\":470,\"y\":589},{\"x\":466,\"y\":618},{\"x\":444,\"y\":616}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":85,\"y\":718},{\"x\":334,\"y\":718},{\"x\":334,\"y\":763},{\"x\":85,\"y\":762}],\"text\":\"[0.0, 0.0, 0.0}\"},{\"boundingBox\":[{\"x\":461,\"y\":719},{\"x\":707,\"y\":718},{\"x\":707,\"y\":763},{\"x\":461,\"y\":764}],\"text\":\"10.0, 0.0, 0.0}\"},{\"boundingBox\":[{\"x\":75,\"y\":860},{\"x\":97,\"y\":861},{\"x\":96,\"y\":890},{\"x\":74,\"y\":888}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":447,\"y\":859},{\"x\":469,\"y\":859},{\"x\":469,\"y\":889},{\"x\":446,\"y\":888}],\"text\":\"3\"}],\"words\":[{\"boundingBox\":[{\"x\":76,\"y\":39},{\"x\":94,\"y\":41},{\"x\":91,\"y\":67},{\"x\":75,\"y\":66}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":449,\"y\":42},{\"x\":466,\"y\":41},{\"x\":468,\"y\":66},{\"x\":452,\"y\":68}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":88,\"y\":179},{\"x\":173,\"y\":180},{\"x\":173,\"y\":214},{\"x\":87,\"y\":213}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":180,\"y\":180},{\"x\":250,\"y\":179},{\"x\":250,\"y\":215},{\"x\":180,\"y\":214}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":257,\"y\":179},{\"x\":334,\"y\":178},{\"x\":335,\"y\":217},{\"x\":257,\"y\":215}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":476,\"y\":177},{\"x\":544,\"y\":179},{\"x\":543,\"y\":217},{\"x\":475,\"y\":215}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":551,\"y\":179},{\"x\":619,\"y\":179},{\"x\":619,\"y\":218},{\"x\":551,\"y\":217}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":627,\"y\":179},{\"x\":705,\"y\":179},{\"x\":705,\"y\":218},{\"x\":626,\"y\":218}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":74,\"y\":318},{\"x\":90,\"y\":318},{\"x\":90,\"y\":345},{\"x\":74,\"y\":345}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":447,\"y\":317},{\"x\":464,\"y\":317},{\"x\":464,\"y\":346},{\"x\":447,\"y\":346}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":87,\"y\":449},{\"x\":173,\"y\":451},{\"x\":172,\"y\":487},{\"x\":87,\"y\":487}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":180,\"y\":451},{\"x\":249,\"y\":450},{\"x\":248,\"y\":487},{\"x\":179,\"y\":487}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":256,\"y\":450},{\"x\":334,\"y\":449},{\"x\":333,\"y\":488},{\"x\":255,\"y\":487}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":462,\"y\":450},{\"x\":543,\"y\":450},{\"x\":543,\"y\":486},{\"x\":462,\"y\":486}],\"text\":\"(1.0,\"},{\"boundingBox\":[{\"x\":550,\"y\":450},{\"x\":619,\"y\":450},{\"x\":619,\"y\":486},{\"x\":550,\"y\":486}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":627,\"y\":450},{\"x\":706,\"y\":450},{\"x\":706,\"y\":486},{\"x\":627,\"y\":486}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":75,\"y\":588},{\"x\":92,\"y\":589},{\"x\":89,\"y\":620},{\"x\":73,\"y\":618}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":448,\"y\":586},{\"x\":467,\"y\":587},{\"x\":464,\"y\":617},{\"x\":444,\"y\":615}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":86,\"y\":721},{\"x\":167,\"y\":720},{\"x\":167,\"y\":763},{\"x\":85,\"y\":760}],\"text\":\"[0.0,\"},{\"boundingBox\":[{\"x\":176,\"y\":720},{\"x\":246,\"y\":720},{\"x\":246,\"y\":764},{\"x\":175,\"y\":763}],\"text\":\"0.0,\"},{\"boundingBox\":[{\"x\":255,\"y\":719},{\"x\":334,\"y\":718},{\"x\":335,\"y\":764},{\"x\":255,\"y\":764}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":462,\"y\":721},{\"x\":540,\"y\":720},{\"x\":539,\"y\":764},{\"x\":462,\"y\":762}],\"text\":\"10.0,\"},{\"boundingBox\":[{\"x\":548,\"y\":720},{\"x\":615,\"y\":719},{\"x\":615,\"y\":764},{\"x\":548,\"y\":764}],\"text\":\"0.0,\"},{\"boundingBox\":[{\"x\":624,\"y\":719},{\"x\":705,\"y\":719},{\"x\":705,\"y\":764},{\"x\":623,\"y\":764}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":76,\"y\":860},{\"x\":93,\"y\":861},{\"x\":91,\"y\":890},{\"x\":74,\"y\":888}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":448,\"y\":859},{\"x\":465,\"y\":859},{\"x\":464,\"y\":889},{\"x\":447,\"y\":888}],\"text\":\"3\"}]}",
        "{\"language\":\"en\",\"text\":\"0 0 0 0.22 (1.0, 1.0, 1.0} {1.0, 1.0, 1.0} 0.3 0.22 1 1 1 0.3 0.22 0.12 {1.0, 1.0, 1.0} {1.0, 1.0, 1.0} K1.0, 1.0, 1.0} 0.3 0.12 0.36 0.22 2 2 0.36 0.3 3 0.12 K0.0, 0.0, 0.0} {0.0, 0.0, 0.0} 0.36 /0.12 3 3 2 00.36\",\"lines\":[{\"boundingBox\":[{\"x\":45,\"y\":24},{\"x\":60,\"y\":25},{\"x\":60,\"y\":43},{\"x\":45,\"y\":43}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":380,\"y\":37},{\"x\":393,\"y\":37},{\"x\":393,\"y\":53},{\"x\":380,\"y\":53}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":1016,\"y\":78},{\"x\":1029,\"y\":79},{\"x\":1027,\"y\":93},{\"x\":1014,\"y\":92}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":1100,\"y\":77},{\"x\":1143,\"y\":76},{\"x\":1144,\"y\":94},{\"x\":1101,\"y\":95}],\"text\":\"0.22\"},{\"boundingBox\":[{\"x\":52,\"y\":107},{\"x\":209,\"y\":106},{\"x\":209,\"y\":134},{\"x\":52,\"y\":135}],\"text\":\"(1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":301,\"y\":117},{\"x\":456,\"y\":117},{\"x\":456,\"y\":141},{\"x\":301,\"y\":142}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":822,\"y\":154},{\"x\":854,\"y\":154},{\"x\":854,\"y\":171},{\"x\":821,\"y\":171}],\"text\":\"0.3\"},{\"boundingBox\":[{\"x\":900,\"y\":154},{\"x\":944,\"y\":153},{\"x\":944,\"y\":172},{\"x\":900,\"y\":173}],\"text\":\"0.22\"},{\"boundingBox\":[{\"x\":45,\"y\":196},{\"x\":59,\"y\":196},{\"x\":60,\"y\":215},{\"x\":45,\"y\":215}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":281,\"y\":203},{\"x\":295,\"y\":203},{\"x\":295,\"y\":224},{\"x\":282,\"y\":224}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":789,\"y\":232},{\"x\":803,\"y\":233},{\"x\":803,\"y\":250},{\"x\":790,\"y\":250}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":841,\"y\":229},{\"x\":907,\"y\":229},{\"x\":907,\"y\":251},{\"x\":842,\"y\":254}],\"text\":\"0.3\"},{\"boundingBox\":[{\"x\":968,\"y\":230},{\"x\":1071,\"y\":230},{\"x\":1071,\"y\":249},{\"x\":968,\"y\":249}],\"text\":\"0.22 0.12\"},{\"boundingBox\":[{\"x\":52,\"y\":277},{\"x\":209,\"y\":276},{\"x\":209,\"y\":302},{\"x\":52,\"y\":302}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":286,\"y\":282},{\"x\":439,\"y\":283},{\"x\":439,\"y\":311},{\"x\":286,\"y\":310}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":497,\"y\":284},{\"x\":652,\"y\":284},{\"x\":652,\"y\":309},{\"x\":497,\"y\":310}],\"text\":\"K1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":822,\"y\":309},{\"x\":856,\"y\":306},{\"x\":857,\"y\":327},{\"x\":822,\"y\":329}],\"text\":\"0.3\"},{\"boundingBox\":[{\"x\":858,\"y\":307},{\"x\":927,\"y\":307},{\"x\":927,\"y\":329},{\"x\":858,\"y\":328}],\"text\":\"0.12\"},{\"boundingBox\":[{\"x\":1086,\"y\":308},{\"x\":1182,\"y\":309},{\"x\":1181,\"y\":328},{\"x\":1086,\"y\":327}],\"text\":\"0.36 0.22\"},{\"boundingBox\":[{\"x\":44,\"y\":362},{\"x\":60,\"y\":364},{\"x\":61,\"y\":386},{\"x\":44,\"y\":385}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":279,\"y\":368},{\"x\":296,\"y\":368},{\"x\":296,\"y\":392},{\"x\":279,\"y\":391}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":686,\"y\":385},{\"x\":730,\"y\":386},{\"x\":730,\"y\":405},{\"x\":686,\"y\":404}],\"text\":\"0.36\"},{\"boundingBox\":[{\"x\":820,\"y\":386},{\"x\":853,\"y\":385},{\"x\":856,\"y\":405},{\"x\":821,\"y\":404}],\"text\":\"0.3\"},{\"boundingBox\":[{\"x\":929,\"y\":385},{\"x\":944,\"y\":385},{\"x\":945,\"y\":405},{\"x\":930,\"y\":404}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":1016,\"y\":379},{\"x\":1060,\"y\":381},{\"x\":1060,\"y\":408},{\"x\":1016,\"y\":406}],\"text\":\"0.12\"},{\"boundingBox\":[{\"x\":51,\"y\":448},{\"x\":209,\"y\":447},{\"x\":209,\"y\":475},{\"x\":51,\"y\":476}],\"text\":\"K0.0, 0.0, 0.0}\"},{\"boundingBox\":[{\"x\":301,\"y\":451},{\"x\":455,\"y\":450},{\"x\":455,\"y\":476},{\"x\":301,\"y\":477}],\"text\":\"{0.0, 0.0, 0.0}\"},{\"boundingBox\":[{\"x\":864,\"y\":460},{\"x\":907,\"y\":461},{\"x\":908,\"y\":484},{\"x\":864,\"y\":484}],\"text\":\"0.36\"},{\"boundingBox\":[{\"x\":914,\"y\":464},{\"x\":965,\"y\":462},{\"x\":965,\"y\":480},{\"x\":914,\"y\":482}],\"text\":\"/0.12\"},{\"boundingBox\":[{\"x\":44,\"y\":533},{\"x\":60,\"y\":533},{\"x\":61,\"y\":554},{\"x\":45,\"y\":554}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":380,\"y\":535},{\"x\":395,\"y\":535},{\"x\":395,\"y\":555},{\"x\":379,\"y\":555}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":893,\"y\":540},{\"x\":907,\"y\":541},{\"x\":907,\"y\":558},{\"x\":893,\"y\":556}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":972,\"y\":540},{\"x\":1023,\"y\":539},{\"x\":1025,\"y\":558},{\"x\":973,\"y\":561}],\"text\":\"00.36\"}],\"words\":[{\"boundingBox\":[{\"x\":46,\"y\":24},{\"x\":57,\"y\":24},{\"x\":56,\"y\":43},{\"x\":45,\"y\":42}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":380,\"y\":37},{\"x\":389,\"y\":37},{\"x\":389,\"y\":53},{\"x\":380,\"y\":53}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":1019,\"y\":78},{\"x\":1028,\"y\":79},{\"x\":1027,\"y\":93},{\"x\":1018,\"y\":92}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":1102,\"y\":77},{\"x\":1141,\"y\":76},{\"x\":1141,\"y\":94},{\"x\":1102,\"y\":95}],\"text\":\"0.22\"},{\"boundingBox\":[{\"x\":53,\"y\":108},{\"x\":104,\"y\":107},{\"x\":103,\"y\":135},{\"x\":53,\"y\":135}],\"text\":\"(1.0,\"},{\"boundingBox\":[{\"x\":109,\"y\":107},{\"x\":151,\"y\":107},{\"x\":151,\"y\":135},{\"x\":109,\"y\":135}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":157,\"y\":107},{\"x\":209,\"y\":106},{\"x\":208,\"y\":135},{\"x\":157,\"y\":135}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":302,\"y\":119},{\"x\":355,\"y\":119},{\"x\":356,\"y\":142},{\"x\":302,\"y\":141}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":360,\"y\":119},{\"x\":401,\"y\":119},{\"x\":402,\"y\":142},{\"x\":360,\"y\":142}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":405,\"y\":119},{\"x\":454,\"y\":117},{\"x\":455,\"y\":142},{\"x\":406,\"y\":142}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":822,\"y\":154},{\"x\":851,\"y\":154},{\"x\":851,\"y\":171},{\"x\":822,\"y\":171}],\"text\":\"0.3\"},{\"boundingBox\":[{\"x\":900,\"y\":154},{\"x\":942,\"y\":153},{\"x\":942,\"y\":172},{\"x\":901,\"y\":173}],\"text\":\"0.22\"},{\"boundingBox\":[{\"x\":46,\"y\":196},{\"x\":57,\"y\":196},{\"x\":57,\"y\":215},{\"x\":46,\"y\":215}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":282,\"y\":203},{\"x\":294,\"y\":203},{\"x\":294,\"y\":224},{\"x\":282,\"y\":224}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":790,\"y\":232},{\"x\":800,\"y\":232},{\"x\":800,\"y\":250},{\"x\":789,\"y\":249}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":871,\"y\":229},{\"x\":904,\"y\":229},{\"x\":904,\"y\":253},{\"x\":871,\"y\":253}],\"text\":\"0.3\"},{\"boundingBox\":[{\"x\":969,\"y\":230},{\"x\":1010,\"y\":231},{\"x\":1010,\"y\":250},{\"x\":969,\"y\":250}],\"text\":\"0.22\"},{\"boundingBox\":[{\"x\":1027,\"y\":231},{\"x\":1068,\"y\":231},{\"x\":1068,\"y\":249},{\"x\":1026,\"y\":250}],\"text\":\"0.12\"},{\"boundingBox\":[{\"x\":53,\"y\":278},{\"x\":107,\"y\":279},{\"x\":107,\"y\":303},{\"x\":53,\"y\":302}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":112,\"y\":279},{\"x\":155,\"y\":279},{\"x\":154,\"y\":303},{\"x\":111,\"y\":303}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":160,\"y\":278},{\"x\":209,\"y\":277},{\"x\":208,\"y\":303},{\"x\":159,\"y\":303}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":287,\"y\":283},{\"x\":336,\"y\":283},{\"x\":337,\"y\":311},{\"x\":287,\"y\":311}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":342,\"y\":283},{\"x\":385,\"y\":283},{\"x\":385,\"y\":311},{\"x\":342,\"y\":311}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":390,\"y\":283},{\"x\":439,\"y\":283},{\"x\":439,\"y\":312},{\"x\":391,\"y\":311}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":498,\"y\":285},{\"x\":553,\"y\":285},{\"x\":553,\"y\":310},{\"x\":499,\"y\":311}],\"text\":\"K1.0,\"},{\"boundingBox\":[{\"x\":558,\"y\":285},{\"x\":600,\"y\":285},{\"x\":601,\"y\":310},{\"x\":558,\"y\":310}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":605,\"y\":285},{\"x\":653,\"y\":284},{\"x\":653,\"y\":310},{\"x\":606,\"y\":310}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":822,\"y\":308},{\"x\":852,\"y\":306},{\"x\":853,\"y\":327},{\"x\":823,\"y\":329}],\"text\":\"0.3\"},{\"boundingBox\":[{\"x\":882,\"y\":308},{\"x\":924,\"y\":308},{\"x\":925,\"y\":328},{\"x\":882,\"y\":329}],\"text\":\"0.12\"},{\"boundingBox\":[{\"x\":1087,\"y\":308},{\"x\":1125,\"y\":309},{\"x\":1125,\"y\":329},{\"x\":1086,\"y\":328}],\"text\":\"0.36\"},{\"boundingBox\":[{\"x\":1137,\"y\":309},{\"x\":1179,\"y\":310},{\"x\":1179,\"y\":328},{\"x\":1136,\"y\":329}],\"text\":\"0.22\"},{\"boundingBox\":[{\"x\":44,\"y\":362},{\"x\":62,\"y\":363},{\"x\":60,\"y\":386},{\"x\":44,\"y\":384}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":279,\"y\":368},{\"x\":295,\"y\":368},{\"x\":294,\"y\":392},{\"x\":279,\"y\":391}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":686,\"y\":385},{\"x\":727,\"y\":386},{\"x\":727,\"y\":405},{\"x\":686,\"y\":404}],\"text\":\"0.36\"},{\"boundingBox\":[{\"x\":821,\"y\":385},{\"x\":851,\"y\":385},{\"x\":851,\"y\":405},{\"x\":821,\"y\":405}],\"text\":\"0.3\"},{\"boundingBox\":[{\"x\":930,\"y\":385},{\"x\":942,\"y\":385},{\"x\":941,\"y\":405},{\"x\":929,\"y\":404}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":1017,\"y\":379},{\"x\":1061,\"y\":381},{\"x\":1060,\"y\":408},{\"x\":1016,\"y\":406}],\"text\":\"0.12\"},{\"boundingBox\":[{\"x\":52,\"y\":450},{\"x\":105,\"y\":450},{\"x\":105,\"y\":474},{\"x\":52,\"y\":475}],\"text\":\"K0.0,\"},{\"boundingBox\":[{\"x\":110,\"y\":450},{\"x\":152,\"y\":449},{\"x\":152,\"y\":474},{\"x\":110,\"y\":474}],\"text\":\"0.0,\"},{\"boundingBox\":[{\"x\":157,\"y\":449},{\"x\":208,\"y\":448},{\"x\":207,\"y\":476},{\"x\":157,\"y\":474}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":301,\"y\":452},{\"x\":353,\"y\":452},{\"x\":352,\"y\":478},{\"x\":301,\"y\":478}],\"text\":\"{0.0,\"},{\"boundingBox\":[{\"x\":358,\"y\":452},{\"x\":399,\"y\":451},{\"x\":399,\"y\":478},{\"x\":357,\"y\":478}],\"text\":\"0.0,\"},{\"boundingBox\":[{\"x\":404,\"y\":451},{\"x\":455,\"y\":451},{\"x\":454,\"y\":477},{\"x\":404,\"y\":477}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":864,\"y\":460},{\"x\":906,\"y\":460},{\"x\":906,\"y\":484},{\"x\":864,\"y\":483}],\"text\":\"0.36\"},{\"boundingBox\":[{\"x\":914,\"y\":464},{\"x\":962,\"y\":462},{\"x\":963,\"y\":480},{\"x\":915,\"y\":482}],\"text\":\"/0.12\"},{\"boundingBox\":[{\"x\":45,\"y\":533},{\"x\":57,\"y\":533},{\"x\":57,\"y\":554},{\"x\":45,\"y\":554}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":380,\"y\":535},{\"x\":392,\"y\":535},{\"x\":392,\"y\":555},{\"x\":380,\"y\":555}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":896,\"y\":540},{\"x\":907,\"y\":541},{\"x\":905,\"y\":558},{\"x\":894,\"y\":557}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":972,\"y\":540},{\"x\":1021,\"y\":539},{\"x\":1022,\"y\":559},{\"x\":972,\"y\":561}],\"text\":\"00.36\"}]}",
        "{\"language\":\"en\",\"text\":\"0 0 {1.0, 1.0, 1.0} {1.0, 1.0, 1.0} 1 1 {1.0, 1.0, 1.0} {1.0, 1.0, 1.0} K0.0, 0.0, 0.0} 2 2 (0.0, 0.0, 0.0} {0.0, 0.0, 0.0} 3 3\",\"lines\":[{\"boundingBox\":[{\"x\":62,\"y\":50},{\"x\":80,\"y\":48},{\"x\":83,\"y\":73},{\"x\":65,\"y\":76}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":515,\"y\":35},{\"x\":536,\"y\":36},{\"x\":536,\"y\":60},{\"x\":515,\"y\":59}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":78,\"y\":160},{\"x\":279,\"y\":160},{\"x\":279,\"y\":199},{\"x\":78,\"y\":199}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":408,\"y\":149},{\"x\":620,\"y\":147},{\"x\":620,\"y\":183},{\"x\":408,\"y\":185}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":66,\"y\":279},{\"x\":83,\"y\":280},{\"x\":82,\"y\":305},{\"x\":67,\"y\":304}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":378,\"y\":269},{\"x\":400,\"y\":270},{\"x\":401,\"y\":296},{\"x\":379,\"y\":295}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":74,\"y\":388},{\"x\":282,\"y\":388},{\"x\":282,\"y\":422},{\"x\":74,\"y\":422}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":392,\"y\":379},{\"x\":598,\"y\":378},{\"x\":598,\"y\":416},{\"x\":392,\"y\":417}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":683,\"y\":378},{\"x\":894,\"y\":378},{\"x\":895,\"y\":415},{\"x\":683,\"y\":416}],\"text\":\"K0.0, 0.0, 0.0}\"},{\"boundingBox\":[{\"x\":64,\"y\":503},{\"x\":84,\"y\":504},{\"x\":85,\"y\":532},{\"x\":65,\"y\":531}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":376,\"y\":496},{\"x\":399,\"y\":497},{\"x\":400,\"y\":527},{\"x\":376,\"y\":526}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":75,\"y\":617},{\"x\":282,\"y\":616},{\"x\":282,\"y\":651},{\"x\":75,\"y\":652}],\"text\":\"(0.0, 0.0, 0.0}\"},{\"boundingBox\":[{\"x\":407,\"y\":613},{\"x\":620,\"y\":612},{\"x\":620,\"y\":647},{\"x\":407,\"y\":648}],\"text\":\"{0.0, 0.0, 0.0}\"},{\"boundingBox\":[{\"x\":65,\"y\":727},{\"x\":83,\"y\":728},{\"x\":84,\"y\":757},{\"x\":66,\"y\":756}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":516,\"y\":728},{\"x\":537,\"y\":728},{\"x\":537,\"y\":756},{\"x\":516,\"y\":755}],\"text\":\"3\"}],\"words\":[{\"boundingBox\":[{\"x\":63,\"y\":50},{\"x\":78,\"y\":48},{\"x\":81,\"y\":74},{\"x\":66,\"y\":76}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":516,\"y\":35},{\"x\":530,\"y\":36},{\"x\":529,\"y\":60},{\"x\":515,\"y\":59}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":79,\"y\":161},{\"x\":144,\"y\":161},{\"x\":143,\"y\":198},{\"x\":78,\"y\":199}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":151,\"y\":161},{\"x\":208,\"y\":161},{\"x\":208,\"y\":199},{\"x\":150,\"y\":198}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":216,\"y\":161},{\"x\":278,\"y\":161},{\"x\":278,\"y\":200},{\"x\":215,\"y\":199}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":408,\"y\":150},{\"x\":480,\"y\":149},{\"x\":481,\"y\":185},{\"x\":409,\"y\":186}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":487,\"y\":149},{\"x\":546,\"y\":148},{\"x\":547,\"y\":184},{\"x\":488,\"y\":185}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":553,\"y\":148},{\"x\":620,\"y\":148},{\"x\":620,\"y\":184},{\"x\":554,\"y\":184}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":67,\"y\":279},{\"x\":82,\"y\":280},{\"x\":80,\"y\":305},{\"x\":66,\"y\":304}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":381,\"y\":269},{\"x\":396,\"y\":270},{\"x\":395,\"y\":296},{\"x\":380,\"y\":295}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":75,\"y\":389},{\"x\":144,\"y\":390},{\"x\":144,\"y\":422},{\"x\":75,\"y\":422}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":150,\"y\":390},{\"x\":209,\"y\":390},{\"x\":210,\"y\":423},{\"x\":151,\"y\":422}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":216,\"y\":389},{\"x\":281,\"y\":388},{\"x\":281,\"y\":423},{\"x\":216,\"y\":423}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":394,\"y\":380},{\"x\":457,\"y\":380},{\"x\":456,\"y\":417},{\"x\":393,\"y\":417}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":465,\"y\":380},{\"x\":524,\"y\":379},{\"x\":523,\"y\":417},{\"x\":464,\"y\":417}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":531,\"y\":379},{\"x\":598,\"y\":379},{\"x\":598,\"y\":417},{\"x\":531,\"y\":417}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":683,\"y\":379},{\"x\":753,\"y\":379},{\"x\":754,\"y\":416},{\"x\":685,\"y\":417}],\"text\":\"K0.0,\"},{\"boundingBox\":[{\"x\":760,\"y\":379},{\"x\":819,\"y\":380},{\"x\":820,\"y\":415},{\"x\":761,\"y\":416}],\"text\":\"0.0,\"},{\"boundingBox\":[{\"x\":826,\"y\":380},{\"x\":895,\"y\":380},{\"x\":895,\"y\":414},{\"x\":827,\"y\":415}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":65,\"y\":503},{\"x\":84,\"y\":504},{\"x\":82,\"y\":532},{\"x\":64,\"y\":531}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":379,\"y\":496},{\"x\":397,\"y\":497},{\"x\":396,\"y\":527},{\"x\":378,\"y\":526}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":75,\"y\":617},{\"x\":144,\"y\":617},{\"x\":144,\"y\":651},{\"x\":75,\"y\":653}],\"text\":\"(0.0,\"},{\"boundingBox\":[{\"x\":151,\"y\":617},{\"x\":208,\"y\":617},{\"x\":208,\"y\":651},{\"x\":151,\"y\":651}],\"text\":\"0.0,\"},{\"boundingBox\":[{\"x\":215,\"y\":617},{\"x\":282,\"y\":616},{\"x\":283,\"y\":652},{\"x\":215,\"y\":651}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":410,\"y\":614},{\"x\":481,\"y\":614},{\"x\":480,\"y\":647},{\"x\":409,\"y\":648}],\"text\":\"{0.0,\"},{\"boundingBox\":[{\"x\":487,\"y\":614},{\"x\":547,\"y\":614},{\"x\":546,\"y\":647},{\"x\":487,\"y\":647}],\"text\":\"0.0,\"},{\"boundingBox\":[{\"x\":553,\"y\":614},{\"x\":620,\"y\":613},{\"x\":620,\"y\":648},{\"x\":553,\"y\":647}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":65,\"y\":727},{\"x\":84,\"y\":728},{\"x\":83,\"y\":757},{\"x\":65,\"y\":756}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":517,\"y\":728},{\"x\":534,\"y\":728},{\"x\":533,\"y\":756},{\"x\":517,\"y\":755}],\"text\":\"3\"}]}",
        "{\"language\":\"en\",\"text\":\"0 0 (1.0, 1.0, 1.0} {1.0, 1.0, 1.0} 1 1 {1.0, 1.0, 1.0} {1.0, 1.0, 1.0} 2 2 [0.0, 0.0, 0.0} {0.0, 0.0, 0.0}[0.0, 0.0. 0.0} 3 3\",\"lines\":[{\"boundingBox\":[{\"x\":534,\"y\":41},{\"x\":556,\"y\":41},{\"x\":554,\"y\":67},{\"x\":532,\"y\":68}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":71,\"y\":69},{\"x\":94,\"y\":69},{\"x\":94,\"y\":98},{\"x\":71,\"y\":97}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":85,\"y\":200},{\"x\":327,\"y\":200},{\"x\":327,\"y\":243},{\"x\":85,\"y\":244}],\"text\":\"(1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":545,\"y\":177},{\"x\":799,\"y\":179},{\"x\":799,\"y\":217},{\"x\":545,\"y\":215}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":74,\"y\":341},{\"x\":96,\"y\":341},{\"x\":95,\"y\":372},{\"x\":74,\"y\":372}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":532,\"y\":317},{\"x\":557,\"y\":319},{\"x\":556,\"y\":355},{\"x\":531,\"y\":352}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":85,\"y\":469},{\"x\":330,\"y\":469},{\"x\":330,\"y\":507},{\"x\":85,\"y\":506}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":547,\"y\":454},{\"x\":801,\"y\":454},{\"x\":801,\"y\":493},{\"x\":547,\"y\":493}],\"text\":\"{1.0, 1.0, 1.0}\"},{\"boundingBox\":[{\"x\":72,\"y\":605},{\"x\":97,\"y\":608},{\"x\":96,\"y\":640},{\"x\":71,\"y\":637}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":535,\"y\":592},{\"x\":558,\"y\":594},{\"x\":554,\"y\":631},{\"x\":531,\"y\":628}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":81,\"y\":736},{\"x\":893,\"y\":731},{\"x\":894,\"y\":773},{\"x\":81,\"y\":779}],\"text\":\"[0.0, 0.0, 0.0} {0.0, 0.0, 0.0}[0.0, 0.0. 0.0}\"},{\"boundingBox\":[{\"x\":72,\"y\":875},{\"x\":96,\"y\":876},{\"x\":97,\"y\":905},{\"x\":73,\"y\":904}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":532,\"y\":870},{\"x\":558,\"y\":872},{\"x\":557,\"y\":904},{\"x\":530,\"y\":901}],\"text\":\"3\"}],\"words\":[{\"boundingBox\":[{\"x\":532,\"y\":41},{\"x\":547,\"y\":41},{\"x\":547,\"y\":68},{\"x\":532,\"y\":68}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":72,\"y\":69},{\"x\":89,\"y\":69},{\"x\":89,\"y\":98},{\"x\":72,\"y\":97}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":85,\"y\":201},{\"x\":167,\"y\":201},{\"x\":167,\"y\":244},{\"x\":85,\"y\":245}],\"text\":\"(1.0,\"},{\"boundingBox\":[{\"x\":176,\"y\":201},{\"x\":244,\"y\":201},{\"x\":244,\"y\":244},{\"x\":176,\"y\":244}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":252,\"y\":201},{\"x\":327,\"y\":200},{\"x\":328,\"y\":245},{\"x\":253,\"y\":244}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":546,\"y\":178},{\"x\":634,\"y\":180},{\"x\":634,\"y\":217},{\"x\":546,\"y\":214}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":641,\"y\":180},{\"x\":711,\"y\":181},{\"x\":711,\"y\":217},{\"x\":641,\"y\":217}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":718,\"y\":181},{\"x\":798,\"y\":179},{\"x\":798,\"y\":217},{\"x\":718,\"y\":217}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":76,\"y\":341},{\"x\":94,\"y\":341},{\"x\":94,\"y\":372},{\"x\":76,\"y\":372}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":534,\"y\":317},{\"x\":557,\"y\":319},{\"x\":554,\"y\":355},{\"x\":531,\"y\":352}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":86,\"y\":470},{\"x\":169,\"y\":472},{\"x\":169,\"y\":507},{\"x\":85,\"y\":506}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":176,\"y\":472},{\"x\":245,\"y\":472},{\"x\":245,\"y\":508},{\"x\":176,\"y\":507}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":252,\"y\":472},{\"x\":328,\"y\":470},{\"x\":329,\"y\":508},{\"x\":252,\"y\":508}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":548,\"y\":455},{\"x\":633,\"y\":455},{\"x\":634,\"y\":494},{\"x\":549,\"y\":494}],\"text\":\"{1.0,\"},{\"boundingBox\":[{\"x\":641,\"y\":455},{\"x\":712,\"y\":455},{\"x\":712,\"y\":494},{\"x\":641,\"y\":494}],\"text\":\"1.0,\"},{\"boundingBox\":[{\"x\":720,\"y\":455},{\"x\":800,\"y\":455},{\"x\":800,\"y\":493},{\"x\":720,\"y\":494}],\"text\":\"1.0}\"},{\"boundingBox\":[{\"x\":72,\"y\":605},{\"x\":97,\"y\":608},{\"x\":94,\"y\":640},{\"x\":71,\"y\":637}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":536,\"y\":592},{\"x\":556,\"y\":594},{\"x\":552,\"y\":630},{\"x\":532,\"y\":628}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":82,\"y\":740},{\"x\":165,\"y\":738},{\"x\":165,\"y\":779},{\"x\":82,\"y\":779}],\"text\":\"[0.0,\"},{\"boundingBox\":[{\"x\":174,\"y\":738},{\"x\":241,\"y\":736},{\"x\":241,\"y\":779},{\"x\":174,\"y\":779}],\"text\":\"0.0,\"},{\"boundingBox\":[{\"x\":249,\"y\":736},{\"x\":330,\"y\":735},{\"x\":330,\"y\":779},{\"x\":249,\"y\":779}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":384,\"y\":734},{\"x\":468,\"y\":733},{\"x\":468,\"y\":778},{\"x\":384,\"y\":778}],\"text\":\"{0.0,\"},{\"boundingBox\":[{\"x\":477,\"y\":733},{\"x\":547,\"y\":732},{\"x\":547,\"y\":777},{\"x\":477,\"y\":778}],\"text\":\"0.0,\"},{\"boundingBox\":[{\"x\":556,\"y\":732},{\"x\":730,\"y\":731},{\"x\":730,\"y\":775},{\"x\":556,\"y\":777}],\"text\":\"0.0}[0.0,\"},{\"boundingBox\":[{\"x\":738,\"y\":731},{\"x\":805,\"y\":732},{\"x\":805,\"y\":774},{\"x\":738,\"y\":775}],\"text\":\"0.0.\"},{\"boundingBox\":[{\"x\":814,\"y\":732},{\"x\":893,\"y\":732},{\"x\":893,\"y\":773},{\"x\":814,\"y\":774}],\"text\":\"0.0}\"},{\"boundingBox\":[{\"x\":73,\"y\":875},{\"x\":90,\"y\":876},{\"x\":89,\"y\":905},{\"x\":72,\"y\":904}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":537,\"y\":870},{\"x\":558,\"y\":872},{\"x\":555,\"y\":904},{\"x\":534,\"y\":902}],\"text\":\"3\"}]}",
        "{\"language\":\"en\",\"text\":\"1.0 1.0 2 0.0 1.0 3\",\"lines\":[{\"boundingBox\":[{\"x\":501,\"y\":385},{\"x\":600,\"y\":382},{\"x\":601,\"y\":447},{\"x\":503,\"y\":450}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":377,\"y\":961},{\"x\":488,\"y\":963},{\"x\":486,\"y\":1028},{\"x\":376,\"y\":1024}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":181,\"y\":1253},{\"x\":207,\"y\":1252},{\"x\":209,\"y\":1309},{\"x\":183,\"y\":1310}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":510,\"y\":1244},{\"x\":631,\"y\":1250},{\"x\":622,\"y\":1320},{\"x\":507,\"y\":1314}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":343,\"y\":1550},{\"x\":452,\"y\":1542},{\"x\":455,\"y\":1609},{\"x\":345,\"y\":1609}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":421,\"y\":1835},{\"x\":467,\"y\":1832},{\"x\":468,\"y\":1892},{\"x\":421,\"y\":1895}],\"text\":\"3\"}],\"words\":[{\"boundingBox\":[{\"x\":501,\"y\":385},{\"x\":590,\"y\":382},{\"x\":592,\"y\":447},{\"x\":503,\"y\":450}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":377,\"y\":961},{\"x\":474,\"y\":963},{\"x\":473,\"y\":1028},{\"x\":376,\"y\":1025}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":181,\"y\":1253},{\"x\":204,\"y\":1252},{\"x\":206,\"y\":1309},{\"x\":183,\"y\":1310}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":513,\"y\":1244},{\"x\":615,\"y\":1249},{\"x\":611,\"y\":1319},{\"x\":510,\"y\":1314}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":343,\"y\":1546},{\"x\":439,\"y\":1542},{\"x\":441,\"y\":1609},{\"x\":345,\"y\":1610}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":421,\"y\":1834},{\"x\":455,\"y\":1832},{\"x\":459,\"y\":1892},{\"x\":424,\"y\":1894}],\"text\":\"3\"}]}",
        "{\"language\":\"en\",\"text\":\"0 1.0 1 1.0 0.0 0.0 0.0 0.0 0.0 0.0 2 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 6 4 3 11 5 12 9 13 8 10\",\"lines\":[{\"boundingBox\":[{\"x\":658,\"y\":25},{\"x\":673,\"y\":26},{\"x\":672,\"y\":43},{\"x\":658,\"y\":42}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":664,\"y\":104},{\"x\":698,\"y\":103},{\"x\":698,\"y\":123},{\"x\":664,\"y\":124}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":657,\"y\":184},{\"x\":672,\"y\":185},{\"x\":673,\"y\":203},{\"x\":658,\"y\":203}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":709,\"y\":262},{\"x\":744,\"y\":261},{\"x\":745,\"y\":280},{\"x\":710,\"y\":281}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":179,\"y\":340},{\"x\":211,\"y\":341},{\"x\":212,\"y\":360},{\"x\":179,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":317,\"y\":340},{\"x\":348,\"y\":341},{\"x\":348,\"y\":361},{\"x\":316,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":432,\"y\":340},{\"x\":464,\"y\":340},{\"x\":464,\"y\":361},{\"x\":431,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":512,\"y\":340},{\"x\":545,\"y\":340},{\"x\":545,\"y\":360},{\"x\":512,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":588,\"y\":340},{\"x\":666,\"y\":340},{\"x\":666,\"y\":359},{\"x\":588,\"y\":360}],\"text\":\"0.0 0.0\"},{\"boundingBox\":[{\"x\":733,\"y\":341},{\"x\":749,\"y\":340},{\"x\":750,\"y\":361},{\"x\":734,\"y\":361}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":910,\"y\":340},{\"x\":943,\"y\":341},{\"x\":944,\"y\":360},{\"x\":910,\"y\":361}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":1023,\"y\":340},{\"x\":1056,\"y\":341},{\"x\":1056,\"y\":360},{\"x\":1023,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":1144,\"y\":340},{\"x\":1177,\"y\":340},{\"x\":1177,\"y\":360},{\"x\":1144,\"y\":361}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":1270,\"y\":341},{\"x\":1301,\"y\":341},{\"x\":1301,\"y\":361},{\"x\":1269,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":1359,\"y\":340},{\"x\":1391,\"y\":340},{\"x\":1392,\"y\":361},{\"x\":1358,\"y\":361}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":303,\"y\":421},{\"x\":334,\"y\":419},{\"x\":336,\"y\":439},{\"x\":305,\"y\":441}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":426,\"y\":421},{\"x\":457,\"y\":419},{\"x\":459,\"y\":439},{\"x\":427,\"y\":441}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":530,\"y\":421},{\"x\":563,\"y\":418},{\"x\":564,\"y\":438},{\"x\":532,\"y\":441}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":618,\"y\":420},{\"x\":669,\"y\":420},{\"x\":668,\"y\":441},{\"x\":619,\"y\":439}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":679,\"y\":419},{\"x\":771,\"y\":419},{\"x\":771,\"y\":441},{\"x\":679,\"y\":441}],\"text\":\"1.0 1.0\"},{\"boundingBox\":[{\"x\":803,\"y\":419},{\"x\":838,\"y\":419},{\"x\":839,\"y\":441},{\"x\":803,\"y\":439}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":893,\"y\":419},{\"x\":926,\"y\":421},{\"x\":925,\"y\":440},{\"x\":891,\"y\":439}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":1001,\"y\":420},{\"x\":1032,\"y\":420},{\"x\":1032,\"y\":439},{\"x\":1001,\"y\":439}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":1124,\"y\":419},{\"x\":1157,\"y\":420},{\"x\":1157,\"y\":440},{\"x\":1124,\"y\":439}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":1257,\"y\":421},{\"x\":1290,\"y\":419},{\"x\":1290,\"y\":439},{\"x\":1256,\"y\":440}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":45,\"y\":500},{\"x\":57,\"y\":501},{\"x\":57,\"y\":518},{\"x\":44,\"y\":517}],\"text\":\"6\"},{\"boundingBox\":[{\"x\":325,\"y\":497},{\"x\":340,\"y\":498},{\"x\":339,\"y\":518},{\"x\":324,\"y\":517}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":454,\"y\":498},{\"x\":469,\"y\":498},{\"x\":470,\"y\":519},{\"x\":454,\"y\":518}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":581,\"y\":498},{\"x\":607,\"y\":497},{\"x\":608,\"y\":517},{\"x\":581,\"y\":518}],\"text\":\"11\"},{\"boundingBox\":[{\"x\":715,\"y\":497},{\"x\":731,\"y\":497},{\"x\":730,\"y\":519},{\"x\":715,\"y\":518}],\"text\":\"5\"},{\"boundingBox\":[{\"x\":839,\"y\":497},{\"x\":865,\"y\":497},{\"x\":866,\"y\":517},{\"x\":840,\"y\":517}],\"text\":\"12\"},{\"boundingBox\":[{\"x\":991,\"y\":497},{\"x\":1007,\"y\":498},{\"x\":1006,\"y\":517},{\"x\":990,\"y\":517}],\"text\":\"9\"},{\"boundingBox\":[{\"x\":1128,\"y\":498},{\"x\":1155,\"y\":498},{\"x\":1155,\"y\":518},{\"x\":1128,\"y\":518}],\"text\":\"13\"},{\"boundingBox\":[{\"x\":1267,\"y\":497},{\"x\":1282,\"y\":498},{\"x\":1282,\"y\":518},{\"x\":1267,\"y\":517}],\"text\":\"8\"},{\"boundingBox\":[{\"x\":1391,\"y\":498},{\"x\":1419,\"y\":497},{\"x\":1420,\"y\":517},{\"x\":1392,\"y\":518}],\"text\":\"10\"}],\"words\":[{\"boundingBox\":[{\"x\":659,\"y\":25},{\"x\":669,\"y\":26},{\"x\":668,\"y\":43},{\"x\":658,\"y\":42}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":666,\"y\":104},{\"x\":695,\"y\":103},{\"x\":695,\"y\":123},{\"x\":666,\"y\":124}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":658,\"y\":184},{\"x\":670,\"y\":184},{\"x\":670,\"y\":203},{\"x\":657,\"y\":202}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":709,\"y\":262},{\"x\":739,\"y\":261},{\"x\":740,\"y\":280},{\"x\":710,\"y\":281}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":179,\"y\":340},{\"x\":209,\"y\":340},{\"x\":209,\"y\":360},{\"x\":179,\"y\":359}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":317,\"y\":340},{\"x\":346,\"y\":341},{\"x\":345,\"y\":361},{\"x\":316,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":431,\"y\":340},{\"x\":462,\"y\":340},{\"x\":462,\"y\":361},{\"x\":431,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":512,\"y\":340},{\"x\":542,\"y\":340},{\"x\":542,\"y\":360},{\"x\":512,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":590,\"y\":341},{\"x\":620,\"y\":341},{\"x\":620,\"y\":360},{\"x\":590,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":633,\"y\":341},{\"x\":662,\"y\":341},{\"x\":662,\"y\":360},{\"x\":633,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":733,\"y\":340},{\"x\":747,\"y\":340},{\"x\":748,\"y\":361},{\"x\":734,\"y\":361}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":910,\"y\":340},{\"x\":940,\"y\":340},{\"x\":940,\"y\":361},{\"x\":910,\"y\":361}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":1023,\"y\":340},{\"x\":1053,\"y\":340},{\"x\":1053,\"y\":360},{\"x\":1023,\"y\":359}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":1145,\"y\":340},{\"x\":1174,\"y\":340},{\"x\":1174,\"y\":361},{\"x\":1145,\"y\":361}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":1269,\"y\":341},{\"x\":1299,\"y\":341},{\"x\":1299,\"y\":361},{\"x\":1269,\"y\":360}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":1358,\"y\":340},{\"x\":1390,\"y\":340},{\"x\":1390,\"y\":361},{\"x\":1358,\"y\":361}],\"text\":\"0.0\"},{\"boundingBox\":[{\"x\":304,\"y\":421},{\"x\":331,\"y\":419},{\"x\":333,\"y\":439},{\"x\":305,\"y\":441}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":427,\"y\":420},{\"x\":454,\"y\":419},{\"x\":456,\"y\":439},{\"x\":428,\"y\":441}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":530,\"y\":421},{\"x\":559,\"y\":418},{\"x\":561,\"y\":438},{\"x\":532,\"y\":441}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":618,\"y\":420},{\"x\":652,\"y\":420},{\"x\":651,\"y\":441},{\"x\":618,\"y\":440}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":682,\"y\":420},{\"x\":711,\"y\":420},{\"x\":711,\"y\":442},{\"x\":681,\"y\":440}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":735,\"y\":420},{\"x\":766,\"y\":419},{\"x\":767,\"y\":442},{\"x\":735,\"y\":442}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":806,\"y\":419},{\"x\":836,\"y\":419},{\"x\":835,\"y\":441},{\"x\":805,\"y\":440}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":892,\"y\":419},{\"x\":924,\"y\":420},{\"x\":923,\"y\":440},{\"x\":891,\"y\":438}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":1001,\"y\":420},{\"x\":1030,\"y\":420},{\"x\":1030,\"y\":439},{\"x\":1001,\"y\":439}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":1124,\"y\":419},{\"x\":1153,\"y\":420},{\"x\":1152,\"y\":440},{\"x\":1124,\"y\":439}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":1256,\"y\":420},{\"x\":1286,\"y\":419},{\"x\":1287,\"y\":439},{\"x\":1257,\"y\":440}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":45,\"y\":500},{\"x\":55,\"y\":501},{\"x\":53,\"y\":518},{\"x\":44,\"y\":517}],\"text\":\"6\"},{\"boundingBox\":[{\"x\":326,\"y\":497},{\"x\":338,\"y\":498},{\"x\":336,\"y\":518},{\"x\":325,\"y\":517}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":455,\"y\":498},{\"x\":467,\"y\":498},{\"x\":467,\"y\":519},{\"x\":454,\"y\":518}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":581,\"y\":497},{\"x\":605,\"y\":497},{\"x\":605,\"y\":517},{\"x\":582,\"y\":518}],\"text\":\"11\"},{\"boundingBox\":[{\"x\":716,\"y\":497},{\"x\":730,\"y\":497},{\"x\":729,\"y\":519},{\"x\":715,\"y\":518}],\"text\":\"5\"},{\"boundingBox\":[{\"x\":840,\"y\":497},{\"x\":862,\"y\":497},{\"x\":862,\"y\":517},{\"x\":840,\"y\":517}],\"text\":\"12\"},{\"boundingBox\":[{\"x\":992,\"y\":497},{\"x\":1004,\"y\":497},{\"x\":1003,\"y\":517},{\"x\":992,\"y\":516}],\"text\":\"9\"},{\"boundingBox\":[{\"x\":1129,\"y\":498},{\"x\":1151,\"y\":498},{\"x\":1151,\"y\":518},{\"x\":1129,\"y\":518}],\"text\":\"13\"},{\"boundingBox\":[{\"x\":1268,\"y\":497},{\"x\":1280,\"y\":498},{\"x\":1278,\"y\":518},{\"x\":1267,\"y\":517}],\"text\":\"8\"},{\"boundingBox\":[{\"x\":1391,\"y\":498},{\"x\":1415,\"y\":497},{\"x\":1416,\"y\":517},{\"x\":1392,\"y\":518}],\"text\":\"10\"}]}",
        "{\"language\":\"en\",\"text\":\"1.0 1 1.0 1.0 2 3\",\"lines\":[{\"boundingBox\":[{\"x\":70,\"y\":63},{\"x\":91,\"y\":63},{\"x\":91,\"y\":76},{\"x\":70,\"y\":75}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":67,\"y\":114},{\"x\":77,\"y\":114},{\"x\":77,\"y\":126},{\"x\":67,\"y\":126}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":55,\"y\":162},{\"x\":77,\"y\":162},{\"x\":78,\"y\":175},{\"x\":55,\"y\":175}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":92,\"y\":162},{\"x\":115,\"y\":162},{\"x\":115,\"y\":174},{\"x\":93,\"y\":175}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":27,\"y\":211},{\"x\":35,\"y\":212},{\"x\":36,\"y\":224},{\"x\":27,\"y\":224}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":106,\"y\":211},{\"x\":117,\"y\":211},{\"x\":117,\"y\":224},{\"x\":106,\"y\":224}],\"text\":\"3\"}],\"words\":[{\"boundingBox\":[{\"x\":72,\"y\":63},{\"x\":89,\"y\":63},{\"x\":89,\"y\":76},{\"x\":71,\"y\":75}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":68,\"y\":114},{\"x\":75,\"y\":114},{\"x\":75,\"y\":126},{\"x\":68,\"y\":126}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":56,\"y\":162},{\"x\":74,\"y\":162},{\"x\":74,\"y\":175},{\"x\":56,\"y\":175}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":94,\"y\":162},{\"x\":113,\"y\":162},{\"x\":113,\"y\":175},{\"x\":94,\"y\":175}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":27,\"y\":211},{\"x\":36,\"y\":211},{\"x\":35,\"y\":224},{\"x\":27,\"y\":223}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":107,\"y\":211},{\"x\":114,\"y\":211},{\"x\":114,\"y\":224},{\"x\":107,\"y\":224}],\"text\":\"3\"}]}",
        "{\"language\":\"en\",\"text\":\"? 1 2 3\",\"lines\":[{\"boundingBox\":[{\"x\":78,\"y\":72},{\"x\":89,\"y\":73},{\"x\":89,\"y\":86},{\"x\":78,\"y\":86}],\"text\":\"?\"},{\"boundingBox\":[{\"x\":73,\"y\":129},{\"x\":84,\"y\":128},{\"x\":85,\"y\":142},{\"x\":75,\"y\":142}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":30,\"y\":222},{\"x\":39,\"y\":223},{\"x\":40,\"y\":238},{\"x\":30,\"y\":237}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":138,\"y\":223},{\"x\":147,\"y\":223},{\"x\":148,\"y\":236},{\"x\":138,\"y\":236}],\"text\":\"3\"}],\"words\":[{\"boundingBox\":[{\"x\":78,\"y\":72},{\"x\":87,\"y\":72},{\"x\":87,\"y\":86},{\"x\":78,\"y\":85}],\"text\":\"?\"},{\"boundingBox\":[{\"x\":73,\"y\":128},{\"x\":81,\"y\":128},{\"x\":82,\"y\":142},{\"x\":74,\"y\":142}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":30,\"y\":222},{\"x\":40,\"y\":223},{\"x\":38,\"y\":238},{\"x\":30,\"y\":237}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":140,\"y\":223},{\"x\":147,\"y\":223},{\"x\":147,\"y\":236},{\"x\":140,\"y\":236}],\"text\":\"3\"}]}",
        "{\"language\":\"en\",\"text\":\"0 1.0 1.0 1 4 1.0 1.0 1.0 2 3\",\"lines\":[{\"boundingBox\":[{\"x\":145,\"y\":14},{\"x\":152,\"y\":14},{\"x\":152,\"y\":24},{\"x\":145,\"y\":24}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":130,\"y\":61},{\"x\":151,\"y\":60},{\"x\":151,\"y\":73},{\"x\":130,\"y\":74}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":169,\"y\":62},{\"x\":188,\"y\":61},{\"x\":189,\"y\":72},{\"x\":169,\"y\":73}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":103,\"y\":109},{\"x\":111,\"y\":109},{\"x\":111,\"y\":121},{\"x\":103,\"y\":121}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":179,\"y\":108},{\"x\":189,\"y\":108},{\"x\":190,\"y\":121},{\"x\":179,\"y\":120}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":76,\"y\":155},{\"x\":97,\"y\":155},{\"x\":97,\"y\":167},{\"x\":76,\"y\":168}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":103,\"y\":155},{\"x\":125,\"y\":156},{\"x\":125,\"y\":168},{\"x\":103,\"y\":167}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":183,\"y\":156},{\"x\":203,\"y\":155},{\"x\":203,\"y\":168},{\"x\":183,\"y\":168}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":25,\"y\":204},{\"x\":34,\"y\":204},{\"x\":34,\"y\":216},{\"x\":25,\"y\":215}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":102,\"y\":203},{\"x\":112,\"y\":204},{\"x\":112,\"y\":216},{\"x\":102,\"y\":215}],\"text\":\"3\"}],\"words\":[{\"boundingBox\":[{\"x\":145,\"y\":14},{\"x\":151,\"y\":14},{\"x\":151,\"y\":24},{\"x\":145,\"y\":24}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":130,\"y\":61},{\"x\":148,\"y\":60},{\"x\":149,\"y\":73},{\"x\":131,\"y\":74}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":169,\"y\":61},{\"x\":186,\"y\":61},{\"x\":187,\"y\":72},{\"x\":170,\"y\":73}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":103,\"y\":109},{\"x\":111,\"y\":109},{\"x\":111,\"y\":121},{\"x\":103,\"y\":121}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":181,\"y\":108},{\"x\":189,\"y\":108},{\"x\":189,\"y\":121},{\"x\":180,\"y\":121}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":76,\"y\":155},{\"x\":93,\"y\":155},{\"x\":94,\"y\":168},{\"x\":77,\"y\":168}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":108,\"y\":155},{\"x\":124,\"y\":156},{\"x\":124,\"y\":168},{\"x\":107,\"y\":167}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":184,\"y\":155},{\"x\":201,\"y\":155},{\"x\":202,\"y\":168},{\"x\":184,\"y\":168}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":25,\"y\":204},{\"x\":33,\"y\":204},{\"x\":32,\"y\":216},{\"x\":25,\"y\":215}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":103,\"y\":203},{\"x\":110,\"y\":204},{\"x\":108,\"y\":216},{\"x\":102,\"y\":215}],\"text\":\"3\"}]}",
        "{\"language\":\"en\",\"text\":\"0 1 2 3 5\",\"lines\":[{\"boundingBox\":[{\"x\":142,\"y\":14},{\"x\":150,\"y\":14},{\"x\":149,\"y\":24},{\"x\":141,\"y\":24}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":74,\"y\":93},{\"x\":83,\"y\":93},{\"x\":84,\"y\":103},{\"x\":75,\"y\":103}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":25,\"y\":171},{\"x\":33,\"y\":172},{\"x\":33,\"y\":183},{\"x\":25,\"y\":183}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":111,\"y\":171},{\"x\":120,\"y\":171},{\"x\":121,\"y\":183},{\"x\":111,\"y\":183}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":193,\"y\":171},{\"x\":202,\"y\":171},{\"x\":202,\"y\":183},{\"x\":193,\"y\":183}],\"text\":\"5\"}],\"words\":[{\"boundingBox\":[{\"x\":141,\"y\":14},{\"x\":147,\"y\":14},{\"x\":147,\"y\":24},{\"x\":141,\"y\":24}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":74,\"y\":93},{\"x\":80,\"y\":93},{\"x\":80,\"y\":103},{\"x\":74,\"y\":103}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":27,\"y\":171},{\"x\":33,\"y\":171},{\"x\":32,\"y\":183},{\"x\":26,\"y\":182}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":112,\"y\":171},{\"x\":119,\"y\":171},{\"x\":119,\"y\":183},{\"x\":112,\"y\":183}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":194,\"y\":171},{\"x\":201,\"y\":171},{\"x\":201,\"y\":183},{\"x\":194,\"y\":183}],\"text\":\"5\"}]}",
        "{\"language\":\"en\",\"text\":\"1.0 1 1.0 2 1.0 1.0 3\",\"lines\":[{\"boundingBox\":[{\"x\":78,\"y\":60},{\"x\":98,\"y\":60},{\"x\":98,\"y\":73},{\"x\":78,\"y\":73}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":74,\"y\":108},{\"x\":83,\"y\":108},{\"x\":83,\"y\":120},{\"x\":75,\"y\":120}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":60,\"y\":154},{\"x\":78,\"y\":154},{\"x\":78,\"y\":166},{\"x\":59,\"y\":167}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":25,\"y\":202},{\"x\":33,\"y\":201},{\"x\":34,\"y\":214},{\"x\":25,\"y\":214}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":81,\"y\":202},{\"x\":102,\"y\":201},{\"x\":102,\"y\":214},{\"x\":81,\"y\":214}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":53,\"y\":250},{\"x\":72,\"y\":249},{\"x\":73,\"y\":260},{\"x\":54,\"y\":262}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":66,\"y\":296},{\"x\":76,\"y\":295},{\"x\":76,\"y\":308},{\"x\":66,\"y\":308}],\"text\":\"3\"}],\"words\":[{\"boundingBox\":[{\"x\":80,\"y\":60},{\"x\":97,\"y\":60},{\"x\":97,\"y\":73},{\"x\":80,\"y\":73}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":75,\"y\":108},{\"x\":82,\"y\":108},{\"x\":82,\"y\":120},{\"x\":75,\"y\":120}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":59,\"y\":154},{\"x\":77,\"y\":154},{\"x\":77,\"y\":167},{\"x\":60,\"y\":167}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":25,\"y\":201},{\"x\":32,\"y\":201},{\"x\":33,\"y\":213},{\"x\":26,\"y\":214}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":82,\"y\":201},{\"x\":99,\"y\":201},{\"x\":100,\"y\":214},{\"x\":82,\"y\":214}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":54,\"y\":250},{\"x\":70,\"y\":249},{\"x\":71,\"y\":261},{\"x\":54,\"y\":262}],\"text\":\"1.0\"},{\"boundingBox\":[{\"x\":66,\"y\":295},{\"x\":74,\"y\":295},{\"x\":74,\"y\":308},{\"x\":67,\"y\":308}],\"text\":\"3\"}]}",
        "{\"language\":\"en\",\"text\":\"0 1 2 3\",\"lines\":[{\"boundingBox\":[{\"x\":105,\"y\":16},{\"x\":114,\"y\":16},{\"x\":114,\"y\":27},{\"x\":105,\"y\":27}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":30,\"y\":107},{\"x\":37,\"y\":106},{\"x\":37,\"y\":118},{\"x\":30,\"y\":118}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":89,\"y\":212},{\"x\":98,\"y\":212},{\"x\":98,\"y\":224},{\"x\":89,\"y\":224}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":87,\"y\":302},{\"x\":97,\"y\":302},{\"x\":98,\"y\":314},{\"x\":88,\"y\":314}],\"text\":\"3\"}],\"words\":[{\"boundingBox\":[{\"x\":106,\"y\":16},{\"x\":112,\"y\":16},{\"x\":112,\"y\":27},{\"x\":106,\"y\":27}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":30,\"y\":106},{\"x\":35,\"y\":106},{\"x\":36,\"y\":118},{\"x\":30,\"y\":118}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":89,\"y\":212},{\"x\":97,\"y\":212},{\"x\":97,\"y\":224},{\"x\":89,\"y\":224}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":89,\"y\":302},{\"x\":97,\"y\":302},{\"x\":97,\"y\":314},{\"x\":89,\"y\":314}],\"text\":\"3\"}]}",
        "{\"language\":\"en\",\"text\":\"4 2 r 1.5 1 0.5 Feedback value,f & Reputation,r 0 2 3 4 15 1 Feedback, i\",\"lines\":[{\"boundingBox\":[{\"x\":1020,\"y\":27},{\"x\":1020,\"y\":46},{\"x\":1010,\"y\":47},{\"x\":1010,\"y\":28}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":100,\"y\":1},{\"x\":121,\"y\":4},{\"x\":119,\"y\":28},{\"x\":99,\"y\":26}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":1010,\"y\":69},{\"x\":1023,\"y\":69},{\"x\":1022,\"y\":89},{\"x\":1009,\"y\":88}],\"text\":\"r\"},{\"boundingBox\":[{\"x\":74,\"y\":196},{\"x\":117,\"y\":196},{\"x\":117,\"y\":225},{\"x\":74,\"y\":225}],\"text\":\"1.5\"},{\"boundingBox\":[{\"x\":104,\"y\":391},{\"x\":119,\"y\":393},{\"x\":118,\"y\":416},{\"x\":103,\"y\":414}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":73,\"y\":585},{\"x\":116,\"y\":584},{\"x\":116,\"y\":613},{\"x\":72,\"y\":613}],\"text\":\"0.5\"},{\"boundingBox\":[{\"x\":2,\"y\":644},{\"x\":2,\"y\":183},{\"x\":33,\"y\":183},{\"x\":31,\"y\":644}],\"text\":\"Feedback value,f & Reputation,r\"},{\"boundingBox\":[{\"x\":99,\"y\":783},{\"x\":118,\"y\":782},{\"x\":120,\"y\":805},{\"x\":101,\"y\":805}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":390,\"y\":817},{\"x\":411,\"y\":818},{\"x\":412,\"y\":846},{\"x\":390,\"y\":845}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":647,\"y\":817},{\"x\":667,\"y\":817},{\"x\":669,\"y\":843},{\"x\":648,\"y\":843}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":906,\"y\":817},{\"x\":925,\"y\":819},{\"x\":925,\"y\":843},{\"x\":905,\"y\":841}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":1159,\"y\":818},{\"x\":1179,\"y\":818},{\"x\":1179,\"y\":841},{\"x\":1160,\"y\":840}],\"text\":\"15\"},{\"boundingBox\":[{\"x\":137,\"y\":820},{\"x\":151,\"y\":820},{\"x\":152,\"y\":839},{\"x\":138,\"y\":838}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":569,\"y\":872},{\"x\":734,\"y\":872},{\"x\":734,\"y\":900},{\"x\":569,\"y\":900}],\"text\":\"Feedback, i\"}],\"words\":[{\"boundingBox\":[{\"x\":1020,\"y\":27},{\"x\":1020,\"y\":33},{\"x\":1010,\"y\":33},{\"x\":1010,\"y\":27}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":101,\"y\":1},{\"x\":117,\"y\":2},{\"x\":114,\"y\":27},{\"x\":99,\"y\":25}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":1009,\"y\":69},{\"x\":1020,\"y\":69},{\"x\":1020,\"y\":89},{\"x\":1009,\"y\":88}],\"text\":\"r\"},{\"boundingBox\":[{\"x\":75,\"y\":196},{\"x\":114,\"y\":196},{\"x\":114,\"y\":225},{\"x\":75,\"y\":225}],\"text\":\"1.5\"},{\"boundingBox\":[{\"x\":104,\"y\":391},{\"x\":119,\"y\":393},{\"x\":116,\"y\":416},{\"x\":103,\"y\":414}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":72,\"y\":584},{\"x\":113,\"y\":584},{\"x\":114,\"y\":613},{\"x\":72,\"y\":613}],\"text\":\"0.5\"},{\"boundingBox\":[{\"x\":2,\"y\":641},{\"x\":2,\"y\":501},{\"x\":31,\"y\":501},{\"x\":30,\"y\":641}],\"text\":\"Feedback\"},{\"boundingBox\":[{\"x\":2,\"y\":492},{\"x\":2,\"y\":394},{\"x\":32,\"y\":394},{\"x\":31,\"y\":492}],\"text\":\"value,f\"},{\"boundingBox\":[{\"x\":2,\"y\":388},{\"x\":2,\"y\":371},{\"x\":32,\"y\":371},{\"x\":32,\"y\":387}],\"text\":\"&\"},{\"boundingBox\":[{\"x\":2,\"y\":360},{\"x\":2,\"y\":184},{\"x\":33,\"y\":184},{\"x\":32,\"y\":360}],\"text\":\"Reputation,r\"},{\"boundingBox\":[{\"x\":100,\"y\":782},{\"x\":113,\"y\":782},{\"x\":114,\"y\":805},{\"x\":100,\"y\":805}],\"text\":\"0\"},{\"boundingBox\":[{\"x\":391,\"y\":817},{\"x\":410,\"y\":818},{\"x\":408,\"y\":846},{\"x\":390,\"y\":845}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":648,\"y\":817},{\"x\":663,\"y\":817},{\"x\":663,\"y\":843},{\"x\":648,\"y\":843}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":910,\"y\":817},{\"x\":925,\"y\":819},{\"x\":923,\"y\":843},{\"x\":907,\"y\":841}],\"text\":\"4\"},{\"boundingBox\":[{\"x\":1159,\"y\":818},{\"x\":1177,\"y\":818},{\"x\":1177,\"y\":841},{\"x\":1159,\"y\":840}],\"text\":\"15\"},{\"boundingBox\":[{\"x\":139,\"y\":820},{\"x\":150,\"y\":820},{\"x\":150,\"y\":839},{\"x\":139,\"y\":838}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":569,\"y\":873},{\"x\":716,\"y\":874},{\"x\":716,\"y\":900},{\"x\":569,\"y\":901}],\"text\":\"Feedback,\"},{\"boundingBox\":[{\"x\":721,\"y\":874},{\"x\":734,\"y\":874},{\"x\":734,\"y\":899},{\"x\":721,\"y\":900}],\"text\":\"i\"}]}",
        "{\"language\":\"en\",\"text\":\"Published online: 07 September 2015\",\"lines\":[{\"boundingBox\":[{\"x\":5,\"y\":15},{\"x\":1065,\"y\":17},{\"x\":1065,\"y\":72},{\"x\":5,\"y\":71}],\"text\":\"Published online: 07 September 2015\"}],\"words\":[{\"boundingBox\":[{\"x\":6,\"y\":16},{\"x\":272,\"y\":17},{\"x\":272,\"y\":71},{\"x\":6,\"y\":68}],\"text\":\"Published\"},{\"boundingBox\":[{\"x\":290,\"y\":17},{\"x\":494,\"y\":18},{\"x\":494,\"y\":73},{\"x\":290,\"y\":71}],\"text\":\"online:\"},{\"boundingBox\":[{\"x\":505,\"y\":18},{\"x\":578,\"y\":18},{\"x\":578,\"y\":73},{\"x\":505,\"y\":73}],\"text\":\"07\"},{\"boundingBox\":[{\"x\":597,\"y\":18},{\"x\":906,\"y\":18},{\"x\":905,\"y\":72},{\"x\":596,\"y\":73}],\"text\":\"September\"},{\"boundingBox\":[{\"x\":921,\"y\":18},{\"x\":1057,\"y\":17},{\"x\":1056,\"y\":70},{\"x\":920,\"y\":72}],\"text\":\"2015\"}]}"
      ]
    },
    {
      "@search.score": 2.585697,
      "content": "\nSentiment analysis and the complex \nnatural language\nMuhammad Taimoor Khan1*, Mehr Durrani2, Armughan Ali2, Irum Inayat3, Shehzad Khalid1 and Kamran \nHabib Khan4\n\nIntroduction\nSentiment analysis (Pang and Lillian 2008) is a type of text classification that deals with \nsubjective statements. It is also known as opinion mining, since it processes opinions in \norder to learn about public perception. Sentiment analysis and opinion mining are the \nsame, and are used interchangeably throughout the document. It uses natural language \nprocessing (NLP) to collect and examine opinion or sentiment words. SA is explained \nas identifying the sentiments of people about a topic and its features (Pang and Lillian \n2008). The reason for the popularity of opinion mining is because people prefer to take \nadvice from others in order to invest sensibly. Determining subjective attitudes in big \nsocial data is a hotspot in the field of data mining and NLP (Hai et al. 2014).\n\nAbstract \n\nThere is huge amount of content produced online by amateur authors, covering a \nlarge variety of topics. Sentiment analysis (SA) extracts and aggregates users’ senti-\nments towards a target entity. Machine learning (ML) techniques are frequently used \nas the natural language data is in abundance and has definite patterns. ML techniques \nadapt to domain specific solution at high accuracy depending upon the feature set \nused. The lexicon-based techniques, using external dictionary, are independent of data \nto prevent overfitting but they miss context too in specialized domains. Corpus-based \nstatistical techniques require large data to stabilize. Complex network based tech-\nniques are highly resourceful, preserving order, proximity, context and relationships. \nRecent applications developed incorporate the platform specific structural information \ni.e. meta-data. New sub-domains are introduced as influence analysis, bias analysis, and \ndata leakage analysis. The nature of data is also evolving where transcribed customer-\nagent phone conversation are also used for sentiment analysis. This paper reviews \nsentiment analysis techniques and highlight the need to address natural language \nprocessing (NLP) specific open challenges. Without resolving the complex NLP chal-\nlenges, ML techniques cannot make considerable advancements. The open issues and \nchallenges in the area are discussed, stressing on the need of standard datasets and \nevaluation methodology. It also emphasized on the need of better language models \nthat could capture context and proximity.\n\nKeywords: Sentiment analysis, Machine learning, Sentiment orientation, Complex \nnetworks\n\nOpen Access\n\n© 2016 Khan et al. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://\ncreativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided \nyou give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate \nif changes were made.\n\nREVIEW\n\nKhan et al. Complex Adapt Syst Model  (2016) 4:2 \nDOI 10.1186/s40294-016-0016-9\n\n*Correspondence:   \ntaimoor.muhammad@gmail.\ncom \n1 Bahria University, Shangrilla \nRoad, Sector E-8, Islamabad, \nPakistan\nFull list of author information \nis available at the end of the \narticle\n\n\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40294-016-0016-9&domain=pdf\n\n\nPage 2 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nManufacturers are also interested to know which features of their products are more \npopular in public, in order to make profitable business decisions. There is a huge reposi-\ntory of opinion content available at various online sources in the form of blogs, forums, \nsocial media, review websites etc. They are growing, with more opinionated content \npoured in continuously. It is, therefore, beyond the control of manual techniques to \nanalyze millions of reviews and to aggregate them towards a rapid and efficient deci-\nsion. Sentiment analysis techniques perform this task through automated processes with \nminimal or no user support. The online datasets may also contain objective statements, \nwhich do not contribute effectively in sentiment analysis. Such statements are filtered at \npre-processing.\n\nOpinion mining deals with identifying opinion patterns and presenting them in a \nway that is easy to understand. The outcome of sentiment analysis can be in the form \nof binary classification, such as categorizing opinions as recommended or not recom-\nmended. It can be considered as a multi-class classification problem on a given scale of \nlikeness. Cambria et al. (2013) used common-sense knowledge to improve the results of \nsentiment analysis. The results can be presented in the form of a short summary gen-\nerated from the overall analysis. Sentiment analysis has various sub streams including \nemotion analysis, trend analysis, and bias analysis etc. Its applications has outgrown \nfrom business to social, political and geographical domains. Sentiment analysis is \napplied to emails for gender identification through emotion analysis (Mohammad and \nYang 2011). Emotion is applied to fairy tales to draw interesting patterns (Mohammad \n2011). Considering text a complex network of words that are associated to each other \nwith sentiments, graph based analysis techniques are used for NLP tasks.\n\nNatural language processing\n\nOpinion mining requires NLP, to extract semantics of opinion words and sentences. \nHowever, NLP has open challenges that are too complex to be handled accurately till \ndate. Since sentiment analysis makes extensive use of NLP, it has this complex behav-\nior reflected. The assumptions in NLP for text categorization do not work with opinion \nmining, as they are different in nature. Documents having high frequency of matching \nwords may not necessarily possess same sentiment polarity. It is because, a fact in text \ncategorization could be either correct or incorrect, and is well known to all. Unlike facts, \na variety of opinions can be correct about the same product, due to its subjective nature. \nAnother difference is that, opinion mining is sensitive to individual words, where a sin-\ngle word like NOT may change the whole context. The open challenges are negations \nwithout using NOT word, sarcastic and comparative sentences etc. The later section has \na detailed discussion on NLP issues that affect sentiment analysis.\n\nThe subjective content from the online sources have simple, compound or complex \nsentences. Simple sentences possess single opinion about a product, while compound \nsentences have multiple opinions expressed together. Complex sentences have implicit \nmeaning and are hard to evaluate. Regular opinions pertain to a single entity only, while \ncomparative opinions have an object or some of its aspects discussed in comparison to \nanother object. Comparative opinions can either be objective or subjective. An example \nof a subjective sentence having comparison is “The sound effects of game X are much \nbetter than that of game Y” whereas an example of objective sentence with comparison is \n\n\n\nPage 3 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\n“Game X has twice as many control options as that of Game Y”. Opinion mining expects \na variety of sentence types, since people follow different writing styles in order to express \nthemselves in a better way.\n\nSentiment analysis\n\nThe machine learning (ML) based techniques are supervised, semi supervised or unsu-\npervised. The supervised techniques require labeled data, while the semi supervised \ntechniques need manual tuning from domain experts. The unsupervised techniques \nmake use of statistical analysis on large volume of data. ML techniques has a large fea-\nture set using Bag-of-words (BOW). Results are improved by pruning repetitive and \nlow quality features. The opinion words are extracted to identify the polarity of opinion \nexpressed for a feature. The performance of a classifier is measured through its effective-\nness at the cost of efficiency. Effectiveness is calculated as precision/recall and F-meas-\nure, which are measurements of relevance.\n\nSentiment analysis can also be considered as a complex network. It consists of nodes \nand edges joining them. Many complex systems from a variety of domains are repre-\nsented as network including environmental modeling (Niazi et al.  2010), business sys-\ntems (Aoyama 2002), wireless sensors, and ad-hoc networks (Niazi and Hussain 2009). \nNetworks are rich in information, having a range of local and global properties. Text cor-\npora can be used with words as nodes and edges representing the structural or seman-\ntic association between them. The adjacent nodes sharing a link are closely associated \nand directly affect each other through the weight of the link they share. Representing \ntext as complex network, various properties like centrality, degree distribution, com-\nponents, communities, paths etc. can be used to explore the data thoroughly. Through \nmulti-partite graphs, nodes can be distributed among various clusters with inter-cluster \nedges only. It separates different types of entities discussed in comparison. Entities are \nlinked to their respective aspects/features and then to the sentiments associated. The \nsentiments can be linked with the reasons shared in support of those sentiments.\n\nData sources\n\nOpinion mining has diverse subjective data sources that are available online. They cover \na large number of topics and are up-to-date with current issues. Introduction of Web2.0 \nin the last decade has enabled people to post their thoughts and opinions on a range of \ntopics. The data produced online is growing all the time produced by people from differ-\nent backgrounds (Katz et al. 2015). Opinion mining makes use of this data generated by \nmillions of users all over the world. According to Business Week survey in 2009, 70 % of \nthe people consult online reviews and ratings to make a purchase. Comscore/The Kelsey \ngroup in 2007 reported that 97 % of the people who made purchases based on online \nreviews, found them to be honest.\n\nThe user generated subjective content is of value to be assessed and summarized for \nprospective customers. These online data sources are in the form of blogs, reviews and \nsocial media websites. The popularity of blogging is on the rise, where people from dif-\nferent walks of life express their opinions about various entities and events and get com-\nments on them. At times, it leads to a form of discussion among the author and various \nusers commenting on them. A detailed analysis on blogging styles of authors, as they \n\n\n\nPage 4 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nfollow their own unique approaches for expressing their feelings is provided in (Chau \nand Xu 2007). Blogs contain opinions about various products, services, their features, \npackages and promotions. Most of the online studies on opinion extraction use blogs as \ndatasets (Qiang and Rob 2009) to perform detailed analysis.\n\nThere are professional review websites providing customers’ feedbacks, used for sen-\ntiment analysis. E-commerce websites allow customers to comment on their products. \nSocial media is another popular medium of sharing information among like-minded \npeople. Here, a variety of subjects are discussed where people express their opinions, \nbased on their own experience. Social media websites have a very complex struc-\nture for extracting information having user opinions. They allow users to express their \nviews through sharing articles and other media sources as an external link. Twitter, also \nreferred to as microblogging, has the problem of reviews being too short and at times \nmiss the context.\n\nThis review article is organized into the following divisions. Section 2 reviews the Sen-\ntiment analysis techniques and the NLP issues. Section 3 provides a discussion on the \nreview studied and Sect. 4 list the application areas for sentiment analysis. Section 5 has \nconcluded the study to important issues drawn from the study. Section 6 has distribu-\ntion of the work carried out by the authors.\n\nReview\nThe sentiment analysis techniques categorize reviews into positive and negative bins or \nmultiple degrees of it. The social data can be analyzed at three different levels i.e. user \ndata, relationship data and content (Tang et al.  2014). In survey (Guellil and Boukhalfa \n2015) these categories are further elaborated. Recommender systems are extended to \nsupport textual content using knowledge (Tang et al. 2013). In our previous work (Khan \nand Khalid 2015) sentiment analysis is highlighted to address health care problems from \nthe view point of a user. The issues faced in SA also depend on the data sources and \nnature of analysis required. An important aspect of social data analysis is the identifi-\ncation of sentiments and sentiment targets (Tuveri and Angioni 2014; Zhang and Liu \n2014). Opinion mining also consider the additional features of opinion holder and time. \nSentiment analysis techniques can be separated into three groups: supervised, semi-\nsupervised and unsupervised techniques.\n\nThe supervised techniques are the machine learning classifiers. They are more accu-\nrate, however, need to be trained on a relevant domain. The unsupervised statistical \ntechniques do not require training. They are efficient in dynamic environment but at the \ncost of accuracy. Sentiment analysis techniques analyze opinion datasets to generate a \ngeneral perception that people have about a product. The classification of sentiments in \na review document is performed through identifying and separating all the positive and \nnegative opinion words. Considering the strength of these words, along with their polar-\nity, helps in multi-class classification. Machine learning classifiers such as Naive-Bayes, \nk-nearest neighbor and centroid based classifier etc., are successfully used for this pur-\npose. Semantic orientation based techniques used for opinion mining are Lexicon based \nand statistical analysis. Lexicon based technique works with individual words while sta-\ntistical analysis incorporates words co-occurrence using point wise mutual information \n(PMI) and latent semantic analysis (LSA). Semi-supervised techniques start with a small \n\n\n\nPage 5 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nset of opinion words from the given domain, and expand on it. More opinion words are \nexplored by querying the starting seeds. The newly found words are queried again to find \nmore words until no new words are returned. Orientation of the opinion word form the \nbasis for classification. Other attributes used are frequency of occurrence, location and \nco-occurrence with other words. The taxonomy of these approaches is shown in Fig. 1.\n\nSentiment classification\n\nThese are the machine learning classifiers used for sentiment analysis. They can be \napplied to text documents at three levels for analysis. A document level approach, \nwhich studies the whole document as a single entity is appropriate for text categoriza-\ntion. However, document level approach is not viable for sentiment analysis with docu-\nments having multiple opinions. Therefore, sentiment analysis is performed extensively \nat sentence or word level. Word level analysis is also known as sentiment level analysis. \nML techniques suits sentiment analysis as the data is in abundance and there is obvious \npresence of patterns (Schouten and Frasincar 2015). The classifiers are trained on label \ndataset having samples representing all classes. A test dataset is used to evaluate the per-\nformance of the classifiers for the given task. Let the set of documents as {D = d1,…,dn}, \nand set of classes labeled as {C = c1,…,cn}, then the task is to classify document di in D \nwith a label ci in C. This task can be performed using supervised classifiers. The more \nfrequently used classifiers for sentiment analysis are discussed below.\n\nNaïve Bayes\n\nNaive Bayes (NB) classifier is extensively used for text classification. It learns from a \ntraining dataset of annotated feature vectors, with labels as positive and negative (in case \nof binary classification). The probability of a feature vector is calculated with each label \nusing the annotated training dataset. The feature vector is assigned a label that has high-\nest probability for it. If this information is preserved, it can be used to show confidence \nin a label for a feature vector. In further modifications of NB a fuzzy region is defined \nin which feature vectors hold both labels with a certain level of confidence. Text data \nnormally have high dimensional feature vectors. Therefore, the process of calculating \nprobability is repeated for each feature vector, and then all the probabilities contribute \ntowards the final decision. The feature set is represented as F = f1, f2…fm}, where prob-\nability of a document belonging to a class shown as:\n\nFig. 1 Taxonomy of expository literature on sentiment analysis\n\n\n\n\n\nPage 6 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nShows the probability of a document dj represented by its vector dj* belonging to a class \nci. It is the product of probabilities for all the features in the feature set. The document \nvector dj\n\n* is assigned to a class ci in order to maximize P\n(\n\nci\n\n∣\n\n∣\n\n∣\nd∗j\n\n)\n\n. The logarithm of prob-\nabilities are summed up to classify an opinion document. It is preferred over product of \nprobabilities to avoid underflow. It addresses the missing value problem as well. Slack \nvariables add smoothing effect against noisy data. Weights can also be assigned to fea-\ntures which define their contribution towards the classification. It is a biased approach, \nwhere prominent features are given high weights to play a major role in choose a senti-\nment label.\n\nNaive Bayes works on the assumption that all the sentences of a review document are \nopinion sentences. It also assumes that features of a document are independent of each \nother. Despite of this unrealistic assumption, Naïve Bayes is very successful and is used \nin various practical applications. The assumption of treating features as independent of \neach other makes Naive Bayes highly efficient (Dai et al. 2007). Although, Naive Bayes \nclassifier is simple, yet it is effective because of its robustness to irrelevant features. It \nperforms well in domains with many equally important features. It is considered to be \nmore reliable for text classification and sentiment analysis. The accuracy of the classifier \nimproves with pre-processing noise. It also used as transfer learning when trained on a \ndataset similar to the target dataset.\n\nNearest neighbor\n\nk-nearest neighbor classifier has been frequently used in literature for text classifica-\ntion. It considers the labels of k nearest neighbors to classify a test document. A special \ncase of the k-NN problem is typically referred to as classimbalance problem identified \nin (Yang and Liu 1999). Classes with more training data have higher influence to predict \nsame label for the new document. There are fewer chances of acquiring a class label if \nthat class has fewer training examples. (Li et al. 2003) catered this problem by using vari-\nable value of k for each class. Thus, the class having more training data will have higher \nvalue of k as compared to the one having few samples. This solution is helpful in online \nclassification, where there is time constraint on trying different values of k.\n\nA study on performance of k-NN using pre-processed dataset is conducted in (Shin \net al. 2006) claiming 10 % improvement when noise and outliers are filtered out. An opti-\nmum value is chosen as threshold to separate regular data from noise. Sentiment analy-\nsis is performed with a reduced set of feature vector in (Sreemathy and Balamurugan \n2012) to avoid the curse of dimensionality. Accuracy of the model improves as irrelevant \nfeatures were removed. Features are assigned weights to vary their contribution towards \ndecision making. Weights are extracted from probability of information in documents \nacross different categories. Tree-fast k-NN is introduced as fast kNN model (Soucy and \nMineau 2001). This tree based indexing of retrieval system improves the accuracy of \nk-NN in distance calculation. Its effective against large feature sets. The order of features \nand their thresholds are identified from within the training data. k-NN has promising \n\n(1)P(ci\n∣\n\n∣dj\n∗\n) =\n\np(ci)(\n∏m\n\ni=1 p(fi|ci) )\n\np(d∗j )\n\n\n\nPage 7 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nresults in sentiment analysis; however, it is more susceptible to noise and high dimen-\nsional feature set. Therefore, more of the work in k-NN for text classification has focused \non feature selection and reduction techniques as they are the driving factors of k-NN’s \nperformance.\n\nCentroid based\n\nCentroid based (CB) classifier calculates centroid vector or prototype vector for each \nclass in the training dataset. Centroid vector is the central point of the class and may not \nrepresent an actual training data. The distance of each test document is calculated with \nthe prototype vector of the class and is classified based on similarity with it. Its perfor-\nmance depends on the chosen centroid vectors. It is efficient since time and space com-\nplexities are proportional to the number of classes rather than training documents. To \ndouble the training data reverse of reviews are generated in (Xia et al. 2015) by invert-\ning the sentiment terms and their labels. Using both sets of training data with Mutual \nInformation (MI) the results were improved when only selected reviews were inverted. \nExternal dictionary WordNet is used to generate inverse for sentiment terms, however, \npseudo-antonyms can be generated internally using the corpus.\n\nms, however, pseudo-antonyms can be generated internally using the corpus. A variety \nof approaches have been used for CB classifier. Rocchio algorithm calculates centroid \nto represent feature space of documents (Ana and Arlindo 2007; Tan 2007a, b). Cen-\ntroid is computed through average of positive examples in (Han and Karypis 2000) and \nsum of positive cases i.e. the related training examples (Chuang et al. 2000). Normalized \nsum of positive vectors used in (Lertnattee and Theeramunkong2004), cosine similar-\nity between the test document and the Centroid of a class (Hidayet and Tunga 2012). \nCentroid is used with inverse of class similarity as well improving the accuracy close to \n100 % on the given dataset when characters are chosen as features instead of n-grams.\n\nCentroid evaluation is sensitive to noise in the training dataset which affects the over-\nall performance of the classifier. This shortfall is exposed when Centroid classifier is \napplied to a slightly different domain. The reason for this drawback is that some opinion \nwords are domain dependent. They have different polarity or strength of polarity when \nused in a different domain. Smoothing techniques have being proposed in (Tan 2007a, b;  \nLertnattee and Theeramunkong 2006; Guan 2009) that minimizes the effect of noise \nin the dataset. (Chizi et al. 2009) defined a weighting scheme giving higher weights to \nexplicit opinion words. Characters and special characters for feature selection are used \nin (Ozgur and Gungor 2009). The work in (Shankar and Karypis 2000; Tan et al. 2005) \nis focused on adjusting the value of centroid based with feedback looping, hypothesis \nmargin and weight-adjustment respectively. They try to rectify class Centroid, if it is not \ncalculated accurately. Centroid based classifier performs efficiently as it doesn’t consider \ntraining data each time to decide a test document.\n\nSupport vector machine\n\nSupport vector machine classifier is used for text classification in various studies. It finds \na separation among the data using the annotated training dataset. The margin of sep-\naration between classes, which is known as hyperplane, is used to classify the incom-\ning data. The hyperplane should give maximum separation between the classes. It is \n\n\n\nPage 8 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\napplicable even in the presence of high dimensional feature set representation. It classify \nbased o hyperplane among classes. Like centroid-based, SVM also consider the hyper-\nplane to classify a test document. (Brown et  al. 1997) has compared SVM with artifi-\ncial neural networks for text classification and has found it better. Since it has promising \nresults in text classification, it also performs well for opinion mining. They have also \nclaimed in (Brown et al. 1997) that SVM is better than Naive Bayes and decision trees \nclassification algorithms. However, SVM consumes more resources at the training \nstage. Although, it is efficient with large feature set, Feldman et al.(2011) has shown that \ndimensionality reduction in feature set further improves the performance of SVM. It \nexhibits linear complexity and can scale up to a large dataset.\n\nSVM has a limitation of over-reliance on selection of suitable kernel function. Kernel \nis calculated through Linear, Polynomial, Gaussian or sigmoid methods but they tend to \nbe domain specific. Kernel functions that perform well for one domain may not repeat it \nfor next. Its accuracy is also sensitive to number of training samples close to hyperplane. \nSlack variables are introduced to limit the impact of boundary samples by generalizing \nthe classifier, known as soft margin classification. They also help to avoid over-fitting the \ntraining data.\n\nUnsupervised techniques\n\nThe unsupervised sentiment analysis techniques do not require training data and rather \nrely on semantic orientation. They make use of lexicons to identify the positive or neg-\native semantics of opinion words. The meaning of the word, expressed by its use in a \ncontext is called lexicon. An online or off-line dictionary is consulted for this purpose. \nStatistical analysis techniques are also unsupervised, identifying the orientation of senti-\nment words through statistical evaluations. They require large volume of data for high \naccuracy.\n\nLanguages consists of lexicons that are the words used for a particular sense, and a \ngrammar that connect these lexicons. Part-of-speech rules are used to extract senti-\nment phrases from text document. Search engines are used to identify the orientation \nof sentiment words that are missing in the dictionary. Its polarity is identified through \nthe nearby words brought by search engines. They purely rely on external sources and \ntherefore cannot address the context. Lexicon based techniques perform well for general \ndomains while statistical techniques addresses the context and are useful in specialized \ndomains. The two types of approaches are discussed in detail.\n\nDictionary (Lexicon) based techniques\n\nLexicon based techniques extract opinion lexicons from the document and analyzes \nits orientation without the support of any training data. These techniques process the \nopinion words separately, ignoring the relationship between them. Lexicons refer to the \nsemantic orientation. Lexicons are independent of the source data and therefore it does \nnot fall for over-fitting. But context not addressed either in this approach (Katz et  al. \n2015; Cambria 2013). Search engines are used to find the meaning of unknown opinion \nlexicons. They are searched and the top N results are accepted to identify its orientation. \nThe semantics of lexicons can be categorized as positive or negative with weights rep-\nresenting their strength. This approach struggles with lexicons having domain specific \n\n\n\nPage 9 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\npolarity. For example, good has positive polarity in any type of domain but “heavy \nweight” has positive polarity for bike domain but negative for the domain of electronic \ndevices.\n\nIn its simplest form, sentiment words are split into positive and negative as binary \ndistribution. A more sophisticated approach has fuzzy lexicons, introducing a grey area \nbetween the two categories. These fuzzy lexicons exist in both the classes with a score \nassociated to it, representing the strength of each label. Various manual and semi-auto-\nmatic techniques can be used for building lexicons. Princeton University’s WordNet is \na popular lexicon source available for sentiment analysis. Dictionaries like WordNet, \nextracts synonyms and antonyms for the provided opinion words. Manual cleansing is \nemployed to rectify the lists generated for the unknown sentiment words. These opinion \nwords are used to classify a review as positive or negative.\n\nFixed syntactic patterns are also used for expressing opinions which are composed of \npart-of-speech (POS) tags. The basic idea of this technique is to identify the patterns in \nwhich words co-occur with each other and to exploit those patterns for understanding \nits semantic orientation. One example of such pattern is an adverb followed by an adjec-\ntive. A more sophisticated approach was proposed by (Mohammad and Yang 2011), \nwhich used a WordNet distance based method to determine the sentiment orientation. \nThe distance d(t1, t2) between terms t1 and t2 is the length of the shortest path that con-\nnects them in WordNet, as shown in Eq. 2. The semantic orientation (SO) of an adjective \nterm t is determined by its relative distance from two reference (or seed) terms good and \nbad. The polarity of opinion term t is resolved through eq.\n\nStatistics (Corpus) based techniques\n\nStatistical analysis of large corpus of text can also be used to determine the sentiment \norientation of words. Co-occurrence of words is evaluated without consulting any exter-\nnal support. Two methods are used for this purpose which are point wise mutual infor-\nmation (PMI) and latent semantic analysis (LSA). PMI method for co-occurrence is \ngiven as:\n\nwhere w1 and w2 refers to two words in a given sentence. The main concept behind PMI \nbased techniques is that the semantic orientation of a word has a tendency of being \nclosely related to that of its neighbors. Equation 3 gives the probability of words w1 and \nw2 to co-exist, based on the measure of degree of statistical dependence between the \ntwo. This approach is, however, implemented differently in LSA based techniques. In \nLSA, matrix factorization technique is used with singular value decomposition to dem-\nonstrate the statistical co-occurrence of words. More formally, this process can be speci-\nfied as:\n\n(2)SO(t) =\nd(t, bad)− d(t, good)\n\nd(bad, good)\n\n(3)p(w1,w2) =\np(w1,w2)\n\np(w1) p(w2)\n\n(4)LSA(w) = LSA(w, {+paradigms})− LSA(w, {−paradigms})\n\n\n\nPage 10 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nwhere a word w is passed to LSA with positive and negative paradigms. LSA based tech-\nniques develop a matrix having rows as words and columns as sentences or paragraphs. \nEach cell possesses a weight corresponding to the relation of the word in row with the \nsentence or paragraph in columns. This matrix is decomposed into three matrices using \nsingular value decomposition (SVD).\n\nComplex challenges\n\nOpinion mining is a relatively new area of research and there are open challenges that \nneed to be answered. Some of the challenges are common to opinion mining in general \nwhile others are related to their own sources and context depending upon the domain of \nthe dataset. These issues affect the performance of machine learning techniques, but it \nhas little control on them. Figure 2 gives NLP challenges faced in sentiment analysis, dis-\ntributing them into their logical groups. The groupings are based on the parsing level, at \nwhich these issues occur. The following sub section has detailed discussion on the NLP \nissues.\n\nDocument level\n\nDocument level NLP challenges are the ones that are faced at the document or review \nlevel. They deal in general with the review document or the reviewer style. It is common \nto find reviews that have the information about an object, given in an informal manner. \nCapitalization is over or under used. Spelling mistakes are ignored or words being short-\nened. It makes the analysis very difficult for the automatic techniques to identify features \nand associate them. The unknown words (shortened/miss spelled) are matched with \nsimilar words to identify the aspect or opinion words. Slang specific to a certain region \nare also occasionally used in reviews and discussions. Reviews having sarcastic expres-\nsions are the hardest to deal with. Even though they have the opinion words explicitly ",
      "metadata_storage_size": 1582435,
      "metadata_storage_path": "aHR0cHM6Ly9qdHJhaW5pbmdjYXRhbG9nc3RvcmFnZS5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL3M0MDI5NC0wMTYtMDAxNi05LnBkZg2",
      "metadata_author": "Muhammad Taimoor Khan",
      "metadata_title": "Sentiment analysis and the complex natural language",
      "metadata_creation_date": "2016-02-02T06:54:52Z",
      "people": [
        "Muhammad Taimoor Khan1",
        "Mehr Durrani2",
        "Armughan Ali2",
        "Irum Inayat3",
        "Shehzad Khalid1",
        "Kamran",
        "Habib Khan4",
        "Pang",
        "Lillian",
        "niques",
        "Khan",
        "19Khan",
        "Cambria",
        "Mohammad",
        "Yang",
        "Niazi",
        "Aoyama",
        "Hussain",
        "Katz",
        "Xu",
        "Qiang",
        "Rob",
        "Tang",
        "Guellil",
        "Boukhalfa",
        "Khalid",
        "Tuveri",
        "Angioni",
        "Zhang",
        "Liu",
        "Schouten",
        "Frasincar",
        "Thorsten",
        "Kamps",
        "Liu,",
        "Dai",
        "Shin",
        "Guan",
        "Basu",
        "Vinodhini",
        "Ding",
        "Sreemathy",
        "Soucy",
        "Hu",
        "Bayes",
        "Li",
        "Balamurugan",
        "Mineau",
        "k-NN",
        "Xia",
        "Ana",
        "Arlindo",
        "Han",
        "Karypis",
        "Chuang",
        "Lertnattee",
        "Theeramunkong2004",
        "Hidayet",
        "Tunga",
        "Tan",
        "Theeramunkong",
        "Chizi",
        "Ozgur",
        "Gungor",
        "Shankar",
        "Brown",
        "Feldman"
      ],
      "organizations": [
        "analysis",
        "NLP",
        "Creative Commons Attribution",
        "International",
        "Bahria University",
        "Sentiment analysis",
        "ML techniques",
        "business sys-",
        "Business Week",
        "Comscore",
        "The Kelsey",
        "Twitter",
        "unsupervised",
        "Naive-Bayes",
        "Sentiment",
        "ments",
        "Word level",
        "NB",
        "k-NN",
        "Mutual",
        "Cen",
        "cial neural networks",
        "Princeton University",
        "WordNet",
        "PMI"
      ],
      "locations": [
        "SA",
        "big",
        "Corpus",
        "platform",
        "Shangrilla",
        "Pakistan",
        "pora",
        "domain",
        "Slack",
        "domains",
        "in",
        "Shin",
        "NN",
        "Centroid",
        "mance",
        "ms",
        "hyperplane",
        "Cambria",
        "SO",
        "LSA"
      ],
      "keyphrases": [
        "Creative Commons Attribution 4.0 International License",
        "customer- agent phone conversation",
        "Complex networks Open Access",
        "Complex Adapt Syst Model",
        "Creative Commons license",
        "users’ senti- ments",
        "domain specific solution",
        "profitable business decisions",
        "various online sources",
        "Complex network based",
        "specific structural information",
        "original author(s",
        "natural language processing",
        "specific open challenges",
        "natural language data",
        "data leakage analysis",
        "Muhammad Taimoor Khan1",
        "sentiment analysis techniques",
        "open issues",
        "author information",
        "language models",
        "influence analysis",
        "bias analysis",
        "ML) techniques",
        "ML techniques",
        "lexicon-based techniques",
        "statistical techniques",
        "sentiment words",
        "Sentiment orientation",
        "Mehr Durrani",
        "Armughan Ali",
        "Irum Inayat",
        "Shehzad Khalid1",
        "Habib Khan4",
        "text classification",
        "subjective statements",
        "subjective attitudes",
        "social data",
        "huge amount",
        "amateur authors",
        "large variety",
        "target entity",
        "Machine learning",
        "definite patterns",
        "high accuracy",
        "feature set",
        "external dictionary",
        "specialized domains",
        "large data",
        "Recent applications",
        "New sub-domains",
        "considerable advancements",
        "standard datasets",
        "evaluation methodology",
        "unrestricted use",
        "appropriate credit",
        "1 Bahria University",
        "Shangrilla Road",
        "Sector E",
        "Full list",
        "social media",
        "data mining",
        "opinionated content",
        "public perception",
        "opinion mining",
        "opinion content",
        "REVIEW Khan",
        "Kamran",
        "Introduction",
        "Pang",
        "Lillian",
        "type",
        "opinions",
        "order",
        "document",
        "NLP",
        "sentiments",
        "people",
        "topic",
        "features",
        "reason",
        "popularity",
        "advice",
        "others",
        "big",
        "hotspot",
        "field",
        "Hai",
        "Abstract",
        "abundance",
        "overfitting",
        "context",
        "Corpus-based",
        "proximity",
        "relationships",
        "platform",
        "meta-data",
        "nature",
        "paper",
        "need",
        "area",
        "better",
        "Keywords",
        "article",
        "terms",
        "creativecommons",
        "licenses",
        "distribution",
        "reproduction",
        "medium",
        "link",
        "changes",
        "DOI",
        "Correspondence",
        "Islamabad",
        "Pakistan",
        "end",
        "crossmark",
        "org",
        "Page",
        "19Khan",
        "Manufacturers",
        "products",
        "tory",
        "blogs",
        "forums",
        "websites",
        "graph based analysis techniques",
        "various sub streams",
        "different writing styles",
        "multi-class classification problem",
        "ML) based techniques",
        "Natural language processing",
        "many control options",
        "same sentiment polarity",
        "Sentiment analysis techniques",
        "binary classification",
        "complex network",
        "manual techniques",
        "supervised techniques",
        "overall analysis",
        "trend analysis",
        "statistical analysis",
        "complex sentences",
        "automated processes",
        "user support",
        "online datasets",
        "objective statements",
        "Such statements",
        "common-sense knowledge",
        "geographical domains",
        "gender identification",
        "fairy tales",
        "interesting patterns",
        "open challenges",
        "high frequency",
        "same product",
        "later section",
        "detailed discussion",
        "subjective content",
        "online sources",
        "single entity",
        "subjective sentence",
        "sound effects",
        "game X",
        "game Y",
        "objective sentence",
        "sentence types",
        "machine learning",
        "manual tuning",
        "domain experts",
        "large volume",
        "Opinion mining",
        "opinion patterns",
        "single opinion",
        "emotion analysis",
        "text categorization",
        "comparative sentences",
        "multiple opinions",
        "Regular opinions",
        "comparative opinions",
        "extensive use",
        "subjective nature",
        "gle word",
        "individual words",
        "NLP tasks",
        "NLP issues",
        "opinion words",
        "Simple sentences",
        "millions",
        "reviews",
        "rapid",
        "minimal",
        "way",
        "outcome",
        "form",
        "scale",
        "likeness",
        "Cambria",
        "results",
        "applications",
        "business",
        "political",
        "emails",
        "Mohammad",
        "Yang",
        "semantics",
        "date",
        "ior",
        "assumptions",
        "Documents",
        "matching",
        "fact",
        "variety",
        "difference",
        "negations",
        "NOT",
        "sarcastic",
        "compound",
        "implicit",
        "meaning",
        "aspects",
        "comparison",
        "example",
        "Bag",
        "BOW",
        "diverse subjective data sources",
        "seman- tic association",
        "Business Week survey",
        "Many complex systems",
        "complex struc- ture",
        "professional review websites",
        "other media sources",
        "social media websites",
        "The Kelsey group",
        "low quality features",
        "online data sources",
        "E-commerce websites",
        "online studies",
        "effective- ness",
        "Sentiment analysis",
        "environmental modeling",
        "wireless sensors",
        "global properties",
        "degree distribution",
        "multi-partite graphs",
        "different types",
        "large number",
        "current issues",
        "last decade",
        "ferent walks",
        "detailed analysis",
        "unique approaches",
        "popular medium",
        "various properties",
        "various clusters",
        "opinion extraction",
        "online reviews",
        "prospective customers",
        "customers’ feedbacks",
        "ad-hoc networks",
        "blogging styles",
        "external link",
        "various products",
        "adjacent nodes",
        "various entities",
        "user opinions",
        "Results",
        "repetitive",
        "polarity",
        "performance",
        "classifier",
        "cost",
        "efficiency",
        "Effectiveness",
        "precision/recall",
        "measurements",
        "relevance",
        "edges",
        "domains",
        "Niazi",
        "Aoyama",
        "Hussain",
        "information",
        "range",
        "local",
        "Text",
        "pora",
        "structural",
        "weight",
        "centrality",
        "ponents",
        "communities",
        "paths",
        "inter-cluster",
        "reasons",
        "support",
        "topics",
        "Web2.0",
        "thoughts",
        "backgrounds",
        "Katz",
        "users",
        "world",
        "ratings",
        "purchase",
        "Comscore",
        "value",
        "rise",
        "life",
        "events",
        "times",
        "discussion",
        "author",
        "feelings",
        "Chau",
        "Xu",
        "services",
        "packages",
        "promotions",
        "datasets",
        "Qiang",
        "Rob",
        "minded",
        "subjects",
        "experience",
        "articles",
        "Twitter",
        "point wise mutual information",
        "Semantic orientation based techniques",
        "centroid based classifier",
        "health care problems",
        "latent semantic analysis",
        "Lexicon based technique",
        "machine learning classifiers",
        "document level approach",
        "timent analysis techniques",
        "three different levels",
        "unsupervised statistical techniques",
        "text categoriza- tion",
        "Word level analysis",
        "sentiment level analysis",
        "social data analysis",
        "negative opinion words",
        "unsupervised techniques",
        "view point",
        "three levels",
        "sentiment analysis",
        "Semi-supervised techniques",
        "negative bins",
        "sentiment targets",
        "three groups",
        "opinion holder",
        "opinion datasets",
        "following divisions",
        "application areas",
        "multiple degrees",
        "relationship data",
        "Recommender systems",
        "data sources",
        "important aspect",
        "identifi- cation",
        "additional features",
        "dynamic environment",
        "general perception",
        "polar- ity",
        "k-nearest neighbor",
        "starting seeds",
        "Other attributes",
        "text documents",
        "docu- ments",
        "label dataset",
        "test dataset",
        "Sentiment classification",
        "review document",
        "new words",
        "other words",
        "important issues",
        "review article",
        "user data",
        "textual content",
        "previous work",
        "relevant domain",
        "multi-class classification",
        "Section 2",
        "Sect.",
        "Section 5",
        "study",
        "Section 6",
        "authors",
        "positive",
        "Tang",
        "survey",
        "Guellil",
        "Boukhalfa",
        "categories",
        "knowledge",
        "Khan",
        "Khalid",
        "SA",
        "Tuveri",
        "Angioni",
        "Zhang",
        "Liu",
        "rate",
        "training",
        "accuracy",
        "product",
        "strength",
        "Naive-Bayes",
        "pose",
        "occurrence",
        "PMI",
        "small",
        "More",
        "basis",
        "frequency",
        "location",
        "taxonomy",
        "approaches",
        "Fig.",
        "sentence",
        "presence",
        "patterns",
        "Schouten",
        "Frasincar",
        "classes",
        "formance",
        "task",
        "Sentiment Analysis Supervised Classifiers Unsupervised Semantic Orientation Techniques",
        "Nearest Neighbor Centroid Based Support Vector",
        "many equally important features",
        "high dimensional feature vectors",
        "k nearest neighbors",
        "Statistical Analysis Machine",
        "various practical applications",
        "k-nearest neighbor classifier",
        "Naïve Bayes",
        "annotated feature vectors",
        "missing value problem",
        "text classifica- tion",
        "Naive Bayes K",
        "senti- ment label",
        "Naive Bayes classifier",
        "document vector dj",
        "high weights",
        "k-NN problem",
        "classimbalance problem",
        "Text data",
        "document dj",
        "fuzzy region",
        "final decision",
        "Thorsten J.",
        "prob- abilities",
        "Slack variables",
        "smoothing effect",
        "noisy data",
        "fea- tures",
        "biased approach",
        "major role",
        "pre-processing noise",
        "transfer learning",
        "training data",
        "higher influence",
        "document di",
        "opinion document",
        "test document",
        "new document",
        "prominent features",
        "irrelevant features",
        "NB) classifier",
        "target dataset",
        "expository literature",
        "opinion sentences",
        "special case",
        "same label",
        "class ci",
        "unrealistic assumption",
        "Liu B.",
        "C.",
        "labels",
        "probability",
        "confidence",
        "modifications",
        "level",
        "probabilities",
        "Taxonomy",
        "Lexicons",
        "Baoli",
        "Hidayet",
        "Kamps",
        "Vinodhini",
        "S.",
        "Istvan",
        "P.",
        "Zhai",
        "Dai",
        "Shin",
        "Guan",
        "Basu",
        "Ding",
        "Sreemathy",
        "Soucy",
        "Hu",
        "logarithm",
        "underflow",
        "contribution",
        "robustness",
        "External dictionary WordNet",
        "fast kNN model",
        "related training examples",
        "sional feature set",
        "actual training data",
        "training data reverse",
        "fewer training examples",
        "large feature sets",
        "positive examples",
        "fewer chances",
        "reduced set",
        "feature vector",
        "feature selection",
        "regular data",
        "online classification",
        "different values",
        "decision making",
        "different categories",
        "retrieval system",
        "reduction techniques",
        "driving factors",
        "prototype vector",
        "central point",
        "Rocchio algorithm",
        "Cen- troid",
        "positive cases",
        "positive vectors",
        "different domain",
        "Smoothing techniques",
        "training dataset",
        "feature space",
        "sentiment terms",
        "training documents",
        "able value",
        "mum value",
        "Centroid based",
        "centroid vector",
        "Centroid evaluation",
        "time constraint",
        "distance calculation",
        "Mutual Information",
        "different polarity",
        "class label",
        "Tree-fast k-NN",
        "Centroid classifier",
        "CB classifier",
        "class similarity",
        "problem",
        "higher",
        "samples",
        "solution",
        "k.",
        "processed",
        "10 % improvement",
        "noise",
        "outliers",
        "opti",
        "threshold",
        "Balamurugan",
        "curse",
        "dimensionality",
        "Accuracy",
        "weights",
        "Mineau",
        "indexing",
        "dj",
        "work",
        "plexities",
        "number",
        "Xia",
        "inverse",
        "pseudo-antonyms",
        "corpus",
        "Arlindo",
        "average",
        "Karypis",
        "sum",
        "Chuang",
        "Lertnattee",
        "Theeramunkong2004",
        "cosine",
        "Tunga",
        "characters",
        "n-grams",
        "shortfall",
        "drawback",
        "high dimensional feature set representation",
        "decision trees classification algorithms",
        "Support vector machine classifier",
        "unsupervised sentiment analysis techniques",
        "large feature set",
        "cial neural networks",
        "Statistical analysis techniques",
        "suitable kernel function",
        "incom- ing data",
        "senti- ment words",
        "soft margin classification",
        "Lexicon based techniques",
        "explicit opinion words",
        "Centroid based classifier",
        "Unsupervised techniques",
        "ment phrases",
        "statistical evaluations",
        "nearby words",
        "weighting scheme",
        "higher weights",
        "feedback looping",
        "hypothesis margin",
        "various studies",
        "sep- aration",
        "Naive Bayes",
        "training stage",
        "dimensionality reduction",
        "large dataset",
        "sigmoid methods",
        "Kernel functions",
        "training samples",
        "boundary samples",
        "ative semantics",
        "particular sense",
        "speech rules",
        "Search engines",
        "external sources",
        "two types",
        "class Centroid",
        "text document",
        "special characters",
        "maximum separation",
        "linear complexity",
        "one domain",
        "general domains",
        "opinion lexicons",
        "line dictionary",
        "semantic orientation",
        "Theeramunkong",
        "effect",
        "Chizi",
        "Ozgur",
        "Gungor",
        "Shankar",
        "Tan",
        "weight-adjustment",
        "hyperplane",
        "SVM",
        "Brown",
        "resources",
        "Feldman",
        "limitation",
        "reliance",
        "Polynomial",
        "Gaussian",
        "impact",
        "use",
        "online",
        "purpose",
        "Languages",
        "grammar",
        "detail",
        "WordNet distance based method",
        "top N results",
        "singular value decomposition",
        "popular lexicon source",
        "semi-auto- matic techniques",
        "Fixed syntactic patterns",
        "matrix factorization technique",
        "LSA based techniques",
        "unknown opinion lexicons",
        "unknown sentiment words",
        "source data",
        "relative distance",
        "Statistical analysis",
        "PMI method",
        "electronic devices",
        "simplest form",
        "grey area",
        "two categories",
        "Various manual",
        "Princeton University",
        "Manual cleansing",
        "POS) tags",
        "basic idea",
        "shortest path",
        "adjective term",
        "two reference",
        "opinion term",
        "Two methods",
        "main concept",
        "statistical dependence",
        "sentiment orientation",
        "domain specific",
        "bike domain",
        "fuzzy lexicons",
        "One example",
        "large corpus",
        "two words",
        "statistical co-occurrence",
        "sophisticated approach",
        "word w",
        "positive polarity",
        "negative paradigms",
        "relationship",
        "good",
        "score",
        "label",
        "Dictionaries",
        "synonyms",
        "antonyms",
        "lists",
        "review",
        "speech",
        "understanding",
        "adverb",
        "t2",
        "length",
        "Eq.",
        "seed",
        "Statistics",
        "mation",
        "w1",
        "w2",
        "tendency",
        "neighbors",
        "Equation",
        "measure",
        "degree",
        "process",
        "rows",
        "columns",
        "paragraphs",
        "cell",
        "Document level NLP challenges",
        "following sub section",
        "machine learning techniques",
        "parsing level",
        "review level",
        "automatic techniques",
        "Complex challenges",
        "three matrices",
        "new area",
        "little control",
        "logical groups",
        "reviewer style",
        "informal manner",
        "Spelling mistakes",
        "unknown words",
        "similar words",
        "matrix",
        "SVD",
        "research",
        "general",
        "sources",
        "domain",
        "dataset",
        "Figure",
        "groupings",
        "object",
        "Capitalization",
        "aspect",
        "Slang",
        "region",
        "discussions"
      ],
      "merged_content": "\nSentiment analysis and the complex \nnatural language\nMuhammad Taimoor Khan1*, Mehr Durrani2, Armughan Ali2, Irum Inayat3, Shehzad Khalid1 and Kamran \nHabib Khan4\n\nIntroduction\nSentiment analysis (Pang and Lillian 2008) is a type of text classification that deals with \nsubjective statements. It is also known as opinion mining, since it processes opinions in \norder to learn about public perception. Sentiment analysis and opinion mining are the \nsame, and are used interchangeably throughout the document. It uses natural language \nprocessing (NLP) to collect and examine opinion or sentiment words. SA is explained \nas identifying the sentiments of people about a topic and its features (Pang and Lillian \n2008). The reason for the popularity of opinion mining is because people prefer to take \nadvice from others in order to invest sensibly. Determining subjective attitudes in big \nsocial data is a hotspot in the field of data mining and NLP (Hai et al. 2014).\n\nAbstract \n\nThere is huge amount of content produced online by amateur authors, covering a \nlarge variety of topics. Sentiment analysis (SA) extracts and aggregates users’ senti-\nments towards a target entity. Machine learning (ML) techniques are frequently used \nas the natural language data is in abundance and has definite patterns. ML techniques \nadapt to domain specific solution at high accuracy depending upon the feature set \nused. The lexicon-based techniques, using external dictionary, are independent of data \nto prevent overfitting but they miss context too in specialized domains. Corpus-based \nstatistical techniques require large data to stabilize. Complex network based tech-\nniques are highly resourceful, preserving order, proximity, context and relationships. \nRecent applications developed incorporate the platform specific structural information \ni.e. meta-data. New sub-domains are introduced as influence analysis, bias analysis, and \ndata leakage analysis. The nature of data is also evolving where transcribed customer-\nagent phone conversation are also used for sentiment analysis. This paper reviews \nsentiment analysis techniques and highlight the need to address natural language \nprocessing (NLP) specific open challenges. Without resolving the complex NLP chal-\nlenges, ML techniques cannot make considerable advancements. The open issues and \nchallenges in the area are discussed, stressing on the need of standard datasets and \nevaluation methodology. It also emphasized on the need of better language models \nthat could capture context and proximity.\n\nKeywords: Sentiment analysis, Machine learning, Sentiment orientation, Complex \nnetworks\n\nOpen Access\n\n© 2016 Khan et al. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://\ncreativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided \nyou give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate \nif changes were made.\n\nREVIEW\n\nKhan et al. Complex Adapt Syst Model  (2016) 4:2 \nDOI 10.1186/s40294-016-0016-9\n\n*Correspondence:   \ntaimoor.muhammad@gmail.\ncom \n1 Bahria University, Shangrilla \nRoad, Sector E-8, Islamabad, \nPakistan\nFull list of author information \nis available at the end of the \narticle\n\n  \n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40294-016-0016-9&domain=pdf\n\n\nPage 2 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nManufacturers are also interested to know which features of their products are more \npopular in public, in order to make profitable business decisions. There is a huge reposi-\ntory of opinion content available at various online sources in the form of blogs, forums, \nsocial media, review websites etc. They are growing, with more opinionated content \npoured in continuously. It is, therefore, beyond the control of manual techniques to \nanalyze millions of reviews and to aggregate them towards a rapid and efficient deci-\nsion. Sentiment analysis techniques perform this task through automated processes with \nminimal or no user support. The online datasets may also contain objective statements, \nwhich do not contribute effectively in sentiment analysis. Such statements are filtered at \npre-processing.\n\nOpinion mining deals with identifying opinion patterns and presenting them in a \nway that is easy to understand. The outcome of sentiment analysis can be in the form \nof binary classification, such as categorizing opinions as recommended or not recom-\nmended. It can be considered as a multi-class classification problem on a given scale of \nlikeness. Cambria et al. (2013) used common-sense knowledge to improve the results of \nsentiment analysis. The results can be presented in the form of a short summary gen-\nerated from the overall analysis. Sentiment analysis has various sub streams including \nemotion analysis, trend analysis, and bias analysis etc. Its applications has outgrown \nfrom business to social, political and geographical domains. Sentiment analysis is \napplied to emails for gender identification through emotion analysis (Mohammad and \nYang 2011). Emotion is applied to fairy tales to draw interesting patterns (Mohammad \n2011). Considering text a complex network of words that are associated to each other \nwith sentiments, graph based analysis techniques are used for NLP tasks.\n\nNatural language processing\n\nOpinion mining requires NLP, to extract semantics of opinion words and sentences. \nHowever, NLP has open challenges that are too complex to be handled accurately till \ndate. Since sentiment analysis makes extensive use of NLP, it has this complex behav-\nior reflected. The assumptions in NLP for text categorization do not work with opinion \nmining, as they are different in nature. Documents having high frequency of matching \nwords may not necessarily possess same sentiment polarity. It is because, a fact in text \ncategorization could be either correct or incorrect, and is well known to all. Unlike facts, \na variety of opinions can be correct about the same product, due to its subjective nature. \nAnother difference is that, opinion mining is sensitive to individual words, where a sin-\ngle word like NOT may change the whole context. The open challenges are negations \nwithout using NOT word, sarcastic and comparative sentences etc. The later section has \na detailed discussion on NLP issues that affect sentiment analysis.\n\nThe subjective content from the online sources have simple, compound or complex \nsentences. Simple sentences possess single opinion about a product, while compound \nsentences have multiple opinions expressed together. Complex sentences have implicit \nmeaning and are hard to evaluate. Regular opinions pertain to a single entity only, while \ncomparative opinions have an object or some of its aspects discussed in comparison to \nanother object. Comparative opinions can either be objective or subjective. An example \nof a subjective sentence having comparison is “The sound effects of game X are much \nbetter than that of game Y” whereas an example of objective sentence with comparison is \n\n\n\nPage 3 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\n“Game X has twice as many control options as that of Game Y”. Opinion mining expects \na variety of sentence types, since people follow different writing styles in order to express \nthemselves in a better way.\n\nSentiment analysis\n\nThe machine learning (ML) based techniques are supervised, semi supervised or unsu-\npervised. The supervised techniques require labeled data, while the semi supervised \ntechniques need manual tuning from domain experts. The unsupervised techniques \nmake use of statistical analysis on large volume of data. ML techniques has a large fea-\nture set using Bag-of-words (BOW). Results are improved by pruning repetitive and \nlow quality features. The opinion words are extracted to identify the polarity of opinion \nexpressed for a feature. The performance of a classifier is measured through its effective-\nness at the cost of efficiency. Effectiveness is calculated as precision/recall and F-meas-\nure, which are measurements of relevance.\n\nSentiment analysis can also be considered as a complex network. It consists of nodes \nand edges joining them. Many complex systems from a variety of domains are repre-\nsented as network including environmental modeling (Niazi et al.  2010), business sys-\ntems (Aoyama 2002), wireless sensors, and ad-hoc networks (Niazi and Hussain 2009). \nNetworks are rich in information, having a range of local and global properties. Text cor-\npora can be used with words as nodes and edges representing the structural or seman-\ntic association between them. The adjacent nodes sharing a link are closely associated \nand directly affect each other through the weight of the link they share. Representing \ntext as complex network, various properties like centrality, degree distribution, com-\nponents, communities, paths etc. can be used to explore the data thoroughly. Through \nmulti-partite graphs, nodes can be distributed among various clusters with inter-cluster \nedges only. It separates different types of entities discussed in comparison. Entities are \nlinked to their respective aspects/features and then to the sentiments associated. The \nsentiments can be linked with the reasons shared in support of those sentiments.\n\nData sources\n\nOpinion mining has diverse subjective data sources that are available online. They cover \na large number of topics and are up-to-date with current issues. Introduction of Web2.0 \nin the last decade has enabled people to post their thoughts and opinions on a range of \ntopics. The data produced online is growing all the time produced by people from differ-\nent backgrounds (Katz et al. 2015). Opinion mining makes use of this data generated by \nmillions of users all over the world. According to Business Week survey in 2009, 70 % of \nthe people consult online reviews and ratings to make a purchase. Comscore/The Kelsey \ngroup in 2007 reported that 97 % of the people who made purchases based on online \nreviews, found them to be honest.\n\nThe user generated subjective content is of value to be assessed and summarized for \nprospective customers. These online data sources are in the form of blogs, reviews and \nsocial media websites. The popularity of blogging is on the rise, where people from dif-\nferent walks of life express their opinions about various entities and events and get com-\nments on them. At times, it leads to a form of discussion among the author and various \nusers commenting on them. A detailed analysis on blogging styles of authors, as they \n\n\n\nPage 4 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nfollow their own unique approaches for expressing their feelings is provided in (Chau \nand Xu 2007). Blogs contain opinions about various products, services, their features, \npackages and promotions. Most of the online studies on opinion extraction use blogs as \ndatasets (Qiang and Rob 2009) to perform detailed analysis.\n\nThere are professional review websites providing customers’ feedbacks, used for sen-\ntiment analysis. E-commerce websites allow customers to comment on their products. \nSocial media is another popular medium of sharing information among like-minded \npeople. Here, a variety of subjects are discussed where people express their opinions, \nbased on their own experience. Social media websites have a very complex struc-\nture for extracting information having user opinions. They allow users to express their \nviews through sharing articles and other media sources as an external link. Twitter, also \nreferred to as microblogging, has the problem of reviews being too short and at times \nmiss the context.\n\nThis review article is organized into the following divisions. Section 2 reviews the Sen-\ntiment analysis techniques and the NLP issues. Section 3 provides a discussion on the \nreview studied and Sect. 4 list the application areas for sentiment analysis. Section 5 has \nconcluded the study to important issues drawn from the study. Section 6 has distribu-\ntion of the work carried out by the authors.\n\nReview\nThe sentiment analysis techniques categorize reviews into positive and negative bins or \nmultiple degrees of it. The social data can be analyzed at three different levels i.e. user \ndata, relationship data and content (Tang et al.  2014). In survey (Guellil and Boukhalfa \n2015) these categories are further elaborated. Recommender systems are extended to \nsupport textual content using knowledge (Tang et al. 2013). In our previous work (Khan \nand Khalid 2015) sentiment analysis is highlighted to address health care problems from \nthe view point of a user. The issues faced in SA also depend on the data sources and \nnature of analysis required. An important aspect of social data analysis is the identifi-\ncation of sentiments and sentiment targets (Tuveri and Angioni 2014; Zhang and Liu \n2014). Opinion mining also consider the additional features of opinion holder and time. \nSentiment analysis techniques can be separated into three groups: supervised, semi-\nsupervised and unsupervised techniques.\n\nThe supervised techniques are the machine learning classifiers. They are more accu-\nrate, however, need to be trained on a relevant domain. The unsupervised statistical \ntechniques do not require training. They are efficient in dynamic environment but at the \ncost of accuracy. Sentiment analysis techniques analyze opinion datasets to generate a \ngeneral perception that people have about a product. The classification of sentiments in \na review document is performed through identifying and separating all the positive and \nnegative opinion words. Considering the strength of these words, along with their polar-\nity, helps in multi-class classification. Machine learning classifiers such as Naive-Bayes, \nk-nearest neighbor and centroid based classifier etc., are successfully used for this pur-\npose. Semantic orientation based techniques used for opinion mining are Lexicon based \nand statistical analysis. Lexicon based technique works with individual words while sta-\ntistical analysis incorporates words co-occurrence using point wise mutual information \n(PMI) and latent semantic analysis (LSA). Semi-supervised techniques start with a small \n\n\n\nPage 5 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nset of opinion words from the given domain, and expand on it. More opinion words are \nexplored by querying the starting seeds. The newly found words are queried again to find \nmore words until no new words are returned. Orientation of the opinion word form the \nbasis for classification. Other attributes used are frequency of occurrence, location and \nco-occurrence with other words. The taxonomy of these approaches is shown in Fig. 1.\n\nSentiment classification\n\nThese are the machine learning classifiers used for sentiment analysis. They can be \napplied to text documents at three levels for analysis. A document level approach, \nwhich studies the whole document as a single entity is appropriate for text categoriza-\ntion. However, document level approach is not viable for sentiment analysis with docu-\nments having multiple opinions. Therefore, sentiment analysis is performed extensively \nat sentence or word level. Word level analysis is also known as sentiment level analysis. \nML techniques suits sentiment analysis as the data is in abundance and there is obvious \npresence of patterns (Schouten and Frasincar 2015). The classifiers are trained on label \ndataset having samples representing all classes. A test dataset is used to evaluate the per-\nformance of the classifiers for the given task. Let the set of documents as {D = d1,…,dn}, \nand set of classes labeled as {C = c1,…,cn}, then the task is to classify document di in D \nwith a label ci in C. This task can be performed using supervised classifiers. The more \nfrequently used classifiers for sentiment analysis are discussed below.\n\nNaïve Bayes\n\nNaive Bayes (NB) classifier is extensively used for text classification. It learns from a \ntraining dataset of annotated feature vectors, with labels as positive and negative (in case \nof binary classification). The probability of a feature vector is calculated with each label \nusing the annotated training dataset. The feature vector is assigned a label that has high-\nest probability for it. If this information is preserved, it can be used to show confidence \nin a label for a feature vector. In further modifications of NB a fuzzy region is defined \nin which feature vectors hold both labels with a certain level of confidence. Text data \nnormally have high dimensional feature vectors. Therefore, the process of calculating \nprobability is repeated for each feature vector, and then all the probabilities contribute \ntowards the final decision. The feature set is represented as F = f1, f2…fm}, where prob-\nability of a document belonging to a class shown as:\n\nFig. 1 Taxonomy of expository literature on sentiment analysis\n\n Sentiment Analysis Supervised Classifiers Unsupervised Semantic Orientation Techniques Naive Bayes K Nearest Neighbor Centroid Based Support Vector Using Lexicons Statistical Analysis Machine Liu B. [1] Baoli et al. [19] Hidayet et al. [29] Thorsten J. [29] Kamps et al. [54] Vinodhini et al. [7] Pang et al. [2] Yang et al. [20] Tan, S. [30] Istvan, P. [42] Zhai et al. [12] Liu, B. [1] Dai et al. [18] Shin et al. [21] Guan et al. [33] Basu et al. [59] Vinodhini et al. [7] Ding et al. [6] Sreemathy et al. [22] Soucy et al. [23] Hu et al. [36] Liu, B. [1] Liu, B. [1] Kamps et al. [54] \n\n\n\nPage 6 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nShows the probability of a document dj represented by its vector dj* belonging to a class \nci. It is the product of probabilities for all the features in the feature set. The document \nvector dj\n\n* is assigned to a class ci in order to maximize P\n(\n\nci\n\n∣\n\n∣\n\n∣\nd∗j\n\n)\n\n. The logarithm of prob-\nabilities are summed up to classify an opinion document. It is preferred over product of \nprobabilities to avoid underflow. It addresses the missing value problem as well. Slack \nvariables add smoothing effect against noisy data. Weights can also be assigned to fea-\ntures which define their contribution towards the classification. It is a biased approach, \nwhere prominent features are given high weights to play a major role in choose a senti-\nment label.\n\nNaive Bayes works on the assumption that all the sentences of a review document are \nopinion sentences. It also assumes that features of a document are independent of each \nother. Despite of this unrealistic assumption, Naïve Bayes is very successful and is used \nin various practical applications. The assumption of treating features as independent of \neach other makes Naive Bayes highly efficient (Dai et al. 2007). Although, Naive Bayes \nclassifier is simple, yet it is effective because of its robustness to irrelevant features. It \nperforms well in domains with many equally important features. It is considered to be \nmore reliable for text classification and sentiment analysis. The accuracy of the classifier \nimproves with pre-processing noise. It also used as transfer learning when trained on a \ndataset similar to the target dataset.\n\nNearest neighbor\n\nk-nearest neighbor classifier has been frequently used in literature for text classifica-\ntion. It considers the labels of k nearest neighbors to classify a test document. A special \ncase of the k-NN problem is typically referred to as classimbalance problem identified \nin (Yang and Liu 1999). Classes with more training data have higher influence to predict \nsame label for the new document. There are fewer chances of acquiring a class label if \nthat class has fewer training examples. (Li et al. 2003) catered this problem by using vari-\nable value of k for each class. Thus, the class having more training data will have higher \nvalue of k as compared to the one having few samples. This solution is helpful in online \nclassification, where there is time constraint on trying different values of k.\n\nA study on performance of k-NN using pre-processed dataset is conducted in (Shin \net al. 2006) claiming 10 % improvement when noise and outliers are filtered out. An opti-\nmum value is chosen as threshold to separate regular data from noise. Sentiment analy-\nsis is performed with a reduced set of feature vector in (Sreemathy and Balamurugan \n2012) to avoid the curse of dimensionality. Accuracy of the model improves as irrelevant \nfeatures were removed. Features are assigned weights to vary their contribution towards \ndecision making. Weights are extracted from probability of information in documents \nacross different categories. Tree-fast k-NN is introduced as fast kNN model (Soucy and \nMineau 2001). This tree based indexing of retrieval system improves the accuracy of \nk-NN in distance calculation. Its effective against large feature sets. The order of features \nand their thresholds are identified from within the training data. k-NN has promising \n\n(1)P(ci\n∣\n\n∣dj\n∗\n) =\n\np(ci)(\n∏m\n\ni=1 p(fi|ci) )\n\np(d∗j )\n\n\n\nPage 7 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nresults in sentiment analysis; however, it is more susceptible to noise and high dimen-\nsional feature set. Therefore, more of the work in k-NN for text classification has focused \non feature selection and reduction techniques as they are the driving factors of k-NN’s \nperformance.\n\nCentroid based\n\nCentroid based (CB) classifier calculates centroid vector or prototype vector for each \nclass in the training dataset. Centroid vector is the central point of the class and may not \nrepresent an actual training data. The distance of each test document is calculated with \nthe prototype vector of the class and is classified based on similarity with it. Its perfor-\nmance depends on the chosen centroid vectors. It is efficient since time and space com-\nplexities are proportional to the number of classes rather than training documents. To \ndouble the training data reverse of reviews are generated in (Xia et al. 2015) by invert-\ning the sentiment terms and their labels. Using both sets of training data with Mutual \nInformation (MI) the results were improved when only selected reviews were inverted. \nExternal dictionary WordNet is used to generate inverse for sentiment terms, however, \npseudo-antonyms can be generated internally using the corpus.\n\nms, however, pseudo-antonyms can be generated internally using the corpus. A variety \nof approaches have been used for CB classifier. Rocchio algorithm calculates centroid \nto represent feature space of documents (Ana and Arlindo 2007; Tan 2007a, b). Cen-\ntroid is computed through average of positive examples in (Han and Karypis 2000) and \nsum of positive cases i.e. the related training examples (Chuang et al. 2000). Normalized \nsum of positive vectors used in (Lertnattee and Theeramunkong2004), cosine similar-\nity between the test document and the Centroid of a class (Hidayet and Tunga 2012). \nCentroid is used with inverse of class similarity as well improving the accuracy close to \n100 % on the given dataset when characters are chosen as features instead of n-grams.\n\nCentroid evaluation is sensitive to noise in the training dataset which affects the over-\nall performance of the classifier. This shortfall is exposed when Centroid classifier is \napplied to a slightly different domain. The reason for this drawback is that some opinion \nwords are domain dependent. They have different polarity or strength of polarity when \nused in a different domain. Smoothing techniques have being proposed in (Tan 2007a, b;  \nLertnattee and Theeramunkong 2006; Guan 2009) that minimizes the effect of noise \nin the dataset. (Chizi et al. 2009) defined a weighting scheme giving higher weights to \nexplicit opinion words. Characters and special characters for feature selection are used \nin (Ozgur and Gungor 2009). The work in (Shankar and Karypis 2000; Tan et al. 2005) \nis focused on adjusting the value of centroid based with feedback looping, hypothesis \nmargin and weight-adjustment respectively. They try to rectify class Centroid, if it is not \ncalculated accurately. Centroid based classifier performs efficiently as it doesn’t consider \ntraining data each time to decide a test document.\n\nSupport vector machine\n\nSupport vector machine classifier is used for text classification in various studies. It finds \na separation among the data using the annotated training dataset. The margin of sep-\naration between classes, which is known as hyperplane, is used to classify the incom-\ning data. The hyperplane should give maximum separation between the classes. It is \n\n\n\nPage 8 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\napplicable even in the presence of high dimensional feature set representation. It classify \nbased o hyperplane among classes. Like centroid-based, SVM also consider the hyper-\nplane to classify a test document. (Brown et  al. 1997) has compared SVM with artifi-\ncial neural networks for text classification and has found it better. Since it has promising \nresults in text classification, it also performs well for opinion mining. They have also \nclaimed in (Brown et al. 1997) that SVM is better than Naive Bayes and decision trees \nclassification algorithms. However, SVM consumes more resources at the training \nstage. Although, it is efficient with large feature set, Feldman et al.(2011) has shown that \ndimensionality reduction in feature set further improves the performance of SVM. It \nexhibits linear complexity and can scale up to a large dataset.\n\nSVM has a limitation of over-reliance on selection of suitable kernel function. Kernel \nis calculated through Linear, Polynomial, Gaussian or sigmoid methods but they tend to \nbe domain specific. Kernel functions that perform well for one domain may not repeat it \nfor next. Its accuracy is also sensitive to number of training samples close to hyperplane. \nSlack variables are introduced to limit the impact of boundary samples by generalizing \nthe classifier, known as soft margin classification. They also help to avoid over-fitting the \ntraining data.\n\nUnsupervised techniques\n\nThe unsupervised sentiment analysis techniques do not require training data and rather \nrely on semantic orientation. They make use of lexicons to identify the positive or neg-\native semantics of opinion words. The meaning of the word, expressed by its use in a \ncontext is called lexicon. An online or off-line dictionary is consulted for this purpose. \nStatistical analysis techniques are also unsupervised, identifying the orientation of senti-\nment words through statistical evaluations. They require large volume of data for high \naccuracy.\n\nLanguages consists of lexicons that are the words used for a particular sense, and a \ngrammar that connect these lexicons. Part-of-speech rules are used to extract senti-\nment phrases from text document. Search engines are used to identify the orientation \nof sentiment words that are missing in the dictionary. Its polarity is identified through \nthe nearby words brought by search engines. They purely rely on external sources and \ntherefore cannot address the context. Lexicon based techniques perform well for general \ndomains while statistical techniques addresses the context and are useful in specialized \ndomains. The two types of approaches are discussed in detail.\n\nDictionary (Lexicon) based techniques\n\nLexicon based techniques extract opinion lexicons from the document and analyzes \nits orientation without the support of any training data. These techniques process the \nopinion words separately, ignoring the relationship between them. Lexicons refer to the \nsemantic orientation. Lexicons are independent of the source data and therefore it does \nnot fall for over-fitting. But context not addressed either in this approach (Katz et  al. \n2015; Cambria 2013). Search engines are used to find the meaning of unknown opinion \nlexicons. They are searched and the top N results are accepted to identify its orientation. \nThe semantics of lexicons can be categorized as positive or negative with weights rep-\nresenting their strength. This approach struggles with lexicons having domain specific \n\n\n\nPage 9 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\npolarity. For example, good has positive polarity in any type of domain but “heavy \nweight” has positive polarity for bike domain but negative for the domain of electronic \ndevices.\n\nIn its simplest form, sentiment words are split into positive and negative as binary \ndistribution. A more sophisticated approach has fuzzy lexicons, introducing a grey area \nbetween the two categories. These fuzzy lexicons exist in both the classes with a score \nassociated to it, representing the strength of each label. Various manual and semi-auto-\nmatic techniques can be used for building lexicons. Princeton University’s WordNet is \na popular lexicon source available for sentiment analysis. Dictionaries like WordNet, \nextracts synonyms and antonyms for the provided opinion words. Manual cleansing is \nemployed to rectify the lists generated for the unknown sentiment words. These opinion \nwords are used to classify a review as positive or negative.\n\nFixed syntactic patterns are also used for expressing opinions which are composed of \npart-of-speech (POS) tags. The basic idea of this technique is to identify the patterns in \nwhich words co-occur with each other and to exploit those patterns for understanding \nits semantic orientation. One example of such pattern is an adverb followed by an adjec-\ntive. A more sophisticated approach was proposed by (Mohammad and Yang 2011), \nwhich used a WordNet distance based method to determine the sentiment orientation. \nThe distance d(t1, t2) between terms t1 and t2 is the length of the shortest path that con-\nnects them in WordNet, as shown in Eq. 2. The semantic orientation (SO) of an adjective \nterm t is determined by its relative distance from two reference (or seed) terms good and \nbad. The polarity of opinion term t is resolved through eq.\n\nStatistics (Corpus) based techniques\n\nStatistical analysis of large corpus of text can also be used to determine the sentiment \norientation of words. Co-occurrence of words is evaluated without consulting any exter-\nnal support. Two methods are used for this purpose which are point wise mutual infor-\nmation (PMI) and latent semantic analysis (LSA). PMI method for co-occurrence is \ngiven as:\n\nwhere w1 and w2 refers to two words in a given sentence. The main concept behind PMI \nbased techniques is that the semantic orientation of a word has a tendency of being \nclosely related to that of its neighbors. Equation 3 gives the probability of words w1 and \nw2 to co-exist, based on the measure of degree of statistical dependence between the \ntwo. This approach is, however, implemented differently in LSA based techniques. In \nLSA, matrix factorization technique is used with singular value decomposition to dem-\nonstrate the statistical co-occurrence of words. More formally, this process can be speci-\nfied as:\n\n(2)SO(t) =\nd(t, bad)− d(t, good)\n\nd(bad, good)\n\n(3)p(w1,w2) =\np(w1,w2)\n\np(w1) p(w2)\n\n(4)LSA(w) = LSA(w, {+paradigms})− LSA(w, {−paradigms})\n\n\n\nPage 10 of 19Khan et al. Complex Adapt Syst Model  (2016) 4:2 \n\nwhere a word w is passed to LSA with positive and negative paradigms. LSA based tech-\nniques develop a matrix having rows as words and columns as sentences or paragraphs. \nEach cell possesses a weight corresponding to the relation of the word in row with the \nsentence or paragraph in columns. This matrix is decomposed into three matrices using \nsingular value decomposition (SVD).\n\nComplex challenges\n\nOpinion mining is a relatively new area of research and there are open challenges that \nneed to be answered. Some of the challenges are common to opinion mining in general \nwhile others are related to their own sources and context depending upon the domain of \nthe dataset. These issues affect the performance of machine learning techniques, but it \nhas little control on them. Figure 2 gives NLP challenges faced in sentiment analysis, dis-\ntributing them into their logical groups. The groupings are based on the parsing level, at \nwhich these issues occur. The following sub section has detailed discussion on the NLP \nissues.\n\nDocument level\n\nDocument level NLP challenges are the ones that are faced at the document or review \nlevel. They deal in general with the review document or the reviewer style. It is common \nto find reviews that have the information about an object, given in an informal manner. \nCapitalization is over or under used. Spelling mistakes are ignored or words being short-\nened. It makes the analysis very difficult for the automatic techniques to identify features \nand associate them. The unknown words (shortened/miss spelled) are matched with \nsimilar words to identify the aspect or opinion words. Slang specific to a certain region \nare also occasionally used in reviews and discussions. Reviews having sarcastic expres-\nsions are the hardest to deal with. Even though they have the opinion words explicitly ",
      "text": [
        "",
        "Sentiment Analysis Supervised Classifiers Unsupervised Semantic Orientation Techniques Naive Bayes K Nearest Neighbor Centroid Based Support Vector Using Lexicons Statistical Analysis Machine Liu B. [1] Baoli et al. [19] Hidayet et al. [29] Thorsten J. [29] Kamps et al. [54] Vinodhini et al. [7] Pang et al. [2] Yang et al. [20] Tan, S. [30] Istvan, P. [42] Zhai et al. [12] Liu, B. [1] Dai et al. [18] Shin et al. [21] Guan et al. [33] Basu et al. [59] Vinodhini et al. [7] Ding et al. [6] Sreemathy et al. [22] Soucy et al. [23] Hu et al. [36] Liu, B. [1] Liu, B. [1] Kamps et al. [54]",
        "· Discussions · Domain dependent opinions Document · Way of expression Level · Informal nature of content · Opinion spamming · Conditional sentences · Comparative sentences · sharing opinion word Sentence · Determining subjective sentences Level · Identifying Opinion source and target · Negation · Grouping feature synonyms · Aspect-based mining Feature · Stemming features level · Pruning large feature set * Opinion word orientation · Sarcastic terms · Object-attribute co-reference Lexicon · Linguistic rules level · Dual meaning words . Lack of opinion lexicons available",
        "Published online: 03 February 2016"
      ],
      "layoutText": [
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"Sentiment Analysis Supervised Classifiers Unsupervised Semantic Orientation Techniques Naive Bayes K Nearest Neighbor Centroid Based Support Vector Using Lexicons Statistical Analysis Machine Liu B. [1] Baoli et al. [19] Hidayet et al. [29] Thorsten J. [29] Kamps et al. [54] Vinodhini et al. [7] Pang et al. [2] Yang et al. [20] Tan, S. [30] Istvan, P. [42] Zhai et al. [12] Liu, B. [1] Dai et al. [18] Shin et al. [21] Guan et al. [33] Basu et al. [59] Vinodhini et al. [7] Ding et al. [6] Sreemathy et al. [22] Soucy et al. [23] Hu et al. [36] Liu, B. [1] Liu, B. [1] Kamps et al. [54]\",\"lines\":[{\"boundingBox\":[{\"x\":859,\"y\":32},{\"x\":1107,\"y\":32},{\"x\":1107,\"y\":63},{\"x\":859,\"y\":63}],\"text\":\"Sentiment Analysis\"},{\"boundingBox\":[{\"x\":399,\"y\":215},{\"x\":683,\"y\":212},{\"x\":683,\"y\":243},{\"x\":399,\"y\":245}],\"text\":\"Supervised Classifiers\"},{\"boundingBox\":[{\"x\":1183,\"y\":214},{\"x\":1647,\"y\":213},{\"x\":1648,\"y\":243},{\"x\":1183,\"y\":244}],\"text\":\"Unsupervised Semantic Orientation\"},{\"boundingBox\":[{\"x\":1353,\"y\":252},{\"x\":1502,\"y\":253},{\"x\":1502,\"y\":283},{\"x\":1353,\"y\":281}],\"text\":\"Techniques\"},{\"boundingBox\":[{\"x\":30,\"y\":429},{\"x\":188,\"y\":431},{\"x\":188,\"y\":461},{\"x\":29,\"y\":459}],\"text\":\"Naive Bayes\"},{\"boundingBox\":[{\"x\":331,\"y\":428},{\"x\":586,\"y\":429},{\"x\":586,\"y\":459},{\"x\":331,\"y\":458}],\"text\":\"K Nearest Neighbor\"},{\"boundingBox\":[{\"x\":697,\"y\":427},{\"x\":895,\"y\":426},{\"x\":895,\"y\":456},{\"x\":697,\"y\":458}],\"text\":\"Centroid Based\"},{\"boundingBox\":[{\"x\":1007,\"y\":424},{\"x\":1210,\"y\":424},{\"x\":1210,\"y\":454},{\"x\":1007,\"y\":455}],\"text\":\"Support Vector\"},{\"boundingBox\":[{\"x\":1340,\"y\":423},{\"x\":1534,\"y\":423},{\"x\":1534,\"y\":455},{\"x\":1340,\"y\":454}],\"text\":\"Using Lexicons\"},{\"boundingBox\":[{\"x\":1699,\"y\":421},{\"x\":1939,\"y\":422},{\"x\":1939,\"y\":453},{\"x\":1699,\"y\":451}],\"text\":\"Statistical Analysis\"},{\"boundingBox\":[{\"x\":1009,\"y\":462},{\"x\":1121,\"y\":463},{\"x\":1120,\"y\":490},{\"x\":1008,\"y\":490}],\"text\":\"Machine\"},{\"boundingBox\":[{\"x\":16,\"y\":570},{\"x\":135,\"y\":571},{\"x\":135,\"y\":603},{\"x\":15,\"y\":600}],\"text\":\"Liu B. [1]\"},{\"boundingBox\":[{\"x\":365,\"y\":579},{\"x\":564,\"y\":579},{\"x\":564,\"y\":609},{\"x\":365,\"y\":608}],\"text\":\"Baoli et al. [19]\"},{\"boundingBox\":[{\"x\":710,\"y\":578},{\"x\":945,\"y\":578},{\"x\":945,\"y\":611},{\"x\":710,\"y\":610}],\"text\":\"Hidayet et al. [29]\"},{\"boundingBox\":[{\"x\":1044,\"y\":580},{\"x\":1254,\"y\":581},{\"x\":1253,\"y\":613},{\"x\":1044,\"y\":609}],\"text\":\"Thorsten J. [29]\"},{\"boundingBox\":[{\"x\":1375,\"y\":583},{\"x\":1595,\"y\":583},{\"x\":1595,\"y\":613},{\"x\":1375,\"y\":613}],\"text\":\"Kamps et al. [54]\"},{\"boundingBox\":[{\"x\":1727,\"y\":582},{\"x\":1968,\"y\":582},{\"x\":1968,\"y\":615},{\"x\":1727,\"y\":612}],\"text\":\"Vinodhini et al. [7]\"},{\"boundingBox\":[{\"x\":19,\"y\":609},{\"x\":196,\"y\":609},{\"x\":196,\"y\":641},{\"x\":19,\"y\":640}],\"text\":\"Pang et al. [2]\"},{\"boundingBox\":[{\"x\":364,\"y\":618},{\"x\":563,\"y\":619},{\"x\":562,\"y\":650},{\"x\":364,\"y\":648}],\"text\":\"Yang et al. [20]\"},{\"boundingBox\":[{\"x\":711,\"y\":617},{\"x\":863,\"y\":618},{\"x\":863,\"y\":650},{\"x\":710,\"y\":648}],\"text\":\"Tan, S. [30]\"},{\"boundingBox\":[{\"x\":1049,\"y\":620},{\"x\":1232,\"y\":620},{\"x\":1232,\"y\":650},{\"x\":1049,\"y\":651}],\"text\":\"Istvan, P. [42]\"},{\"boundingBox\":[{\"x\":1373,\"y\":620},{\"x\":1561,\"y\":621},{\"x\":1561,\"y\":652},{\"x\":1372,\"y\":651}],\"text\":\"Zhai et al. [12]\"},{\"boundingBox\":[{\"x\":1730,\"y\":621},{\"x\":1854,\"y\":621},{\"x\":1854,\"y\":654},{\"x\":1730,\"y\":653}],\"text\":\"Liu, B. [1]\"},{\"boundingBox\":[{\"x\":17,\"y\":648},{\"x\":187,\"y\":648},{\"x\":187,\"y\":679},{\"x\":17,\"y\":679}],\"text\":\"Dai et al. [18]\"},{\"boundingBox\":[{\"x\":364,\"y\":657},{\"x\":554,\"y\":657},{\"x\":554,\"y\":690},{\"x\":364,\"y\":688}],\"text\":\"Shin et al. [21]\"},{\"boundingBox\":[{\"x\":712,\"y\":656},{\"x\":919,\"y\":656},{\"x\":919,\"y\":690},{\"x\":712,\"y\":689}],\"text\":\"Guan et al. [33]\"},{\"boundingBox\":[{\"x\":1047,\"y\":658},{\"x\":1242,\"y\":659},{\"x\":1242,\"y\":690},{\"x\":1046,\"y\":688}],\"text\":\"Basu et al. [59]\"},{\"boundingBox\":[{\"x\":1377,\"y\":658},{\"x\":1615,\"y\":660},{\"x\":1615,\"y\":691},{\"x\":1376,\"y\":690}],\"text\":\"Vinodhini et al. [7]\"},{\"boundingBox\":[{\"x\":1730,\"y\":659},{\"x\":1905,\"y\":661},{\"x\":1905,\"y\":693},{\"x\":1730,\"y\":691}],\"text\":\"Ding et al. [6]\"},{\"boundingBox\":[{\"x\":15,\"y\":688},{\"x\":290,\"y\":688},{\"x\":290,\"y\":720},{\"x\":15,\"y\":719}],\"text\":\"Sreemathy et al. [22]\"},{\"boundingBox\":[{\"x\":364,\"y\":695},{\"x\":581,\"y\":696},{\"x\":580,\"y\":728},{\"x\":364,\"y\":727}],\"text\":\"Soucy et al. [23]\"},{\"boundingBox\":[{\"x\":713,\"y\":695},{\"x\":881,\"y\":695},{\"x\":880,\"y\":729},{\"x\":712,\"y\":727}],\"text\":\"Hu et al. [36]\"},{\"boundingBox\":[{\"x\":1049,\"y\":698},{\"x\":1170,\"y\":698},{\"x\":1170,\"y\":729},{\"x\":1049,\"y\":728}],\"text\":\"Liu, B. [1]\"},{\"boundingBox\":[{\"x\":1373,\"y\":699},{\"x\":1499,\"y\":699},{\"x\":1498,\"y\":731},{\"x\":1373,\"y\":731}],\"text\":\"Liu, B. [1]\"},{\"boundingBox\":[{\"x\":1729,\"y\":698},{\"x\":1949,\"y\":698},{\"x\":1949,\"y\":732},{\"x\":1729,\"y\":732}],\"text\":\"Kamps et al. [54]\"}],\"words\":[{\"boundingBox\":[{\"x\":861,\"y\":33},{\"x\":989,\"y\":33},{\"x\":989,\"y\":63},{\"x\":859,\"y\":63}],\"text\":\"Sentiment\"},{\"boundingBox\":[{\"x\":995,\"y\":33},{\"x\":1107,\"y\":34},{\"x\":1107,\"y\":64},{\"x\":995,\"y\":63}],\"text\":\"Analysis\"},{\"boundingBox\":[{\"x\":401,\"y\":215},{\"x\":542,\"y\":215},{\"x\":542,\"y\":244},{\"x\":400,\"y\":246}],\"text\":\"Supervised\"},{\"boundingBox\":[{\"x\":548,\"y\":214},{\"x\":681,\"y\":213},{\"x\":682,\"y\":244},{\"x\":548,\"y\":244}],\"text\":\"Classifiers\"},{\"boundingBox\":[{\"x\":1184,\"y\":216},{\"x\":1361,\"y\":214},{\"x\":1361,\"y\":244},{\"x\":1184,\"y\":244}],\"text\":\"Unsupervised\"},{\"boundingBox\":[{\"x\":1368,\"y\":214},{\"x\":1487,\"y\":213},{\"x\":1487,\"y\":244},{\"x\":1368,\"y\":244}],\"text\":\"Semantic\"},{\"boundingBox\":[{\"x\":1493,\"y\":213},{\"x\":1642,\"y\":214},{\"x\":1642,\"y\":244},{\"x\":1493,\"y\":244}],\"text\":\"Orientation\"},{\"boundingBox\":[{\"x\":1353,\"y\":253},{\"x\":1500,\"y\":253},{\"x\":1500,\"y\":283},{\"x\":1353,\"y\":281}],\"text\":\"Techniques\"},{\"boundingBox\":[{\"x\":31,\"y\":429},{\"x\":100,\"y\":431},{\"x\":100,\"y\":461},{\"x\":30,\"y\":459}],\"text\":\"Naive\"},{\"boundingBox\":[{\"x\":106,\"y\":431},{\"x\":185,\"y\":431},{\"x\":187,\"y\":462},{\"x\":106,\"y\":461}],\"text\":\"Bayes\"},{\"boundingBox\":[{\"x\":332,\"y\":429},{\"x\":344,\"y\":429},{\"x\":343,\"y\":459},{\"x\":332,\"y\":458}],\"text\":\"K\"},{\"boundingBox\":[{\"x\":350,\"y\":429},{\"x\":453,\"y\":429},{\"x\":452,\"y\":460},{\"x\":349,\"y\":459}],\"text\":\"Nearest\"},{\"boundingBox\":[{\"x\":459,\"y\":429},{\"x\":585,\"y\":429},{\"x\":585,\"y\":460},{\"x\":458,\"y\":460}],\"text\":\"Neighbor\"},{\"boundingBox\":[{\"x\":698,\"y\":428},{\"x\":807,\"y\":427},{\"x\":807,\"y\":458},{\"x\":698,\"y\":457}],\"text\":\"Centroid\"},{\"boundingBox\":[{\"x\":814,\"y\":427},{\"x\":894,\"y\":426},{\"x\":895,\"y\":456},{\"x\":814,\"y\":458}],\"text\":\"Based\"},{\"boundingBox\":[{\"x\":1007,\"y\":425},{\"x\":1113,\"y\":424},{\"x\":1113,\"y\":455},{\"x\":1007,\"y\":456}],\"text\":\"Support\"},{\"boundingBox\":[{\"x\":1119,\"y\":424},{\"x\":1210,\"y\":425},{\"x\":1210,\"y\":455},{\"x\":1119,\"y\":455}],\"text\":\"Vector\"},{\"boundingBox\":[{\"x\":1340,\"y\":423},{\"x\":1413,\"y\":424},{\"x\":1413,\"y\":456},{\"x\":1340,\"y\":455}],\"text\":\"Using\"},{\"boundingBox\":[{\"x\":1419,\"y\":424},{\"x\":1534,\"y\":425},{\"x\":1533,\"y\":455},{\"x\":1419,\"y\":456}],\"text\":\"Lexicons\"},{\"boundingBox\":[{\"x\":1700,\"y\":422},{\"x\":1822,\"y\":422},{\"x\":1821,\"y\":453},{\"x\":1699,\"y\":451}],\"text\":\"Statistical\"},{\"boundingBox\":[{\"x\":1828,\"y\":422},{\"x\":1939,\"y\":423},{\"x\":1939,\"y\":453},{\"x\":1828,\"y\":453}],\"text\":\"Analysis\"},{\"boundingBox\":[{\"x\":1010,\"y\":463},{\"x\":1119,\"y\":464},{\"x\":1119,\"y\":491},{\"x\":1009,\"y\":490}],\"text\":\"Machine\"},{\"boundingBox\":[{\"x\":18,\"y\":571},{\"x\":53,\"y\":571},{\"x\":51,\"y\":601},{\"x\":16,\"y\":599}],\"text\":\"Liu\"},{\"boundingBox\":[{\"x\":59,\"y\":572},{\"x\":85,\"y\":572},{\"x\":84,\"y\":602},{\"x\":57,\"y\":601}],\"text\":\"B.\"},{\"boundingBox\":[{\"x\":91,\"y\":572},{\"x\":135,\"y\":572},{\"x\":134,\"y\":604},{\"x\":90,\"y\":603}],\"text\":\"[1]\"},{\"boundingBox\":[{\"x\":366,\"y\":580},{\"x\":428,\"y\":580},{\"x\":428,\"y\":608},{\"x\":365,\"y\":608}],\"text\":\"Baoli\"},{\"boundingBox\":[{\"x\":434,\"y\":580},{\"x\":462,\"y\":580},{\"x\":462,\"y\":609},{\"x\":433,\"y\":608}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":468,\"y\":580},{\"x\":498,\"y\":580},{\"x\":498,\"y\":609},{\"x\":467,\"y\":609}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":504,\"y\":580},{\"x\":563,\"y\":580},{\"x\":563,\"y\":610},{\"x\":503,\"y\":609}],\"text\":\"[19]\"},{\"boundingBox\":[{\"x\":711,\"y\":579},{\"x\":811,\"y\":579},{\"x\":810,\"y\":611},{\"x\":710,\"y\":609}],\"text\":\"Hidayet\"},{\"boundingBox\":[{\"x\":817,\"y\":579},{\"x\":843,\"y\":579},{\"x\":842,\"y\":611},{\"x\":817,\"y\":611}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":849,\"y\":579},{\"x\":880,\"y\":579},{\"x\":880,\"y\":612},{\"x\":848,\"y\":611}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":887,\"y\":579},{\"x\":946,\"y\":578},{\"x\":945,\"y\":612},{\"x\":886,\"y\":612}],\"text\":\"[29]\"},{\"boundingBox\":[{\"x\":1046,\"y\":580},{\"x\":1162,\"y\":581},{\"x\":1162,\"y\":612},{\"x\":1046,\"y\":609}],\"text\":\"Thorsten\"},{\"boundingBox\":[{\"x\":1168,\"y\":581},{\"x\":1188,\"y\":581},{\"x\":1187,\"y\":613},{\"x\":1167,\"y\":612}],\"text\":\"J.\"},{\"boundingBox\":[{\"x\":1193,\"y\":581},{\"x\":1254,\"y\":581},{\"x\":1254,\"y\":614},{\"x\":1193,\"y\":613}],\"text\":\"[29]\"},{\"boundingBox\":[{\"x\":1376,\"y\":584},{\"x\":1462,\"y\":584},{\"x\":1462,\"y\":614},{\"x\":1376,\"y\":612}],\"text\":\"Kamps\"},{\"boundingBox\":[{\"x\":1468,\"y\":584},{\"x\":1495,\"y\":584},{\"x\":1494,\"y\":614},{\"x\":1467,\"y\":614}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":1501,\"y\":584},{\"x\":1533,\"y\":584},{\"x\":1533,\"y\":614},{\"x\":1500,\"y\":614}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":1539,\"y\":584},{\"x\":1596,\"y\":584},{\"x\":1594,\"y\":613},{\"x\":1538,\"y\":614}],\"text\":\"[54]\"},{\"boundingBox\":[{\"x\":1728,\"y\":583},{\"x\":1852,\"y\":582},{\"x\":1852,\"y\":614},{\"x\":1728,\"y\":611}],\"text\":\"Vinodhini\"},{\"boundingBox\":[{\"x\":1858,\"y\":582},{\"x\":1884,\"y\":582},{\"x\":1884,\"y\":614},{\"x\":1858,\"y\":614}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":1891,\"y\":582},{\"x\":1921,\"y\":582},{\"x\":1921,\"y\":615},{\"x\":1890,\"y\":614}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":1927,\"y\":582},{\"x\":1968,\"y\":583},{\"x\":1968,\"y\":616},{\"x\":1927,\"y\":615}],\"text\":\"[7]\"},{\"boundingBox\":[{\"x\":21,\"y\":610},{\"x\":79,\"y\":610},{\"x\":78,\"y\":641},{\"x\":19,\"y\":639}],\"text\":\"Pang\"},{\"boundingBox\":[{\"x\":85,\"y\":611},{\"x\":114,\"y\":611},{\"x\":113,\"y\":642},{\"x\":84,\"y\":641}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":120,\"y\":610},{\"x\":151,\"y\":610},{\"x\":149,\"y\":642},{\"x\":119,\"y\":642}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":157,\"y\":610},{\"x\":196,\"y\":609},{\"x\":195,\"y\":642},{\"x\":155,\"y\":642}],\"text\":\"[2]\"},{\"boundingBox\":[{\"x\":365,\"y\":618},{\"x\":428,\"y\":619},{\"x\":427,\"y\":650},{\"x\":364,\"y\":649}],\"text\":\"Yang\"},{\"boundingBox\":[{\"x\":434,\"y\":619},{\"x\":460,\"y\":619},{\"x\":460,\"y\":650},{\"x\":433,\"y\":650}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":466,\"y\":619},{\"x\":499,\"y\":619},{\"x\":499,\"y\":651},{\"x\":466,\"y\":650}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":505,\"y\":619},{\"x\":563,\"y\":619},{\"x\":562,\"y\":651},{\"x\":505,\"y\":651}],\"text\":\"[20]\"},{\"boundingBox\":[{\"x\":711,\"y\":618},{\"x\":765,\"y\":618},{\"x\":765,\"y\":649},{\"x\":711,\"y\":649}],\"text\":\"Tan,\"},{\"boundingBox\":[{\"x\":771,\"y\":618},{\"x\":796,\"y\":618},{\"x\":796,\"y\":650},{\"x\":771,\"y\":650}],\"text\":\"S.\"},{\"boundingBox\":[{\"x\":802,\"y\":618},{\"x\":862,\"y\":619},{\"x\":863,\"y\":651},{\"x\":802,\"y\":650}],\"text\":\"[30]\"},{\"boundingBox\":[{\"x\":1050,\"y\":622},{\"x\":1137,\"y\":621},{\"x\":1136,\"y\":651},{\"x\":1049,\"y\":651}],\"text\":\"Istvan,\"},{\"boundingBox\":[{\"x\":1143,\"y\":621},{\"x\":1168,\"y\":621},{\"x\":1168,\"y\":651},{\"x\":1142,\"y\":651}],\"text\":\"P.\"},{\"boundingBox\":[{\"x\":1174,\"y\":621},{\"x\":1232,\"y\":621},{\"x\":1232,\"y\":651},{\"x\":1174,\"y\":651}],\"text\":\"[42]\"},{\"boundingBox\":[{\"x\":1375,\"y\":621},{\"x\":1428,\"y\":621},{\"x\":1427,\"y\":651},{\"x\":1373,\"y\":651}],\"text\":\"Zhai\"},{\"boundingBox\":[{\"x\":1434,\"y\":621},{\"x\":1460,\"y\":622},{\"x\":1459,\"y\":652},{\"x\":1433,\"y\":651}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":1466,\"y\":622},{\"x\":1498,\"y\":622},{\"x\":1497,\"y\":652},{\"x\":1465,\"y\":652}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":1504,\"y\":622},{\"x\":1560,\"y\":622},{\"x\":1560,\"y\":653},{\"x\":1503,\"y\":652}],\"text\":\"[12]\"},{\"boundingBox\":[{\"x\":1731,\"y\":622},{\"x\":1772,\"y\":622},{\"x\":1772,\"y\":653},{\"x\":1730,\"y\":653}],\"text\":\"Liu,\"},{\"boundingBox\":[{\"x\":1778,\"y\":622},{\"x\":1805,\"y\":622},{\"x\":1805,\"y\":654},{\"x\":1778,\"y\":653}],\"text\":\"B.\"},{\"boundingBox\":[{\"x\":1812,\"y\":622},{\"x\":1854,\"y\":622},{\"x\":1854,\"y\":655},{\"x\":1812,\"y\":654}],\"text\":\"[1]\"},{\"boundingBox\":[{\"x\":18,\"y\":648},{\"x\":57,\"y\":649},{\"x\":56,\"y\":679},{\"x\":17,\"y\":679}],\"text\":\"Dai\"},{\"boundingBox\":[{\"x\":63,\"y\":649},{\"x\":91,\"y\":649},{\"x\":90,\"y\":679},{\"x\":62,\"y\":679}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":97,\"y\":649},{\"x\":129,\"y\":649},{\"x\":128,\"y\":679},{\"x\":96,\"y\":679}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":135,\"y\":649},{\"x\":187,\"y\":648},{\"x\":186,\"y\":680},{\"x\":134,\"y\":679}],\"text\":\"[18]\"},{\"boundingBox\":[{\"x\":367,\"y\":657},{\"x\":423,\"y\":657},{\"x\":421,\"y\":687},{\"x\":365,\"y\":688}],\"text\":\"Shin\"},{\"boundingBox\":[{\"x\":429,\"y\":657},{\"x\":455,\"y\":657},{\"x\":454,\"y\":687},{\"x\":427,\"y\":687}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":461,\"y\":657},{\"x\":492,\"y\":657},{\"x\":490,\"y\":688},{\"x\":460,\"y\":688}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":498,\"y\":657},{\"x\":555,\"y\":658},{\"x\":554,\"y\":690},{\"x\":497,\"y\":688}],\"text\":\"[21]\"},{\"boundingBox\":[{\"x\":713,\"y\":658},{\"x\":780,\"y\":657},{\"x\":779,\"y\":688},{\"x\":712,\"y\":687}],\"text\":\"Guan\"},{\"boundingBox\":[{\"x\":786,\"y\":657},{\"x\":813,\"y\":657},{\"x\":812,\"y\":689},{\"x\":785,\"y\":688}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":819,\"y\":657},{\"x\":849,\"y\":657},{\"x\":847,\"y\":689},{\"x\":818,\"y\":689}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":855,\"y\":657},{\"x\":918,\"y\":657},{\"x\":917,\"y\":691},{\"x\":854,\"y\":689}],\"text\":\"[33]\"},{\"boundingBox\":[{\"x\":1048,\"y\":658},{\"x\":1109,\"y\":659},{\"x\":1108,\"y\":689},{\"x\":1047,\"y\":688}],\"text\":\"Basu\"},{\"boundingBox\":[{\"x\":1115,\"y\":659},{\"x\":1141,\"y\":659},{\"x\":1140,\"y\":690},{\"x\":1114,\"y\":689}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":1147,\"y\":659},{\"x\":1177,\"y\":659},{\"x\":1176,\"y\":690},{\"x\":1146,\"y\":690}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":1184,\"y\":659},{\"x\":1242,\"y\":659},{\"x\":1241,\"y\":691},{\"x\":1182,\"y\":690}],\"text\":\"[59]\"},{\"boundingBox\":[{\"x\":1377,\"y\":659},{\"x\":1497,\"y\":660},{\"x\":1496,\"y\":691},{\"x\":1377,\"y\":691}],\"text\":\"Vinodhini\"},{\"boundingBox\":[{\"x\":1503,\"y\":660},{\"x\":1530,\"y\":660},{\"x\":1529,\"y\":691},{\"x\":1502,\"y\":691}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":1536,\"y\":660},{\"x\":1567,\"y\":660},{\"x\":1566,\"y\":692},{\"x\":1535,\"y\":691}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":1573,\"y\":660},{\"x\":1615,\"y\":661},{\"x\":1614,\"y\":692},{\"x\":1572,\"y\":692}],\"text\":\"[7]\"},{\"boundingBox\":[{\"x\":1731,\"y\":659},{\"x\":1786,\"y\":660},{\"x\":1785,\"y\":692},{\"x\":1731,\"y\":691}],\"text\":\"Ding\"},{\"boundingBox\":[{\"x\":1792,\"y\":660},{\"x\":1820,\"y\":660},{\"x\":1819,\"y\":693},{\"x\":1791,\"y\":692}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":1826,\"y\":660},{\"x\":1856,\"y\":661},{\"x\":1854,\"y\":693},{\"x\":1825,\"y\":693}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":1862,\"y\":661},{\"x\":1905,\"y\":661},{\"x\":1903,\"y\":694},{\"x\":1861,\"y\":693}],\"text\":\"[6]\"},{\"boundingBox\":[{\"x\":16,\"y\":689},{\"x\":156,\"y\":688},{\"x\":156,\"y\":719},{\"x\":16,\"y\":719}],\"text\":\"Sreemathy\"},{\"boundingBox\":[{\"x\":162,\"y\":688},{\"x\":189,\"y\":688},{\"x\":189,\"y\":719},{\"x\":162,\"y\":719}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":195,\"y\":688},{\"x\":226,\"y\":688},{\"x\":225,\"y\":720},{\"x\":195,\"y\":719}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":232,\"y\":688},{\"x\":289,\"y\":688},{\"x\":289,\"y\":721},{\"x\":231,\"y\":720}],\"text\":\"[22]\"},{\"boundingBox\":[{\"x\":365,\"y\":695},{\"x\":442,\"y\":695},{\"x\":442,\"y\":727},{\"x\":365,\"y\":728}],\"text\":\"Soucy\"},{\"boundingBox\":[{\"x\":448,\"y\":695},{\"x\":476,\"y\":695},{\"x\":475,\"y\":727},{\"x\":448,\"y\":727}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":482,\"y\":696},{\"x\":513,\"y\":696},{\"x\":513,\"y\":728},{\"x\":482,\"y\":727}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":520,\"y\":696},{\"x\":581,\"y\":697},{\"x\":581,\"y\":729},{\"x\":519,\"y\":728}],\"text\":\"[23]\"},{\"boundingBox\":[{\"x\":714,\"y\":696},{\"x\":748,\"y\":696},{\"x\":747,\"y\":726},{\"x\":713,\"y\":727}],\"text\":\"Hu\"},{\"boundingBox\":[{\"x\":755,\"y\":696},{\"x\":781,\"y\":696},{\"x\":781,\"y\":726},{\"x\":754,\"y\":726}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":788,\"y\":696},{\"x\":819,\"y\":696},{\"x\":818,\"y\":727},{\"x\":787,\"y\":726}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":825,\"y\":696},{\"x\":881,\"y\":696},{\"x\":881,\"y\":730},{\"x\":825,\"y\":727}],\"text\":\"[36]\"},{\"boundingBox\":[{\"x\":1049,\"y\":699},{\"x\":1091,\"y\":698},{\"x\":1090,\"y\":728},{\"x\":1049,\"y\":728}],\"text\":\"Liu,\"},{\"boundingBox\":[{\"x\":1097,\"y\":698},{\"x\":1125,\"y\":698},{\"x\":1124,\"y\":729},{\"x\":1096,\"y\":729}],\"text\":\"B.\"},{\"boundingBox\":[{\"x\":1131,\"y\":698},{\"x\":1171,\"y\":699},{\"x\":1170,\"y\":730},{\"x\":1130,\"y\":729}],\"text\":\"[1]\"},{\"boundingBox\":[{\"x\":1375,\"y\":701},{\"x\":1420,\"y\":701},{\"x\":1420,\"y\":731},{\"x\":1374,\"y\":730}],\"text\":\"Liu,\"},{\"boundingBox\":[{\"x\":1426,\"y\":701},{\"x\":1453,\"y\":700},{\"x\":1452,\"y\":731},{\"x\":1426,\"y\":731}],\"text\":\"B.\"},{\"boundingBox\":[{\"x\":1459,\"y\":700},{\"x\":1499,\"y\":699},{\"x\":1499,\"y\":732},{\"x\":1458,\"y\":731}],\"text\":\"[1]\"},{\"boundingBox\":[{\"x\":1731,\"y\":699},{\"x\":1815,\"y\":699},{\"x\":1814,\"y\":733},{\"x\":1730,\"y\":732}],\"text\":\"Kamps\"},{\"boundingBox\":[{\"x\":1821,\"y\":699},{\"x\":1846,\"y\":699},{\"x\":1845,\"y\":733},{\"x\":1820,\"y\":733}],\"text\":\"et\"},{\"boundingBox\":[{\"x\":1852,\"y\":699},{\"x\":1884,\"y\":699},{\"x\":1883,\"y\":733},{\"x\":1851,\"y\":733}],\"text\":\"al.\"},{\"boundingBox\":[{\"x\":1890,\"y\":699},{\"x\":1949,\"y\":698},{\"x\":1948,\"y\":733},{\"x\":1889,\"y\":733}],\"text\":\"[54]\"}]}",
        "{\"language\":\"en\",\"text\":\"· Discussions · Domain dependent opinions Document · Way of expression Level · Informal nature of content · Opinion spamming · Conditional sentences · Comparative sentences · sharing opinion word Sentence · Determining subjective sentences Level · Identifying Opinion source and target · Negation · Grouping feature synonyms · Aspect-based mining Feature · Stemming features level · Pruning large feature set * Opinion word orientation · Sarcastic terms · Object-attribute co-reference Lexicon · Linguistic rules level · Dual meaning words . Lack of opinion lexicons available\",\"lines\":[{\"boundingBox\":[{\"x\":297,\"y\":18},{\"x\":543,\"y\":19},{\"x\":543,\"y\":57},{\"x\":297,\"y\":56}],\"text\":\"· Discussions\"},{\"boundingBox\":[{\"x\":297,\"y\":71},{\"x\":863,\"y\":72},{\"x\":863,\"y\":120},{\"x\":297,\"y\":118}],\"text\":\"· Domain dependent opinions\"},{\"boundingBox\":[{\"x\":15,\"y\":169},{\"x\":258,\"y\":169},{\"x\":258,\"y\":210},{\"x\":15,\"y\":210}],\"text\":\"Document\"},{\"boundingBox\":[{\"x\":297,\"y\":133},{\"x\":675,\"y\":134},{\"x\":675,\"y\":178},{\"x\":297,\"y\":178}],\"text\":\"· Way of expression\"},{\"boundingBox\":[{\"x\":73,\"y\":228},{\"x\":200,\"y\":228},{\"x\":200,\"y\":271},{\"x\":73,\"y\":271}],\"text\":\"Level\"},{\"boundingBox\":[{\"x\":299,\"y\":190},{\"x\":826,\"y\":190},{\"x\":826,\"y\":234},{\"x\":299,\"y\":233}],\"text\":\"· Informal nature of content\"},{\"boundingBox\":[{\"x\":299,\"y\":247},{\"x\":681,\"y\":248},{\"x\":681,\"y\":295},{\"x\":299,\"y\":293}],\"text\":\"· Opinion spamming\"},{\"boundingBox\":[{\"x\":299,\"y\":353},{\"x\":745,\"y\":353},{\"x\":745,\"y\":396},{\"x\":299,\"y\":394}],\"text\":\"· Conditional sentences\"},{\"boundingBox\":[{\"x\":297,\"y\":411},{\"x\":772,\"y\":411},{\"x\":772,\"y\":454},{\"x\":297,\"y\":454}],\"text\":\"· Comparative sentences\"},{\"boundingBox\":[{\"x\":298,\"y\":469},{\"x\":737,\"y\":468},{\"x\":737,\"y\":514},{\"x\":298,\"y\":515}],\"text\":\"· sharing opinion word\"},{\"boundingBox\":[{\"x\":28,\"y\":529},{\"x\":247,\"y\":530},{\"x\":247,\"y\":576},{\"x\":27,\"y\":574}],\"text\":\"Sentence\"},{\"boundingBox\":[{\"x\":297,\"y\":525},{\"x\":975,\"y\":526},{\"x\":975,\"y\":572},{\"x\":297,\"y\":570}],\"text\":\"· Determining subjective sentences\"},{\"boundingBox\":[{\"x\":75,\"y\":592},{\"x\":200,\"y\":590},{\"x\":198,\"y\":635},{\"x\":75,\"y\":634}],\"text\":\"Level\"},{\"boundingBox\":[{\"x\":298,\"y\":582},{\"x\":1052,\"y\":584},{\"x\":1052,\"y\":630},{\"x\":298,\"y\":628}],\"text\":\"· Identifying Opinion source and target\"},{\"boundingBox\":[{\"x\":296,\"y\":643},{\"x\":515,\"y\":647},{\"x\":515,\"y\":685},{\"x\":296,\"y\":682}],\"text\":\"· Negation\"},{\"boundingBox\":[{\"x\":297,\"y\":737},{\"x\":848,\"y\":737},{\"x\":848,\"y\":786},{\"x\":297,\"y\":784}],\"text\":\"· Grouping feature synonyms\"},{\"boundingBox\":[{\"x\":296,\"y\":794},{\"x\":729,\"y\":794},{\"x\":728,\"y\":843},{\"x\":296,\"y\":840}],\"text\":\"· Aspect-based mining\"},{\"boundingBox\":[{\"x\":46,\"y\":849},{\"x\":227,\"y\":851},{\"x\":227,\"y\":896},{\"x\":45,\"y\":894}],\"text\":\"Feature\"},{\"boundingBox\":[{\"x\":297,\"y\":855},{\"x\":687,\"y\":855},{\"x\":687,\"y\":900},{\"x\":297,\"y\":898}],\"text\":\"· Stemming features\"},{\"boundingBox\":[{\"x\":82,\"y\":911},{\"x\":192,\"y\":912},{\"x\":190,\"y\":958},{\"x\":83,\"y\":956}],\"text\":\"level\"},{\"boundingBox\":[{\"x\":298,\"y\":910},{\"x\":793,\"y\":911},{\"x\":793,\"y\":958},{\"x\":298,\"y\":957}],\"text\":\"· Pruning large feature set\"},{\"boundingBox\":[{\"x\":310,\"y\":1043},{\"x\":832,\"y\":1044},{\"x\":832,\"y\":1092},{\"x\":310,\"y\":1091}],\"text\":\"* Opinion word orientation\"},{\"boundingBox\":[{\"x\":309,\"y\":1114},{\"x\":623,\"y\":1115},{\"x\":623,\"y\":1153},{\"x\":309,\"y\":1151}],\"text\":\"· Sarcastic terms\"},{\"boundingBox\":[{\"x\":305,\"y\":1168},{\"x\":897,\"y\":1169},{\"x\":897,\"y\":1212},{\"x\":305,\"y\":1211}],\"text\":\"· Object-attribute co-reference\"},{\"boundingBox\":[{\"x\":49,\"y\":1222},{\"x\":226,\"y\":1224},{\"x\":225,\"y\":1267},{\"x\":49,\"y\":1264}],\"text\":\"Lexicon\"},{\"boundingBox\":[{\"x\":312,\"y\":1229},{\"x\":613,\"y\":1228},{\"x\":613,\"y\":1271},{\"x\":312,\"y\":1274}],\"text\":\"· Linguistic rules\"},{\"boundingBox\":[{\"x\":84,\"y\":1283},{\"x\":192,\"y\":1283},{\"x\":192,\"y\":1330},{\"x\":84,\"y\":1329}],\"text\":\"level\"},{\"boundingBox\":[{\"x\":306,\"y\":1285},{\"x\":724,\"y\":1286},{\"x\":724,\"y\":1329},{\"x\":306,\"y\":1328}],\"text\":\"· Dual meaning words\"},{\"boundingBox\":[{\"x\":309,\"y\":1339},{\"x\":957,\"y\":1339},{\"x\":958,\"y\":1387},{\"x\":309,\"y\":1387}],\"text\":\". Lack of opinion lexicons available\"}],\"words\":[{\"boundingBox\":[{\"x\":297,\"y\":20},{\"x\":306,\"y\":20},{\"x\":307,\"y\":56},{\"x\":298,\"y\":56}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":314,\"y\":19},{\"x\":538,\"y\":20},{\"x\":539,\"y\":58},{\"x\":314,\"y\":56}],\"text\":\"Discussions\"},{\"boundingBox\":[{\"x\":298,\"y\":74},{\"x\":304,\"y\":74},{\"x\":303,\"y\":116},{\"x\":297,\"y\":116}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":313,\"y\":74},{\"x\":461,\"y\":72},{\"x\":460,\"y\":119},{\"x\":312,\"y\":116}],\"text\":\"Domain\"},{\"boundingBox\":[{\"x\":470,\"y\":72},{\"x\":682,\"y\":72},{\"x\":682,\"y\":120},{\"x\":469,\"y\":119}],\"text\":\"dependent\"},{\"boundingBox\":[{\"x\":692,\"y\":72},{\"x\":862,\"y\":73},{\"x\":862,\"y\":120},{\"x\":692,\"y\":120}],\"text\":\"opinions\"},{\"boundingBox\":[{\"x\":16,\"y\":169},{\"x\":258,\"y\":169},{\"x\":258,\"y\":211},{\"x\":16,\"y\":210}],\"text\":\"Document\"},{\"boundingBox\":[{\"x\":300,\"y\":134},{\"x\":308,\"y\":134},{\"x\":306,\"y\":178},{\"x\":298,\"y\":177}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":316,\"y\":134},{\"x\":401,\"y\":134},{\"x\":400,\"y\":179},{\"x\":314,\"y\":178}],\"text\":\"Way\"},{\"boundingBox\":[{\"x\":411,\"y\":134},{\"x\":451,\"y\":135},{\"x\":449,\"y\":179},{\"x\":409,\"y\":179}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":460,\"y\":135},{\"x\":671,\"y\":135},{\"x\":669,\"y\":178},{\"x\":458,\"y\":179}],\"text\":\"expression\"},{\"boundingBox\":[{\"x\":74,\"y\":230},{\"x\":200,\"y\":229},{\"x\":201,\"y\":272},{\"x\":75,\"y\":272}],\"text\":\"Level\"},{\"boundingBox\":[{\"x\":301,\"y\":191},{\"x\":306,\"y\":191},{\"x\":304,\"y\":233},{\"x\":299,\"y\":233}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":314,\"y\":191},{\"x\":478,\"y\":190},{\"x\":477,\"y\":233},{\"x\":312,\"y\":233}],\"text\":\"Informal\"},{\"boundingBox\":[{\"x\":487,\"y\":190},{\"x\":611,\"y\":190},{\"x\":610,\"y\":234},{\"x\":485,\"y\":233}],\"text\":\"nature\"},{\"boundingBox\":[{\"x\":620,\"y\":190},{\"x\":662,\"y\":191},{\"x\":661,\"y\":234},{\"x\":619,\"y\":234}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":671,\"y\":191},{\"x\":824,\"y\":191},{\"x\":823,\"y\":235},{\"x\":670,\"y\":234}],\"text\":\"content\"},{\"boundingBox\":[{\"x\":299,\"y\":248},{\"x\":304,\"y\":248},{\"x\":305,\"y\":294},{\"x\":300,\"y\":294}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":314,\"y\":248},{\"x\":463,\"y\":248},{\"x\":464,\"y\":294},{\"x\":314,\"y\":294}],\"text\":\"Opinion\"},{\"boundingBox\":[{\"x\":473,\"y\":248},{\"x\":680,\"y\":249},{\"x\":680,\"y\":296},{\"x\":473,\"y\":294}],\"text\":\"spamming\"},{\"boundingBox\":[{\"x\":300,\"y\":354},{\"x\":307,\"y\":354},{\"x\":307,\"y\":396},{\"x\":300,\"y\":395}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":315,\"y\":354},{\"x\":534,\"y\":353},{\"x\":534,\"y\":396},{\"x\":315,\"y\":396}],\"text\":\"Conditional\"},{\"boundingBox\":[{\"x\":542,\"y\":353},{\"x\":742,\"y\":357},{\"x\":742,\"y\":395},{\"x\":542,\"y\":396}],\"text\":\"sentences\"},{\"boundingBox\":[{\"x\":299,\"y\":412},{\"x\":306,\"y\":412},{\"x\":305,\"y\":455},{\"x\":298,\"y\":455}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":314,\"y\":412},{\"x\":559,\"y\":412},{\"x\":558,\"y\":453},{\"x\":313,\"y\":455}],\"text\":\"Comparative\"},{\"boundingBox\":[{\"x\":567,\"y\":412},{\"x\":768,\"y\":414},{\"x\":768,\"y\":453},{\"x\":566,\"y\":453}],\"text\":\"sentences\"},{\"boundingBox\":[{\"x\":299,\"y\":470},{\"x\":314,\"y\":470},{\"x\":313,\"y\":515},{\"x\":298,\"y\":515}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":323,\"y\":470},{\"x\":462,\"y\":469},{\"x\":461,\"y\":515},{\"x\":322,\"y\":515}],\"text\":\"sharing\"},{\"boundingBox\":[{\"x\":471,\"y\":469},{\"x\":616,\"y\":469},{\"x\":616,\"y\":515},{\"x\":470,\"y\":515}],\"text\":\"opinion\"},{\"boundingBox\":[{\"x\":625,\"y\":469},{\"x\":731,\"y\":468},{\"x\":730,\"y\":515},{\"x\":625,\"y\":515}],\"text\":\"word\"},{\"boundingBox\":[{\"x\":30,\"y\":530},{\"x\":241,\"y\":532},{\"x\":242,\"y\":577},{\"x\":28,\"y\":576}],\"text\":\"Sentence\"},{\"boundingBox\":[{\"x\":299,\"y\":526},{\"x\":316,\"y\":526},{\"x\":314,\"y\":570},{\"x\":298,\"y\":570}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":325,\"y\":526},{\"x\":566,\"y\":526},{\"x\":565,\"y\":572},{\"x\":323,\"y\":570}],\"text\":\"Determining\"},{\"boundingBox\":[{\"x\":574,\"y\":526},{\"x\":768,\"y\":527},{\"x\":768,\"y\":572},{\"x\":574,\"y\":572}],\"text\":\"subjective\"},{\"boundingBox\":[{\"x\":777,\"y\":527},{\"x\":975,\"y\":529},{\"x\":975,\"y\":570},{\"x\":777,\"y\":572}],\"text\":\"sentences\"},{\"boundingBox\":[{\"x\":75,\"y\":590},{\"x\":198,\"y\":590},{\"x\":198,\"y\":635},{\"x\":75,\"y\":635}],\"text\":\"Level\"},{\"boundingBox\":[{\"x\":298,\"y\":583},{\"x\":315,\"y\":583},{\"x\":315,\"y\":627},{\"x\":298,\"y\":627}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":324,\"y\":583},{\"x\":530,\"y\":583},{\"x\":531,\"y\":629},{\"x\":324,\"y\":627}],\"text\":\"Identifying\"},{\"boundingBox\":[{\"x\":539,\"y\":583},{\"x\":691,\"y\":583},{\"x\":692,\"y\":630},{\"x\":540,\"y\":630}],\"text\":\"Opinion\"},{\"boundingBox\":[{\"x\":700,\"y\":583},{\"x\":831,\"y\":584},{\"x\":832,\"y\":630},{\"x\":701,\"y\":630}],\"text\":\"source\"},{\"boundingBox\":[{\"x\":847,\"y\":584},{\"x\":915,\"y\":584},{\"x\":916,\"y\":629},{\"x\":847,\"y\":630}],\"text\":\"and\"},{\"boundingBox\":[{\"x\":924,\"y\":584},{\"x\":1050,\"y\":585},{\"x\":1051,\"y\":628},{\"x\":925,\"y\":629}],\"text\":\"target\"},{\"boundingBox\":[{\"x\":297,\"y\":644},{\"x\":318,\"y\":644},{\"x\":319,\"y\":682},{\"x\":298,\"y\":681}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":336,\"y\":645},{\"x\":509,\"y\":647},{\"x\":509,\"y\":685},{\"x\":337,\"y\":683}],\"text\":\"Negation\"},{\"boundingBox\":[{\"x\":298,\"y\":740},{\"x\":304,\"y\":740},{\"x\":303,\"y\":782},{\"x\":298,\"y\":782}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":313,\"y\":740},{\"x\":490,\"y\":737},{\"x\":490,\"y\":786},{\"x\":312,\"y\":782}],\"text\":\"Grouping\"},{\"boundingBox\":[{\"x\":499,\"y\":737},{\"x\":640,\"y\":737},{\"x\":639,\"y\":786},{\"x\":499,\"y\":786}],\"text\":\"feature\"},{\"boundingBox\":[{\"x\":649,\"y\":737},{\"x\":848,\"y\":740},{\"x\":848,\"y\":784},{\"x\":649,\"y\":786}],\"text\":\"synonyms\"},{\"boundingBox\":[{\"x\":297,\"y\":794},{\"x\":315,\"y\":794},{\"x\":315,\"y\":840},{\"x\":297,\"y\":839}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":324,\"y\":794},{\"x\":583,\"y\":794},{\"x\":582,\"y\":843},{\"x\":324,\"y\":840}],\"text\":\"Aspect-based\"},{\"boundingBox\":[{\"x\":592,\"y\":794},{\"x\":728,\"y\":795},{\"x\":728,\"y\":844},{\"x\":592,\"y\":843}],\"text\":\"mining\"},{\"boundingBox\":[{\"x\":48,\"y\":849},{\"x\":223,\"y\":852},{\"x\":223,\"y\":896},{\"x\":46,\"y\":895}],\"text\":\"Feature\"},{\"boundingBox\":[{\"x\":298,\"y\":856},{\"x\":306,\"y\":856},{\"x\":305,\"y\":897},{\"x\":297,\"y\":896}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":315,\"y\":856},{\"x\":508,\"y\":856},{\"x\":509,\"y\":900},{\"x\":314,\"y\":897}],\"text\":\"Stemming\"},{\"boundingBox\":[{\"x\":517,\"y\":856},{\"x\":684,\"y\":856},{\"x\":686,\"y\":900},{\"x\":517,\"y\":900}],\"text\":\"features\"},{\"boundingBox\":[{\"x\":82,\"y\":911},{\"x\":189,\"y\":912},{\"x\":189,\"y\":958},{\"x\":82,\"y\":956}],\"text\":\"level\"},{\"boundingBox\":[{\"x\":300,\"y\":911},{\"x\":306,\"y\":911},{\"x\":304,\"y\":955},{\"x\":299,\"y\":955}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":315,\"y\":911},{\"x\":460,\"y\":911},{\"x\":459,\"y\":959},{\"x\":313,\"y\":956}],\"text\":\"Pruning\"},{\"boundingBox\":[{\"x\":469,\"y\":911},{\"x\":566,\"y\":912},{\"x\":565,\"y\":959},{\"x\":468,\"y\":959}],\"text\":\"large\"},{\"boundingBox\":[{\"x\":575,\"y\":912},{\"x\":717,\"y\":912},{\"x\":716,\"y\":957},{\"x\":574,\"y\":959}],\"text\":\"feature\"},{\"boundingBox\":[{\"x\":726,\"y\":912},{\"x\":793,\"y\":912},{\"x\":793,\"y\":955},{\"x\":725,\"y\":957}],\"text\":\"set\"},{\"boundingBox\":[{\"x\":311,\"y\":1044},{\"x\":323,\"y\":1044},{\"x\":323,\"y\":1091},{\"x\":311,\"y\":1091}],\"text\":\"*\"},{\"boundingBox\":[{\"x\":332,\"y\":1044},{\"x\":493,\"y\":1044},{\"x\":493,\"y\":1092},{\"x\":333,\"y\":1091}],\"text\":\"Opinion\"},{\"boundingBox\":[{\"x\":502,\"y\":1044},{\"x\":603,\"y\":1044},{\"x\":603,\"y\":1092},{\"x\":502,\"y\":1092}],\"text\":\"word\"},{\"boundingBox\":[{\"x\":612,\"y\":1044},{\"x\":829,\"y\":1044},{\"x\":829,\"y\":1092},{\"x\":612,\"y\":1092}],\"text\":\"orientation\"},{\"boundingBox\":[{\"x\":309,\"y\":1115},{\"x\":316,\"y\":1115},{\"x\":317,\"y\":1152},{\"x\":310,\"y\":1152}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":324,\"y\":1115},{\"x\":495,\"y\":1114},{\"x\":495,\"y\":1153},{\"x\":325,\"y\":1152}],\"text\":\"Sarcastic\"},{\"boundingBox\":[{\"x\":502,\"y\":1114},{\"x\":622,\"y\":1116},{\"x\":622,\"y\":1154},{\"x\":503,\"y\":1153}],\"text\":\"terms\"},{\"boundingBox\":[{\"x\":306,\"y\":1170},{\"x\":317,\"y\":1170},{\"x\":316,\"y\":1212},{\"x\":306,\"y\":1212}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":325,\"y\":1170},{\"x\":637,\"y\":1169},{\"x\":637,\"y\":1212},{\"x\":324,\"y\":1212}],\"text\":\"Object-attribute\"},{\"boundingBox\":[{\"x\":645,\"y\":1169},{\"x\":892,\"y\":1172},{\"x\":894,\"y\":1212},{\"x\":646,\"y\":1212}],\"text\":\"co-reference\"},{\"boundingBox\":[{\"x\":50,\"y\":1223},{\"x\":214,\"y\":1225},{\"x\":214,\"y\":1268},{\"x\":49,\"y\":1265}],\"text\":\"Lexicon\"},{\"boundingBox\":[{\"x\":313,\"y\":1230},{\"x\":316,\"y\":1230},{\"x\":315,\"y\":1275},{\"x\":312,\"y\":1275}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":324,\"y\":1230},{\"x\":503,\"y\":1228},{\"x\":501,\"y\":1272},{\"x\":323,\"y\":1275}],\"text\":\"Linguistic\"},{\"boundingBox\":[{\"x\":511,\"y\":1228},{\"x\":613,\"y\":1229},{\"x\":612,\"y\":1271},{\"x\":510,\"y\":1272}],\"text\":\"rules\"},{\"boundingBox\":[{\"x\":84,\"y\":1283},{\"x\":191,\"y\":1283},{\"x\":190,\"y\":1330},{\"x\":84,\"y\":1329}],\"text\":\"level\"},{\"boundingBox\":[{\"x\":307,\"y\":1286},{\"x\":317,\"y\":1286},{\"x\":317,\"y\":1328},{\"x\":306,\"y\":1328}],\"text\":\"·\"},{\"boundingBox\":[{\"x\":326,\"y\":1286},{\"x\":415,\"y\":1286},{\"x\":414,\"y\":1329},{\"x\":325,\"y\":1328}],\"text\":\"Dual\"},{\"boundingBox\":[{\"x\":423,\"y\":1286},{\"x\":589,\"y\":1286},{\"x\":588,\"y\":1330},{\"x\":422,\"y\":1329}],\"text\":\"meaning\"},{\"boundingBox\":[{\"x\":597,\"y\":1286},{\"x\":724,\"y\":1286},{\"x\":723,\"y\":1330},{\"x\":597,\"y\":1330}],\"text\":\"words\"},{\"boundingBox\":[{\"x\":311,\"y\":1343},{\"x\":316,\"y\":1343},{\"x\":315,\"y\":1386},{\"x\":309,\"y\":1386}],\"text\":\".\"},{\"boundingBox\":[{\"x\":326,\"y\":1343},{\"x\":407,\"y\":1342},{\"x\":406,\"y\":1386},{\"x\":324,\"y\":1386}],\"text\":\"Lack\"},{\"boundingBox\":[{\"x\":416,\"y\":1342},{\"x\":459,\"y\":1341},{\"x\":458,\"y\":1386},{\"x\":415,\"y\":1386}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":468,\"y\":1341},{\"x\":610,\"y\":1340},{\"x\":610,\"y\":1386},{\"x\":467,\"y\":1386}],\"text\":\"opinion\"},{\"boundingBox\":[{\"x\":619,\"y\":1340},{\"x\":776,\"y\":1340},{\"x\":777,\"y\":1387},{\"x\":619,\"y\":1386}],\"text\":\"lexicons\"},{\"boundingBox\":[{\"x\":785,\"y\":1340},{\"x\":955,\"y\":1340},{\"x\":957,\"y\":1388},{\"x\":786,\"y\":1387}],\"text\":\"available\"}]}",
        "{\"language\":\"en\",\"text\":\"Published online: 03 February 2016\",\"lines\":[{\"boundingBox\":[{\"x\":4,\"y\":14},{\"x\":1020,\"y\":16},{\"x\":1020,\"y\":74},{\"x\":4,\"y\":70}],\"text\":\"Published online: 03 February 2016\"}],\"words\":[{\"boundingBox\":[{\"x\":4,\"y\":15},{\"x\":270,\"y\":15},{\"x\":270,\"y\":71},{\"x\":4,\"y\":70}],\"text\":\"Published\"},{\"boundingBox\":[{\"x\":290,\"y\":15},{\"x\":494,\"y\":15},{\"x\":493,\"y\":72},{\"x\":289,\"y\":71}],\"text\":\"online:\"},{\"boundingBox\":[{\"x\":505,\"y\":15},{\"x\":575,\"y\":16},{\"x\":574,\"y\":72},{\"x\":504,\"y\":72}],\"text\":\"03\"},{\"boundingBox\":[{\"x\":594,\"y\":16},{\"x\":854,\"y\":16},{\"x\":852,\"y\":74},{\"x\":594,\"y\":72}],\"text\":\"February\"},{\"boundingBox\":[{\"x\":869,\"y\":16},{\"x\":1010,\"y\":17},{\"x\":1008,\"y\":75},{\"x\":868,\"y\":74}],\"text\":\"2016\"}]}"
      ]
    },
    {
      "@search.score": 2.585697,
      "content": "\nPrivacy preservation techniques in big \ndata analytics: a survey\nP. Ram Mohan Rao1,4*, S. Murali Krishna2 and A. P. Siva Kumar3\n\nIntroduction\nThere is an exponential growth in volume and variety of data as due to diverse applica-\ntions of computers in all domain areas. The growth has been achieved due to afford-\nable availability of computer technology, storage, and network connectivity. The large \nscale data, which also include person specific private and sensitive data like gender, zip \ncode, disease, caste, shopping cart, religion etc. is being stored in public domain. The \ndata holder can release this data to a third party data analyst to gain deeper insights and \nidentify hidden patterns which are useful in making important decisions that may help \nin improving businesses, provide value added services to customers [1], prediction, fore-\ncasting and recommendation [2]. One of the prominent applications of data analytics is \nrecommendation systems which is widely used by ecommerce sites like Amazon, Flip \nkart for suggesting products to customers based on their buying habits. Face book does \nsuggest friends, places to visit and even movie recommendation based on our interest. \nHowever releasing user activity data may lead inference attacks like identifying gender \nbased on user activity [3]. We have studied a number of privacy preserving techniques \nwhich are being employed to protect against privacy threats. Each of these techniques \nhas their own merits and demerits. This paper explores the merits and demerits of each \n\nAbstract \n\nIncredible amounts of data is being generated by various organizations like hospitals, \nbanks, e-commerce, retail and supply chain, etc. by virtue of digital technology. Not \nonly humans but machines also contribute to data in the form of closed circuit televi-\nsion streaming, web site logs, etc. Tons of data is generated every minute by social \nmedia and smart phones. The voluminous data generated from the various sources \ncan be processed and analyzed to support decision making. However data analytics \nis prone to privacy violations. One of the applications of data analytics is recommen-\ndation systems which is widely used by ecommerce sites like Amazon, Flip kart for \nsuggesting products to customers based on their buying habits leading to inference \nattacks. Although data analytics is useful in decision making, it will lead to serious \nprivacy concerns. Hence privacy preserving data analytics became very important. This \npaper examines various privacy threats, privacy preservation techniques and models \nwith their limitations, also proposes a data lake based modernistic privacy preservation \ntechnique to handle privacy preservation in unstructured data.\n\nKeywords: Data, Data analytics, Privacy threats, Privacy preservation\n\nOpen Access\n\n© The Author(s) 2018. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nRam Mohan Rao et al. J Big Data  (2018) 5:33  \nhttps://doi.org/10.1186/s40537-018-0141-8\n\n*Correspondence:   \nrammohan04@gmail.com \n1 Department of Computer \nScience and Engineering, \nMLR Institute of Technology, \nHyderabad, India\nFull list of author information \nis available at the end of the \narticle\n\n\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-018-0141-8&domain=pdf\n\n\nPage 2 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nof these techniques and also describes the research challenges in the area of privacy \npreservation. Always there exists a trade off between data utility and privacy. This paper \nalso proposes a data lake based modernistic privacy preservation technique to handle \nprivacy preservation in unstructured data with maximum data utility.\n\nPrivacy threats in data analytics\nPrivacy is the ability of an individual to determine what data can be shared, and employ \naccess control. If the data is in public domain then it is a threat to individual privacy \nas the data is held by data holder. Data holder can be social networking application, \nwebsites, mobile apps, ecommerce site, banks, hospitals etc. It is the responsibility of \nthe data holder to ensure privacy of the users data. Apart from the data held in public \ndomain, knowing or unknowingly users themself contribute to data leakage. For exam-\nple most of the mobile apps, seek access to our contacts, files, camera etc. and without \nreading the privacy statement we agree for all terms and conditions, there by contribut-\ning to data leakage.\n\nHence there is a need to educate the smart phone users regarding privacy and privacy \nthreats. Some of the key privacy threats include (1) Surveillance; (2) Disclosure; (3) Dis-\ncrimination; (4) Personal embracement and abuse.\n\nSurveillance\n\nMany organizations including retail, e-commerce, etc. study their customers buying \nhabits and try to come up with various offers and value added services [4]. Based on the \nopinion data and sentiment analysis, social media sites does provide recommendations \nof the new friends, places to visit, people to follow etc. This is possible only when they \ncontinuously monitor their customer’s transactions. This is a serious privacy threat as no \nindividual accepts surveillance.\n\nDisclosure\n\nConsider a hospital holding patient’s data which include (Zip, gender, age, disease) [5–7]. \nThe data holder has released data to a third party for analysis by anonymizing sensitive \nperson specific data so that the person cannot be identified. The third party data analyst \ncan map this information with the freely available external data sources like census data \nand can identify person suffering with some disorder. This is how private information of \na person can be disclosed which is considered to be a serious privacy breach.\n\nDiscrimination\n\nDiscrimination is the bias or inequality which can happen when some private informa-\ntion of a person is disclosed. For instance, statistical analysis of electoral results proved \nthat people of one community were completely against the party, which formed the gov-\nernment. Now the government can neglect that community or can have bias over them.\n\nPersonal embracement and abuse\n\nWhenever some private information of a person is disclosed, it can even lead to per-\nsonal embracement or abuse. For example, a person was privately undergoing medica-\ntion for some specific problem and was buying some medicines on a regular basis from a \n\n\n\nPage 3 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nmedical shop. As part of their regular business model, the medical shop may send some \nreminder and offers related to these medicines over phone. If any family member has \nnoticed this, it will lead to personal embracement and even abuse [8].\n\nData analytics activity will affect data Privacy. Many countries are enforcing Privacy \npreservation laws. Lack of awareness is also a major reason for privacy attacks. For \nexample many smart phones users are not aware of the information that is stolen from \ntheir phones by many apps. Previous research shows only 17% of smart phone users are \naware of privacy threats [9].\n\nPrivacy preservation methods\nMany Privacy preserving techniques were developed, but most of them are based on \nanonymization of data. The list of privacy preservation techniques is given below.\n\n  • K anonymity\n  • L diversity\n  • T closeness\n  • Randomization\n  • Data distribution\n  • Cryptographic techniques\n  • Multidimensional Sensitivity Based Anonymization (MDSBA).\n\nK anonymity [10]\n\nAnonymization is the process of modifying data before it is given for data analytics [11], \nso that de identification is not possible and will lead to K indistinguishable records if \nan attempt is made to de identify by mapping the anonymized data with external data \nsources. K anonymity is prone to two attacks namely homogeneity attack and back \nground knowledge attack. Some of the algorithms applied include, Incognito [12], Mon-\ndrian [13] to ensure Anonymization. K anonymity is applied on the patient data shown \nin Table 1. The table shows data before anonymization.\n\nK anonymity algorithm is applied with k value as 3 to ensure 3 indistinguishable \nrecords when an attempt is made to identify a particular person’s data. K anonymity is \napplied on the two attributes viz. Zip and age shown in Table 1. The result of applying \nanonymization on Zip and age attributes is shown in Table 2.\n\nTable 1 Patient data, before anonymization\n\nSno Zip Age Disease\n\n1 57677 29 Cardiac problem\n\n2 57602 22 Cardiac problem\n\n3 57678 27 Cardiac problem\n\n4 57905 43 Skin allergy\n\n5 57909 52 Cardiac problem\n\n6 57906 47 Cancer\n\n7 57605 30 Cardiac problem\n\n8 57673 36 Cancer\n\n9 57607 32 Cancer\n\n\n\nPage 4 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nThe above technique has used generalization [14] to achieve Anonymization. Suppose \nif we know that John is 27 year old and lives in 57677 zip codes then we can conclude \nJohn to have Cardiac problem even after anonymization as shown in Table  2. This is \ncalled Homogeneity attack. For example if John is 36 year old and it is known that John \ndoes not have cancer, then definitely John must have Cardiac problem. This is called as \nbackground knowledge attack. Achieving K anonymity [15, 16] can be done either by \nusing generalization or suppression. K anonymity can optimized if the minimal gener-\nalization can be done without huge data loss [17]. Identity disclosure is the major pri-\nvacy threat which cannot be guaranteed by K anonymity [18]. Personalized privacy is the \nmost important aspect of individual privacy [19].\n\nL diversity\n\nTo address homogeneity attack, another technique called L diversity has been proposed. \nAs per L diversity there must be L well represented values for the sensitive attribute (dis-\nease) in each equivalence class.\n\nImplementing L diversity is not possible every time because of the variety of data. L \ndiversity is also prone to skewness attack. When overall distribution of data is skewed \ninto few equivalence classes attribute disclosure cannot be ensured. For example if the \nentire records are distributed into only three equivalence classes then semantic close-\nness of these values may lead to attribute disclosure. Also L diversity may lead to simi-\nlarity attack. From Table 3 it can be noticed that if we know that John is 27 year old and \nlives in 57677 zip, then definitely John is under low income group because salaries of all \n\nTable 2 After applying anonymization on Zip and age\n\nSno Zip Age Disease\n\n1 576** 2* Cardiac problem\n\n2 576** 2* Cardiac problem\n\n3 576** 2* Cardiac problem\n\n4 5790* > 40 Skin allergy\n\n5 5790* > 40 Cardiac problem\n\n6 5790* > 40 Cancer\n\n7 576** 3* Cardiac problem\n\n8 576** 3* Cancer\n\n9 576** 3* Cancer\n\nTable 3 L diversity privacy preservation technique\n\nSno Zip Age Salary Disease\n\n1 576** 2* 5k Cardiac problem\n\n2 576** 2* 6k Cardiac problem\n\n3 576** 2* 7k Cardiac problem\n\n4 5790* > 40 20k Skin allergy\n\n5 5790* > 40 22k Cardiac problem\n\n6 5790* > 40 24k Cancer\n\n\n\nPage 5 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nthree persons in 576** zip is low compare to others in the table. This is called as similar-\nity attack.\n\nT closeness\n\nAnother improvement to L diversity is T closeness measure where an equivalence class \nis considered to have ‘T closeness’ if the distance between the distributions of sensi-\ntive attribute in the class is no more than a threshold and all equivalence classes have T \ncloseness [20]. T closeness can be calculated on every attribute with respect to sensitive \nattribute.\n\nFrom Table 4 it can be observed that if we know John is 27 year old, still it will be dif-\nficult to estimate whether John has Cardiac problem or not and he is under low income \ngroup or not. T closeness may ensure attribute disclosure but implementing T closeness \nmay not give proper distribution of data every time.\n\nRandomization technique\n\nRandomization is the process of adding noise to the data which is generally done by \nprobability distribution [21]. Randomization is applied in surveys, sentiment analy-\nsis etc. Randomization does not need knowledge of other records in the data. It can be \napplied during data collection and pre processing time. There is no anonymization over-\nhead in randomization. However, applying randomization on large datasets is not possi-\nble because of time complexity and data utility which has been proved in our experiment \ndescribed below.\n\nWe have loaded 10k records from an employee database into Hadoop Distributed File \nSystem and processed them by executing a Map Reduce Job. We have experimented to \nclassify the employees based on their salary and age groups. In order apply randomiza-\ntion we added noise in the form of 5k records which are randomly added to make a data-\nbase of 15k records and following observations were made after running Map Reduce \njob.\n\n  • More number of Mappers and Reducers were used as data volume increased.\n  • Results before and after randomization were significantly different.\n  • Some of the records which are outliers remain unaffected with randomization and \n\nare vulnerable to adversary attack.\n  • Privacy preservation at the cost of data utility is not appreciated and hence randomi-\n\nzation may not be suitable for privacy preservation especially attribute disclosure.\n\nTable 4 T closeness privacy preservation technique\n\nSno Zip Age Salary Disease\n\n1 576** 2* 5k Cardiac problem\n\n2 576** 2* 16k Cancer\n\n3 576** 2* 9k Skin allergy\n\n4 5790* > 40 20k Skin allergy\n\n5 5790* > 40 42k Cardiac problem\n\n6 5790* > 40 8k Flu\n\n\n\nPage 6 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nData distribution technique\n\nIn this technique, the data is distributed across many sites. Distribution of the data can \nbe done in two ways:\n\ni. Horizontal distribution of data\nii. Vertical distribution of data\n\nHorizontal distribution When data is distributed across many sites with same attrib-\nutes then the distribution is said to be horizontal distribution which is described in \nFig. 1.\n\nHorizontal distribution of data can be applied only when some aggregate functions or \noperations are to be applied on the data without actually sharing the data. For example, \nif a retail store wants to analyse their sales across various branches, they may employ \nsome analytics which does computations on aggregate data. However, as part of data \nanalysis the data holder may need to share the data with third party analyst which may \nlead to privacy breach. Classification and Clustering algorithms can be applied on dis-\ntributed data but it does not ensure privacy. If the data is distributed across different \nsites which belong to different organizations, then results of aggregate functions may \nhelp one party in detecting the data held with other parties. In such situations we expect \nall participating sites to be honest with each other [21].\n\nVertical distribution of data When Person specific information is distributed across \ndifferent sites under custodian of different organizations, then the distribution is called \nvertical distribution as shown in Fig. 2. For example, in crime investigations, the police \nofficials would like to know details of a particular criminal which include health, profes-\nsion, financial, personal etc. All this information may not be available at one site. Such a \ndistribution is called vertical distribution where each site holds few set of attributes of a \nperson. When some analytics has to be done data has to be pooled in from all these sites \nand there is a vulnerability of privacy breach.\n\nIn order to perform data analytics on vertically distributed data, where the attributes \nare distributed across different sites under custodian of different parties, it is highly \n\nFig. 1 Distribution of sales data across different sites\n\n\n\n\n\nPage 7 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\ndifficult to ensure privacy if the datasets are shared. For example, as part of a police \ninvestigation, the investigating officer wants to access some information about the \naccused from his employer, health department, bank to gain more insights about the \ncharacter of the person. In this process some of the personal and sensitive information \nof the accused may be disclosed to investigating officer leading to personal embarrass-\nment or abuse. Anonymization cannot be applied when entire records are not needed \nfor analytics. Distribution of data will not ensure privacy preservation but it closely \noverlaps with cryptographic techniques.\n\nCryptographic techniques\n\nThe data holder may encrypt the data before releasing the same for analytics. But \nencrypting large scale data using conventional encryption techniques is highly difficult \nand must be applied only during data collection time. Differential privacy techniques \nhave already been applied where some aggregate computations on the data are done \nwithout actually sharing the inputs. For example, if x and y are two data items then a \nfunction F(x, y) will be computed to gain some aggregate information from both x and \ny without actually sharing x and y. This can be applied on when x and y are held with \ndifferent parties as in the case of vertical distribution. However, if the data is at single \nlocation under the custodian of a single organization, then differential privacy can-\nnot be employed. Another similar technique called secure multiparty computation has \nbeen used but proved to be inadequate in privacy preservation. Data utility will be less \nif encryption is applied during data analytics. Thus encryption is not only difficult to \nimplement but it reduces the data utility [22].\n\nMultidimensional Sensitivity Based Anonymization (MDSBA)\n\nBottom up Generalization [23] and Top down Generalization [24] are the conventional \nmethods of Anonymization which were applied on well represented structured data \nrecords. However, applying the same on large scale data sets is very difficult leading to \n\nFig. 2 Vertical distribution of person specific data\n\n\n\n\n\nPage 8 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nissues of scalability and information loss. Multidimensional Sensitivity Based Anonymi-\nzation is a improved version of Anonymization proved to be more effective than conven-\ntional Anonymization techniques.\n\nMultidimensional Sensitivity Based Anonymization is an improved Anonymization \n[25] technique such that it can be applied on large data sets with reduced loss of informa-\ntion and predefined quasi identifiers. As part of this technique Apache MAP REDUCE \n[26] framework has been used to handle large data sets. In conventional Hadoop Distrib-\nuted Files System, the data will be divided into blocks of either 64 MB or 128 MB each \nand distributed across different nodes without considering the data inside the blocks. \nAs part of Multidimensional Sensitivity Based Anonymization [27] technique the data is \nsplit into different bags based on the probability distribution of the quasi identifiers by \nmaking use of filters in Apache Pig scripting language.\n\nMultidimensional Sensitivity Based Anonymization makes use of bottom up generali-\nzation but on a set of attributes with certain class values where class represents a sensi-\ntive attributes. Data distribution was made effectively when compared to conventional \nmethod of blocks. Data Anonymization was done using four quasi identifiers using \nApache Pig.\n\nSince the data is vertically partitioned into different groups, it can protect from back-\nground knowledge attack if the bag contains only few attributes. This method also \nmakes it difficult to map the data with external sources to disclose any person specific \ninformation.\n\nIn this method, the implementation was done using Apache Pig. Apache Pig is a script-\ning language, hence development effort is less. However, code efficiency of Apache Pig is \nrelatively less when compared to Map Reduce job because ultimately every Apache Pig \nscript has to be converted into a Map Reduce job. Multidimensional Sensitivity Based \nAnonymization [28] is more appropriate for large scale data but only when the data is at \nrest. Multidimensional Sensitivity Based Anonymization cannot be applied for stream-\ning data.\n\nAnalysis\nVarious privacy preservation techniques have been studied with respect to features \nincluding, type of data, data utility, attribute preservation and complexity. The compari-\nson of various privacy preservation techniques is shown in Table 5.\n\nTable 5 Comparison of privacy preservation techniques\n\nFeatures Privacy preservation techniques\n\nAnonymization \ntechniques\n\nCryptographic \ntechniques\n\nData \ndistribution\n\nRandomization MDSBA\n\nSuitability for unstructured data No No No No Yes\n\nAttribute preservation No No No Yes Yes\n\nDamage to data utility No No Yes No Yes\n\nVery complex to apply No Yes Yes Yes Yes\n\nAccuracy of results of data \nanalytics\n\nNo Yes No No No\n\n\n\nPage 9 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nResults and discussions\nAs part of systematic literature review, it has been observed that all existing mecha-\nnisms of privacy preservation are with respect to structured data. More than 80% of data \nbeing generated today is unstructured [29]. As such, there is a need to address following \nchallenges.\n\ni. Develop concrete solution to protect privacy in both structured and unstructured \ndata.\n\nii. Scalable and robust techniques to be developed to handle large scale heterogeneous \ndata sets.\n\niii. Data should be allowed to stay in its native form without need for transformation \nand data analytics can be carried out while ensuring privacy preservation.\n\niv. New techniques apart from Anonymization must be developed to ensure protection \nagainst key privacy threats which include identity disclosure, discrimination, surveil-\nlance etc.\n\nv. Maximizing data utility while ensuring data privacy.\n\nConclusion\nNo concrete solution for unstructured data has been developed yet. Conventional \ndata mining algorithms can be applied for classification and clustering problems but \ncannot be used in privacy preservation especially when dealing with person specific \ninformation. Machine learning and soft computing techniques can be used to develop \nnew and more appropriate solution to privacy problems which include identity dis-\nclosure that can lead to personal embarrassment and abuse.\n\nThere is a strong need for law enforcement by governments of all countries to \nensure individual privacy. European Union [30] is making an attempt to enforce pri-\nvacy preservation law. Apart from technological solutions, there is a strong need to \ncreate awareness among the people regarding privacy hazards to safeguard them-\nselves form privacy breaches. One of the serious privacy threats is smart phone. Lot \nof personal information in the form of contacts, messages, chats and files are being \naccessed by many apps running in our smart phone without our knowledge. Most \nof the time people do not even read the privacy statement before installing any app. \nHence there is a strong need to educate people on the various vulnerabilities which \ncan contribute to leakage of private information.\n\nWe propose a novel privacy preservation model based on Data Lake concept to \nhold variety of data from diverse sources. Data lake is a repository to hold data from \ndiverse sources in their raw format [31, 32]. Data ingestion from variety of sources can \nbe done using Apache Flume and an intelligent algorithm based on machine learning \ncan be applied to identify sensitive attributes dynamically [33, 34]. The algorithm will \nbe trained with existing data sets with known sensitive attributes and rigorous train-\ning of the model will help in predicting the sensitive attributes in a given data set [35]. \nAccuracy of the model can be improved by adding more layers of training leading \nto deep learning techniques [36]. Advanced computing techniques like Apache Spark \ncan be used in implementing privacy preserving algorithms which is a distributed \n\n\n\nPage 10 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nmassive parallel computing with in memory processing to ensure very fast processing \n[37]. The proposed model is shown in Fig. 3.\n\nData analytics is done on the data collected from various sources. If an ecommerce \nsite would like to perform data analytics, they need transactional data, website logs and \ncustomers opinion through social media pages. A Data lake is used to collect data from \ndifferent sources. Apache Flume is used to ingest data from social media sites, website \nlogs into Hadoop Distributed File System(HDFS). Using SQOOP relational data can be \nloaded into HDFS.\n\nIn Data lake the data can remain in its native form which is either structured or \nunstructured. When data has to be processed, it can be transformed into HIVE tables. A \nHadoop map reduce job using machine learning can be executed on the data to classify \nthe sensitive attributes [38]. The data can be vertically distributed to separate the sensi-\ntive attributes from rest of the data and apply tokenization to map the vertically distrib-\nuted data. The data without any sensitive attributes can be published for data analytics.\n\nAbbreviations\nCCTV: closed circuit television; MDSBA: Multidimensional Sensitivity Based Anonymization.\n\nAuthors’ contributions\nPRMR: as part of Ph.D. work I have done my literature survey and submitted my work in the form of a paper. SMK: \nsupported me in compiling the paper. APSK: suggested necessary amendments and helped in revising the paper. All \nauthors read and approved the final manuscript.\n\nAuthor details\n1 Department of Computer Science and Engineering, MLR Institute of Technology, Hyderabad, India. 2 Department \nof Computer Science and Engineering, Sri Venkateswara College of Engineering, Tirupati, Andhra Pradesh, India. \n3 Department of Computer Science and Engineering, JNTU Anantapur, Anantapuramu, Andhra Pradesh, India. 4 JNTU \nAnantapur, Anantapur, Andhra Pradesh, India. \n\nAcknowledgements\nI would like to thank my guides, for supporting my work and for suggesting necessary corrections.\n\nData Lake\n\nSqoop to load data from RDBMS\n\nApache \nFlume \nto load \nsocial \nmedia \ndata\n\nLoad data from\ndifferent sources\nand varie�es into\nHive Table for\nprocessing\n\nHadoop\nMap\nReduce\nJob to\nclassify\nsensi�ve\ndata\n\nNovel Privacy \nPreserva�on \nalgorithm \nbased on \nver�cal \ndistribu�on and \ntokeniza�on\n\nFig. 3 A Novel privacy preservation model based on vertical distribution and tokenization\n\n\n\nPage 11 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nAvailability of data and materials\nIf any one is interested in our work, we are ready to provide more details of the map reduce job which we have \nexecuted and the data processing techniques applied. However the data is used in our work, is freely available in many \nrepositories.\n\nFunding\nNo Funding.\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nReceived: 21 March 2018   Accepted: 4 September 2018\n\nReferences\n 1. Ducange Pietro, Pecori Riccardo, Mezzina Paolo. A glimpse on big data analytics in the framework of marketing \n\nstrategies. Soft Comput. 2018;22(1):325–42.\n 2. Chauhan Arun, Kummamuru Krishna, Toshniwal Durga. Prediction of places of visit using tweets. Knowl Inf Syst. \n\n2017;50(1):145–66.\n 3. Yang D, Bingqing Q, Cudre-Mauroux P. Privacy-preserving social media data publishing for personalized ranking-\n\nbased recommendation. IEEE Trans Knowl Data Eng. 2018. ISSN (Print):1041-4347, ISSN (Electronic):1558-2191.\n 4. Liu Y et al. A practical privacy-preserving data aggregation (3PDA) scheme for smart grid. IEEE Trans Ind Inf. 2018.\n 5. Duncan GT et al. Disclosure limitation methods and information loss for tabular data. In: Confidentiality, disclosure \n\nand data access: theory and practical applications for statistical agencies. 2001. p. 135–166.\n 6. Duncan GT, Diane L. Disclosure-limited data dissemination. J Am Stat Assoc. 1986;81(393):10–8.\n 7. Lambert Diane. Measures of disclosure risk and harm. J Off Stat. 1993;9(2):313.\n 8. Spiller K, et al. Data privacy: users’ thoughts on quantified self personal data. Self-Tracking. Cham: Palgrave Macmil-\n\nlan; 2018. p. 111–24.\n 9. Hettig M, Kiss E, Kassel J-F, Weber S, Harbach M. Visualizing risk by example: demonstrating threats arising from \n\nandroid apps. In: Smith M, editor. Symposium on usable privacy and security (SOUPS), Newcastle, UK, July 24–26, \n2013.\n\n 10. Bayardo RJ, Agrawal A. Data privacy through optimal k-anonymization. In: Proceedings 21st international confer-\nence on data engineering, 2005 (ICDE 2005). Piscataway: IEEE; 2005.\n\n 11. Iyengar S. Transforming data to satisfy privacy constraints. In: Proceedings of the eighth ACM SIGKDD international \nconference on knowledge discovery and data mining. New York: ACM; 2002.\n\n 12. LeFevre K, DeWitt DJ, Ramakrishnan R. Incognito: efficient full-domain k-anonymity. In: Proceedings of the 2005 \nACM SIGMOD international conference on management of data. New York: ACM; 2005.\n\n 13. LeFevre K, DeWitt DJ, Ramakrishnan R. Mondrian multidimensional k-anonymity. In: Proceedings of the 22nd inter-\nnational conference (ICDE’06) on data engineering, 2006. New York: ACM; 2006.\n\n 14. Samarati, Pierangela, and Latanya Sweeney. In: Protecting privacy when disclosing information: k-anonymity and its \nenforcement through generalization and suppression. Technical report, SRI International, 1998.\n\n 15. Sweeney Latanya. Achieving k-anonymity privacy protection using generalization and suppression. In J Uncertain \nFuzziness Knowl Based Syst. 2002;10(05):571–88.\n\n 16. Sweeney Latanya. k-Anonymity: a model for protecting privacy. Int J Uncertain, Fuzziness Knowl Based Syst. \n2002;10(05):557–70.\n\n 17. Williams R. On the complexity of optimal k-anonymity. In: Proc. 23rd ACM SIGMOD-SIGACT-SIGART symp. principles \nof database systems (PODS). New York: ACM; 2004.\n\n 18. Machanavajjhala A et al. L-diversity: privacy beyond k-anonymity. In: Proceedings of the 22nd international confer-\nence on data engineering (ICDE’06), 2006. Piscataway: IEEE; 2006.\n\n 19. Xiao X, Yufei T. Personalized privacy preservation. In: Proceedings of the 2006 ACM SIGMOD international confer-\nence on Management of data. New York: ACM; 2006.\n\n 20. Rubner Y, Tomasi T, Guibas LJ. The earth mover’s distance as a metric for image retrieval. Int J Comput Vision. \n2000;40(2):99–121.\n\n 21. Aggarwal CC, Philip SY. A general survey of privacy-preserving data mining models and algorithms. Privacy-preserv-\ning data mining. Springer: US; 2008. p. 11–52.\n\n 22. Jiang R, Lu R, Choo KK. Achieving high performance and privacy-preserving query over encrypted multidimensional \nbig metering data. Future Gen Comput Syst. 2018;78:392–401.\n\n 23. Wang K, Yu PS, Chakraborty S. Bottom-up generalization: A data mining solution to privacy protection. In: Fourth \nIEEE international conference on data mining, 2004 (ICDM’04). Piscataway: IEEE; 2004.\n\n 24. Fung BCM, Wang K, Yu PS. Top-down specialization for information and privacy preservation. In: Proceedings 21st \ninternational conference on data engineering, 2005 (ICDE 2005). Piscataway: IEEE; 2005.\n\n 25. Zhang X et al. A MapReduce based approach of scalable multidimensional anonymization for big data privacy \npreservation on cloud. In: Third international conference on cloud and green computing (CGC), 2013. Piscataway: \nIEEE; 2013.\n\n\n\n\n\nPage 12 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\n 26. Zhang X, et al. A scalable two-phase top-down specialization approach for data anonymization using mapreduce \non cloud. IEEE Trans Parallel Distrib Syst. 2014;25(2):363–73.\n\n 27. Al-Zobbi M, Shahrestani S, Ruan C. Improving MapReduce privacy by implementing multi-dimensional sensitivity-\nbased anonymization. J Big Data. 2017;4(1):45.\n\n 28. Al-Zobbi M, Shahrestani S, Ruan C. Implementing a framework for big data anonymity and analytics access control. \nIn: Trustcom/BigDataSE/ICESS, 2017 IEEE. Piscataway: IEEE; 2017.\n\n 29. Schneider C. IBM Blogs; 2016. https ://www.ibm.com/blogs /watso n/2016/05/bigge st-data-chall enges -might \n-not-even-know/.\n\n 30. TCS. Emphasizing the need for government regulations on data privacy; 2016. https ://www.tcs.com/conte nt/dam/\ntcs/pdf/techn ologi es/Cyber -Secur ity/Abstr act/Stren gthen ing-Priva cy-Pro",
      "metadata_storage_size": 1156098,
      "metadata_storage_path": "aHR0cHM6Ly9qdHJhaW5pbmdjYXRhbG9nc3RvcmFnZS5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL3M0MDUzNy0wMTgtMDE0MS04LnBkZg2",
      "metadata_author": "P. Ram Mohan Rao ",
      "metadata_title": "Privacy preservation techniques in big data analytics: a survey",
      "metadata_creation_date": "2018-09-20T05:58:23Z",
      "people": [
        "P. Ram Mohan Rao",
        "S. Murali Krishna2",
        "A. P. Siva Kumar3",
        "kart",
        "Ram Mohan Rao",
        "12Ram Mohan Rao",
        "John",
        "K",
        "12Ram",
        "Rao",
        "Job",
        "Pietro",
        "Pecori Riccardo",
        "Mezzina Paolo",
        "Chauhan Arun",
        "Kummamuru Krishna",
        "Toshniwal Durga",
        "Yang D",
        "Bingqing Q",
        "Cudre-Mauroux P.",
        "Liu Y",
        "Duncan GT",
        "Diane L.",
        "Lambert Diane",
        "Spiller K",
        "Hettig M",
        "Kiss E",
        "Kassel J-F",
        "Weber S",
        "Harbach M",
        "Smith M",
        "Bayardo RJ",
        "Agrawal A.",
        "ence",
        "Iyengar S.",
        "LeFevre K",
        "DeWitt",
        "Ramakrishnan R",
        "DeWitt DJ",
        "Ramakrishnan R. Mondrian",
        "Samarati",
        "Pierangela",
        "Latanya Sweeney",
        "Sweeney Latanya",
        "J Uncertain",
        "Williams R.",
        "Machanavajjhala A",
        "Xiao X",
        "Yufei T.",
        "Rubner Y",
        "Tomasi T",
        "Guibas LJ",
        "Aggarwal CC",
        "Philip SY",
        "Jiang R",
        "Lu R",
        "Choo KK",
        "Wang K",
        "Yu PS",
        "Chakraborty S.",
        "Fung",
        "Zhang X",
        "Al-Zobbi M",
        "Shahrestani S",
        "Ruan C.",
        "Ruan C",
        "Schneider C."
      ],
      "organizations": [
        "Amazon",
        "Flip",
        "social",
        "MLR Institute of Technology",
        "contribut",
        "health department",
        "Generalization",
        "Health Department",
        "analytics",
        "nisms",
        "preservation",
        "European Union",
        "CCTV",
        "APSK",
        "Science and Engineering",
        "Sri Venkateswara College of Engineering",
        "Springer Nature",
        "Soft Comput",
        "Knowl Inf Syst.",
        "lan",
        "IEEE",
        "ACM",
        "SRI International",
        "Int J",
        "Vision",
        "Springer",
        "BCM",
        "J Big Data",
        "IBM"
      ],
      "locations": [
        "big",
        "data lake",
        "Hyderabad",
        "India",
        "hospitals",
        "hospital",
        "medical shop",
        "countries",
        "K",
        "L",
        "sites",
        "utes",
        "Hadoop Distrib",
        "MDSBA",
        "Lot",
        "Data Lake",
        "Data lake",
        "Tirupati",
        "Andhra Pradesh",
        "Anantapur",
        "Flume",
        "Hive Table",
        "Hadoop",
        "tokeniza",
        "Cham",
        "In",
        "Newcastle",
        "UK",
        "Piscataway",
        "New York",
        "Int",
        "US"
      ],
      "keyphrases": [
        "Creative Commons Attribution 4.0 International License",
        "A. P. Siva Kumar3",
        "P. Ram Mohan Rao",
        "third party data analyst",
        "modernistic privacy preservation technique",
        "Privacy preservation Open Access",
        "Creative Commons license",
        "Ram Mohan Rao",
        "S. Murali Krishna2",
        "diverse applica- tions",
        "person specific private",
        "value added services",
        "web site logs",
        "creat iveco mmons",
        "original author(s",
        "J Big Data",
        "Privacy preservation techniques",
        "privacy preserving techniques",
        "The data holder",
        "various privacy threats",
        "user activity data",
        "big data analytics",
        "The Author",
        "privacy violations",
        "privacy concerns",
        "various organizations",
        "various sources",
        "author information",
        "domain areas",
        "able availability",
        "network connectivity",
        "scale data",
        "sensitive data",
        "zip code",
        "shopping cart",
        "public domain",
        "deeper insights",
        "hidden patterns",
        "important decisions",
        "ecommerce sites",
        "buying habits",
        "Face book",
        "inference attacks",
        "Incredible amounts",
        "supply chain",
        "sion streaming",
        "social media",
        "smart phones",
        "voluminous data",
        "decision making",
        "dation systems",
        "data lake",
        "unstructured data",
        "unrestricted use",
        "appropriate credit",
        "MLR Institute",
        "Full list",
        "research challenges",
        "data utility",
        "movie recommendation",
        "digital technology",
        "exponential growth",
        "prominent applications",
        "doi.org",
        "computer technology",
        "Flip kart",
        "SURVEY PAPER",
        "Introduction",
        "volume",
        "variety",
        "computers",
        "storage",
        "gender",
        "disease",
        "caste",
        "religion",
        "businesses",
        "customers",
        "prediction",
        "casting",
        "Amazon",
        "products",
        "friends",
        "places",
        "interest",
        "number",
        "merits",
        "Abstract",
        "hospitals",
        "banks",
        "retail",
        "virtue",
        "humans",
        "machines",
        "Tons",
        "serious",
        "models",
        "limitations",
        "Keywords",
        "article",
        "terms",
        "distribution",
        "reproduction",
        "medium",
        "link",
        "changes",
        "Correspondence",
        "rammohan04",
        "1 Department",
        "Science",
        "Engineering",
        "Hyderabad",
        "India",
        "creativecommons",
        "licenses",
        "crossmark",
        "crossref",
        "dialog",
        "Page",
        "trade",
        "Multidimensional Sensitivity Based Anonymization",
        "Many Privacy preserving techniques",
        "many smart phones users",
        "social networking application",
        "social media sites",
        "hospital holding patient",
        "12Ram Mohan Rao",
        "regular business model",
        "serious privacy breach",
        "Privacy preservation laws",
        "Privacy preservation methods",
        "privacy preservation techniques",
        "smart phone users",
        "maximum data utility",
        "external data sources",
        "private informa- tion",
        "key privacy threats",
        "Data analytics activity",
        "serious privacy threat",
        "person specific data",
        "Cryptographic techniques",
        "Many organizations",
        "Many countries",
        "many apps",
        "users data",
        "medica- tion",
        "specific problem",
        "regular basis",
        "privacy statement",
        "data Privacy",
        "privacy attacks",
        "data holder",
        "mobile apps",
        "ecommerce site",
        "data leakage",
        "Personal embracement",
        "opinion data",
        "new friends",
        "census data",
        "electoral results",
        "medical shop",
        "family member",
        "major reason",
        "Previous research",
        "K anonymity",
        "L diversity",
        "T closeness",
        "Data distribution",
        "private information",
        "individual privacy",
        "sentiment analysis",
        "statistical analysis",
        "access control",
        "various offers",
        "one community",
        "ability",
        "websites",
        "responsibility",
        "contacts",
        "files",
        "camera",
        "conditions",
        "need",
        "Surveillance",
        "Disclosure",
        "crimination",
        "abuse",
        "habits",
        "recommendations",
        "people",
        "transactions",
        "Zip",
        "sensitive",
        "disorder",
        "bias",
        "inequality",
        "instance",
        "government",
        "example",
        "medicines",
        "reminder",
        "Lack",
        "awareness",
        "list",
        "Randomization",
        "MDSBA",
        "Sno Zip Age Salary Disease",
        "Table 3 L diversity privacy preservation technique",
        "Sno Zip Age Disease",
        "equivalence classes attribute disclosure",
        "minimal gener- alization",
        "low income group",
        "sensi- tive attribute",
        "ground knowledge attack",
        "three equivalence classes",
        "huge data loss",
        "40 20k Skin allergy",
        "T closeness measure",
        "2* 6k Cardiac problem",
        "7k Cardiac problem",
        "22k Cardiac problem",
        "K anonymity algorithm",
        "K indistinguishable records",
        "Personalized privacy",
        "age attributes",
        "sensitive attribute",
        "40 Skin allergy",
        "Identity disclosure",
        "three persons",
        "40 Cardiac problem",
        "k value",
        "57677 zip codes",
        "larity attack",
        "de identification",
        "two attacks",
        "particular person",
        "two attributes",
        "vacy threat",
        "important aspect",
        "overall distribution",
        "entire records",
        "close- ness",
        "data analytics",
        "anonymized data",
        "patient data",
        "homogeneity attack",
        "40 24k Cancer",
        "576** zip",
        "3 indistinguishable",
        "Table 1",
        "40 Cancer",
        "Anonymization",
        "process",
        "attempt",
        "algorithms",
        "Incognito",
        "drian",
        "result",
        "generalization",
        "John",
        "Achieving",
        "suppression",
        "values",
        "salaries",
        "others",
        "improvement",
        "distance",
        "distributions",
        "threshold",
        "Table 4 T closeness privacy preservation technique",
        "Hadoop Distributed File System",
        "2* 9k Skin allergy",
        "same attrib- utes",
        "pre processing time",
        "third party analyst",
        "40 42k Cardiac problem",
        "Map Reduce Job",
        "Person specific information",
        "Data distribution technique",
        "age groups",
        "privacy breach",
        "time complexity",
        "one party",
        "Randomization technique",
        "low income",
        "large datasets",
        "employee database",
        "data- base",
        "More number",
        "adversary attack",
        "40 8k Flu",
        "many sites",
        "two ways",
        "aggregate functions",
        "retail store",
        "various branches",
        "Clustering algorithms",
        "different sites",
        "different organizations",
        "other parties",
        "participating sites",
        "crime investigations",
        "police officials",
        "particular criminal",
        "other records",
        "10k records",
        "5k records",
        "proper distribution",
        "probability distribution",
        "Horizontal distribution",
        "Vertical distribution",
        "attribute disclosure",
        "one site",
        "data collection",
        "data volume",
        "aggregate data",
        "respect",
        "ficult",
        "noise",
        "surveys",
        "sis",
        "knowledge",
        "anonymization",
        "head",
        "experiment",
        "employees",
        "order",
        "observations",
        "Mappers",
        "Reducers",
        "Results",
        "outliers",
        "cost",
        "Fig.",
        "operations",
        "sales",
        "analytics",
        "computations",
        "Classification",
        "situations",
        "custodian",
        "details",
        "sion",
        "attributes",
        "10K 10K to 20 sales K sales records records",
        "20K to 30K sales records",
        "person specific data Health Department Data",
        "social network organizations accounts",
        "Apache Pig scripting language",
        "large scale data sets",
        "Apache MAP REDUCE",
        "large data sets",
        "data collection time",
        "two data items",
        "tional Anonymization techniques",
        "sales data",
        "data records",
        "Differential privacy techniques",
        "conventional encryption techniques",
        "Personal Bank custodian",
        "cryptographic techniques",
        "conventional methods",
        "Data utility",
        "police investigation",
        "embarrass- ment",
        "privacy preservation",
        "aggregate computations",
        "single location",
        "single organization",
        "reduced loss",
        "informa- tion",
        "quasi identifiers",
        "Files System",
        "different parties",
        "different nodes",
        "different bags",
        "sensitive information",
        "aggregate information",
        "information loss",
        "vertical distribution",
        "investigating officer",
        "similar technique",
        "Employer site",
        "vulnerability",
        "datasets",
        "insights",
        "character",
        "overlaps",
        "inputs",
        "function",
        "case",
        "Generalization",
        "email",
        "issues",
        "scalability",
        "version",
        "predefined",
        "blocks",
        "64 MB",
        "128 MB",
        "filters",
        "bottom",
        "Cryptographic techniques Data distribution Randomization",
        "Various privacy preservation techniques",
        "soft computing techniques",
        "four quasi identifiers",
        "script- ing language",
        "systematic literature review",
        "large scale heterogeneous",
        "serious privacy threats",
        "vacy preservation law",
        "large scale data",
        "stream- ing data",
        "data mining algorithms",
        "Apache Pig script",
        "Map Reduce job",
        "various vulnerabilities",
        "Anonymization techniques",
        "robust techniques",
        "attribute preservation",
        "New techniques",
        "law enforcement",
        "privacy problems",
        "privacy hazards",
        "privacy breaches",
        "data privacy",
        "different groups",
        "external sources",
        "specific information",
        "development effort",
        "code efficiency",
        "concrete solution",
        "identity disclosure",
        "clustering problems",
        "Machine learning",
        "appropriate solution",
        "personal embarrassment",
        "European Union",
        "technological solutions",
        "smart phone",
        "personal information",
        "Data Anonymization",
        "Big Data",
        "data sets",
        "strong need",
        "class values",
        "native form",
        "time people",
        "conventional",
        "method",
        "bag",
        "implementation",
        "rest",
        "Analysis",
        "features",
        "type",
        "complexity",
        "compari",
        "Table",
        "Suitability",
        "Damage",
        "Accuracy",
        "results",
        "discussions",
        "part",
        "nisms",
        "More",
        "challenges",
        "Scalable",
        "transformation",
        "protection",
        "discrimination",
        "lance",
        "Conclusion",
        "classification",
        "governments",
        "countries",
        "selves",
        "Lot",
        "messages",
        "chats",
        "novel privacy preservation model",
        "privacy preserving algorithms",
        "rigorous train- ing",
        "Advanced computing techniques",
        "massive parallel computing",
        "social media pages",
        "closed circuit television",
        "Sri Venkateswara College",
        "deep learning techniques",
        "existing data sets",
        "SQOOP relational data",
        "social media data",
        "Ph.D. work",
        "Data Lake concept",
        "A Data lake",
        "Data Lake Sqoop",
        "data processing techniques",
        "proposed model",
        "machine learning",
        "Hadoop map",
        "raw format",
        "sensitive attributes",
        "memory processing",
        "fast processing",
        "website logs",
        "customers opinion",
        "HIVE tables",
        "Abbreviations CCTV",
        "literature survey",
        "necessary amendments",
        "final manuscript",
        "Computer Science",
        "Andhra Pradesh",
        "necessary corrections",
        "Competing interests",
        "Springer Nature",
        "jurisdictional claims",
        "institutional affiliations",
        "diverse sources",
        "different sources",
        "Data ingestion",
        "Data analytics",
        "transactional data",
        "Load data",
        "Apache Spark",
        "Author details",
        "Apache Flume",
        "intelligent algorithm",
        "Authors’ contributions",
        "JNTU Anantapur",
        "4 JNTU",
        "leakage",
        "repository",
        "layers",
        "training",
        "HDFS",
        "job",
        "tokenization",
        "PRMR",
        "paper",
        "SMK",
        "APSK",
        "Technology",
        "Tirupati",
        "Anantapuramu",
        "Acknowledgements",
        "guides",
        "RDBMS",
        "�cal",
        "Availability",
        "materials",
        "one",
        "many",
        "repositories",
        "Funding",
        "Publisher",
        "Note",
        "regard",
        "maps",
        "23rd ACM SIGMOD-SIGACT-SIGART symp. principles",
        "Privacy-preserving social media data publishing",
        "Diane L. Disclosure-limited data dissemination",
        "eighth ACM SIGKDD international conference",
        "2006 ACM SIGMOD international confer- ence",
        "IEEE Trans Knowl Data Eng",
        "J Am Stat Assoc",
        "quantified self personal data",
        "IEEE Trans Ind Inf.",
        "ACM SIGMOD international conference",
        "Int J Comput Vision",
        "Future Gen Comput Syst",
        "practical privacy-preserving data aggregation",
        "privacy-preserving data mining models",
        "IEEE international conference",
        "J Off Stat",
        "Int J Uncertain",
        "Knowl Inf Syst.",
        "big metering data",
        "Ramakrishnan R. Incognito",
        "Ramakrishnan R. Mondrian",
        "data mining solution",
        "Disclosure limitation methods",
        "efficient full-domain k-anonymity",
        "Personalized privacy preservation",
        "k-anonymity privacy protection",
        "SRI International",
        "privacy-preserving query",
        "Lambert Diane",
        "Soft Comput",
        "practical applications",
        "Fuzziness Knowl",
        "tabular data",
        "data access",
        "data engineering",
        "Data privacy",
        "Williams R.",
        "Jiang R",
        "Lu R",
        "Ducange Pietro",
        "Pecori Riccardo",
        "Mezzina Paolo",
        "marketing strategies",
        "Chauhan Arun",
        "Kummamuru Krishna",
        "Toshniwal Durga",
        "Yang D",
        "Bingqing Q",
        "Cudre-Mauroux P",
        "Liu Y",
        "smart grid",
        "Duncan GT",
        "statistical agencies",
        "Spiller K",
        "Hettig M",
        "Kiss E",
        "Kassel J-F",
        "Weber S",
        "Harbach M",
        "android apps",
        "Smith M",
        "Bayardo RJ",
        "Agrawal A.",
        "optimal k-anonymization",
        "Iyengar S.",
        "knowledge discovery",
        "New York",
        "LeFevre K",
        "DeWitt DJ",
        "Latanya Sweeney",
        "Technical report",
        "Sweeney Latanya",
        "optimal k-anonymity",
        "database systems",
        "Machanavajjhala A",
        "Xiao X",
        "Yufei T.",
        "Rubner Y",
        "Tomasi T",
        "Guibas LJ.",
        "earth mover",
        "image retrieval",
        "Aggarwal CC",
        "Philip SY",
        "general survey",
        "Choo KK",
        "high performance",
        "Wang K",
        "Yu PS",
        "Chakraborty S",
        "usable privacy",
        "privacy constraints",
        "disclosure risk",
        "multidimensional k-anonymity",
        "Bottom-up generalization",
        "References",
        "glimpse",
        "framework",
        "Prediction",
        "visit",
        "tweets",
        "recommendation",
        "ISSN",
        "Print",
        "Confidentiality",
        "theory",
        "Measures",
        "harm",
        "users",
        "thoughts",
        "Self-Tracking",
        "Cham",
        "lan",
        "threats",
        "editor",
        "Symposium",
        "security",
        "SOUPS",
        "Newcastle",
        "UK",
        "July",
        "Proceedings",
        "ICDE",
        "Piscataway",
        "management",
        "Samarati",
        "Pierangela",
        "enforcement",
        "Proc.",
        "PODS",
        "L-diversity",
        "metric",
        "Springer",
        "Fourth",
        "ICDM",
        "4",
        "IEEE Trans Parallel Distrib Syst",
        "scalable two-phase top-down specialization approach",
        "big data privacy preservation",
        "scalable multidimensional anonymization",
        "analytics access control",
        "Secur ity/Abstr act",
        "big data anonymity",
        "Third international conference",
        "data anonymization",
        "MapReduce privacy",
        "Fung BCM",
        "Zhang X",
        "green computing",
        "Al-Zobbi M",
        "Shahrestani S",
        "Ruan C",
        "29. Schneider C.",
        "government regulations",
        "techn ologi",
        "Stren gthen",
        "Priva cy-Pro",
        "A MapReduce",
        "IBM Blogs",
        "information",
        "cloud",
        "CGC",
        "Trustcom/BigDataSE/ICESS",
        "bigge",
        "chall",
        "TCS",
        "conte",
        "Cyber"
      ],
      "merged_content": "\nPrivacy preservation techniques in big \ndata analytics: a survey\nP. Ram Mohan Rao1,4*, S. Murali Krishna2 and A. P. Siva Kumar3\n\nIntroduction\nThere is an exponential growth in volume and variety of data as due to diverse applica-\ntions of computers in all domain areas. The growth has been achieved due to afford-\nable availability of computer technology, storage, and network connectivity. The large \nscale data, which also include person specific private and sensitive data like gender, zip \ncode, disease, caste, shopping cart, religion etc. is being stored in public domain. The \ndata holder can release this data to a third party data analyst to gain deeper insights and \nidentify hidden patterns which are useful in making important decisions that may help \nin improving businesses, provide value added services to customers [1], prediction, fore-\ncasting and recommendation [2]. One of the prominent applications of data analytics is \nrecommendation systems which is widely used by ecommerce sites like Amazon, Flip \nkart for suggesting products to customers based on their buying habits. Face book does \nsuggest friends, places to visit and even movie recommendation based on our interest. \nHowever releasing user activity data may lead inference attacks like identifying gender \nbased on user activity [3]. We have studied a number of privacy preserving techniques \nwhich are being employed to protect against privacy threats. Each of these techniques \nhas their own merits and demerits. This paper explores the merits and demerits of each \n\nAbstract \n\nIncredible amounts of data is being generated by various organizations like hospitals, \nbanks, e-commerce, retail and supply chain, etc. by virtue of digital technology. Not \nonly humans but machines also contribute to data in the form of closed circuit televi-\nsion streaming, web site logs, etc. Tons of data is generated every minute by social \nmedia and smart phones. The voluminous data generated from the various sources \ncan be processed and analyzed to support decision making. However data analytics \nis prone to privacy violations. One of the applications of data analytics is recommen-\ndation systems which is widely used by ecommerce sites like Amazon, Flip kart for \nsuggesting products to customers based on their buying habits leading to inference \nattacks. Although data analytics is useful in decision making, it will lead to serious \nprivacy concerns. Hence privacy preserving data analytics became very important. This \npaper examines various privacy threats, privacy preservation techniques and models \nwith their limitations, also proposes a data lake based modernistic privacy preservation \ntechnique to handle privacy preservation in unstructured data.\n\nKeywords: Data, Data analytics, Privacy threats, Privacy preservation\n\nOpen Access\n\n© The Author(s) 2018. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nRam Mohan Rao et al. J Big Data  (2018) 5:33  \nhttps://doi.org/10.1186/s40537-018-0141-8\n\n*Correspondence:   \nrammohan04@gmail.com \n1 Department of Computer \nScience and Engineering, \nMLR Institute of Technology, \nHyderabad, India\nFull list of author information \nis available at the end of the \narticle\n\n  \n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-018-0141-8&domain=pdf\n\n\nPage 2 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nof these techniques and also describes the research challenges in the area of privacy \npreservation. Always there exists a trade off between data utility and privacy. This paper \nalso proposes a data lake based modernistic privacy preservation technique to handle \nprivacy preservation in unstructured data with maximum data utility.\n\nPrivacy threats in data analytics\nPrivacy is the ability of an individual to determine what data can be shared, and employ \naccess control. If the data is in public domain then it is a threat to individual privacy \nas the data is held by data holder. Data holder can be social networking application, \nwebsites, mobile apps, ecommerce site, banks, hospitals etc. It is the responsibility of \nthe data holder to ensure privacy of the users data. Apart from the data held in public \ndomain, knowing or unknowingly users themself contribute to data leakage. For exam-\nple most of the mobile apps, seek access to our contacts, files, camera etc. and without \nreading the privacy statement we agree for all terms and conditions, there by contribut-\ning to data leakage.\n\nHence there is a need to educate the smart phone users regarding privacy and privacy \nthreats. Some of the key privacy threats include (1) Surveillance; (2) Disclosure; (3) Dis-\ncrimination; (4) Personal embracement and abuse.\n\nSurveillance\n\nMany organizations including retail, e-commerce, etc. study their customers buying \nhabits and try to come up with various offers and value added services [4]. Based on the \nopinion data and sentiment analysis, social media sites does provide recommendations \nof the new friends, places to visit, people to follow etc. This is possible only when they \ncontinuously monitor their customer’s transactions. This is a serious privacy threat as no \nindividual accepts surveillance.\n\nDisclosure\n\nConsider a hospital holding patient’s data which include (Zip, gender, age, disease) [5–7]. \nThe data holder has released data to a third party for analysis by anonymizing sensitive \nperson specific data so that the person cannot be identified. The third party data analyst \ncan map this information with the freely available external data sources like census data \nand can identify person suffering with some disorder. This is how private information of \na person can be disclosed which is considered to be a serious privacy breach.\n\nDiscrimination\n\nDiscrimination is the bias or inequality which can happen when some private informa-\ntion of a person is disclosed. For instance, statistical analysis of electoral results proved \nthat people of one community were completely against the party, which formed the gov-\nernment. Now the government can neglect that community or can have bias over them.\n\nPersonal embracement and abuse\n\nWhenever some private information of a person is disclosed, it can even lead to per-\nsonal embracement or abuse. For example, a person was privately undergoing medica-\ntion for some specific problem and was buying some medicines on a regular basis from a \n\n\n\nPage 3 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nmedical shop. As part of their regular business model, the medical shop may send some \nreminder and offers related to these medicines over phone. If any family member has \nnoticed this, it will lead to personal embracement and even abuse [8].\n\nData analytics activity will affect data Privacy. Many countries are enforcing Privacy \npreservation laws. Lack of awareness is also a major reason for privacy attacks. For \nexample many smart phones users are not aware of the information that is stolen from \ntheir phones by many apps. Previous research shows only 17% of smart phone users are \naware of privacy threats [9].\n\nPrivacy preservation methods\nMany Privacy preserving techniques were developed, but most of them are based on \nanonymization of data. The list of privacy preservation techniques is given below.\n\n  • K anonymity\n  • L diversity\n  • T closeness\n  • Randomization\n  • Data distribution\n  • Cryptographic techniques\n  • Multidimensional Sensitivity Based Anonymization (MDSBA).\n\nK anonymity [10]\n\nAnonymization is the process of modifying data before it is given for data analytics [11], \nso that de identification is not possible and will lead to K indistinguishable records if \nan attempt is made to de identify by mapping the anonymized data with external data \nsources. K anonymity is prone to two attacks namely homogeneity attack and back \nground knowledge attack. Some of the algorithms applied include, Incognito [12], Mon-\ndrian [13] to ensure Anonymization. K anonymity is applied on the patient data shown \nin Table 1. The table shows data before anonymization.\n\nK anonymity algorithm is applied with k value as 3 to ensure 3 indistinguishable \nrecords when an attempt is made to identify a particular person’s data. K anonymity is \napplied on the two attributes viz. Zip and age shown in Table 1. The result of applying \nanonymization on Zip and age attributes is shown in Table 2.\n\nTable 1 Patient data, before anonymization\n\nSno Zip Age Disease\n\n1 57677 29 Cardiac problem\n\n2 57602 22 Cardiac problem\n\n3 57678 27 Cardiac problem\n\n4 57905 43 Skin allergy\n\n5 57909 52 Cardiac problem\n\n6 57906 47 Cancer\n\n7 57605 30 Cardiac problem\n\n8 57673 36 Cancer\n\n9 57607 32 Cancer\n\n\n\nPage 4 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nThe above technique has used generalization [14] to achieve Anonymization. Suppose \nif we know that John is 27 year old and lives in 57677 zip codes then we can conclude \nJohn to have Cardiac problem even after anonymization as shown in Table  2. This is \ncalled Homogeneity attack. For example if John is 36 year old and it is known that John \ndoes not have cancer, then definitely John must have Cardiac problem. This is called as \nbackground knowledge attack. Achieving K anonymity [15, 16] can be done either by \nusing generalization or suppression. K anonymity can optimized if the minimal gener-\nalization can be done without huge data loss [17]. Identity disclosure is the major pri-\nvacy threat which cannot be guaranteed by K anonymity [18]. Personalized privacy is the \nmost important aspect of individual privacy [19].\n\nL diversity\n\nTo address homogeneity attack, another technique called L diversity has been proposed. \nAs per L diversity there must be L well represented values for the sensitive attribute (dis-\nease) in each equivalence class.\n\nImplementing L diversity is not possible every time because of the variety of data. L \ndiversity is also prone to skewness attack. When overall distribution of data is skewed \ninto few equivalence classes attribute disclosure cannot be ensured. For example if the \nentire records are distributed into only three equivalence classes then semantic close-\nness of these values may lead to attribute disclosure. Also L diversity may lead to simi-\nlarity attack. From Table 3 it can be noticed that if we know that John is 27 year old and \nlives in 57677 zip, then definitely John is under low income group because salaries of all \n\nTable 2 After applying anonymization on Zip and age\n\nSno Zip Age Disease\n\n1 576** 2* Cardiac problem\n\n2 576** 2* Cardiac problem\n\n3 576** 2* Cardiac problem\n\n4 5790* > 40 Skin allergy\n\n5 5790* > 40 Cardiac problem\n\n6 5790* > 40 Cancer\n\n7 576** 3* Cardiac problem\n\n8 576** 3* Cancer\n\n9 576** 3* Cancer\n\nTable 3 L diversity privacy preservation technique\n\nSno Zip Age Salary Disease\n\n1 576** 2* 5k Cardiac problem\n\n2 576** 2* 6k Cardiac problem\n\n3 576** 2* 7k Cardiac problem\n\n4 5790* > 40 20k Skin allergy\n\n5 5790* > 40 22k Cardiac problem\n\n6 5790* > 40 24k Cancer\n\n\n\nPage 5 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nthree persons in 576** zip is low compare to others in the table. This is called as similar-\nity attack.\n\nT closeness\n\nAnother improvement to L diversity is T closeness measure where an equivalence class \nis considered to have ‘T closeness’ if the distance between the distributions of sensi-\ntive attribute in the class is no more than a threshold and all equivalence classes have T \ncloseness [20]. T closeness can be calculated on every attribute with respect to sensitive \nattribute.\n\nFrom Table 4 it can be observed that if we know John is 27 year old, still it will be dif-\nficult to estimate whether John has Cardiac problem or not and he is under low income \ngroup or not. T closeness may ensure attribute disclosure but implementing T closeness \nmay not give proper distribution of data every time.\n\nRandomization technique\n\nRandomization is the process of adding noise to the data which is generally done by \nprobability distribution [21]. Randomization is applied in surveys, sentiment analy-\nsis etc. Randomization does not need knowledge of other records in the data. It can be \napplied during data collection and pre processing time. There is no anonymization over-\nhead in randomization. However, applying randomization on large datasets is not possi-\nble because of time complexity and data utility which has been proved in our experiment \ndescribed below.\n\nWe have loaded 10k records from an employee database into Hadoop Distributed File \nSystem and processed them by executing a Map Reduce Job. We have experimented to \nclassify the employees based on their salary and age groups. In order apply randomiza-\ntion we added noise in the form of 5k records which are randomly added to make a data-\nbase of 15k records and following observations were made after running Map Reduce \njob.\n\n  • More number of Mappers and Reducers were used as data volume increased.\n  • Results before and after randomization were significantly different.\n  • Some of the records which are outliers remain unaffected with randomization and \n\nare vulnerable to adversary attack.\n  • Privacy preservation at the cost of data utility is not appreciated and hence randomi-\n\nzation may not be suitable for privacy preservation especially attribute disclosure.\n\nTable 4 T closeness privacy preservation technique\n\nSno Zip Age Salary Disease\n\n1 576** 2* 5k Cardiac problem\n\n2 576** 2* 16k Cancer\n\n3 576** 2* 9k Skin allergy\n\n4 5790* > 40 20k Skin allergy\n\n5 5790* > 40 42k Cardiac problem\n\n6 5790* > 40 8k Flu\n\n\n\nPage 6 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nData distribution technique\n\nIn this technique, the data is distributed across many sites. Distribution of the data can \nbe done in two ways:\n\ni. Horizontal distribution of data\nii. Vertical distribution of data\n\nHorizontal distribution When data is distributed across many sites with same attrib-\nutes then the distribution is said to be horizontal distribution which is described in \nFig. 1.\n\nHorizontal distribution of data can be applied only when some aggregate functions or \noperations are to be applied on the data without actually sharing the data. For example, \nif a retail store wants to analyse their sales across various branches, they may employ \nsome analytics which does computations on aggregate data. However, as part of data \nanalysis the data holder may need to share the data with third party analyst which may \nlead to privacy breach. Classification and Clustering algorithms can be applied on dis-\ntributed data but it does not ensure privacy. If the data is distributed across different \nsites which belong to different organizations, then results of aggregate functions may \nhelp one party in detecting the data held with other parties. In such situations we expect \nall participating sites to be honest with each other [21].\n\nVertical distribution of data When Person specific information is distributed across \ndifferent sites under custodian of different organizations, then the distribution is called \nvertical distribution as shown in Fig. 2. For example, in crime investigations, the police \nofficials would like to know details of a particular criminal which include health, profes-\nsion, financial, personal etc. All this information may not be available at one site. Such a \ndistribution is called vertical distribution where each site holds few set of attributes of a \nperson. When some analytics has to be done data has to be pooled in from all these sites \nand there is a vulnerability of privacy breach.\n\nIn order to perform data analytics on vertically distributed data, where the attributes \nare distributed across different sites under custodian of different parties, it is highly \n\nFig. 1 Distribution of sales data across different sites\n\n Site 1 Site 2 1 to 10K 10K to 20 sales K sales records records Site 3 20K to 30K sales records \n\n\n\nPage 7 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\ndifficult to ensure privacy if the datasets are shared. For example, as part of a police \ninvestigation, the investigating officer wants to access some information about the \naccused from his employer, health department, bank to gain more insights about the \ncharacter of the person. In this process some of the personal and sensitive information \nof the accused may be disclosed to investigating officer leading to personal embarrass-\nment or abuse. Anonymization cannot be applied when entire records are not needed \nfor analytics. Distribution of data will not ensure privacy preservation but it closely \noverlaps with cryptographic techniques.\n\nCryptographic techniques\n\nThe data holder may encrypt the data before releasing the same for analytics. But \nencrypting large scale data using conventional encryption techniques is highly difficult \nand must be applied only during data collection time. Differential privacy techniques \nhave already been applied where some aggregate computations on the data are done \nwithout actually sharing the inputs. For example, if x and y are two data items then a \nfunction F(x, y) will be computed to gain some aggregate information from both x and \ny without actually sharing x and y. This can be applied on when x and y are held with \ndifferent parties as in the case of vertical distribution. However, if the data is at single \nlocation under the custodian of a single organization, then differential privacy can-\nnot be employed. Another similar technique called secure multiparty computation has \nbeen used but proved to be inadequate in privacy preservation. Data utility will be less \nif encryption is applied during data analytics. Thus encryption is not only difficult to \nimplement but it reduces the data utility [22].\n\nMultidimensional Sensitivity Based Anonymization (MDSBA)\n\nBottom up Generalization [23] and Top down Generalization [24] are the conventional \nmethods of Anonymization which were applied on well represented structured data \nrecords. However, applying the same on large scale data sets is very difficult leading to \n\nFig. 2 Vertical distribution of person specific data\n\n Health Department Data under Personal Bank custodian of different (email, social network organizations accounts etc) Employer site \n\n\n\nPage 8 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nissues of scalability and information loss. Multidimensional Sensitivity Based Anonymi-\nzation is a improved version of Anonymization proved to be more effective than conven-\ntional Anonymization techniques.\n\nMultidimensional Sensitivity Based Anonymization is an improved Anonymization \n[25] technique such that it can be applied on large data sets with reduced loss of informa-\ntion and predefined quasi identifiers. As part of this technique Apache MAP REDUCE \n[26] framework has been used to handle large data sets. In conventional Hadoop Distrib-\nuted Files System, the data will be divided into blocks of either 64 MB or 128 MB each \nand distributed across different nodes without considering the data inside the blocks. \nAs part of Multidimensional Sensitivity Based Anonymization [27] technique the data is \nsplit into different bags based on the probability distribution of the quasi identifiers by \nmaking use of filters in Apache Pig scripting language.\n\nMultidimensional Sensitivity Based Anonymization makes use of bottom up generali-\nzation but on a set of attributes with certain class values where class represents a sensi-\ntive attributes. Data distribution was made effectively when compared to conventional \nmethod of blocks. Data Anonymization was done using four quasi identifiers using \nApache Pig.\n\nSince the data is vertically partitioned into different groups, it can protect from back-\nground knowledge attack if the bag contains only few attributes. This method also \nmakes it difficult to map the data with external sources to disclose any person specific \ninformation.\n\nIn this method, the implementation was done using Apache Pig. Apache Pig is a script-\ning language, hence development effort is less. However, code efficiency of Apache Pig is \nrelatively less when compared to Map Reduce job because ultimately every Apache Pig \nscript has to be converted into a Map Reduce job. Multidimensional Sensitivity Based \nAnonymization [28] is more appropriate for large scale data but only when the data is at \nrest. Multidimensional Sensitivity Based Anonymization cannot be applied for stream-\ning data.\n\nAnalysis\nVarious privacy preservation techniques have been studied with respect to features \nincluding, type of data, data utility, attribute preservation and complexity. The compari-\nson of various privacy preservation techniques is shown in Table 5.\n\nTable 5 Comparison of privacy preservation techniques\n\nFeatures Privacy preservation techniques\n\nAnonymization \ntechniques\n\nCryptographic \ntechniques\n\nData \ndistribution\n\nRandomization MDSBA\n\nSuitability for unstructured data No No No No Yes\n\nAttribute preservation No No No Yes Yes\n\nDamage to data utility No No Yes No Yes\n\nVery complex to apply No Yes Yes Yes Yes\n\nAccuracy of results of data \nanalytics\n\nNo Yes No No No\n\n\n\nPage 9 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nResults and discussions\nAs part of systematic literature review, it has been observed that all existing mecha-\nnisms of privacy preservation are with respect to structured data. More than 80% of data \nbeing generated today is unstructured [29]. As such, there is a need to address following \nchallenges.\n\ni. Develop concrete solution to protect privacy in both structured and unstructured \ndata.\n\nii. Scalable and robust techniques to be developed to handle large scale heterogeneous \ndata sets.\n\niii. Data should be allowed to stay in its native form without need for transformation \nand data analytics can be carried out while ensuring privacy preservation.\n\niv. New techniques apart from Anonymization must be developed to ensure protection \nagainst key privacy threats which include identity disclosure, discrimination, surveil-\nlance etc.\n\nv. Maximizing data utility while ensuring data privacy.\n\nConclusion\nNo concrete solution for unstructured data has been developed yet. Conventional \ndata mining algorithms can be applied for classification and clustering problems but \ncannot be used in privacy preservation especially when dealing with person specific \ninformation. Machine learning and soft computing techniques can be used to develop \nnew and more appropriate solution to privacy problems which include identity dis-\nclosure that can lead to personal embarrassment and abuse.\n\nThere is a strong need for law enforcement by governments of all countries to \nensure individual privacy. European Union [30] is making an attempt to enforce pri-\nvacy preservation law. Apart from technological solutions, there is a strong need to \ncreate awareness among the people regarding privacy hazards to safeguard them-\nselves form privacy breaches. One of the serious privacy threats is smart phone. Lot \nof personal information in the form of contacts, messages, chats and files are being \naccessed by many apps running in our smart phone without our knowledge. Most \nof the time people do not even read the privacy statement before installing any app. \nHence there is a strong need to educate people on the various vulnerabilities which \ncan contribute to leakage of private information.\n\nWe propose a novel privacy preservation model based on Data Lake concept to \nhold variety of data from diverse sources. Data lake is a repository to hold data from \ndiverse sources in their raw format [31, 32]. Data ingestion from variety of sources can \nbe done using Apache Flume and an intelligent algorithm based on machine learning \ncan be applied to identify sensitive attributes dynamically [33, 34]. The algorithm will \nbe trained with existing data sets with known sensitive attributes and rigorous train-\ning of the model will help in predicting the sensitive attributes in a given data set [35]. \nAccuracy of the model can be improved by adding more layers of training leading \nto deep learning techniques [36]. Advanced computing techniques like Apache Spark \ncan be used in implementing privacy preserving algorithms which is a distributed \n\n\n\nPage 10 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nmassive parallel computing with in memory processing to ensure very fast processing \n[37]. The proposed model is shown in Fig. 3.\n\nData analytics is done on the data collected from various sources. If an ecommerce \nsite would like to perform data analytics, they need transactional data, website logs and \ncustomers opinion through social media pages. A Data lake is used to collect data from \ndifferent sources. Apache Flume is used to ingest data from social media sites, website \nlogs into Hadoop Distributed File System(HDFS). Using SQOOP relational data can be \nloaded into HDFS.\n\nIn Data lake the data can remain in its native form which is either structured or \nunstructured. When data has to be processed, it can be transformed into HIVE tables. A \nHadoop map reduce job using machine learning can be executed on the data to classify \nthe sensitive attributes [38]. The data can be vertically distributed to separate the sensi-\ntive attributes from rest of the data and apply tokenization to map the vertically distrib-\nuted data. The data without any sensitive attributes can be published for data analytics.\n\nAbbreviations\nCCTV: closed circuit television; MDSBA: Multidimensional Sensitivity Based Anonymization.\n\nAuthors’ contributions\nPRMR: as part of Ph.D. work I have done my literature survey and submitted my work in the form of a paper. SMK: \nsupported me in compiling the paper. APSK: suggested necessary amendments and helped in revising the paper. All \nauthors read and approved the final manuscript.\n\nAuthor details\n1 Department of Computer Science and Engineering, MLR Institute of Technology, Hyderabad, India. 2 Department \nof Computer Science and Engineering, Sri Venkateswara College of Engineering, Tirupati, Andhra Pradesh, India. \n3 Department of Computer Science and Engineering, JNTU Anantapur, Anantapuramu, Andhra Pradesh, India. 4 JNTU \nAnantapur, Anantapur, Andhra Pradesh, India. \n\nAcknowledgements\nI would like to thank my guides, for supporting my work and for suggesting necessary corrections.\n\nData Lake\n\nSqoop to load data from RDBMS\n\nApache \nFlume \nto load \nsocial \nmedia \ndata\n\nLoad data from\ndifferent sources\nand varie�es into\nHive Table for\nprocessing\n\nHadoop\nMap\nReduce\nJob to\nclassify\nsensi�ve\ndata\n\nNovel Privacy \nPreserva�on \nalgorithm \nbased on \nver�cal \ndistribu�on and \ntokeniza�on\n\nFig. 3 A Novel privacy preservation model based on vertical distribution and tokenization\n\n\n\nPage 11 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nAvailability of data and materials\nIf any one is interested in our work, we are ready to provide more details of the map reduce job which we have \nexecuted and the data processing techniques applied. However the data is used in our work, is freely available in many \nrepositories.\n\nFunding\nNo Funding.\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nReceived: 21 March 2018   Accepted: 4 September 2018\n\nReferences\n 1. Ducange Pietro, Pecori Riccardo, Mezzina Paolo. A glimpse on big data analytics in the framework of marketing \n\nstrategies. Soft Comput. 2018;22(1):325–42.\n 2. Chauhan Arun, Kummamuru Krishna, Toshniwal Durga. Prediction of places of visit using tweets. Knowl Inf Syst. \n\n2017;50(1):145–66.\n 3. Yang D, Bingqing Q, Cudre-Mauroux P. Privacy-preserving social media data publishing for personalized ranking-\n\nbased recommendation. IEEE Trans Knowl Data Eng. 2018. ISSN (Print):1041-4347, ISSN (Electronic):1558-2191.\n 4. Liu Y et al. A practical privacy-preserving data aggregation (3PDA) scheme for smart grid. IEEE Trans Ind Inf. 2018.\n 5. Duncan GT et al. Disclosure limitation methods and information loss for tabular data. In: Confidentiality, disclosure \n\nand data access: theory and practical applications for statistical agencies. 2001. p. 135–166.\n 6. Duncan GT, Diane L. Disclosure-limited data dissemination. J Am Stat Assoc. 1986;81(393):10–8.\n 7. Lambert Diane. Measures of disclosure risk and harm. J Off Stat. 1993;9(2):313.\n 8. Spiller K, et al. Data privacy: users’ thoughts on quantified self personal data. Self-Tracking. Cham: Palgrave Macmil-\n\nlan; 2018. p. 111–24.\n 9. Hettig M, Kiss E, Kassel J-F, Weber S, Harbach M. Visualizing risk by example: demonstrating threats arising from \n\nandroid apps. In: Smith M, editor. Symposium on usable privacy and security (SOUPS), Newcastle, UK, July 24–26, \n2013.\n\n 10. Bayardo RJ, Agrawal A. Data privacy through optimal k-anonymization. In: Proceedings 21st international confer-\nence on data engineering, 2005 (ICDE 2005). Piscataway: IEEE; 2005.\n\n 11. Iyengar S. Transforming data to satisfy privacy constraints. In: Proceedings of the eighth ACM SIGKDD international \nconference on knowledge discovery and data mining. New York: ACM; 2002.\n\n 12. LeFevre K, DeWitt DJ, Ramakrishnan R. Incognito: efficient full-domain k-anonymity. In: Proceedings of the 2005 \nACM SIGMOD international conference on management of data. New York: ACM; 2005.\n\n 13. LeFevre K, DeWitt DJ, Ramakrishnan R. Mondrian multidimensional k-anonymity. In: Proceedings of the 22nd inter-\nnational conference (ICDE’06) on data engineering, 2006. New York: ACM; 2006.\n\n 14. Samarati, Pierangela, and Latanya Sweeney. In: Protecting privacy when disclosing information: k-anonymity and its \nenforcement through generalization and suppression. Technical report, SRI International, 1998.\n\n 15. Sweeney Latanya. Achieving k-anonymity privacy protection using generalization and suppression. In J Uncertain \nFuzziness Knowl Based Syst. 2002;10(05):571–88.\n\n 16. Sweeney Latanya. k-Anonymity: a model for protecting privacy. Int J Uncertain, Fuzziness Knowl Based Syst. \n2002;10(05):557–70.\n\n 17. Williams R. On the complexity of optimal k-anonymity. In: Proc. 23rd ACM SIGMOD-SIGACT-SIGART symp. principles \nof database systems (PODS). New York: ACM; 2004.\n\n 18. Machanavajjhala A et al. L-diversity: privacy beyond k-anonymity. In: Proceedings of the 22nd international confer-\nence on data engineering (ICDE’06), 2006. Piscataway: IEEE; 2006.\n\n 19. Xiao X, Yufei T. Personalized privacy preservation. In: Proceedings of the 2006 ACM SIGMOD international confer-\nence on Management of data. New York: ACM; 2006.\n\n 20. Rubner Y, Tomasi T, Guibas LJ. The earth mover’s distance as a metric for image retrieval. Int J Comput Vision. \n2000;40(2):99–121.\n\n 21. Aggarwal CC, Philip SY. A general survey of privacy-preserving data mining models and algorithms. Privacy-preserv-\ning data mining. Springer: US; 2008. p. 11–52.\n\n 22. Jiang R, Lu R, Choo KK. Achieving high performance and privacy-preserving query over encrypted multidimensional \nbig metering data. Future Gen Comput Syst. 2018;78:392–401.\n\n 23. Wang K, Yu PS, Chakraborty S. Bottom-up generalization: A data mining solution to privacy protection. In: Fourth \nIEEE international conference on data mining, 2004 (ICDM’04). Piscataway: IEEE; 2004.\n\n 24. Fung BCM, Wang K, Yu PS. Top-down specialization for information and privacy preservation. In: Proceedings 21st \ninternational conference on data engineering, 2005 (ICDE 2005). Piscataway: IEEE; 2005.\n\n 25. Zhang X et al. A MapReduce based approach of scalable multidimensional anonymization for big data privacy \npreservation on cloud. In: Third international conference on cloud and green computing (CGC), 2013. Piscataway: \nIEEE; 2013.\n\n Published online: 22 September 2018 \n\n\n\nPage 12 of 12Ram Mohan Rao et al. J Big Data  (2018) 5:33 \n\n 26. Zhang X, et al. A scalable two-phase top-down specialization approach for data anonymization using mapreduce \non cloud. IEEE Trans Parallel Distrib Syst. 2014;25(2):363–73.\n\n 27. Al-Zobbi M, Shahrestani S, Ruan C. Improving MapReduce privacy by implementing multi-dimensional sensitivity-\nbased anonymization. J Big Data. 2017;4(1):45.\n\n 28. Al-Zobbi M, Shahrestani S, Ruan C. Implementing a framework for big data anonymity and analytics access control. \nIn: Trustcom/BigDataSE/ICESS, 2017 IEEE. Piscataway: IEEE; 2017.\n\n 29. Schneider C. IBM Blogs; 2016. https ://www.ibm.com/blogs /watso n/2016/05/bigge st-data-chall enges -might \n-not-even-know/.\n\n 30. TCS. Emphasizing the need for government regulations on data privacy; 2016. https ://www.tcs.com/conte nt/dam/\ntcs/pdf/techn ologi es/Cyber -Secur ity/Abstr act/Stren gthen ing-Priva cy-Pro",
      "text": [
        "",
        "Site 1 Site 2 1 to 10K 10K to 20 sales K sales records records Site 3 20K to 30K sales records",
        "Health Department Data under Personal Bank custodian of different (email, social network organizations accounts etc) Employer site",
        "Published online: 22 September 2018"
      ],
      "layoutText": [
        "{\"language\":\"en\",\"text\":\"\",\"lines\":[],\"words\":[]}",
        "{\"language\":\"en\",\"text\":\"Site 1 Site 2 1 to 10K 10K to 20 sales K sales records records Site 3 20K to 30K sales records\",\"lines\":[{\"boundingBox\":[{\"x\":135,\"y\":145},{\"x\":246,\"y\":144},{\"x\":248,\"y\":184},{\"x\":134,\"y\":184}],\"text\":\"Site 1\"},{\"boundingBox\":[{\"x\":436,\"y\":133},{\"x\":553,\"y\":131},{\"x\":553,\"y\":174},{\"x\":436,\"y\":176}],\"text\":\"Site 2\"},{\"boundingBox\":[{\"x\":105,\"y\":218},{\"x\":282,\"y\":218},{\"x\":282,\"y\":259},{\"x\":105,\"y\":258}],\"text\":\"1 to 10K\"},{\"boundingBox\":[{\"x\":392,\"y\":207},{\"x\":596,\"y\":206},{\"x\":596,\"y\":246},{\"x\":392,\"y\":248}],\"text\":\"10K to 20\"},{\"boundingBox\":[{\"x\":143,\"y\":274},{\"x\":241,\"y\":272},{\"x\":241,\"y\":313},{\"x\":143,\"y\":313}],\"text\":\"sales\"},{\"boundingBox\":[{\"x\":418,\"y\":259},{\"x\":567,\"y\":260},{\"x\":567,\"y\":301},{\"x\":418,\"y\":300}],\"text\":\"K sales\"},{\"boundingBox\":[{\"x\":115,\"y\":327},{\"x\":268,\"y\":324},{\"x\":268,\"y\":364},{\"x\":115,\"y\":366}],\"text\":\"records\"},{\"boundingBox\":[{\"x\":416,\"y\":313},{\"x\":569,\"y\":311},{\"x\":569,\"y\":352},{\"x\":417,\"y\":355}],\"text\":\"records\"},{\"boundingBox\":[{\"x\":289,\"y\":461},{\"x\":404,\"y\":461},{\"x\":404,\"y\":504},{\"x\":289,\"y\":506}],\"text\":\"Site 3\"},{\"boundingBox\":[{\"x\":225,\"y\":535},{\"x\":468,\"y\":534},{\"x\":468,\"y\":577},{\"x\":225,\"y\":579}],\"text\":\"20K to 30K\"},{\"boundingBox\":[{\"x\":216,\"y\":589},{\"x\":478,\"y\":588},{\"x\":479,\"y\":632},{\"x\":216,\"y\":634}],\"text\":\"sales records\"}],\"words\":[{\"boundingBox\":[{\"x\":134,\"y\":144},{\"x\":210,\"y\":144},{\"x\":210,\"y\":184},{\"x\":134,\"y\":184}],\"text\":\"Site\"},{\"boundingBox\":[{\"x\":224,\"y\":144},{\"x\":246,\"y\":144},{\"x\":246,\"y\":183},{\"x\":224,\"y\":184}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":436,\"y\":133},{\"x\":511,\"y\":132},{\"x\":512,\"y\":175},{\"x\":436,\"y\":176}],\"text\":\"Site\"},{\"boundingBox\":[{\"x\":521,\"y\":132},{\"x\":546,\"y\":131},{\"x\":546,\"y\":174},{\"x\":521,\"y\":175}],\"text\":\"2\"},{\"boundingBox\":[{\"x\":106,\"y\":218},{\"x\":126,\"y\":218},{\"x\":127,\"y\":259},{\"x\":106,\"y\":259}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":134,\"y\":218},{\"x\":176,\"y\":218},{\"x\":176,\"y\":259},{\"x\":135,\"y\":259}],\"text\":\"to\"},{\"boundingBox\":[{\"x\":193,\"y\":218},{\"x\":264,\"y\":220},{\"x\":263,\"y\":259},{\"x\":193,\"y\":259}],\"text\":\"10K\"},{\"boundingBox\":[{\"x\":393,\"y\":207},{\"x\":461,\"y\":207},{\"x\":460,\"y\":248},{\"x\":393,\"y\":247}],\"text\":\"10K\"},{\"boundingBox\":[{\"x\":486,\"y\":207},{\"x\":528,\"y\":207},{\"x\":527,\"y\":248},{\"x\":485,\"y\":248}],\"text\":\"to\"},{\"boundingBox\":[{\"x\":542,\"y\":207},{\"x\":592,\"y\":206},{\"x\":590,\"y\":247},{\"x\":541,\"y\":248}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":143,\"y\":273},{\"x\":238,\"y\":272},{\"x\":239,\"y\":313},{\"x\":143,\"y\":314}],\"text\":\"sales\"},{\"boundingBox\":[{\"x\":418,\"y\":260},{\"x\":441,\"y\":260},{\"x\":441,\"y\":301},{\"x\":418,\"y\":301}],\"text\":\"K\"},{\"boundingBox\":[{\"x\":463,\"y\":260},{\"x\":567,\"y\":261},{\"x\":567,\"y\":301},{\"x\":463,\"y\":301}],\"text\":\"sales\"},{\"boundingBox\":[{\"x\":116,\"y\":329},{\"x\":267,\"y\":324},{\"x\":267,\"y\":366},{\"x\":116,\"y\":366}],\"text\":\"records\"},{\"boundingBox\":[{\"x\":417,\"y\":315},{\"x\":568,\"y\":312},{\"x\":568,\"y\":353},{\"x\":417,\"y\":355}],\"text\":\"records\"},{\"boundingBox\":[{\"x\":289,\"y\":461},{\"x\":368,\"y\":461},{\"x\":368,\"y\":505},{\"x\":289,\"y\":506}],\"text\":\"Site\"},{\"boundingBox\":[{\"x\":378,\"y\":461},{\"x\":403,\"y\":461},{\"x\":403,\"y\":505},{\"x\":378,\"y\":505}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":226,\"y\":535},{\"x\":297,\"y\":536},{\"x\":297,\"y\":580},{\"x\":226,\"y\":580}],\"text\":\"20K\"},{\"boundingBox\":[{\"x\":321,\"y\":536},{\"x\":364,\"y\":535},{\"x\":364,\"y\":579},{\"x\":321,\"y\":580}],\"text\":\"to\"},{\"boundingBox\":[{\"x\":376,\"y\":535},{\"x\":451,\"y\":534},{\"x\":451,\"y\":578},{\"x\":376,\"y\":579}],\"text\":\"30K\"},{\"boundingBox\":[{\"x\":217,\"y\":593},{\"x\":313,\"y\":590},{\"x\":312,\"y\":634},{\"x\":216,\"y\":633}],\"text\":\"sales\"},{\"boundingBox\":[{\"x\":321,\"y\":589},{\"x\":478,\"y\":590},{\"x\":478,\"y\":632},{\"x\":321,\"y\":634}],\"text\":\"records\"}]}",
        "{\"language\":\"en\",\"text\":\"Health Department Data under Personal Bank custodian of different (email, social network organizations accounts etc) Employer site\",\"lines\":[{\"boundingBox\":[{\"x\":454,\"y\":77},{\"x\":573,\"y\":76},{\"x\":573,\"y\":111},{\"x\":454,\"y\":111}],\"text\":\"Health\"},{\"boundingBox\":[{\"x\":409,\"y\":122},{\"x\":614,\"y\":123},{\"x\":614,\"y\":164},{\"x\":409,\"y\":163}],\"text\":\"Department\"},{\"boundingBox\":[{\"x\":421,\"y\":330},{\"x\":614,\"y\":330},{\"x\":614,\"y\":367},{\"x\":421,\"y\":368}],\"text\":\"Data under\"},{\"boundingBox\":[{\"x\":829,\"y\":331},{\"x\":966,\"y\":331},{\"x\":966,\"y\":363},{\"x\":829,\"y\":364}],\"text\":\"Personal\"},{\"boundingBox\":[{\"x\":97,\"y\":397},{\"x\":205,\"y\":396},{\"x\":206,\"y\":436},{\"x\":98,\"y\":438}],\"text\":\"Bank\"},{\"boundingBox\":[{\"x\":408,\"y\":376},{\"x\":626,\"y\":375},{\"x\":626,\"y\":412},{\"x\":408,\"y\":415}],\"text\":\"custodian of\"},{\"boundingBox\":[{\"x\":442,\"y\":419},{\"x\":587,\"y\":419},{\"x\":587,\"y\":456},{\"x\":442,\"y\":457}],\"text\":\"different\"},{\"boundingBox\":[{\"x\":790,\"y\":387},{\"x\":1004,\"y\":385},{\"x\":1005,\"y\":423},{\"x\":791,\"y\":426}],\"text\":\"(email, social\"},{\"boundingBox\":[{\"x\":832,\"y\":432},{\"x\":962,\"y\":430},{\"x\":963,\"y\":460},{\"x\":832,\"y\":462}],\"text\":\"network\"},{\"boundingBox\":[{\"x\":399,\"y\":467},{\"x\":629,\"y\":462},{\"x\":630,\"y\":501},{\"x\":399,\"y\":507}],\"text\":\"organizations\"},{\"boundingBox\":[{\"x\":792,\"y\":472},{\"x\":997,\"y\":472},{\"x\":997,\"y\":502},{\"x\":792,\"y\":503}],\"text\":\"accounts etc)\"},{\"boundingBox\":[{\"x\":412,\"y\":667},{\"x\":614,\"y\":669},{\"x\":614,\"y\":717},{\"x\":412,\"y\":716}],\"text\":\"Employer\"},{\"boundingBox\":[{\"x\":480,\"y\":724},{\"x\":548,\"y\":723},{\"x\":547,\"y\":758},{\"x\":478,\"y\":758}],\"text\":\"site\"}],\"words\":[{\"boundingBox\":[{\"x\":455,\"y\":77},{\"x\":565,\"y\":77},{\"x\":566,\"y\":111},{\"x\":455,\"y\":112}],\"text\":\"Health\"},{\"boundingBox\":[{\"x\":412,\"y\":122},{\"x\":613,\"y\":123},{\"x\":612,\"y\":165},{\"x\":409,\"y\":163}],\"text\":\"Department\"},{\"boundingBox\":[{\"x\":422,\"y\":331},{\"x\":504,\"y\":332},{\"x\":505,\"y\":368},{\"x\":422,\"y\":368}],\"text\":\"Data\"},{\"boundingBox\":[{\"x\":512,\"y\":332},{\"x\":613,\"y\":331},{\"x\":614,\"y\":367},{\"x\":513,\"y\":368}],\"text\":\"under\"},{\"boundingBox\":[{\"x\":829,\"y\":332},{\"x\":965,\"y\":333},{\"x\":966,\"y\":363},{\"x\":830,\"y\":365}],\"text\":\"Personal\"},{\"boundingBox\":[{\"x\":97,\"y\":397},{\"x\":196,\"y\":396},{\"x\":197,\"y\":437},{\"x\":97,\"y\":438}],\"text\":\"Bank\"},{\"boundingBox\":[{\"x\":408,\"y\":377},{\"x\":570,\"y\":375},{\"x\":571,\"y\":413},{\"x\":408,\"y\":416}],\"text\":\"custodian\"},{\"boundingBox\":[{\"x\":581,\"y\":375},{\"x\":623,\"y\":375},{\"x\":623,\"y\":413},{\"x\":581,\"y\":413}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":442,\"y\":420},{\"x\":587,\"y\":420},{\"x\":586,\"y\":456},{\"x\":442,\"y\":458}],\"text\":\"different\"},{\"boundingBox\":[{\"x\":791,\"y\":387},{\"x\":899,\"y\":386},{\"x\":900,\"y\":421},{\"x\":793,\"y\":427}],\"text\":\"(email,\"},{\"boundingBox\":[{\"x\":906,\"y\":386},{\"x\":1004,\"y\":385},{\"x\":1003,\"y\":423},{\"x\":907,\"y\":421}],\"text\":\"social\"},{\"boundingBox\":[{\"x\":833,\"y\":434},{\"x\":954,\"y\":431},{\"x\":955,\"y\":461},{\"x\":833,\"y\":463}],\"text\":\"network\"},{\"boundingBox\":[{\"x\":400,\"y\":467},{\"x\":629,\"y\":462},{\"x\":629,\"y\":503},{\"x\":400,\"y\":508}],\"text\":\"organizations\"},{\"boundingBox\":[{\"x\":794,\"y\":474},{\"x\":932,\"y\":472},{\"x\":932,\"y\":503},{\"x\":794,\"y\":503}],\"text\":\"accounts\"},{\"boundingBox\":[{\"x\":938,\"y\":472},{\"x\":997,\"y\":472},{\"x\":997,\"y\":503},{\"x\":938,\"y\":503}],\"text\":\"etc)\"},{\"boundingBox\":[{\"x\":415,\"y\":668},{\"x\":614,\"y\":671},{\"x\":611,\"y\":718},{\"x\":412,\"y\":716}],\"text\":\"Employer\"},{\"boundingBox\":[{\"x\":478,\"y\":723},{\"x\":544,\"y\":723},{\"x\":544,\"y\":758},{\"x\":478,\"y\":758}],\"text\":\"site\"}]}",
        "{\"language\":\"en\",\"text\":\"Published online: 22 September 2018\",\"lines\":[{\"boundingBox\":[{\"x\":4,\"y\":14},{\"x\":1064,\"y\":15},{\"x\":1064,\"y\":74},{\"x\":4,\"y\":72}],\"text\":\"Published online: 22 September 2018\"}],\"words\":[{\"boundingBox\":[{\"x\":4,\"y\":15},{\"x\":272,\"y\":15},{\"x\":272,\"y\":72},{\"x\":4,\"y\":68}],\"text\":\"Published\"},{\"boundingBox\":[{\"x\":292,\"y\":15},{\"x\":494,\"y\":15},{\"x\":494,\"y\":74},{\"x\":292,\"y\":73}],\"text\":\"online:\"},{\"boundingBox\":[{\"x\":505,\"y\":15},{\"x\":575,\"y\":15},{\"x\":575,\"y\":74},{\"x\":505,\"y\":74}],\"text\":\"22\"},{\"boundingBox\":[{\"x\":595,\"y\":15},{\"x\":904,\"y\":16},{\"x\":904,\"y\":73},{\"x\":595,\"y\":74}],\"text\":\"September\"},{\"boundingBox\":[{\"x\":916,\"y\":16},{\"x\":1058,\"y\":16},{\"x\":1058,\"y\":72},{\"x\":916,\"y\":73}],\"text\":\"2018\"}]}"
      ]
    },
    {
      "@search.score": 2.585697,
      "content": "\nRawnaque et al. Brain Inf.            (2020) 7:10  \nhttps://doi.org/10.1186/s40708-020-00109-x\n\nREVIEW\n\nTechnological advancements \nand opportunities in Neuromarketing: \na systematic review\nFerdousi Sabera Rawnaque1*, Khandoker Mahmudur Rahman2, Syed Ferhat Anwar3, Ravi Vaidyanathan4, \nTom Chau5, Farhana Sarker6 and Khondaker Abdullah Al Mamun1,7\n\nAbstract \n\nNeuromarketing has become an academic and commercial area of interest, as the advancements in neural record-\ning techniques and interpreting algorithms have made it an effective tool for recognizing the unspoken response \nof consumers to the marketing stimuli. This article presents the very first systematic review of the technological \nadvancements in Neuromarketing field over the last 5 years. For this purpose, authors have selected and reviewed a \ntotal of 57 relevant literatures from valid databases which directly contribute to the Neuromarketing field with basic \nor empirical research findings. This review finds consumer goods as the prevalent marketing stimuli used in both \nproduct and promotion forms in these selected literatures. A trend of analyzing frontal and prefrontal alpha band sig-\nnals is observed among the consumer emotion recognition-based experiments, which corresponds to frontal alpha \nasymmetry theory. The use of electroencephalogram (EEG) is found favorable by many researchers over functional \nmagnetic resonance imaging (fMRI) in video advertisement-based Neuromarketing experiments, apparently due to \nits low cost and high time resolution advantages. Physiological response measuring techniques such as eye tracking, \nskin conductance recording, heart rate monitoring, and facial mapping have also been found in these empirical stud-\nies exclusively or in parallel with brain recordings. Alongside traditional filtering methods, independent component \nanalysis (ICA) was found most commonly in artifact removal from neural signal. In consumer response prediction and \nclassification, Artificial Neural Network (ANN), Support Vector Machine (SVM) and Linear Discriminant Analysis (LDA) \nhave performed with the highest average accuracy among other machine learning algorithms used in these litera-\ntures. The authors hope, this review will assist the future researchers with vital information in the field of Neuromarket-\ning for making novel contributions.\n\nKeywords: Neuromarketing, Neural recording, Machine learning algorithm, Brain computer interface, Marketing\n\n© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and \nthe source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material \nin this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material \nis not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the \npermitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creat iveco \nmmons .org/licen ses/by/4.0/.\n\n1 Introduction\nNeuromarketing, an application of the non-invasive \nbrain–computer interface (BCI) technology, has emerged \nas an interdisciplinary bridge between neuroscience and \nmarketing that has changed the perception of market-\ning research. Marketing is the channel between prod-\nuct and consumers which determines the ultimate sale. \n\nWithout effective marketing, a good product fails to \ninform, engage and sustain its targeted audiences [1]. \nThe expanding economy with new businesses is continu-\nously evolving with changing consumer preferences. It \nis hard for the businesses to grow and sustain without \nhaving quantitative or qualitative assessment from their \nconsumers. Newly launched products need even more \neffective marketing to successfully enter into a com-\npetitive market. However, traditional marketing renders \nonly by posteriori analysis of consumer response. Con-\nventional market research depends on surveys, focus \n\nOpen Access\n\nBrain Informatics\n\n*Correspondence:  frawnaque@umassd.edu\n1 Advanced Intelligent Multidisciplinary Systems Lab, Institute \nof Advanced Research, United International University, Dhaka, Bangladesh\nFull list of author information is available at the end of the article\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40708-020-00109-x&domain=pdf\n\n\nPage 2 of 19Rawnaque et al. Brain Inf.            (2020) 7:10 \n\ngroup discussion, personal interviews, field trials and \nobservations for collecting consumer feedback [2]. These \napproaches have the limitations of time requirement, \nhigh cost and unreliable information, which can often \nproduce inaccurate results. In contrast to the traditional \nmarketing research techniques, Neuromarketing allows \ncapturing consumers’ unspoken cognitive and emotional \nresponse to various marketing stimuli and can forecast \nconsumers’ purchase decisions.\n\nNeuromarketing uses non-invasive brain signal record-\ning techniques to directly measure the response of a \ncustomer’s brain to the marketing stimuli, supersed-\ning the traditional survey methods [3]. Functional mag-\nnetic resonance (fMRI), electroencephalography (EEG), \nmagnetoencephalography (MEG), transcranial mag-\nnetic stimulator (TMS), positron emission tomography \n(PET), functional near-infrared spectroscopy (fNIRS) etc. \nare some examples of neural recording devices used in \nNeuromarketing research. By obtaining neuronal activ-\nity from the brain using these devices, one can explore \nthe cognitive and emotional responses (i.e., like/dislike, \napproach/withdrawal) of a customer. Different stimuli \ntrigger associated response in a human brain and the \nresponse can be tracked by monitoring the change in \nneuronal signals or brainwaves [4]. Further, the signal \nand image processing techniques and machine learning \nalgorithms have enabled the researchers to measure, ana-\nlyze and interpret the possible meanings of brainwaves. \nThis opens a new door to detect, analyze and predict \nthe buying behavior of customers in marketing research. \nNow with the help of brain–computer interface, the men-\ntal states of a customer, i.e., excitement, engagement, \nwithdrawal, stress, etc., while experiencing a market-\ning stimuli can be captured [5]. Besides these brain sig-\nnal recording techniques, Neuromarketing also utilizes \nphysiological signals, i.e., eye tracking, heart rate and \nskin conductance measurements to gather the insight of \naudience’s physiological responses due to encountering \nstimuli. These neurophysiological signals with advanced \nspectral analysis and machine learning algorithms can \nnow provide nearly accurate depiction of consumers’ \npreferences and likes/dislikes [6–8].\n\nEarly years of Neuromarketing generated a contro-\nversy between the academician and the marketers due \nto its high promises and lack of groundwork. From \nthe claim of peeping into the consumer mind to find-\ning the buy buttons of human brain, Neuromarketing \nhas long been under the scrutiny of the academicians \nand researchers [9, 10]. However, academic research in \nthis field has started to pile up and the scope of Neuro-\nmarketing to reveal and predict consumer behavior is \ngradually becoming evident. Neuromarketing Science \nand Business Association (NMSBA) was established \n\nin 2012 to bridge the gap between academicians and \nNeuromarketers, and it is promoting Neuromarket-\ning research across the world with its annual event of \nNeuromarketing World Forum [11, 12]. It may be pro-\nposed that further dialogue may continue under such a \nplatform for further industry–academia collaboration. \nEvidently, more than 150 consumer neuroscience com-\npanies are commercially operating across the globe and \nbig brands (Google, Microsoft, Unilever, etc.) are using \ntheir insights to impact their consumers in a tailored and \nefficient way. Academic research, especially the high ana-\nlytical accuracy from the engineering part of Neuromar-\nketing has garnered this breakthrough and acceptance \nover the world. Hence, reviewing the building blocks of \nNeuromarketing is essential to evaluate its scopes and \ncapacities, and to contribute new perspective in this \nfield. Numerous literature reviews have been published \nfocusing the theoretical aspect of consumer neurosci-\nence, such as marketing, business ethics, management, \npsychology, consumer behavior, etc. [13–15]. However, \nsystematic literature review from the engineering per-\nspective with a focus on neural recording tools and inter-\npretational methodologies used in this field is absent. In \nthis regard, our article sets its premises to answer the fol-\nlowing questions:\n\n– What are the types of marketing stimuli currently \nbeing used in Neuromarketing?\n\n– What are the brain regions activated by these mar-\nketing stimuli?\n\n– What is the best brain signal recording tool currently \nbeing used in Neuromarketing research?\n\n– How are these brain signals preprocessed for further \nanalysis?\n\n– And what are the current methods or techniques \nused to interpret these brain signals?\n\nThese questions will allow us to gain a comprehensive \nknowledge on the up-to-date research scopes and tech-\nniques in consumer neuroscience. After this brief intro-\nduction, our methodology of conducting this systematic \nreview will be presented, followed by the state-of-the-art \nfindings corresponding to the aforementioned questions \nand synthesis of the important results. We concluded this \nreview with relevant inference from synthesized result \nand a recommendation for future researchers.\n\n2  Methodology\nThe systematic literature review is a process in which \na body of literature is collected, screened, selected, \nreviewed and assessed with a pre-specified objective for \nthe purpose of unbiased evidence collection and to reach \nan impartial conclusion [16]. Systematic review has the \n\n\n\nPage 3 of 19Rawnaque et al. Brain Inf.            (2020) 7:10  \n\nobligation to explicitly define its research question and to \naddress inclusion–exclusion criteria for setting the scope \nof the investigation. After exhaustive search of existing \nliteratures, articles should be selected based on their rel-\nevance, and the results of the selected studies must be \nsynthesized and assessed critically to achieve clear con-\nclusions [16].\n\nIn this systematic review, we would like to explore \nthe marketing stimuli used in Neuromarketing research \narticles over the last 5 years with their triggered brain \nregions. We would also like to focus on the technologi-\ncal tools used to capture brain signals from these regions, \nand finally deliberate on signal processing and analytical \nmethodologies used in these experiments.\n\nTherefore, the inclusion criteria defined here are  as \nfollows:\n\n– Literatures must be published in the field of Neuro-\nmarketing from 2015 to 2019.\n\n– Studies must use brain–computer interface and/or \nother physiological signal recording device in their \nNeuromarketing experiments.\n\n– Studies must have experimental findings from neu-\nral and/or biometric data used in Neuromarketing \nresearch.\n\nThe exclusion criteria for this review are set as:\n\n– Any other literature review on Neuromarketing are \nexcluded from this review.\n\n– Book chapters are excluded from this review. Since \nNeuromarketing is comparatively a new research \nfield, alongside relevant academic journal articles, \nbook chapters conducting empirical experiments \nusing BCI can only be included.\n\n– Literatures written/published in any language other \nthan English are excluded from this article.\n\nTo serve the purpose of this systematic literature \nreview, a total of 931 articles were found across the \n\ninternet by using the search item “Neuromarketing” \nand “Neuro-marketing” in valid databases. Among the \nscreened publications, Table  1 presents the database \nsource of selected 57 research articles including book \nchapters, which directly contribute to the Neuromarket-\ning field with basic or empirical research findings.\n\nAs for the aggregation of relevant existing literatures, \nthe researchers defined that the search for articles would \nbe performed in six databases—Science Direct, Emer-\nald Insight, Sage, IEEE Xplore, Wiley Online Library, \nand Taylor Francis Online. After the initial article accu-\nmulation, the articles were exhaustively screened by \nthe authors by reviewing their title, abstract, keywords \nand scope to match the objective of this research. Once \nthe studies met our aforementioned inclusion criteria, \nthey were selected for further review and critical analy-\nsis. Table 2 classifies the selected articles in terms of the \naforementioned dimensions.\n\nBy exploring the articles selected to develop this sys-\ntematic review, it was possible to successfully categorize \nthe trends and advancements in Neuromarketing field in \nfollowing dimensions:\n\n i. Marketing stimuli used in Neuromarketing \nresearch\n\n ii. Activation of the brain regions due to marketing \nstimuli\n\n iii. Neural response recording techniques\n iv. Brain signal processing in Neuromarketing\n v. Machine learning applications in Neuromarketing.\n\nSome of these Neuromarketing studies have used \neye tracking, heart rate, galvanic skin response, facial \naction coding, etc., with or without brain signal \nrecording techniques to gauge the consumer’s hidden \nresponse. As they are the response from autonomous \nnervous system (ANS), they have proven themselves \nas successful means of exploring consumer’s focus, \narousal, attention and withdrawal actions. Hence, this \nstudy includes articles those empirically used these \n\nTable 1 Number of articles found and selected\n\nName of the database Results: search “Neuromarketing” Results: search “Neuro-marketing” Articles selected\n\nScience direct 281 55 12\n\nWiley online 111 11 7\n\nEmerald insight 115 8 14\n\nIEEE 34 0 14\n\nSage 12 15 6\n\nTaylor Francis online 106 36 4\n\nTotal found: 806 Total found: 125 Total selected: 57\n\n\n\nPage 4 of 19Rawnaque et al. Brain Inf.            (2020) 7:10 \n\ntools to answer Neuromarketing questions, since this \nstudy mainly focuses on the engineering perspective. \nInterpreting the neural data with only statistical analy-\nsis has been out of scope of this paper.\n\n3  Systematic review on the advancements \nof Neuromarketing\n\nNeuromarketing research utilizes marketing strategies in \nthe form of stimuli, and aims to invoke, capture and ana-\nlyze activities occurring in different brain regions while \n\nTable 2 Studies selected on the dimensions of this review\n\nDimensions Published articles\n\ni. Marketing stimuli used in Neuromarketing Product Chew et al. [17], Yadava et al. [18], Rojas et al. [19], Pozharliev [20], Touchette \nand Lee [21], Marques et al. [22], Shen et al. [23], Çakir et al. [24], Hubert \net al. [25], Hsu and Chen et al. [26], Hoefer et al. [27], Gurbuj and Toga [28], \nWriessnegger et al. [29], Wang et al. [30], Wolfe et al. [31], Bosshard et al. [32], \nFehse et al. [33].\n\nPrice Çakar et al. [34], Marques et al. [22], Çakir et al. [24], Gong et al. [35], Pilelienė \nand Grigaliūnaitė [36], Hsu and Chen [26], Boccia et al. [37], Venkatraman \net al. [38], Baldo et al. [39].\n\nPromotion Soria Morillo et al. [40], Yang et al. [41], Cherubino et al. [42], Soria Morillo \net al. [43], Vasiljević et al. [44], Yang et al. [45], Pilelienė and Grigaliūnaitė \n[36], Daugherty et al. [46], Royo et al. [47], Etzold et al. [48], Chen et al. \n[49], Casado-Aranda et al. [50], Randolph and Pierquet [51], Nomura and \nMitsukura [52], Ungureanu et al. [53], Goyal and Singh [54], Oon et al. [55], \nSingh et al. [56].\n\nii. Activation of brain region due to marketing stimuli Soria Morillo et al. [40], Chew et al. [17], Cherubino et al. [42], Soria Morillo \net al. [43], Çakar et al. [34], Boksem and Smitds [57], Bhardwaj et al. [58], Ven-\nkatraman et al. [38], Touchette and Lee [21], Yang et al. [45], Marques et al. \n[22], Gong et al. [35], Gordon et al. [59], Krampe et al. [60], Hubert et al. [25], \nÇakir et al. [24], Holst and Henseler [61], Hsu and Cheng [62], Hoefer et al. \n[27], Chen et al. [49], Casado-Aranda et al. [50], Wang et al. [30], Jain et al. \n[63], Wolfe et al. [31], Bosshard et al. [32], Fehse et al. [33].\n\niii. Neural response recording techniques EEG Soria Morillo et al. [40], Yang et al. [41], Chew et al. [17], Cherubino et al. [42], \nSoria Morillo et al. [43], Yadava et al. [18], Doborjeh et al. [64], Çakar et al. \n[34], Kaur et al. [65], Baldo et al. [19], Boksem and Smitds [57], Pozharliev \net al. [20], Venkatraman [38], Touchette and Lee [21], Yang et al. [45], Pilelienė \nand Grigaliūnaitė [36], Shen et al. [23], Daugherty et al. [46], Royo et al. [47], \nGong et al. [35], Gordon et al. [59], Hsu and Chen et al. [26], Hoefer et al. [27], \nRandolph and Pierquet [51], Nomura and Mitsukura [52], Bhardwaj et al. \n[58], Fan and Touyama [66], Rakshit and Lahiri [67], Jain et al. [63],Ogino and \nMitsukura [68], Oon et al. [55], Bosshard et al. [32].\n\nfMRI Venkatraman et al. [38], Marques et al. [22], Hubert et al. [25], Hsu and Cheng \n[62], Chen et al. [49], Casado-Aranda et al. [50], Wang et al. [30], Wolfe et al. \n[31], Fehse et al. [33].\n\nfNIRS Çakir et al. [24], Krampe et al. [60].\n\nEMG Missagila et al. [69]\n\nEye tracking Venkatraman [38], Rojas et al. [19], Pilelienė and Grigaliūnaitė [36], Çakar et al. \n[34], Ceravolo et al. [70], Ungureanu et al. [53]\n\nGalvanic skin \nresponse, \nheart rate\n\nCherubino et al. [42], Çakar et al. [34], Magdin et al. [71], Goyal and Singh [54], \nSingh et al. [56].\n\niv. Brain signal processing in Neuromarketing Cherubino et al. [42], Bhardwaj et al. [53], Venkatraman [38], Pozharliev et al. \n[20], Boksem and Smitds [57], Wriessnegger et al. [29], Fan and Touyama \n[66], Pilelienė and Grigaliūnaitė [36], Yadava et al. [18], Baldo et al. [19], \nClerico et al. [72], Chen et al. [49], Casado-Aranda et al. [50], Hsu and Cheng \n[62], Taqwa et al. [73], Bhardwaj et al. [58],Wang et al. [30], Rakshit and Lahiri \n[67], Goyal and Singh [54], Jain et al. [63], Oon et al. [55], Fehse et al. [33],\n\nv. Machine learning applications in Neuromarketing Soria Morillo et al. [40], Yang et al. [41], Chew et al. [17], Soria Morillo et al. [43], \nYadava et al. [18], Doborjeh et al. [64], Gordon [59], Gurbuj and Toga [28], \nWriessnegger et al. [29], Wang et al. [30], Taqwa et al. [73], Bhardwaj et al. \n[58], Randolph and Pierquet [51], Fan and Touyama [66], Rakshit and Lahiri \n[67], Goyal and Singh [54], Jain et al. [63], Ogino and Mitsukura [68], Oon \net al. [55], Singh et al. [56].\n\n\n\nPage 5 of 19Rawnaque et al. Brain Inf.            (2020) 7:10  \n\nsubjects experience these stimuli. To conduct a system-\natic review on this matter, it is important to recall the \ninterconnection between brain functions with human \nbehavior and actions triggered by the  external stimuli. \nThe knowledge of brain anatomy and the physiologi-\ncal functions of brain areas as well as the physiological \nresponse due to external stimuli along with it, makes \nit possible to model brain activity and predict hidden \nresponse. For this purpose, current neural imaging sys-\ntems and neural recording systems have contributed \nmuch to capture the true essence of consumer prefer-\nences. This section will discuss the marketing stimuli, \ntheir targeted brain regions, neural and physiological \nsignal capturing technologies used over the last 5 years \nin Neuromarketing research. Comparing these signals \nwith their associated anatomical functionality some stud-\nies have already reached high accuracy. A number of the \nselected studies have used machine learning techniques \nto predict like/dislike and possible preference from the \ntest subjects.\n\nFor the purpose of Neuromarketing experiments, the \nfollowing literatures selected right-handed participants, \nwith normal or corrected-to-normal vision, free of cen-\ntral nervous system influencing medications and with no \nhistory of neuropathology.\n\n3.1  Marketing stimuli used in Neuromarketing\nAs Neuromarketing is a focus of marketers and consumer \nbehavior researchers, different strategies from market-\ning have been applied in Neuromarketing and they are \nbeing investigated for quantitative assessment from neu-\nrological data. Nemorin et al. asserts that Neuromarket-\ning differentiates from any other marketing models as \nit bypasses the thinking procedures of consumers and \ndirectly enters their brain [74]. Over the last 5  years, \nNeuromarketing stimuli has been mainly in two forms—\nproducts with/without price, and promotions. Product \ncan be defined as physical object or service that meets \nthe consumer demand. In Neuromarketing, product can \nbe physical such as tasting a beverage to conceptual like \na 3D (three dimensional) image of the product. Price in \nNeuromarketing experiments is mostly seen as a stimuli \nis most of the time intermingled with product or pro-\nmotion. However, it plays an important role that deter-\nmines the decision of test subjects to buy or not to buy \nthe product [75].\n\nConsumer response to a product has been recognized \nby either physically experiencing the product or by visu-\nalizing the image of  it. To understand the user esthetics \nof 3D shapes, Chew et  al. [17], used virtual 3D bracelet \nshapes in motion and recorded the brain response of \ntest subjects with EEG with motion. As 3D visualiza-\ntion of objects for preference recognition is a new area \n\nof research, the authors used mathematical model (Gie-\nlis superformula) to create 3D bracelet-like objects. \nTheir study displayed 3D shapes appear like bracelets as \nthe product to subjects. Using the 3D shapes gave the \nauthors an advantage to produce as many of 60 bracelet \nshapes to conduct the research on. Another new prod-\nuct was the E-commerce products presented to the test \nsubjects by Yadava et al. and Çakar et al. [18, 34]. Yadava \net  al. proposed a predictive modeling framework to \nunderstand consumer choice towards E-commerce prod-\nucts in terms of “likes” and “dislikes” by analyzing EEG \nsignals. In showing E-commerce product, they showed a \ntotal of 42 product images to the test participants. These \nproduct images were mainly of apparels and accessory \nitems such as shirts, sweaters, shoes, school bags, wrist \nwatches, etc. The test participants were asked to disclose \ntheir preference in terms of likes and dislikes after view-\ning the items  [18]. Çakar et  al. used both product and \nprice to explore the experience during product search of \nfirst-time buyers in E-commerce. To motivate the partici-\npants, this research provided each participants around \n73 USD as a gift card to use during the experiment. The \ntest participants were asked to search and select three \nproducts of their interest from an e-commerce website \nand reach the maximum of their gift card limit to acti-\nvate. Test subjects often experienced negative emotion \nwhile being unable to find necessary buttons such as “add \nto cart” or “sorting options” [34]. These Neuromarketing \nexperiments on E-commerce products may help develop-\ners to build better user experience. Retail businesses lose \nlarge amount of money when they invest in the wrong \nproduct. Among retail products, shoes have thousands \nof blueprints for manufacturing. Producing thousands \nof shoes of different designs to satisfy consumers can be \nlaborious and unprofitable since a large number of the \ndesigns turn out to be failures. Baldo et al. directly used \n30 existing image of shoe designs to show the test sub-\njects to and to choose from a mock shop showing on the \nscreen [39]. EEG signals were recorded during the whole \nshoe selection time and then subjects were asked to rate \nthe shoes in a rank of 1 to 5 of Likert scale. This experi-\nment helped realize brain response-based prediction can \nsupersede self-report-based methods, as the simulation \non sales data showed 12.1% profit growth for survey-\nbased prediction, and 36.4% profit growth for the brain \nresponse-based prediction.\n\nSimilar to the shoe experiment, Touchette and Lee [21] \nexperimented on the choice of apparel products among \nyoung adults, based on Davidson’s frontal asymmetry \ntheory. EEG signals were recorded while 34 college stu-\ndents viewed three attractive and three unattractive \napparel products on a high-resolution computer screen \nin a random order. Pozharliev et  al. [20] experimented \n\n\n\nPage 6 of 19Rawnaque et al. Brain Inf.            (2020) 7:10 \n\non the emotion associated with visualizing luxury brand \nproducts vs. regular brand products. The experiment dis-\nplayed 60 luxury items and 60 basic brand items to 40 \nfemale undergraduate students to recognize the brain \nresponse of seeing high emotional value (luxury) prod-\nucts in social vs. alone atmosphere. The study found \nthat, luxury brand products invoked a higher emotional \nvalue in social atmosphere which could be utilized by the \nmarketers. Bosshard et al. and Fehse et al. experimented \non brand images and the comparison between the brain \nresponses associated with preferred and not preferred \nbrands [32, 33]. In the study performed by Bosshard et al., \nconsumer attitude towards established brand names were \nmeasured via electroencephalography. Subjects were \nshown 120 brand names in capital white letter in Tahoma \nfont on black background and without any logo while \ntheir brain responses were recorded. On the other hand, \nFehse et al. compared the brain response of test subjects \nwhile they visualized blocks of popular vs. organic food \nbrand logos. These experiments on brand image may help \nmarketers to recognize the implicit response of consum-\ners on different types of branding.\n\nAs price is mentioned as an important factor that \ndetermines the user’s interest on purchasing a product, \na number of Neuromarketing studies have used price \nalongside the products. In the aforementioned study \nby Çakar et  al. [34] price was displayed while recording \nbrain response during first-time e-commerce user expe-\nrience. Marques et al. [22], Çakir et al. [24], Gong et al. \n[35], Pilelienė and Grigaliūnaitė [36], Hsu and Chen [26], \nBoccia et al. [37], Venkatraman et al. [38], and Baldo et al. \n[39] have included price as a marketing stimuli with the \nproduct or promotional.\n\nAn interesting concept was tried by Boccia et  al. to \nrecognize the relation between corporate social respon-\nsibilities and consumer behavior. The author attempted \nto identify if consumers were willing to pay more for the \nproducts from socially or environmentally responsible \ncompany. Consumers were found to prefer the conven-\ntional companies over the socially responsible companies \ndue to lesser price. Marques et  al. [22] investigated the \ninfluence of price to compare national brand vs. own-\nlabeled branded products. In the experiment of Çakir \net  al, product then product and price were shown to \nthe subjects before decision-making time and the brain \nresponses were recorded through fNIRS [24]. Sometimes \nprice can play a passive role in the form of discounts or \ngifts in a promotional. Gong et al. innovatively designed \nan experiment to compare consumer brain response \nassociated with promotional using discount (25% off) vs. \ngift-giving (gift value equivalent to the discount) mar-\nketing strategies. Their study found that lower degree of \nambiguity (e.g., discounts) better motivates consumer \n\ndecision-making [35]. Hsu and Chen used price as a con-\ntrol variable in their wine tasting experiment. As price \nplays a pivotal role in purchase decision, two wines were \nselected of approximately equal price $15. Then the EEG \nsignals of test subjects were recorded during the wine \ntasting session [26].\n\nPromotion is the communication from the marketers’ \nend to influence the purchase decision of consumers [75]. \nIn Neuromarketing research, promotion is usually found \nas the TV commercials and short movies for advertise-\nment. One of the key focus of Neuromarketers is to \nevaluate the consumer engagement of advertisements. \nPredicting the engagement of advertisements before \nbroadcasting them on air, ensures higher rate of success-\nful promotions.\n\nIn 2015, Yang et al. used six smartphone commercials \nof different brands to compare among them in terms \nof extract cognitive neurophysiological indices such as \nhappiness, surprise, and attention as well as behavio-\nral indices (memory rate, preference, etc.) [41]. A com-\nmon experimental design procedure is found among the \npromotion-based Neuromarketing experiments, that is \nsubjects are first made comfortable in the experimental \nsetting, consecutive advertisements were placed at a time \ndistance no shorter than 10 s and consecutive advertise-\nments used neutral stimuli such as white screen, green \nscenario, blank in between them to stabilize the test \nparticipants.\n\nThe Neuromarketing experiments of Soria Morillo \net  al. [40, 43] tried to find out the electrical activity of \naudience brain while viewing advertisement relevant to \naudiences’ taste. They display used 14 TV commercials \ndisplayed to their 10 test subjects for their experiment \nand predicted like or dislike response from audience \nwith the help of advanced algorithms. Cherubino et  al. \n[42] investigated cognitive and emotional changes of \ncerebral activity during the observation of TV commer-\ncials among different aged population. Among seven TV \ncommercials displayed during the experiment, one com-\nmercial with strong images was analyzed for the adults’ \nand older adults’ reaction. Other than them, Vasiljević \net  al. [44] used Nestle advertisement to measure con-\nsumer attention though pulse analysis; Daugherty et  al. \n[46] replicated an experiment of Krugman (1971) using \nboth TV advertisements and print media advertise-\nments to recognize how consumers look and think; Royo \net  al. [47] focused on consumer response while viewing \nadvertisements of sustainable product designs. For their \nexperiment, an animated commercial was made contain-\ning verbal narrative of sustainable product and an exist-\ning commercial was used to convey the visual narrative \nof conventional product. Venkatraman  et al. focused \non measuring the success of TV advertisements using \n\n\n\nPage 7 of 19Rawnaque et al. Brain Inf.            (2020) 7:10  \n\nneuroimaging and biometric data  [38]. Randolph and \nPierquet [51] showed super bowl commercials to under-\ngraduate students to compare the class rank of the com-\nmercials and the neural response from the test subjects. \nNomura and Mitsukura [52] identified emotional states \nof audiences while watching favorable vs. unfavorable TV \ncommercials. They selected 100 TV commercials among \nwhich 50 commercials were award winning which were \nlabeled as favorable advertisements. Singh et al. [56] used \npromotion in the form of static vs. video advertisements \nto predict the success of omnichannel marketing strate-\ngies. Ungureanu et al. [53] measured user attention and \narousal by eye tracking while surfing through web page \ncontaining static advertisements, while Goyal and Singh \n[54] utilized facial biometric sensors to model an auto-\nmated review systems for video advertisements. Oon \net al. [55] used merchandise product advertisement clips \nto recognize user preference. Singh et al. [56] used video \nadvertisements to measure visual attentions of audiences.\n\nMost of the TVC (television commercials) in these lit-\neratures had a standard time of 30 s. In Neuromarketing, \nthese TVCs were displayed in between other videos such \nas documentary film, gaming video, drama, etc., to cap-\nture the true response of consumers.\n\nSometimes Neuromarketing  is observed dealing with \nadvertisement of different purposes, such as social adver-\ntisements or gender-related advertisements. The appli-\ncation of Neuromarketing in social advertisement is to \npredict the success of these ads to reach its messages to \nthe targeted social groups [45, 49, 69]. Chen et  al. [49] \nexperimented on the neural response of adolescent audi-\nences while they are exposed to e-cigarette commercials. \nAnother social advertisement stimuli of smoking cessa-\ntion frames was used by Yang [45], to understand what \ntypes of frames (positive/negative) achieve better atten-\ntion from smokers and non-smokers. Gender plays a \nsubstantial role in advertisement industry from celebrity \nendorsement to gender-targeted marketing. Missaglia \net  al. [69] conducted a research o",
      "metadata_storage_size": 1434817,
      "metadata_storage_path": "aHR0cHM6Ly9qdHJhaW5pbmdjYXRhbG9nc3RvcmFnZS5ibG9iLmNvcmUud2luZG93cy5uZXQvcGFwZXJzL3M0MDcwOC0wMjAtMDAxMDkteC5wZGY1",
      "metadata_author": "Ferdousi Sabera Rawnaque ",
      "metadata_title": "Technological advancements and opportunities in Neuromarketing: a systematic review",
      "metadata_creation_date": "2020-09-18T02:02:41Z",
      "people": [
        "Rawnaque",
        "Ferdousi Sabera Rawnaque1",
        "Khandoker Mahmudur Rahman2",
        "Syed Ferhat Anwar3",
        "Ravi Vaidyanathan4",
        "Tom Chau5",
        "Farhana Sarker6 and",
        "Khondaker Abdullah Al Mamun",
        "nals",
        "19Rawnaque",
        "keting",
        "niques",
        "Sage",
        "Taylor Francis",
        "Chew",
        "Yadava",
        "Rojas",
        "Pozharliev",
        "Touchette",
        "Marques",
        "Shen",
        "Çakir",
        "Hubert",
        "Hsu",
        "Chen",
        "Hoefer",
        "Wriessnegger",
        "Wang",
        "Wolfe",
        "Bosshard",
        "Fehse",
        "Price Çakar",
        "Gong",
        "Pilelienė",
        "Grigaliūnaitė",
        "Boccia",
        "Venkatraman",
        "Baldo",
        "Yang",
        "Cherubino",
        "Soria Morillo",
        "Vasiljević",
        "Daugherty",
        "Royo",
        "Etzold",
        "Casado-Aranda",
        "Randolph",
        "Pierquet",
        "Mitsukura",
        "Ungureanu",
        "Goyal",
        "Singh",
        "Oon",
        "Morillo",
        "Çakar",
        "Boksem",
        "Bhardwaj",
        "katraman",
        "Lee",
        "Gordon",
        "Krampe",
        "Holst",
        "Henseler",
        "Cheng",
        "Jain",
        "Doborjeh",
        "Kaur",
        "Smitds",
        "Nomura",
        "Fan",
        "Touyama",
        "Rakshit",
        "Lahiri",
        "Ogino",
        "Ceravolo",
        "Magdin",
        "Clerico",
        "Taqwa",
        "Gurbuj",
        "Toga",
        "Nemorin",
        "Likert",
        "Davidson",
        "dents",
        "sumer",
        "Krugman"
      ],
      "organizations": [
        "Neuromarketing",
        "response",
        "Creative Commons",
        "Creative",
        "creat iveco \nmmons",
        "uct",
        "focus",
        "Brain Informatics",
        "Institute",
        "Advanced Research",
        "United International University",
        "Functional mag",
        "tal",
        "Neuromarketing Science \nand Business Association",
        "NMSBA",
        "Neuromarketers",
        "Neuromarket-",
        "ing",
        "Google",
        "Microsoft",
        "Unilever",
        "Neuromar",
        "ence",
        "fol",
        "Neuromarket",
        "Taylor Francis",
        "nervous system",
        "ANS",
        "Emerald insight",
        "IEEE",
        "neural recording systems",
        "neu-",
        "luxury brand",
        "luxury",
        "ers",
        "fNIRS",
        "ments",
        "Nestle",
        "ing commercial",
        "com"
      ],
      "locations": [
        "ventional",
        "Dhaka",
        "Bangladesh",
        "field",
        "English",
        "mulation",
        "ing",
        "mines",
        "ment",
        "Tahoma",
        "price",
        "EEG",
        "mon",
        "Royo",
        "Randolph",
        "Missaglia"
      ],
      "keyphrases": [
        "Creative Commons Attribution 4.0 International License",
        "Khondaker Abdullah Al Mamun",
        "high time resolution advantages",
        "Physiological response measuring techniques",
        "consumer emotion recognition-based experiments",
        "other third party material",
        "neural record- ing techniques",
        "video advertisement-based Neuromarketing experiments",
        "other machine learning algorithms",
        "Creative Commons licence",
        "Support Vector Machine",
        "Ferdousi Sabera Rawnaque1",
        "Khandoker Mahmudur Rahman",
        "Syed Ferhat Anwar",
        "empirical research findings",
        "magnetic resonance imaging",
        "heart rate monitoring",
        "traditional filtering methods",
        "independent component analysis",
        "Linear Discriminant Analysis",
        "highest average accuracy",
        "market- ing research",
        "consumer response prediction",
        "Artificial Neural Network",
        "prefrontal alpha band",
        "skin conductance recording",
        "Brain computer interface",
        "brain–computer interface",
        "prevalent marketing stimuli",
        "first systematic review",
        "Neural recording",
        "unspoken response",
        "Neuromarket- ing",
        "consumer goods",
        "neural signal",
        "consumer preferences",
        "Brain Inf.",
        "brain recordings",
        "doi.org",
        "Ravi Vaidyanathan",
        "Tom Chau",
        "Farhana Sarker6",
        "commercial area",
        "last 5 years",
        "valid databases",
        "promotion forms",
        "asymmetry theory",
        "many researchers",
        "low cost",
        "eye tracking",
        "facial mapping",
        "artifact removal",
        "future researchers",
        "vital information",
        "novel contributions",
        "The Author",
        "appropriate credit",
        "original author",
        "credit line",
        "statutory regulation",
        "copyright holder",
        "creat iveco",
        "BCI) technology",
        "interdisciplinary bridge",
        "ultimate sale",
        "targeted audiences",
        "expanding economy",
        "effective marketing",
        "57 relevant literatures",
        "intended use",
        "permitted use",
        "good product",
        "new businesses",
        "Neuromarketing field",
        "Technological advancements",
        "opportunities",
        "Abstract",
        "academic",
        "interest",
        "interpreting",
        "tool",
        "consumers",
        "article",
        "purpose",
        "authors",
        "total",
        "basic",
        "trend",
        "nals",
        "electroencephalogram",
        "EEG",
        "functional",
        "fMRI",
        "parallel",
        "classification",
        "ANN",
        "SVM",
        "LDA",
        "Keywords",
        "sharing",
        "adaptation",
        "distribution",
        "reproduction",
        "medium",
        "source",
        "link",
        "changes",
        "images",
        "permission",
        "1 Introduction",
        "application",
        "invasive",
        "neuroscience",
        "perception",
        "changing",
        "non-invasive brain signal record- ing techniques",
        "1 Advanced Intelligent Multidisciplinary Systems Lab",
        "transcranial mag- netic stimulator",
        "Functional mag- netic resonance",
        "Open Access Brain Informatics",
        "market- ing stimuli",
        "image processing techniques",
        "nal recording techniques",
        "functional near-infrared spectroscopy",
        "com- petitive market",
        "United International University",
        "positron emission tomography",
        "machine learning algorithms",
        "skin conductance measurements",
        "neuronal activ- ity",
        "Different stimuli trigger",
        "marketing research techniques",
        "ventional market research",
        "traditional survey methods",
        "neural recording devices",
        "various marketing stimuli",
        "consumers’ purchase decisions",
        "Neuromarketing World Forum",
        "Advanced Research",
        "neuronal signals",
        "human brain",
        "traditional marketing",
        "Neuro- marketing",
        "academic research",
        "qualitative assessment",
        "posteriori analysis",
        "Full list",
        "author information",
        "group discussion",
        "personal interviews",
        "consumer feedback",
        "time requirement",
        "high cost",
        "unreliable information",
        "inaccurate results",
        "possible meanings",
        "new door",
        "buying behavior",
        "tal states",
        "physiological signals",
        "heart rate",
        "physiological responses",
        "spectral analysis",
        "accurate depiction",
        "Early years",
        "contro- versy",
        "high promises",
        "consumer mind",
        "buy buttons",
        "consumer behavior",
        "Business Association",
        "annual event",
        "Neuromarketing research",
        "field trials",
        "unspoken cognitive",
        "emotional responses",
        "Neuromarketing Science",
        "consumer response",
        "associated response",
        "quantitative",
        "products",
        "surveys",
        "Correspondence",
        "frawnaque",
        "umassd",
        "Institute",
        "Dhaka",
        "Bangladesh",
        "end",
        "creativecommons",
        "licenses",
        "crossmark",
        "crossref",
        "org",
        "Page",
        "19Rawnaque",
        "observations",
        "approaches",
        "limitations",
        "contrast",
        "customer",
        "electroencephalography",
        "magnetoencephalography",
        "MEG",
        "TMS",
        "fNIRS",
        "examples",
        "withdrawal",
        "change",
        "brainwaves",
        "researchers",
        "help",
        "excitement",
        "engagement",
        "stress",
        "insight",
        "audience",
        "preferences",
        "likes",
        "academician",
        "marketers",
        "due",
        "lack",
        "groundwork",
        "claim",
        "scrutiny",
        "scope",
        "NMSBA",
        "gap",
        "dialogue",
        "other physiological signal recording device",
        "best brain signal recording tool",
        "address inclusion–exclusion criteria",
        "relevant academic journal articles",
        "neural recording tools",
        "industry–academia collaboration",
        "brief intro- duction",
        "unbiased evidence collection",
        "clear con- clusions",
        "Numerous literature reviews",
        "other literature review",
        "mar- keting stimuli",
        "date research scopes",
        "systematic literature review",
        "new research field",
        "signal processing",
        "inclusion criteria",
        "Academic research",
        "relevant inference",
        "new perspective",
        "brain signals",
        "cal tools",
        "systematic review",
        "research question",
        "brain regions",
        "150 consumer neuroscience",
        "big brands",
        "efficient way",
        "lytical accuracy",
        "building blocks",
        "theoretical aspect",
        "business ethics",
        "current methods",
        "tech- niques",
        "art findings",
        "synthesized result",
        "impartial conclusion",
        "exhaustive search",
        "experimental findings",
        "neu- ral",
        "biometric data",
        "Book chapters",
        "marketing stimuli",
        "empirical experiments",
        "engineering part",
        "pretational methodologies",
        "important results",
        "lowing questions",
        "Neuromarketing experiments",
        "platform",
        "panies",
        "globe",
        "Google",
        "Microsoft",
        "Unilever",
        "insights",
        "tailored",
        "breakthrough",
        "acceptance",
        "world",
        "capacities",
        "management",
        "psychology",
        "focus",
        "regard",
        "premises",
        "types",
        "analysis",
        "techniques",
        "comprehensive",
        "knowledge",
        "methodology",
        "state",
        "synthesis",
        "recommendation",
        "body",
        "objective",
        "obligation",
        "investigation",
        "existing",
        "literatures",
        "evance",
        "studies",
        "analytical",
        "BCI",
        "language",
        "English",
        "brain signal recording techniques",
        "Neural response recording techniques",
        "Brain signal processing",
        "relevant existing literatures",
        "Machine learning applications",
        "autonomous nervous system",
        "Neuromarket- ing field",
        "different brain regions",
        "galvanic skin response",
        "Wiley Online Library",
        "Neuromarketing Product Chew",
        "neural data",
        "3  Systematic review",
        "database source",
        "book chapters",
        "six databases",
        "Taylor Francis",
        "initial article",
        "critical analy",
        "action coding",
        "successful means",
        "withdrawal actions",
        "engineering perspective",
        "statistical analy",
        "lyze activities",
        "Price Çakar",
        "Grigaliūnaitė",
        "Soria Morillo",
        "marketing strategies",
        "Neuromarketing questions",
        "search item",
        "Science Direct",
        "IEEE Xplore",
        "Table 1 Number",
        "database Results",
        "Emerald insight",
        "Neuromarketing studies",
        "following dimensions",
        "Marketing stimuli",
        "Table 2 Studies",
        "57 research articles",
        "931 articles",
        "internet",
        "Neuro-marketing",
        "publications",
        "aggregation",
        "Sage",
        "mulation",
        "title",
        "abstract",
        "keywords",
        "sis",
        "terms",
        "trends",
        "advancements",
        "Activation",
        "facial",
        "consumer",
        "arousal",
        "attention",
        "study",
        "Name",
        "tools",
        "paper",
        "form",
        "Yadava",
        "Rojas",
        "Pozharliev",
        "Touchette",
        "Lee",
        "Marques",
        "Shen",
        "Çakir",
        "Hubert",
        "Hsu",
        "Chen",
        "Hoefer",
        "Gurbuj",
        "Toga",
        "Wriessnegger",
        "Wang",
        "Wolfe",
        "Bosshard",
        "Fehse",
        "al.",
        "Gong",
        "Pilelienė",
        "Boccia",
        "Venkatraman",
        "Baldo",
        "Promotion",
        "Yang",
        "Cherubino",
        "Vasiljević",
        "Daugherty",
        "Royo",
        "Etzold",
        "Casado-Aranda",
        "Randolph",
        "Pierquet",
        "Nomura",
        "Mitsukura",
        "Ungureanu",
        "Goyal",
        "Singh",
        "Oon",
        "neural recording systems",
        "signal capturing technologies",
        "heart rate Cherubino",
        "EEG Soria Morillo",
        "brain region",
        "brain functions",
        "brain anatomy",
        "brain areas",
        "brain activity",
        "EMG Missagila",
        "Eye tracking",
        "Galvanic skin",
        "atic review",
        "human behavior",
        "cal functions",
        "true essence",
        "consumer prefer",
        "anatomical functionality",
        "high accuracy",
        "external stimuli",
        "fNIRS Çakir",
        "Neuromarketing Cherubino",
        "fMRI Venkatraman",
        "Chew",
        "Çakar",
        "Boksem",
        "Smitds",
        "Bhardwaj",
        "Gordon",
        "Krampe",
        "Holst",
        "Henseler",
        "Cheng",
        "Jain",
        "Doborjeh",
        "Kaur",
        "Fan",
        "Touyama",
        "Rakshit",
        "Lahiri",
        "Ogino",
        "Ceravolo",
        "Magdin",
        "Clerico",
        "Taqwa",
        "subjects",
        "matter",
        "interconnection",
        "actions",
        "physiological",
        "hidden",
        "ences",
        "section",
        "targeted",
        "signals",
        "associated",
        "number",
        "3D (three dimensional) image",
        "machine learning techniques",
        "tral nervous system",
        "predictive modeling framework",
        "3D visualiza- tion",
        "other marketing models",
        "consumer behavior researchers",
        "E-commerce prod- ucts",
        "gift card limit",
        "virtual 3D bracelet",
        "30 existing image",
        "3D shapes",
        "consumer demand",
        "Consumer response",
        "consumer choice",
        "different strategies",
        "market- ing",
        "quantitative assessment",
        "rological data",
        "thinking procedures",
        "last 5  years",
        "two forms",
        "physical object",
        "important role",
        "user esthetics",
        "new area",
        "mathematical model",
        "lis superformula",
        "school bags",
        "first-time buyers",
        "partici- pants",
        "commerce website",
        "negative emotion",
        "necessary buttons",
        "sorting options",
        "Retail businesses",
        "large amount",
        "large number",
        "mock shop",
        "right-handed participants",
        "test participants",
        "different designs",
        "shoe designs",
        "E-commerce products",
        "retail products",
        "test subjects",
        "normal vision",
        "brain response",
        "user experience",
        "42 product images",
        "product search",
        "wrong product",
        "possible preference",
        "60 bracelet",
        "medications",
        "history",
        "neuropathology",
        "Nemorin",
        "price",
        "promotions",
        "service",
        "beverage",
        "decision",
        "objects",
        "recognition",
        "bracelets",
        "advantage",
        "apparels",
        "accessory",
        "items",
        "shirts",
        "sweaters",
        "shoes",
        "wrist",
        "watches",
        "view",
        "maximum",
        "money",
        "thousands",
        "blueprints",
        "manufacturing",
        "failures",
        "3.1",
        "corporate social respon- sibilities",
        "frontal asymmetry theory",
        "female undergraduate students",
        "capital white letter",
        "luxury) prod- ucts",
        "high emotional value",
        "higher emotional value",
        "shoe selection time",
        "high-resolution computer screen",
        "60 basic brand items",
        "wine tasting experiment",
        "regular brand products",
        "luxury brand products",
        "brain response-based prediction",
        "consumer brain response",
        "60 luxury items",
        "gift value",
        "brand images",
        "brand names",
        "brand logos",
        "national brand",
        "social atmosphere",
        "apparel products",
        "branded products",
        "shoe experiment",
        "EEG signals",
        "Likert scale",
        "self-report-based methods",
        "sales data",
        "12.1% profit growth",
        "36.4% profit growth",
        "young adults",
        "random order",
        "alone atmosphere",
        "brain responses",
        "consumer attitude",
        "Tahoma font",
        "black background",
        "other hand",
        "implicit response",
        "different types",
        "important factor",
        "interesting concept",
        "tional companies",
        "responsible companies",
        "decision-making time",
        "passive role",
        "keting strategies",
        "lower degree",
        "con- trol",
        "pivotal role",
        "purchase decision",
        "two wines",
        "lesser price",
        "rank",
        "simulation",
        "choice",
        "Davidson",
        "comparison",
        "brands",
        "blocks",
        "popular",
        "experiments",
        "branding",
        "user",
        "first-time",
        "promotional",
        "relation",
        "author",
        "company",
        "socially",
        "influence",
        "discounts",
        "gifts",
        "gift-giving",
        "ambiguity",
        "40",
        "mon experimental design procedure",
        "merchandise product advertisement clips",
        "wine tasting session",
        "older adults’ reaction",
        "mated review systems",
        "different aged population",
        "facial biometric sensors",
        "TV commer- cials",
        "six smartphone commercials",
        "super bowl commercials",
        "promotion-based Neuromarketing experiments",
        "The Neuromarketing experiments",
        "sustainable product designs",
        "seven TV commercials",
        "unfavorable TV commercials",
        "cognitive neurophysiological indices",
        "consecutive advertise- ments",
        "experimental setting",
        "conventional product",
        "14 TV commercials",
        "100 TV commercials",
        "different brands",
        "ral indices",
        "Nestle advertisement",
        "television commercials",
        "consecutive advertisements",
        "TV advertisements",
        "equal price",
        "short movies",
        "key focus",
        "higher rate",
        "ful promotions",
        "memory rate",
        "time distance",
        "neutral stimuli",
        "white screen",
        "green scenario",
        "electrical activity",
        "advanced algorithms",
        "emotional changes",
        "cerebral activity",
        "strong images",
        "pulse analysis",
        "print media",
        "animated commercial",
        "verbal narrative",
        "ing commercial",
        "visual narrative",
        "graduate students",
        "class rank",
        "emotional states",
        "visual attentions",
        "lit- eratures",
        "standard time",
        "video advertisements",
        "neural response",
        "consumer engagement",
        "audience brain",
        "web page",
        "user preference",
        "audiences’ taste",
        "user attention",
        "favorable advertisements",
        "static advertisements",
        "50 commercials",
        "communication",
        "Neuromarketers",
        "air",
        "extract",
        "happiness",
        "surprise",
        "10 s",
        "participants",
        "observation",
        "Krugman",
        "success",
        "neuroimaging",
        "gies",
        "TVC",
        "30 s",
        "other",
        "videos",
        "social adver- tisements",
        "social advertisement stimuli",
        "social groups",
        "documentary film",
        "gaming video",
        "true response",
        "different purposes",
        "gender-related advertisements",
        "appli- cation",
        "cigarette commercials",
        "smoking cessa",
        "atten- tion",
        "substantial role",
        "advertisement industry",
        "gender-targeted marketing",
        "tion frames",
        "drama",
        "Neuromarketing",
        "The",
        "ads",
        "messages",
        "smokers",
        "celebrity",
        "endorsement",
        "Missaglia",
        "research"
      ],
      "merged_content": "\nRawnaque et al. Brain Inf.            (2020) 7:10  \nhttps://doi.org/10.1186/s40708-020-00109-x\n\nREVIEW\n\nTechnological advancements \nand opportunities in Neuromarketing: \na systematic review\nFerdousi Sabera Rawnaque1*, Khandoker Mahmudur Rahman2, Syed Ferhat Anwar3, Ravi Vaidyanathan4, \nTom Chau5, Farhana Sarker6 and Khondaker Abdullah Al Mamun1,7\n\nAbstract \n\nNeuromarketing has become an academic and commercial area of interest, as the advancements in neural record-\ning techniques and interpreting algorithms have made it an effective tool for recognizing the unspoken response \nof consumers to the marketing stimuli. This article presents the very first systematic review of the technological \nadvancements in Neuromarketing field over the last 5 years. For this purpose, authors have selected and reviewed a \ntotal of 57 relevant literatures from valid databases which directly contribute to the Neuromarketing field with basic \nor empirical research findings. This review finds consumer goods as the prevalent marketing stimuli used in both \nproduct and promotion forms in these selected literatures. A trend of analyzing frontal and prefrontal alpha band sig-\nnals is observed among the consumer emotion recognition-based experiments, which corresponds to frontal alpha \nasymmetry theory. The use of electroencephalogram (EEG) is found favorable by many researchers over functional \nmagnetic resonance imaging (fMRI) in video advertisement-based Neuromarketing experiments, apparently due to \nits low cost and high time resolution advantages. Physiological response measuring techniques such as eye tracking, \nskin conductance recording, heart rate monitoring, and facial mapping have also been found in these empirical stud-\nies exclusively or in parallel with brain recordings. Alongside traditional filtering methods, independent component \nanalysis (ICA) was found most commonly in artifact removal from neural signal. In consumer response prediction and \nclassification, Artificial Neural Network (ANN), Support Vector Machine (SVM) and Linear Discriminant Analysis (LDA) \nhave performed with the highest average accuracy among other machine learning algorithms used in these litera-\ntures. The authors hope, this review will assist the future researchers with vital information in the field of Neuromarket-\ning for making novel contributions.\n\nKeywords: Neuromarketing, Neural recording, Machine learning algorithm, Brain computer interface, Marketing\n\n© The Author(s) 2020. This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and \nthe source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material \nin this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material \nis not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the \npermitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creat iveco \nmmons .org/licen ses/by/4.0/.\n\n1 Introduction\nNeuromarketing, an application of the non-invasive \nbrain–computer interface (BCI) technology, has emerged \nas an interdisciplinary bridge between neuroscience and \nmarketing that has changed the perception of market-\ning research. Marketing is the channel between prod-\nuct and consumers which determines the ultimate sale. \n\nWithout effective marketing, a good product fails to \ninform, engage and sustain its targeted audiences [1]. \nThe expanding economy with new businesses is continu-\nously evolving with changing consumer preferences. It \nis hard for the businesses to grow and sustain without \nhaving quantitative or qualitative assessment from their \nconsumers. Newly launched products need even more \neffective marketing to successfully enter into a com-\npetitive market. However, traditional marketing renders \nonly by posteriori analysis of consumer response. Con-\nventional market research depends on surveys, focus \n\nOpen Access\n\nBrain Informatics\n\n*Correspondence:  frawnaque@umassd.edu\n1 Advanced Intelligent Multidisciplinary Systems Lab, Institute \nof Advanced Research, United International University, Dhaka, Bangladesh\nFull list of author information is available at the end of the article\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40708-020-00109-x&domain=pdf\n\n\nPage 2 of 19Rawnaque et al. Brain Inf.            (2020) 7:10 \n\ngroup discussion, personal interviews, field trials and \nobservations for collecting consumer feedback [2]. These \napproaches have the limitations of time requirement, \nhigh cost and unreliable information, which can often \nproduce inaccurate results. In contrast to the traditional \nmarketing research techniques, Neuromarketing allows \ncapturing consumers’ unspoken cognitive and emotional \nresponse to various marketing stimuli and can forecast \nconsumers’ purchase decisions.\n\nNeuromarketing uses non-invasive brain signal record-\ning techniques to directly measure the response of a \ncustomer’s brain to the marketing stimuli, supersed-\ning the traditional survey methods [3]. Functional mag-\nnetic resonance (fMRI), electroencephalography (EEG), \nmagnetoencephalography (MEG), transcranial mag-\nnetic stimulator (TMS), positron emission tomography \n(PET), functional near-infrared spectroscopy (fNIRS) etc. \nare some examples of neural recording devices used in \nNeuromarketing research. By obtaining neuronal activ-\nity from the brain using these devices, one can explore \nthe cognitive and emotional responses (i.e., like/dislike, \napproach/withdrawal) of a customer. Different stimuli \ntrigger associated response in a human brain and the \nresponse can be tracked by monitoring the change in \nneuronal signals or brainwaves [4]. Further, the signal \nand image processing techniques and machine learning \nalgorithms have enabled the researchers to measure, ana-\nlyze and interpret the possible meanings of brainwaves. \nThis opens a new door to detect, analyze and predict \nthe buying behavior of customers in marketing research. \nNow with the help of brain–computer interface, the men-\ntal states of a customer, i.e., excitement, engagement, \nwithdrawal, stress, etc., while experiencing a market-\ning stimuli can be captured [5]. Besides these brain sig-\nnal recording techniques, Neuromarketing also utilizes \nphysiological signals, i.e., eye tracking, heart rate and \nskin conductance measurements to gather the insight of \naudience’s physiological responses due to encountering \nstimuli. These neurophysiological signals with advanced \nspectral analysis and machine learning algorithms can \nnow provide nearly accurate depiction of consumers’ \npreferences and likes/dislikes [6–8].\n\nEarly years of Neuromarketing generated a contro-\nversy between the academician and the marketers due \nto its high promises and lack of groundwork. From \nthe claim of peeping into the consumer mind to find-\ning the buy buttons of human brain, Neuromarketing \nhas long been under the scrutiny of the academicians \nand researchers [9, 10]. However, academic research in \nthis field has started to pile up and the scope of Neuro-\nmarketing to reveal and predict consumer behavior is \ngradually becoming evident. Neuromarketing Science \nand Business Association (NMSBA) was established \n\nin 2012 to bridge the gap between academicians and \nNeuromarketers, and it is promoting Neuromarket-\ning research across the world with its annual event of \nNeuromarketing World Forum [11, 12]. It may be pro-\nposed that further dialogue may continue under such a \nplatform for further industry–academia collaboration. \nEvidently, more than 150 consumer neuroscience com-\npanies are commercially operating across the globe and \nbig brands (Google, Microsoft, Unilever, etc.) are using \ntheir insights to impact their consumers in a tailored and \nefficient way. Academic research, especially the high ana-\nlytical accuracy from the engineering part of Neuromar-\nketing has garnered this breakthrough and acceptance \nover the world. Hence, reviewing the building blocks of \nNeuromarketing is essential to evaluate its scopes and \ncapacities, and to contribute new perspective in this \nfield. Numerous literature reviews have been published \nfocusing the theoretical aspect of consumer neurosci-\nence, such as marketing, business ethics, management, \npsychology, consumer behavior, etc. [13–15]. However, \nsystematic literature review from the engineering per-\nspective with a focus on neural recording tools and inter-\npretational methodologies used in this field is absent. In \nthis regard, our article sets its premises to answer the fol-\nlowing questions:\n\n– What are the types of marketing stimuli currently \nbeing used in Neuromarketing?\n\n– What are the brain regions activated by these mar-\nketing stimuli?\n\n– What is the best brain signal recording tool currently \nbeing used in Neuromarketing research?\n\n– How are these brain signals preprocessed for further \nanalysis?\n\n– And what are the current methods or techniques \nused to interpret these brain signals?\n\nThese questions will allow us to gain a comprehensive \nknowledge on the up-to-date research scopes and tech-\nniques in consumer neuroscience. After this brief intro-\nduction, our methodology of conducting this systematic \nreview will be presented, followed by the state-of-the-art \nfindings corresponding to the aforementioned questions \nand synthesis of the important results. We concluded this \nreview with relevant inference from synthesized result \nand a recommendation for future researchers.\n\n2  Methodology\nThe systematic literature review is a process in which \na body of literature is collected, screened, selected, \nreviewed and assessed with a pre-specified objective for \nthe purpose of unbiased evidence collection and to reach \nan impartial conclusion [16]. Systematic review has the \n\n\n\nPage 3 of 19Rawnaque et al. Brain Inf.            (2020) 7:10  \n\nobligation to explicitly define its research question and to \naddress inclusion–exclusion criteria for setting the scope \nof the investigation. After exhaustive search of existing \nliteratures, articles should be selected based on their rel-\nevance, and the results of the selected studies must be \nsynthesized and assessed critically to achieve clear con-\nclusions [16].\n\nIn this systematic review, we would like to explore \nthe marketing stimuli used in Neuromarketing research \narticles over the last 5 years with their triggered brain \nregions. We would also like to focus on the technologi-\ncal tools used to capture brain signals from these regions, \nand finally deliberate on signal processing and analytical \nmethodologies used in these experiments.\n\nTherefore, the inclusion criteria defined here are  as \nfollows:\n\n– Literatures must be published in the field of Neuro-\nmarketing from 2015 to 2019.\n\n– Studies must use brain–computer interface and/or \nother physiological signal recording device in their \nNeuromarketing experiments.\n\n– Studies must have experimental findings from neu-\nral and/or biometric data used in Neuromarketing \nresearch.\n\nThe exclusion criteria for this review are set as:\n\n– Any other literature review on Neuromarketing are \nexcluded from this review.\n\n– Book chapters are excluded from this review. Since \nNeuromarketing is comparatively a new research \nfield, alongside relevant academic journal articles, \nbook chapters conducting empirical experiments \nusing BCI can only be included.\n\n– Literatures written/published in any language other \nthan English are excluded from this article.\n\nTo serve the purpose of this systematic literature \nreview, a total of 931 articles were found across the \n\ninternet by using the search item “Neuromarketing” \nand “Neuro-marketing” in valid databases. Among the \nscreened publications, Table  1 presents the database \nsource of selected 57 research articles including book \nchapters, which directly contribute to the Neuromarket-\ning field with basic or empirical research findings.\n\nAs for the aggregation of relevant existing literatures, \nthe researchers defined that the search for articles would \nbe performed in six databases—Science Direct, Emer-\nald Insight, Sage, IEEE Xplore, Wiley Online Library, \nand Taylor Francis Online. After the initial article accu-\nmulation, the articles were exhaustively screened by \nthe authors by reviewing their title, abstract, keywords \nand scope to match the objective of this research. Once \nthe studies met our aforementioned inclusion criteria, \nthey were selected for further review and critical analy-\nsis. Table 2 classifies the selected articles in terms of the \naforementioned dimensions.\n\nBy exploring the articles selected to develop this sys-\ntematic review, it was possible to successfully categorize \nthe trends and advancements in Neuromarketing field in \nfollowing dimensions:\n\n i. Marketing stimuli used in Neuromarketing \nresearch\n\n ii. Activation of the brain regions due to marketing \nstimuli\n\n iii. Neural response recording techniques\n iv. Brain signal processing in Neuromarketing\n v. Machine learning applications in Neuromarketing.\n\nSome of these Neuromarketing studies have used \neye tracking, heart rate, galvanic skin response, facial \naction coding, etc., with or without brain signal \nrecording techniques to gauge the consumer’s hidden \nresponse. As they are the response from autonomous \nnervous system (ANS), they have proven themselves \nas successful means of exploring consumer’s focus, \narousal, attention and withdrawal actions. Hence, this \nstudy includes articles those empirically used these \n\nTable 1 Number of articles found and selected\n\nName of the database Results: search “Neuromarketing” Results: search “Neuro-marketing” Articles selected\n\nScience direct 281 55 12\n\nWiley online 111 11 7\n\nEmerald insight 115 8 14\n\nIEEE 34 0 14\n\nSage 12 15 6\n\nTaylor Francis online 106 36 4\n\nTotal found: 806 Total found: 125 Total selected: 57\n\n\n\nPage 4 of 19Rawnaque et al. Brain Inf.            (2020) 7:10 \n\ntools to answer Neuromarketing questions, since this \nstudy mainly focuses on the engineering perspective. \nInterpreting the neural data with only statistical analy-\nsis has been out of scope of this paper.\n\n3  Systematic review on the advancements \nof Neuromarketing\n\nNeuromarketing research utilizes marketing strategies in \nthe form of stimuli, and aims to invoke, capture and ana-\nlyze activities occurring in different brain regions while \n\nTable 2 Studies selected on the dimensions of this review\n\nDimensions Published articles\n\ni. Marketing stimuli used in Neuromarketing Product Chew et al. [17], Yadava et al. [18], Rojas et al. [19], Pozharliev [20], Touchette \nand Lee [21], Marques et al. [22], Shen et al. [23], Çakir et al. [24], Hubert \net al. [25], Hsu and Chen et al. [26], Hoefer et al. [27], Gurbuj and Toga [28], \nWriessnegger et al. [29], Wang et al. [30], Wolfe et al. [31], Bosshard et al. [32], \nFehse et al. [33].\n\nPrice Çakar et al. [34], Marques et al. [22], Çakir et al. [24], Gong et al. [35], Pilelienė \nand Grigaliūnaitė [36], Hsu and Chen [26], Boccia et al. [37], Venkatraman \net al. [38], Baldo et al. [39].\n\nPromotion Soria Morillo et al. [40], Yang et al. [41], Cherubino et al. [42], Soria Morillo \net al. [43], Vasiljević et al. [44], Yang et al. [45], Pilelienė and Grigaliūnaitė \n[36], Daugherty et al. [46], Royo et al. [47], Etzold et al. [48], Chen et al. \n[49], Casado-Aranda et al. [50], Randolph and Pierquet [51], Nomura and \nMitsukura [52], Ungureanu et al. [53], Goyal and Singh [54], Oon et al. [55], \nSingh et al. [56].\n\nii. Activation of brain region due to marketing stimuli Soria Morillo et al. [40], Chew et al. [17], Cherubino et al. [42], Soria Morillo \net al. [43], Çakar et al. [34], Boksem and Smitds [57], Bhardwaj et al. [58], Ven-\nkatraman et al. [38], Touchette and Lee [21], Yang et al. [45], Marques et al. \n[22], Gong et al. [35], Gordon et al. [59], Krampe et al. [60], Hubert et al. [25], \nÇakir et al. [24], Holst and Henseler [61], Hsu and Cheng [62], Hoefer et al. \n[27], Chen et al. [49], Casado-Aranda et al. [50], Wang et al. [30], Jain et al. \n[63], Wolfe et al. [31], Bosshard et al. [32], Fehse et al. [33].\n\niii. Neural response recording techniques EEG Soria Morillo et al. [40], Yang et al. [41], Chew et al. [17], Cherubino et al. [42], \nSoria Morillo et al. [43], Yadava et al. [18], Doborjeh et al. [64], Çakar et al. \n[34], Kaur et al. [65], Baldo et al. [19], Boksem and Smitds [57], Pozharliev \net al. [20], Venkatraman [38], Touchette and Lee [21], Yang et al. [45], Pilelienė \nand Grigaliūnaitė [36], Shen et al. [23], Daugherty et al. [46], Royo et al. [47], \nGong et al. [35], Gordon et al. [59], Hsu and Chen et al. [26], Hoefer et al. [27], \nRandolph and Pierquet [51], Nomura and Mitsukura [52], Bhardwaj et al. \n[58], Fan and Touyama [66], Rakshit and Lahiri [67], Jain et al. [63],Ogino and \nMitsukura [68], Oon et al. [55], Bosshard et al. [32].\n\nfMRI Venkatraman et al. [38], Marques et al. [22], Hubert et al. [25], Hsu and Cheng \n[62], Chen et al. [49], Casado-Aranda et al. [50], Wang et al. [30], Wolfe et al. \n[31], Fehse et al. [33].\n\nfNIRS Çakir et al. [24], Krampe et al. [60].\n\nEMG Missagila et al. [69]\n\nEye tracking Venkatraman [38], Rojas et al. [19], Pilelienė and Grigaliūnaitė [36], Çakar et al. \n[34], Ceravolo et al. [70], Ungureanu et al. [53]\n\nGalvanic skin \nresponse, \nheart rate\n\nCherubino et al. [42], Çakar et al. [34], Magdin et al. [71], Goyal and Singh [54], \nSingh et al. [56].\n\niv. Brain signal processing in Neuromarketing Cherubino et al. [42], Bhardwaj et al. [53], Venkatraman [38], Pozharliev et al. \n[20], Boksem and Smitds [57], Wriessnegger et al. [29], Fan and Touyama \n[66], Pilelienė and Grigaliūnaitė [36], Yadava et al. [18], Baldo et al. [19], \nClerico et al. [72], Chen et al. [49], Casado-Aranda et al. [50], Hsu and Cheng \n[62], Taqwa et al. [73], Bhardwaj et al. [58],Wang et al. [30], Rakshit and Lahiri \n[67], Goyal and Singh [54], Jain et al. [63], Oon et al. [55], Fehse et al. [33],\n\nv. Machine learning applications in Neuromarketing Soria Morillo et al. [40], Yang et al. [41], Chew et al. [17], Soria Morillo et al. [43], \nYadava et al. [18], Doborjeh et al. [64], Gordon [59], Gurbuj and Toga [28], \nWriessnegger et al. [29], Wang et al. [30], Taqwa et al. [73], Bhardwaj et al. \n[58], Randolph and Pierquet [51], Fan and Touyama [66], Rakshit and Lahiri \n[67], Goyal and Singh [54], Jain et al. [63], Ogino and Mitsukura [68], Oon \net al. [55], Singh et al. [56].\n\n\n\nPage 5 of 19Rawnaque et al. Brain Inf.            (2020) 7:10  \n\nsubjects experience these stimuli. To conduct a system-\natic review on this matter, it is important to recall the \ninterconnection between brain functions with human \nbehavior and actions triggered by the  external stimuli. \nThe knowledge of brain anatomy and the physiologi-\ncal functions of brain areas as well as the physiological \nresponse due to external stimuli along with it, makes \nit possible to model brain activity and predict hidden \nresponse. For this purpose, current neural imaging sys-\ntems and neural recording systems have contributed \nmuch to capture the true essence of consumer prefer-\nences. This section will discuss the marketing stimuli, \ntheir targeted brain regions, neural and physiological \nsignal capturing technologies used over the last 5 years \nin Neuromarketing research. Comparing these signals \nwith their associated anatomical functionality some stud-\nies have already reached high accuracy. A number of the \nselected studies have used machine learning techniques \nto predict like/dislike and possible preference from the \ntest subjects.\n\nFor the purpose of Neuromarketing experiments, the \nfollowing literatures selected right-handed participants, \nwith normal or corrected-to-normal vision, free of cen-\ntral nervous system influencing medications and with no \nhistory of neuropathology.\n\n3.1  Marketing stimuli used in Neuromarketing\nAs Neuromarketing is a focus of marketers and consumer \nbehavior researchers, different strategies from market-\ning have been applied in Neuromarketing and they are \nbeing investigated for quantitative assessment from neu-\nrological data. Nemorin et al. asserts that Neuromarket-\ning differentiates from any other marketing models as \nit bypasses the thinking procedures of consumers and \ndirectly enters their brain [74]. Over the last 5  years, \nNeuromarketing stimuli has been mainly in two forms—\nproducts with/without price, and promotions. Product \ncan be defined as physical object or service that meets \nthe consumer demand. In Neuromarketing, product can \nbe physical such as tasting a beverage to conceptual like \na 3D (three dimensional) image of the product. Price in \nNeuromarketing experiments is mostly seen as a stimuli \nis most of the time intermingled with product or pro-\nmotion. However, it plays an important role that deter-\nmines the decision of test subjects to buy or not to buy \nthe product [75].\n\nConsumer response to a product has been recognized \nby either physically experiencing the product or by visu-\nalizing the image of  it. To understand the user esthetics \nof 3D shapes, Chew et  al. [17], used virtual 3D bracelet \nshapes in motion and recorded the brain response of \ntest subjects with EEG with motion. As 3D visualiza-\ntion of objects for preference recognition is a new area \n\nof research, the authors used mathematical model (Gie-\nlis superformula) to create 3D bracelet-like objects. \nTheir study displayed 3D shapes appear like bracelets as \nthe product to subjects. Using the 3D shapes gave the \nauthors an advantage to produce as many of 60 bracelet \nshapes to conduct the research on. Another new prod-\nuct was the E-commerce products presented to the test \nsubjects by Yadava et al. and Çakar et al. [18, 34]. Yadava \net  al. proposed a predictive modeling framework to \nunderstand consumer choice towards E-commerce prod-\nucts in terms of “likes” and “dislikes” by analyzing EEG \nsignals. In showing E-commerce product, they showed a \ntotal of 42 product images to the test participants. These \nproduct images were mainly of apparels and accessory \nitems such as shirts, sweaters, shoes, school bags, wrist \nwatches, etc. The test participants were asked to disclose \ntheir preference in terms of likes and dislikes after view-\ning the items  [18]. Çakar et  al. used both product and \nprice to explore the experience during product search of \nfirst-time buyers in E-commerce. To motivate the partici-\npants, this research provided each participants around \n73 USD as a gift card to use during the experiment. The \ntest participants were asked to search and select three \nproducts of their interest from an e-commerce website \nand reach the maximum of their gift card limit to acti-\nvate. Test subjects often experienced negative emotion \nwhile being unable to find necessary buttons such as “add \nto cart” or “sorting options” [34]. These Neuromarketing \nexperiments on E-commerce products may help develop-\ners to build better user experience. Retail businesses lose \nlarge amount of money when they invest in the wrong \nproduct. Among retail products, shoes have thousands \nof blueprints for manufacturing. Producing thousands \nof shoes of different designs to satisfy consumers can be \nlaborious and unprofitable since a large number of the \ndesigns turn out to be failures. Baldo et al. directly used \n30 existing image of shoe designs to show the test sub-\njects to and to choose from a mock shop showing on the \nscreen [39]. EEG signals were recorded during the whole \nshoe selection time and then subjects were asked to rate \nthe shoes in a rank of 1 to 5 of Likert scale. This experi-\nment helped realize brain response-based prediction can \nsupersede self-report-based methods, as the simulation \non sales data showed 12.1% profit growth for survey-\nbased prediction, and 36.4% profit growth for the brain \nresponse-based prediction.\n\nSimilar to the shoe experiment, Touchette and Lee [21] \nexperimented on the choice of apparel products among \nyoung adults, based on Davidson’s frontal asymmetry \ntheory. EEG signals were recorded while 34 college stu-\ndents viewed three attractive and three unattractive \napparel products on a high-resolution computer screen \nin a random order. Pozharliev et  al. [20] experimented \n\n\n\nPage 6 of 19Rawnaque et al. Brain Inf.            (2020) 7:10 \n\non the emotion associated with visualizing luxury brand \nproducts vs. regular brand products. The experiment dis-\nplayed 60 luxury items and 60 basic brand items to 40 \nfemale undergraduate students to recognize the brain \nresponse of seeing high emotional value (luxury) prod-\nucts in social vs. alone atmosphere. The study found \nthat, luxury brand products invoked a higher emotional \nvalue in social atmosphere which could be utilized by the \nmarketers. Bosshard et al. and Fehse et al. experimented \non brand images and the comparison between the brain \nresponses associated with preferred and not preferred \nbrands [32, 33]. In the study performed by Bosshard et al., \nconsumer attitude towards established brand names were \nmeasured via electroencephalography. Subjects were \nshown 120 brand names in capital white letter in Tahoma \nfont on black background and without any logo while \ntheir brain responses were recorded. On the other hand, \nFehse et al. compared the brain response of test subjects \nwhile they visualized blocks of popular vs. organic food \nbrand logos. These experiments on brand image may help \nmarketers to recognize the implicit response of consum-\ners on different types of branding.\n\nAs price is mentioned as an important factor that \ndetermines the user’s interest on purchasing a product, \na number of Neuromarketing studies have used price \nalongside the products. In the aforementioned study \nby Çakar et  al. [34] price was displayed while recording \nbrain response during first-time e-commerce user expe-\nrience. Marques et al. [22], Çakir et al. [24], Gong et al. \n[35], Pilelienė and Grigaliūnaitė [36], Hsu and Chen [26], \nBoccia et al. [37], Venkatraman et al. [38], and Baldo et al. \n[39] have included price as a marketing stimuli with the \nproduct or promotional.\n\nAn interesting concept was tried by Boccia et  al. to \nrecognize the relation between corporate social respon-\nsibilities and consumer behavior. The author attempted \nto identify if consumers were willing to pay more for the \nproducts from socially or environmentally responsible \ncompany. Consumers were found to prefer the conven-\ntional companies over the socially responsible companies \ndue to lesser price. Marques et  al. [22] investigated the \ninfluence of price to compare national brand vs. own-\nlabeled branded products. In the experiment of Çakir \net  al, product then product and price were shown to \nthe subjects before decision-making time and the brain \nresponses were recorded through fNIRS [24]. Sometimes \nprice can play a passive role in the form of discounts or \ngifts in a promotional. Gong et al. innovatively designed \nan experiment to compare consumer brain response \nassociated with promotional using discount (25% off) vs. \ngift-giving (gift value equivalent to the discount) mar-\nketing strategies. Their study found that lower degree of \nambiguity (e.g., discounts) better motivates consumer \n\ndecision-making [35]. Hsu and Chen used price as a con-\ntrol variable in their wine tasting experiment. As price \nplays a pivotal role in purchase decision, two wines were \nselected of approximately equal price $15. Then the EEG \nsignals of test subjects were recorded during the wine \ntasting session [26].\n\nPromotion is the communication from the marketers’ \nend to influence the purchase decision of consumers [75]. \nIn Neuromarketing research, promotion is usually found \nas the TV commercials and short movies for advertise-\nment. One of the key focus of Neuromarketers is to \nevaluate the consumer engagement of advertisements. \nPredicting the engagement of advertisements before \nbroadcasting them on air, ensures higher rate of success-\nful promotions.\n\nIn 2015, Yang et al. used six smartphone commercials \nof different brands to compare among them in terms \nof extract cognitive neurophysiological indices such as \nhappiness, surprise, and attention as well as behavio-\nral indices (memory rate, preference, etc.) [41]. A com-\nmon experimental design procedure is found among the \npromotion-based Neuromarketing experiments, that is \nsubjects are first made comfortable in the experimental \nsetting, consecutive advertisements were placed at a time \ndistance no shorter than 10 s and consecutive advertise-\nments used neutral stimuli such as white screen, green \nscenario, blank in between them to stabilize the test \nparticipants.\n\nThe Neuromarketing experiments of Soria Morillo \net  al. [40, 43] tried to find out the electrical activity of \naudience brain while viewing advertisement relevant to \naudiences’ taste. They display used 14 TV commercials \ndisplayed to their 10 test subjects for their experiment \nand predicted like or dislike response from audience \nwith the help of advanced algorithms. Cherubino et  al. \n[42] investigated cognitive and emotional changes of \ncerebral activity during the observation of TV commer-\ncials among different aged population. Among seven TV \ncommercials displayed during the experiment, one com-\nmercial with strong images was analyzed for the adults’ \nand older adults’ reaction. Other than them, Vasiljević \net  al. [44] used Nestle advertisement to measure con-\nsumer attention though pulse analysis; Daugherty et  al. \n[46] replicated an experiment of Krugman (1971) using \nboth TV advertisements and print media advertise-\nments to recognize how consumers look and think; Royo \net  al. [47] focused on consumer response while viewing \nadvertisements of sustainable product designs. For their \nexperiment, an animated commercial was made contain-\ning verbal narrative of sustainable product and an exist-\ning commercial was used to convey the visual narrative \nof conventional product. Venkatraman  et al. focused \non measuring the success of TV advertisements using \n\n\n\nPage 7 of 19Rawnaque et al. Brain Inf.            (2020) 7:10  \n\nneuroimaging and biometric data  [38]. Randolph and \nPierquet [51] showed super bowl commercials to under-\ngraduate students to compare the class rank of the com-\nmercials and the neural response from the test subjects. \nNomura and Mitsukura [52] identified emotional states \nof audiences while watching favorable vs. unfavorable TV \ncommercials. They selected 100 TV commercials among \nwhich 50 commercials were award winning which were \nlabeled as favorable advertisements. Singh et al. [56] used \npromotion in the form of static vs. video advertisements \nto predict the success of omnichannel marketing strate-\ngies. Ungureanu et al. [53] measured user attention and \narousal by eye tracking while surfing through web page \ncontaining static advertisements, while Goyal and Singh \n[54] utilized facial biometric sensors to model an auto-\nmated review systems for video advertisements. Oon \net al. [55] used merchandise product advertisement clips \nto recognize user preference. Singh et al. [56] used video \nadvertisements to measure visual attentions of audiences.\n\nMost of the TVC (television commercials) in these lit-\neratures had a standard time of 30 s. In Neuromarketing, \nthese TVCs were displayed in between other videos such \nas documentary film, gaming video, drama, etc., to cap-\nture the true response of consumers.\n\nSometimes Neuromarketing  is observed dealing with \nadvertisement of different purposes, such as social adver-\ntisements or gender-related advertisements. The appli-\ncation of Neuromarketing in social advertisement is to \npredict the success of these ads to reach its messages to \nthe targeted social groups [45, 49, 69]. Chen et  al. [49] \nexperimented on the neural response of adolescent audi-\nences while they are exposed to e-cigarette commercials. \nAnother social advertisement stimuli of smoking cessa-\ntion frames was used by Yang [45], to understand what \ntypes of frames (positive/negative) achieve better atten-\ntion from smokers and non-smokers. Gender plays a \nsubstantial role in advertisement industry from celebrity \nendorsement to gender-targeted marketing. Missaglia \net  al. [69] conducted a research o",
      "text": [
        "36.0 a 6.0 10.0 4.0 22.0 10.0 Hz 1 20 10 10 -20 -30 -40 Power 10*log . 0(/V/Hz) -50 -60 5 10 15 20 25 30 35 40 45 50 Frequency (Hz) a (a) ----- Servicntermin-Buchung & . -- - 1 (b) 3 Intensity of the view: low high b C",
        "Published online: 21 September 2020"
      ],
      "layoutText": [
        "{\"language\":\"en\",\"text\":\"36.0 a 6.0 10.0 4.0 22.0 10.0 Hz 1 20 10 10 -20 -30 -40 Power 10*log . 0(/V/Hz) -50 -60 5 10 15 20 25 30 35 40 45 50 Frequency (Hz) a (a) ----- Servicntermin-Buchung & . -- - 1 (b) 3 Intensity of the view: low high b C\",\"lines\":[{\"boundingBox\":[{\"x\":1397,\"y\":0},{\"x\":1432,\"y\":3},{\"x\":1431,\"y\":25},{\"x\":1396,\"y\":21}],\"text\":\"36.0\"},{\"boundingBox\":[{\"x\":25,\"y\":4},{\"x\":60,\"y\":5},{\"x\":58,\"y\":37},{\"x\":25,\"y\":36}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":200,\"y\":4},{\"x\":224,\"y\":4},{\"x\":223,\"y\":23},{\"x\":200,\"y\":23}],\"text\":\"6.0\"},{\"boundingBox\":[{\"x\":500,\"y\":0},{\"x\":532,\"y\":3},{\"x\":532,\"y\":22},{\"x\":501,\"y\":19}],\"text\":\"10.0\"},{\"boundingBox\":[{\"x\":805,\"y\":1},{\"x\":833,\"y\":4},{\"x\":832,\"y\":22},{\"x\":804,\"y\":21}],\"text\":\"4.0\"},{\"boundingBox\":[{\"x\":1098,\"y\":2},{\"x\":1127,\"y\":2},{\"x\":1128,\"y\":25},{\"x\":1099,\"y\":25}],\"text\":\"22.0\"},{\"boundingBox\":[{\"x\":1688,\"y\":0},{\"x\":1749,\"y\":2},{\"x\":1749,\"y\":21},{\"x\":1688,\"y\":19}],\"text\":\"10.0 Hz\"},{\"boundingBox\":[{\"x\":137,\"y\":342},{\"x\":137,\"y\":404},{\"x\":92,\"y\":401},{\"x\":92,\"y\":340}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":62,\"y\":345},{\"x\":90,\"y\":345},{\"x\":88,\"y\":376},{\"x\":62,\"y\":375}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":58,\"y\":409},{\"x\":92,\"y\":412},{\"x\":92,\"y\":441},{\"x\":59,\"y\":438}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":61,\"y\":533},{\"x\":98,\"y\":535},{\"x\":93,\"y\":564},{\"x\":59,\"y\":561}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":58,\"y\":594},{\"x\":91,\"y\":597},{\"x\":87,\"y\":625},{\"x\":56,\"y\":623}],\"text\":\"-20\"},{\"boundingBox\":[{\"x\":55,\"y\":657},{\"x\":95,\"y\":656},{\"x\":90,\"y\":686},{\"x\":52,\"y\":686}],\"text\":\"-30\"},{\"boundingBox\":[{\"x\":56,\"y\":721},{\"x\":94,\"y\":721},{\"x\":91,\"y\":746},{\"x\":54,\"y\":745}],\"text\":\"-40\"},{\"boundingBox\":[{\"x\":5,\"y\":775},{\"x\":5,\"y\":491},{\"x\":40,\"y\":491},{\"x\":38,\"y\":775}],\"text\":\"Power 10*log . 0(/V/Hz)\"},{\"boundingBox\":[{\"x\":56,\"y\":779},{\"x\":96,\"y\":780},{\"x\":93,\"y\":812},{\"x\":53,\"y\":811}],\"text\":\"-50\"},{\"boundingBox\":[{\"x\":58,\"y\":839},{\"x\":93,\"y\":839},{\"x\":89,\"y\":866},{\"x\":54,\"y\":866}],\"text\":\"-60\"},{\"boundingBox\":[{\"x\":199,\"y\":919},{\"x\":221,\"y\":918},{\"x\":219,\"y\":945},{\"x\":199,\"y\":947}],\"text\":\"5\"},{\"boundingBox\":[{\"x\":375,\"y\":918},{\"x\":407,\"y\":917},{\"x\":407,\"y\":945},{\"x\":377,\"y\":945}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":553,\"y\":919},{\"x\":585,\"y\":918},{\"x\":586,\"y\":946},{\"x\":555,\"y\":948}],\"text\":\"15\"},{\"boundingBox\":[{\"x\":732,\"y\":917},{\"x\":766,\"y\":917},{\"x\":765,\"y\":945},{\"x\":731,\"y\":945}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":912,\"y\":916},{\"x\":949,\"y\":917},{\"x\":946,\"y\":945},{\"x\":910,\"y\":945}],\"text\":\"25\"},{\"boundingBox\":[{\"x\":1092,\"y\":918},{\"x\":1126,\"y\":919},{\"x\":1125,\"y\":945},{\"x\":1092,\"y\":944}],\"text\":\"30\"},{\"boundingBox\":[{\"x\":1269,\"y\":916},{\"x\":1304,\"y\":915},{\"x\":1303,\"y\":943},{\"x\":1269,\"y\":944}],\"text\":\"35\"},{\"boundingBox\":[{\"x\":1450,\"y\":917},{\"x\":1487,\"y\":918},{\"x\":1487,\"y\":943},{\"x\":1451,\"y\":943}],\"text\":\"40\"},{\"boundingBox\":[{\"x\":1632,\"y\":918},{\"x\":1668,\"y\":918},{\"x\":1667,\"y\":944},{\"x\":1632,\"y\":942}],\"text\":\"45\"},{\"boundingBox\":[{\"x\":1811,\"y\":920},{\"x\":1842,\"y\":920},{\"x\":1842,\"y\":941},{\"x\":1811,\"y\":942}],\"text\":\"50\"},{\"boundingBox\":[{\"x\":842,\"y\":947},{\"x\":1031,\"y\":946},{\"x\":1031,\"y\":971},{\"x\":842,\"y\":972}],\"text\":\"Frequency (Hz)\"},{\"boundingBox\":[{\"x\":916,\"y\":1017},{\"x\":956,\"y\":1017},{\"x\":956,\"y\":1056},{\"x\":918,\"y\":1057}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":129,\"y\":1137},{\"x\":154,\"y\":1137},{\"x\":153,\"y\":1159},{\"x\":129,\"y\":1160}],\"text\":\"(a)\"},{\"boundingBox\":[{\"x\":989,\"y\":1147},{\"x\":1085,\"y\":1148},{\"x\":1085,\"y\":1159},{\"x\":989,\"y\":1158}],\"text\":\"-----\"},{\"boundingBox\":[{\"x\":1077,\"y\":1221},{\"x\":1261,\"y\":1225},{\"x\":1261,\"y\":1246},{\"x\":1077,\"y\":1242}],\"text\":\"Servicntermin-Buchung\"},{\"boundingBox\":[{\"x\":818,\"y\":1258},{\"x\":834,\"y\":1257},{\"x\":833,\"y\":1278},{\"x\":818,\"y\":1280}],\"text\":\"&\"},{\"boundingBox\":[{\"x\":1082,\"y\":1260},{\"x\":1099,\"y\":1260},{\"x\":1097,\"y\":1273},{\"x\":1081,\"y\":1274}],\"text\":\".\"},{\"boundingBox\":[{\"x\":1480,\"y\":1263},{\"x\":1526,\"y\":1264},{\"x\":1526,\"y\":1271},{\"x\":1480,\"y\":1269}],\"text\":\"--\"},{\"boundingBox\":[{\"x\":1613,\"y\":1261},{\"x\":1667,\"y\":1261},{\"x\":1667,\"y\":1276},{\"x\":1613,\"y\":1275}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":825,\"y\":1428},{\"x\":838,\"y\":1430},{\"x\":837,\"y\":1446},{\"x\":825,\"y\":1445}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":132,\"y\":1450},{\"x\":155,\"y\":1451},{\"x\":153,\"y\":1473},{\"x\":132,\"y\":1473}],\"text\":\"(b)\"},{\"boundingBox\":[{\"x\":818,\"y\":1633},{\"x\":832,\"y\":1631},{\"x\":832,\"y\":1647},{\"x\":818,\"y\":1649}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":1093,\"y\":1681},{\"x\":1491,\"y\":1681},{\"x\":1491,\"y\":1720},{\"x\":1093,\"y\":1720}],\"text\":\"Intensity of the view: low\"},{\"boundingBox\":[{\"x\":1605,\"y\":1680},{\"x\":1678,\"y\":1680},{\"x\":1678,\"y\":1719},{\"x\":1605,\"y\":1718}],\"text\":\"high\"},{\"boundingBox\":[{\"x\":399,\"y\":1758},{\"x\":443,\"y\":1761},{\"x\":440,\"y\":1813},{\"x\":397,\"y\":1809}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":1388,\"y\":1767},{\"x\":1431,\"y\":1768},{\"x\":1429,\"y\":1808},{\"x\":1388,\"y\":1807}],\"text\":\"C\"}],\"words\":[{\"boundingBox\":[{\"x\":1397,\"y\":0},{\"x\":1432,\"y\":3},{\"x\":1430,\"y\":25},{\"x\":1396,\"y\":21}],\"text\":\"36.0\"},{\"boundingBox\":[{\"x\":27,\"y\":4},{\"x\":45,\"y\":5},{\"x\":44,\"y\":37},{\"x\":26,\"y\":36}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":200,\"y\":4},{\"x\":223,\"y\":4},{\"x\":223,\"y\":23},{\"x\":200,\"y\":23}],\"text\":\"6.0\"},{\"boundingBox\":[{\"x\":500,\"y\":0},{\"x\":533,\"y\":3},{\"x\":531,\"y\":22},{\"x\":500,\"y\":19}],\"text\":\"10.0\"},{\"boundingBox\":[{\"x\":807,\"y\":1},{\"x\":833,\"y\":3},{\"x\":831,\"y\":23},{\"x\":806,\"y\":21}],\"text\":\"4.0\"},{\"boundingBox\":[{\"x\":1098,\"y\":2},{\"x\":1127,\"y\":2},{\"x\":1127,\"y\":25},{\"x\":1098,\"y\":25}],\"text\":\"22.0\"},{\"boundingBox\":[{\"x\":1688,\"y\":1},{\"x\":1717,\"y\":2},{\"x\":1717,\"y\":21},{\"x\":1688,\"y\":20}],\"text\":\"10.0\"},{\"boundingBox\":[{\"x\":1723,\"y\":2},{\"x\":1749,\"y\":3},{\"x\":1749,\"y\":21},{\"x\":1723,\"y\":21}],\"text\":\"Hz\"},{\"boundingBox\":[{\"x\":137,\"y\":347},{\"x\":137,\"y\":376},{\"x\":92,\"y\":376},{\"x\":92,\"y\":347}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":62,\"y\":345},{\"x\":89,\"y\":345},{\"x\":88,\"y\":376},{\"x\":62,\"y\":375}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":61,\"y\":409},{\"x\":90,\"y\":412},{\"x\":87,\"y\":441},{\"x\":59,\"y\":438}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":64,\"y\":533},{\"x\":91,\"y\":534},{\"x\":89,\"y\":563},{\"x\":62,\"y\":561}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":58,\"y\":594},{\"x\":91,\"y\":596},{\"x\":89,\"y\":625},{\"x\":56,\"y\":622}],\"text\":\"-20\"},{\"boundingBox\":[{\"x\":52,\"y\":656},{\"x\":91,\"y\":656},{\"x\":91,\"y\":686},{\"x\":52,\"y\":686}],\"text\":\"-30\"},{\"boundingBox\":[{\"x\":54,\"y\":721},{\"x\":90,\"y\":721},{\"x\":89,\"y\":746},{\"x\":54,\"y\":745}],\"text\":\"-40\"},{\"boundingBox\":[{\"x\":8,\"y\":775},{\"x\":9,\"y\":702},{\"x\":37,\"y\":701},{\"x\":33,\"y\":775}],\"text\":\"Power\"},{\"boundingBox\":[{\"x\":9,\"y\":695},{\"x\":9,\"y\":631},{\"x\":39,\"y\":630},{\"x\":37,\"y\":695}],\"text\":\"10*log\"},{\"boundingBox\":[{\"x\":8,\"y\":625},{\"x\":8,\"y\":621},{\"x\":39,\"y\":620},{\"x\":39,\"y\":624}],\"text\":\".\"},{\"boundingBox\":[{\"x\":8,\"y\":615},{\"x\":5,\"y\":496},{\"x\":39,\"y\":495},{\"x\":39,\"y\":614}],\"text\":\"0(/V/Hz)\"},{\"boundingBox\":[{\"x\":53,\"y\":779},{\"x\":92,\"y\":780},{\"x\":92,\"y\":812},{\"x\":53,\"y\":811}],\"text\":\"-50\"},{\"boundingBox\":[{\"x\":54,\"y\":839},{\"x\":89,\"y\":839},{\"x\":89,\"y\":866},{\"x\":54,\"y\":866}],\"text\":\"-60\"},{\"boundingBox\":[{\"x\":199,\"y\":919},{\"x\":214,\"y\":918},{\"x\":216,\"y\":945},{\"x\":200,\"y\":946}],\"text\":\"5\"},{\"boundingBox\":[{\"x\":375,\"y\":917},{\"x\":402,\"y\":917},{\"x\":402,\"y\":945},{\"x\":375,\"y\":945}],\"text\":\"10\"},{\"boundingBox\":[{\"x\":554,\"y\":919},{\"x\":581,\"y\":918},{\"x\":582,\"y\":947},{\"x\":555,\"y\":948}],\"text\":\"15\"},{\"boundingBox\":[{\"x\":734,\"y\":917},{\"x\":764,\"y\":917},{\"x\":764,\"y\":945},{\"x\":734,\"y\":945}],\"text\":\"20\"},{\"boundingBox\":[{\"x\":913,\"y\":916},{\"x\":944,\"y\":916},{\"x\":943,\"y\":945},{\"x\":913,\"y\":944}],\"text\":\"25\"},{\"boundingBox\":[{\"x\":1095,\"y\":918},{\"x\":1122,\"y\":919},{\"x\":1122,\"y\":945},{\"x\":1094,\"y\":944}],\"text\":\"30\"},{\"boundingBox\":[{\"x\":1271,\"y\":916},{\"x\":1301,\"y\":915},{\"x\":1302,\"y\":943},{\"x\":1272,\"y\":944}],\"text\":\"35\"},{\"boundingBox\":[{\"x\":1451,\"y\":917},{\"x\":1480,\"y\":917},{\"x\":1480,\"y\":943},{\"x\":1451,\"y\":942}],\"text\":\"40\"},{\"boundingBox\":[{\"x\":1633,\"y\":918},{\"x\":1662,\"y\":918},{\"x\":1662,\"y\":944},{\"x\":1633,\"y\":943}],\"text\":\"45\"},{\"boundingBox\":[{\"x\":1812,\"y\":920},{\"x\":1839,\"y\":920},{\"x\":1840,\"y\":942},{\"x\":1812,\"y\":942}],\"text\":\"50\"},{\"boundingBox\":[{\"x\":844,\"y\":947},{\"x\":970,\"y\":947},{\"x\":970,\"y\":972},{\"x\":844,\"y\":972}],\"text\":\"Frequency\"},{\"boundingBox\":[{\"x\":975,\"y\":947},{\"x\":1031,\"y\":946},{\"x\":1031,\"y\":972},{\"x\":976,\"y\":972}],\"text\":\"(Hz)\"},{\"boundingBox\":[{\"x\":917,\"y\":1017},{\"x\":943,\"y\":1017},{\"x\":944,\"y\":1057},{\"x\":918,\"y\":1057}],\"text\":\"a\"},{\"boundingBox\":[{\"x\":129,\"y\":1137},{\"x\":153,\"y\":1137},{\"x\":153,\"y\":1159},{\"x\":129,\"y\":1160}],\"text\":\"(a)\"},{\"boundingBox\":[{\"x\":990,\"y\":1148},{\"x\":1071,\"y\":1148},{\"x\":1070,\"y\":1159},{\"x\":989,\"y\":1157}],\"text\":\"-----\"},{\"boundingBox\":[{\"x\":1077,\"y\":1221},{\"x\":1262,\"y\":1225},{\"x\":1261,\"y\":1246},{\"x\":1077,\"y\":1243}],\"text\":\"Servicntermin-Buchung\"},{\"boundingBox\":[{\"x\":818,\"y\":1258},{\"x\":828,\"y\":1257},{\"x\":830,\"y\":1278},{\"x\":818,\"y\":1279}],\"text\":\"&\"},{\"boundingBox\":[{\"x\":1082,\"y\":1260},{\"x\":1090,\"y\":1260},{\"x\":1091,\"y\":1274},{\"x\":1083,\"y\":1274}],\"text\":\".\"},{\"boundingBox\":[{\"x\":1481,\"y\":1263},{\"x\":1508,\"y\":1264},{\"x\":1508,\"y\":1270},{\"x\":1481,\"y\":1270}],\"text\":\"--\"},{\"boundingBox\":[{\"x\":1636,\"y\":1262},{\"x\":1644,\"y\":1262},{\"x\":1643,\"y\":1276},{\"x\":1636,\"y\":1275}],\"text\":\"-\"},{\"boundingBox\":[{\"x\":827,\"y\":1428},{\"x\":837,\"y\":1429},{\"x\":835,\"y\":1446},{\"x\":825,\"y\":1444}],\"text\":\"1\"},{\"boundingBox\":[{\"x\":132,\"y\":1450},{\"x\":155,\"y\":1450},{\"x\":154,\"y\":1473},{\"x\":132,\"y\":1472}],\"text\":\"(b)\"},{\"boundingBox\":[{\"x\":818,\"y\":1633},{\"x\":827,\"y\":1632},{\"x\":829,\"y\":1647},{\"x\":820,\"y\":1648}],\"text\":\"3\"},{\"boundingBox\":[{\"x\":1095,\"y\":1682},{\"x\":1223,\"y\":1683},{\"x\":1222,\"y\":1721},{\"x\":1094,\"y\":1721}],\"text\":\"Intensity\"},{\"boundingBox\":[{\"x\":1231,\"y\":1683},{\"x\":1263,\"y\":1683},{\"x\":1261,\"y\":1721},{\"x\":1229,\"y\":1721}],\"text\":\"of\"},{\"boundingBox\":[{\"x\":1270,\"y\":1683},{\"x\":1325,\"y\":1684},{\"x\":1323,\"y\":1721},{\"x\":1269,\"y\":1721}],\"text\":\"the\"},{\"boundingBox\":[{\"x\":1332,\"y\":1684},{\"x\":1419,\"y\":1684},{\"x\":1417,\"y\":1721},{\"x\":1330,\"y\":1721}],\"text\":\"view:\"},{\"boundingBox\":[{\"x\":1426,\"y\":1684},{\"x\":1477,\"y\":1684},{\"x\":1476,\"y\":1721},{\"x\":1424,\"y\":1721}],\"text\":\"low\"},{\"boundingBox\":[{\"x\":1607,\"y\":1680},{\"x\":1676,\"y\":1680},{\"x\":1676,\"y\":1719},{\"x\":1607,\"y\":1719}],\"text\":\"high\"},{\"boundingBox\":[{\"x\":399,\"y\":1758},{\"x\":428,\"y\":1760},{\"x\":424,\"y\":1812},{\"x\":397,\"y\":1809}],\"text\":\"b\"},{\"boundingBox\":[{\"x\":1388,\"y\":1767},{\"x\":1411,\"y\":1767},{\"x\":1410,\"y\":1807},{\"x\":1388,\"y\":1807}],\"text\":\"C\"}]}",
        "{\"language\":\"en\",\"text\":\"Published online: 21 September 2020\",\"lines\":[{\"boundingBox\":[{\"x\":4,\"y\":15},{\"x\":1066,\"y\":15},{\"x\":1066,\"y\":74},{\"x\":4,\"y\":72}],\"text\":\"Published online: 21 September 2020\"}],\"words\":[{\"boundingBox\":[{\"x\":5,\"y\":16},{\"x\":270,\"y\":15},{\"x\":271,\"y\":72},{\"x\":6,\"y\":68}],\"text\":\"Published\"},{\"boundingBox\":[{\"x\":290,\"y\":15},{\"x\":494,\"y\":15},{\"x\":494,\"y\":74},{\"x\":291,\"y\":73}],\"text\":\"online:\"},{\"boundingBox\":[{\"x\":505,\"y\":15},{\"x\":579,\"y\":15},{\"x\":579,\"y\":74},{\"x\":505,\"y\":74}],\"text\":\"21\"},{\"boundingBox\":[{\"x\":595,\"y\":15},{\"x\":907,\"y\":16},{\"x\":906,\"y\":73},{\"x\":594,\"y\":74}],\"text\":\"September\"},{\"boundingBox\":[{\"x\":918,\"y\":16},{\"x\":1058,\"y\":16},{\"x\":1057,\"y\":71},{\"x\":917,\"y\":73}],\"text\":\"2020\"}]}"
      ]
    }
  ]
}